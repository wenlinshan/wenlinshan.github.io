<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ClickHouse 中的常用聚合函数(十一)</title>
    <url>/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0(%E5%8D%81%E4%B8%80)/</url>
    <content><![CDATA[<h1 id="ClickHouse-中的常用聚合函数-十一"><a href="#ClickHouse-中的常用聚合函数-十一" class="headerlink" title="ClickHouse 中的常用聚合函数(十一)"></a>ClickHouse 中的常用聚合函数(十一)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>这次来说一下 ClickHouse 中的聚合函数，因为和关系型数据库的相似性，本来聚合函数不打算说的，但是 ClickHouse 提供了很多关系型数据库中没有的函数，所以我们还是从头了解一下。</strong></p>
<p><strong>count：计算数据的行数，有以下几种方式：</strong></p>
<ul>
<li><code>count(字段)：计算该字段中不为 Null 的元素数量</code></li>
<li><code>count()、count(*)：计算数据集的总行数</code></li>
</ul>
<p><strong>所有如果某个字段中不包含 Null，那么对该字段进行 count 得到的结果和 count()、count(*) 是相等的。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(), <span class="built_in">count</span>(<span class="operator">*</span>), <span class="built_in">count</span>(product) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─count()─┬─count()─┬─count(product)─┐</span></span><br><span class="line"><span class="comment">│    1349 │    1349 │           1349 │</span></span><br><span class="line"><span class="comment">└─────────┴─────────┴────────────────┘</span></span><br></pre></td></tr></table></figure>

<p><strong>这里再提一下聚合函数，聚合函数针对的是多行结果集，而不是数组。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 这里得到的是 1，原因在于这里只有一行数据</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─count()─┐</span></span><br><span class="line"><span class="comment">│       1 │</span></span><br><span class="line"><span class="comment">└─────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 如果将其展开的话，那么会得到 3，因为展开之后变成了 3 行数据</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(arrayJoin([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─count(arrayJoin([1, 2, 3]))─┐</span></span><br><span class="line"><span class="comment">│                           3 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>当然使用 count 计算某个字段的元素数量时，还可以进行去重。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="keyword">DISTINCT</span> product) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─uniqExact(product)─┐</span></span><br><span class="line"><span class="comment">│                  3 │</span></span><br><span class="line"><span class="comment">└────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 根据返回的字段名，我们发现 ClickHouse 在底层实际上调用的是 uniqExact 函数</span></span><br><span class="line"><span class="keyword">SELECT</span> uniqExact(product) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─uniqExact(product)─┐</span></span><br><span class="line"><span class="comment">│                  3 │</span></span><br><span class="line"><span class="comment">└────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">-- 也就是 count(DISTINCT) 等价于 uniqExact</span></span><br><span class="line"><span class="comment">-- 不过还是建议像关系型数据库那样使用 count(DISTINCT) 比较好，因为更加习惯</span></span><br></pre></td></tr></table></figure>

<p><strong>min、max、sum、avg：计算每组数据的最小值、最大值、总和、平均值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">min</span>(amount), <span class="built_in">max</span>(amount), <span class="built_in">sum</span>(amount), <span class="built_in">avg</span>(amount) </span><br><span class="line"><span class="keyword">FROM</span> sales_data <span class="keyword">GROUP</span> <span class="keyword">BY</span> product, channel;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─min(amount)─┬─max(amount)─┬─sum(amount)─┬────────avg(amount)─┐</span></span><br><span class="line"><span class="comment">│         547 │        2788 │      248175 │ 1643.5430463576158 │</span></span><br><span class="line"><span class="comment">│         658 │        2805 │      252148 │ 1669.8543046357615 │</span></span><br><span class="line"><span class="comment">│         613 │        2803 │      246198 │ 1652.3355704697988 │</span></span><br><span class="line"><span class="comment">│         709 │        2870 │      256602 │ 1699.3509933774835 │</span></span><br><span class="line"><span class="comment">│         599 │        2869 │      245029 │ 1601.4967320261437 │</span></span><br><span class="line"><span class="comment">│         511 │        2673 │      252908 │ 1686.0533333333333 │</span></span><br><span class="line"><span class="comment">│         564 │        2710 │      252057 │ 1714.6734693877552 │</span></span><br><span class="line"><span class="comment">│         621 │        2832 │      251795 │ 1701.3175675675675 │</span></span><br><span class="line"><span class="comment">│         642 │        2803 │      245904 │ 1650.3624161073826 │</span></span><br><span class="line"><span class="comment">└─────────────┴─────────────┴─────────────┴────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>除此之外还有两个非聚合函数 least、greatest 也比较实用，那么这两个函数是干什么的呢？看一张图就明白了。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0(%E5%8D%81%E4%B8%80)/1229382-20210905001842525-447267760.png" alt="img"></p>
<p><strong>我们可以测试一下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> least(A, B), greatest(A, B) <span class="keyword">FROM</span> test_1;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─least(A, B)─┬─greatest(A, B)─┐</span></span><br><span class="line"><span class="comment">│          11 │             13 │</span></span><br><span class="line"><span class="comment">│           7 │              8 │</span></span><br><span class="line"><span class="comment">│           5 │              8 │</span></span><br><span class="line"><span class="comment">│          11 │             15 │</span></span><br><span class="line"><span class="comment">│           9 │             13 │</span></span><br><span class="line"><span class="comment">└─────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>问题来了，如果 ClickHouse 没有提供 least 和 greatest 这两个函数，那么我们要如何实现此功能呢？首先我们可以使用 arrayMap：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 由于 arrayMap 针对的是数组，不是多行结果集，所以需要借助 groupArray 将多行结果集转成数组</span></span><br><span class="line"><span class="comment">-- 另外在比较大小的时候也要将两个元素组合成数组 [x, y]，然后使用 arrayMin 比较</span></span><br><span class="line"><span class="comment">-- 或者使用 least(x, y) 也可以对两个标量进行比较，不过这里我们是为了实现 least，所以就不用它了</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(x, y <span class="operator">-</span><span class="operator">&gt;</span> arrayMin([x, y]), groupArray(A), groupArray(B)) arr <span class="keyword">FROM</span> test_1;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arr───────────┐</span></span><br><span class="line"><span class="comment">│ [11,7,5,11,9] │</span></span><br><span class="line"><span class="comment">└───────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 结果确实实现了，但结果是数组，我们还要再将其展开成多行</span></span><br><span class="line"><span class="comment">-- 这里我们使用 WITH，注意 WITH 子句里的查询只可以返回一行结果集</span></span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> arrayMap(x, y <span class="operator">-</span><span class="operator">&gt;</span> arrayMin([x, y]), groupArray(A), groupArray(B)) <span class="keyword">FROM</span> test_1</span><br><span class="line">) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayJoin(arr);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayJoin(arr)─┐</span></span><br><span class="line"><span class="comment">│             11 │</span></span><br><span class="line"><span class="comment">│              7 │</span></span><br><span class="line"><span class="comment">│              5 │</span></span><br><span class="line"><span class="comment">│             11 │</span></span><br><span class="line"><span class="comment">│              9 │</span></span><br><span class="line"><span class="comment">└────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>以上就实现了 least，至于 greatest 也是同理。那么除了使用数组的方式，还可以怎么做呢？如果将这个问题的背景再改成关系型数据库的话，你一定能想到，没错，就是 CASE WHEN。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> A <span class="operator">&lt;</span> B <span class="keyword">THEN</span> A <span class="keyword">ELSE</span> B <span class="keyword">END</span> <span class="keyword">FROM</span> test_1;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─multiIf(less(A, B), A, B)─┐</span></span><br><span class="line"><span class="comment">│                        11 │</span></span><br><span class="line"><span class="comment">│                         7 │</span></span><br><span class="line"><span class="comment">│                         5 │</span></span><br><span class="line"><span class="comment">│                        11 │</span></span><br><span class="line"><span class="comment">│                         9 │</span></span><br><span class="line"><span class="comment">└───────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>整个过程显然变得简单了，所以也不要忘记关系型数据库的语法在 ClickHouse 中也是可以使用的，另外我们看到返回的结果集的字段名叫 multiIf…，虽然我们使用的是 CASE WHEN，但是 ClickHouse 在底层会给语句进行优化，在功能不变的前提下，寻找一个在 ClickHouse 中效率更高的替代方案。因此你直接使用 multiIf… 也是可以的，比如：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT multiIf(less(A, B), A, B) FROM test_1</span><br></pre></td></tr></table></figure>

<p><strong>而至于上面的 multiIf，它的功能和 CASE WHEN 是完全类似的。只不过这里个人有一点建议，既然 ClickHouse 会进行语句的优化，那么能用关系型数据库语法解决的问题，就用关系型数据库语法去解决。这么做的原因主要是为了考虑 SQL 语句的可读性，因为相比 ClickHouse，大部分人对关系型数据库语法显然更熟悉一些。如果使用这里的 mulitIf…，那么当别人阅读时，可能还要查阅一下 multiIf 函数、或者 mulitIf 里面又调用的 less 函数是做什么的；但如果使用 CASE WHEN，绝对的一目了然。</strong></p>
<p><strong>当然以上只是个人的建议，如果你对 ClickHouse 的函数用的非常 6，那么完全可以不优先使用关系型数据库的语法，不然这些函数不是白掌握了吗。</strong></p>
<p><strong>any：选择每组数据中第一个出现的值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 按照 product, channel 进行分组之后，我们可以求每组的最小值、最大值、平均值等等</span></span><br><span class="line"><span class="comment">-- 而这里的 any 则表示获取每组第一个出现的值</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">any</span>(amount) <span class="keyword">FROM</span> sales_data <span class="keyword">GROUP</span> <span class="keyword">BY</span> product, channel;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─any(amount)─┐</span></span><br><span class="line"><span class="comment">│        1864 │</span></span><br><span class="line"><span class="comment">│        1573 │</span></span><br><span class="line"><span class="comment">│         847 │</span></span><br><span class="line"><span class="comment">│        1178 │</span></span><br><span class="line"><span class="comment">│        1736 │</span></span><br><span class="line"><span class="comment">│         511 │</span></span><br><span class="line"><span class="comment">│         568 │</span></span><br><span class="line"><span class="comment">│        1329 │</span></span><br><span class="line"><span class="comment">│        1364 │</span></span><br><span class="line"><span class="comment">└─────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>当然 any 看起来貌似没有实际的意义，因为聚合之后每组第一个出现的值并不一定能代表什么。那么问题来了，如果想选择分组中的任意一个值，该怎么办呢？</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 使用 groupArray 变成一个数组，然后再通过索引选择即可</span></span><br><span class="line"><span class="comment">-- 因为我们选择的是第 1 个元素，所以此时等价于 any</span></span><br><span class="line"><span class="keyword">SELECT</span> groupArray(amount)[<span class="number">1</span>] <span class="keyword">FROM</span> sales_data </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> product, channel;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayElement(groupArray(amount), 1)─┐</span></span><br><span class="line"><span class="comment">│                                1864 │</span></span><br><span class="line"><span class="comment">│                                1573 │</span></span><br><span class="line"><span class="comment">│                                 847 │</span></span><br><span class="line"><span class="comment">│                                1178 │</span></span><br><span class="line"><span class="comment">│                                1736 │</span></span><br><span class="line"><span class="comment">│                                 511 │</span></span><br><span class="line"><span class="comment">│                                 568 │</span></span><br><span class="line"><span class="comment">│                                1329 │</span></span><br><span class="line"><span class="comment">│                                1364 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果想分组之后选择，选择每个组的最小值该怎么做呢？</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 在上面的基础上再调用一下 arrayMin 即可</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayMin(groupArray(amount)) <span class="keyword">FROM</span> sales_data</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> product, channel;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayMin(groupArray(amount))─┐</span></span><br><span class="line"><span class="comment">│                          547 │</span></span><br><span class="line"><span class="comment">│                          658 │</span></span><br><span class="line"><span class="comment">│                          613 │</span></span><br><span class="line"><span class="comment">│                          709 │</span></span><br><span class="line"><span class="comment">│                          599 │</span></span><br><span class="line"><span class="comment">│                          511 │</span></span><br><span class="line"><span class="comment">│                          564 │</span></span><br><span class="line"><span class="comment">│                          621 │</span></span><br><span class="line"><span class="comment">│                          642 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果想分组之后选择，选择每个组的第 N 大的值该怎么做呢？比如我们选择第 3 大的值。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 从小到大排个序即可，然后选择索引为 -3 的元素</span></span><br><span class="line"><span class="comment">-- 或者从大到小排个序，然后选择索引为 3 的元素</span></span><br><span class="line"><span class="keyword">SELECT</span> arraySort(groupArray(amount))[<span class="number">-2</span>] rank3_1, arrayReverseSort(groupArray(amount))[<span class="number">2</span>] rank3_2</span><br><span class="line"><span class="keyword">FROM</span> sales_data <span class="keyword">GROUP</span> <span class="keyword">BY</span> product, channel;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─rank3_1─┬─rank3_2─┐</span></span><br><span class="line"><span class="comment">│    2784 │    2784 │</span></span><br><span class="line"><span class="comment">│    2804 │    2804 │</span></span><br><span class="line"><span class="comment">│    2650 │    2650 │</span></span><br><span class="line"><span class="comment">│    2856 │    2856 │</span></span><br><span class="line"><span class="comment">│    2865 │    2865 │</span></span><br><span class="line"><span class="comment">│    2610 │    2610 │</span></span><br><span class="line"><span class="comment">│    2632 │    2632 │</span></span><br><span class="line"><span class="comment">│    2754 │    2754 │</span></span><br><span class="line"><span class="comment">│    2694 │    2694 │</span></span><br><span class="line"><span class="comment">└─────────┴─────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>确实给人一种 pandas 的感觉，之前做数据分析主要用 pandas。但是 pandas 有一个致命的问题，就是它要求数据能全部加载到内存中，所以在处理中小型数据集的时候确实很方便，但是对于大型数据集就无能为力了，只能另辟蹊径。但是 ClickHouse 则是通过分片机制支持分布式运算，所以个人觉得它简直就是分布式的 pandas。</strong></p>
<p><strong>varPop：计算方差，∑(x−x^)2n∑(�−�^)2�；stddevPop：计算标准差，等于方差开根号</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> varPop(amount) v1, stddevPop(amount) v2, v2 <span class="operator">*</span> v2 </span><br><span class="line"><span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────v1─┬───────v2─┬─multiply(stddevPop(amount), stddevPop(amount))─┐</span></span><br><span class="line"><span class="comment">│ 269907.7 │ 519.5264 │                              269907.7096217908 │</span></span><br><span class="line"><span class="comment">└──────────┴──────────┴────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>问题来了，如果我们想手动实现方差的计算该怎么办？试一下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 将结果集转成数组，并先计算好平均值</span></span><br><span class="line"><span class="keyword">WITH</span> (<span class="keyword">SELECT</span> groupArray(amount) <span class="keyword">FROM</span> sales_data) <span class="keyword">AS</span> arr, </span><br><span class="line">      arraySum(arr) <span class="operator">/</span> length(arr) <span class="keyword">AS</span> amount_avg</span><br><span class="line"><span class="comment">-- 通过 arrayMap 将数组中的每一个元素都和平均值做减法，然后再平方，得到新数组</span></span><br><span class="line"><span class="comment">-- 最后再用 arrayAvg 对新数组取平均值，即可计算出方差</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayAvg(</span><br><span class="line">    arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> pow(x <span class="operator">-</span> amount_avg, <span class="number">2</span>), arr)</span><br><span class="line">) </span><br></pre></td></tr></table></figure>

<p><strong>covarPop：计算协方差，∑(x−x^)(y−y^)n∑(�−�^)(�−�^)�</strong></p>
<p><strong>比较少用，这里不演示的了，可以自己测试一下。</strong></p>
<p><strong>anyHeavy：使用 <a href="http://www.cs.umd.edu/~samir/498/karp.pdf">heavy hitters</a> 算法选择每组中出现频率最高的值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> anyHeavy(amount) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─anyHeavy(amount)─┐</span></span><br><span class="line"><span class="comment">│             2369 │</span></span><br><span class="line"><span class="comment">└──────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>anyLast：选择每组中的最后一个值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> anyLast(amount) <span class="keyword">FROM</span> sales_data <span class="keyword">GROUP</span> <span class="keyword">BY</span> product, channel;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─anyLast(amount)─┐</span></span><br><span class="line"><span class="comment">│            1679 │</span></span><br><span class="line"><span class="comment">│            1767 │</span></span><br><span class="line"><span class="comment">│            2369 │</span></span><br><span class="line"><span class="comment">│            2660 │</span></span><br><span class="line"><span class="comment">│            2865 │</span></span><br><span class="line"><span class="comment">│            2422 │</span></span><br><span class="line"><span class="comment">│            1481 │</span></span><br><span class="line"><span class="comment">│            1439 │</span></span><br><span class="line"><span class="comment">│            2443 │</span></span><br><span class="line"><span class="comment">└─────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 同样可以借助数组实现</span></span><br><span class="line"><span class="keyword">SELECT</span> groupArray(amount)[<span class="number">-1</span>] <span class="keyword">FROM</span> sales_data <span class="keyword">GROUP</span> <span class="keyword">BY</span> product, channel;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayElement(groupArray(amount), -1)─┐</span></span><br><span class="line"><span class="comment">│                                 1679 │</span></span><br><span class="line"><span class="comment">│                                 1767 │</span></span><br><span class="line"><span class="comment">│                                 2369 │</span></span><br><span class="line"><span class="comment">│                                 2660 │</span></span><br><span class="line"><span class="comment">│                                 2865 │</span></span><br><span class="line"><span class="comment">│                                 2422 │</span></span><br><span class="line"><span class="comment">│                                 1481 │</span></span><br><span class="line"><span class="comment">│                                 1439 │</span></span><br><span class="line"><span class="comment">│                                 2443 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>argMin：接收两个列，根据另一个列选择当前列的最小值，我们画一张图，通过和 min 进行比对，就能看出它的用法了</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="keyword">Null</span>] <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> has(arr, <span class="number">2</span>), has(arr, <span class="number">0</span>), has(arr, <span class="keyword">Null</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─has(arr, 2)─┬─has(arr, 0)─┬─has(arr, NULL)─┐</span></span><br><span class="line"><span class="comment">│           1 │           0 │              1 │</span></span><br><span class="line"><span class="comment">└─────────────┴─────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 嵌套数组也是可以的</span></span><br><span class="line"><span class="keyword">SELECT</span> has([[<span class="number">1</span>, <span class="number">2</span>]], [<span class="number">1</span>, <span class="number">2</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─has([[1, 2]], [1, 2])─┐</span></span><br><span class="line"><span class="comment">│                     1 │</span></span><br><span class="line"><span class="comment">└───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0(%E5%8D%81%E4%B8%80)/1229382-20210905001849615-383206319.png" alt="img"></p>
<p><strong>首先 min(A) 和 min(B) 分别返回 5 和 7 无需解释，而 argMin(A, B) 表示根据 B 的最小值选择 A，B 的最小值是 7，对应 A 就是 8；同理 argMin(B, A) 表示根据 A 的最小值选择 B，A 的最小值是 5，对应 B 就是 8。</strong></p>
<p><strong>以上就是 argMin，同理还有 argMax。</strong></p>
<p><strong>topK：选择出现频率最高的 K 个元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 这里选择出现频率最高的两个元素</span></span><br><span class="line"><span class="keyword">SELECT</span> topK(<span class="number">2</span>)(arrayJoin([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─topK(2)(arrayJoin([1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3]))─┐</span></span><br><span class="line"><span class="comment">│ [1,3]                                                    │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们看到以数组的形式返回，因为聚合函数最终每个组只会对应一行数据，所以得到的是数组。</strong></p>
<p><strong>topK 也是非常常见的，如果让我们自己实现，虽然可以做到，但会比较麻烦，ClickHouse 替我们考虑的还是很周到的。</strong></p>
<p><strong>groupArrayMovingSum：滑动窗口，每个窗口内的数据进行累和。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> groupArray(number), groupArrayMovingSum(<span class="number">4</span>)(number)</span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">10</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArray(number)────┬─groupArrayMovingSum(4)(number)─┐</span></span><br><span class="line"><span class="comment">│ [0,1,2,3,4,5,6,7,8,9] │ [0,1,3,6,10,14,18,22,26,30]    │</span></span><br><span class="line"><span class="comment">└───────────────────────┴────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>画一张图，来解释一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0(%E5%8D%81%E4%B8%80)/1229382-20210905001856948-1721448098.png" alt="img"></p>
<p><strong>首先 groupArrayMovingSum(4) 表示窗口的长度为 4，然后不断的向下滑动，计算包含当前元素在内往上的四个元素之和。如果元素的个数不够窗口的长度，那么有几个算几个，比如前三个元素。</strong></p>
<p><strong>那么试想一下，如果窗口长度等于数组的长度，那么会发生什么呢？</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 不指定窗口长度，那么窗口长度就等于数组长度</span></span><br><span class="line"><span class="keyword">SELECT</span> groupArray(number), groupArrayMovingSum(number)</span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">10</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArray(number)────┬─groupArrayMovingSum(number)─┐</span></span><br><span class="line"><span class="comment">│ [0,1,2,3,4,5,6,7,8,9] │ [0,1,3,6,10,15,21,28,36,45] │</span></span><br><span class="line"><span class="comment">└───────────────────────┴─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">-- 显然相当于进行了累和</span></span><br></pre></td></tr></table></figure>

<p><strong>这就是 ClickHouse 提供的窗口函数，但关系型数据库中的窗口函数语法在 ClickHouse 还没有得到完美的支持，但很明显通过这些强大的函数我们也可以实现相应的功能。</strong></p>
<p><strong>除了 groupArrayMovingSum 之外，还有一个 groupArrayMovingAvg，用法完全一样，只不过计算的是平均值，这里就不单独说了。</strong></p>
<p><strong>groupArraySample：随机选择 N 个元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 随机选择 3 个元素</span></span><br><span class="line"><span class="keyword">SELECT</span> groupArraySample(<span class="number">3</span>)(amount) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArraySample(3)(amount)─┐</span></span><br><span class="line"><span class="comment">│ [1268,2246,1606]            │</span></span><br><span class="line"><span class="comment">└─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们还可以绑定一个随机种子，如果种子一样，那么每次随机选择的数据也是一样的。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> groupArraySample(<span class="number">3</span>, <span class="number">666</span>)(amount) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArraySample(3, 666)(amount)─┐</span></span><br><span class="line"><span class="comment">│ [635,1290,1846]                  │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> groupArraySample(<span class="number">3</span>, <span class="number">666</span>)(amount) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArraySample(3, 666)(amount)─┐</span></span><br><span class="line"><span class="comment">│ [635,1290,1846]                  │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> groupArraySample(<span class="number">3</span>, <span class="number">661</span>)(amount) <span class="keyword">FROM</span> sales_data;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArraySample(3, 661)(amount)─┐</span></span><br><span class="line"><span class="comment">│ [2011,2125,1542]                 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>deltaSum：对相邻的行进行做差，然后求和，注意：小于 0 不会计算在内</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 3 - 1 = 2</span></span><br><span class="line"><span class="comment">-- 4 - 3 = 1</span></span><br><span class="line"><span class="comment">-- 1 - 4 = -3</span></span><br><span class="line"><span class="comment">-- 8 - 1 = 7</span></span><br><span class="line"><span class="comment">-- 所以结果为 2 + 1 + 7</span></span><br><span class="line"><span class="keyword">SELECT</span> deltaSum(arrayJoin([<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">8</span>]));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─deltaSum(arrayJoin([1, 3, 4, 1, 8]))─┐</span></span><br><span class="line"><span class="comment">│                                   10 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><strong>以上就是关于 ClickHouse 的一些聚合函数，还有相当一部分没有介绍到，主要是觉得应用的场景非常少见，后续再补充。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>Bean注入的四种方式</title>
    <url>/2022/12/01/Bean%E6%B3%A8%E5%85%A5%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F-bean%E6%B3%A8%E5%85%A5%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="Bean注入的四种方式"><a href="#Bean注入的四种方式" class="headerlink" title="Bean注入的四种方式"></a>Bean注入的四种方式</h1><h2 id="xml-方式"><a href="#xml-方式" class="headerlink" title="xml 方式"></a>xml 方式</h2><p>依稀记得最早接触<code>Spring</code>的时候，用的还是<code>SSH</code>框架，不知道大家对这个还有印象吗？所有的<code>bean</code>的注入得依靠<code>xml</code>文件来完成。</p>
<p>它的注入方式分为：<code>set</code>方法注入、构造方法注入、字段注入，而注入类型分为值类型注入（8种基本数据类型）和引用类型注入（将依赖对象注入）。</p>
<p>以下是<code>set</code>方法注入的简单样例</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">name</span>=<span class="string">&quot;teacher&quot;</span> <span class="attr">class</span>=<span class="string">&quot;cn.vipwen.domain.Teacher&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;name&quot;</span> <span class="attr">value</span>=<span class="string">&quot;vipwen&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>对应的实体类代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Teacher</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>xml方式存在的缺点如下：</strong></p>
<ol>
<li><code>xml</code>文件配置起来比较麻烦，既要维护代码又要维护配置文件，开发效率低；</li>
<li>项目中配置文件过多，维护起来比较困难；</li>
<li>程序编译期间无法对配置项的正确性进行验证，只能在运行期发现并且出错之后不易排查；</li>
<li>解析<code>xml</code>时，无论是将<code>xml</code>一次性装进内存，还是一行一行解析，都会占用内存资源，影响性能。</li>
</ol>
<h2 id="注解方式"><a href="#注解方式" class="headerlink" title="注解方式"></a>注解方式</h2><p>随着<code>Spring</code>的发展，<code>Spring 2.5</code>开始出现了一系列注解，除了我们经常使用的@Controller、@Service、@Repository、@Component 之外，还有一些比较常用的方式，接下来我们简单了解下。</p>
<h3 id="Configuration-Bean"><a href="#Configuration-Bean" class="headerlink" title="@Configuration + @Bean"></a>@Configuration + @Bean</h3><p>当我们需要引入第三方的<code>jar</code>包时，可以用<code>@Bean</code>注解来标注，同时需要搭配<code>@Configuration</code>来使用。</p>
<ul>
<li><code>@Configuration</code>用来声明一个配置类，可以理解为<code>xml</code>的&#96;&#96;标签</li>
<li><code>@Bean</code> 用来声明一个<code>bean</code>，将其加入到<code>Spring</code>容器中，可以理解为<code>xml</code>的&#96;&#96;标签</li>
</ul>
<p><strong>简单样例：将 RedisTemplate 注入 Spring</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedisConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> RedisTemplate&lt;String, Object&gt; <span class="title function_">redisTemplate</span><span class="params">(LettuceConnectionFactory lettuceConnectionFactory)</span> &#123;</span><br><span class="line">        RedisTemplate&lt;String, Object&gt; redisTemplate = <span class="keyword">new</span> <span class="title class_">RedisTemplate</span>&lt;&gt;();</span><br><span class="line">        redisTemplate.setConnectionFactory(lettuceConnectionFactory);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值</span></span><br><span class="line">        <span class="type">StringRedisSerializer</span> <span class="variable">stringRedisSerializer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringRedisSerializer</span>();</span><br><span class="line">        <span class="comment">// key</span></span><br><span class="line">        redisTemplate.setKeySerializer(stringRedisSerializer);</span><br><span class="line">        Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = <span class="keyword">new</span> <span class="title class_">Jackson2JsonRedisSerializer</span>&lt;&gt;(Object.class);</span><br><span class="line">        <span class="type">ObjectMapper</span> <span class="variable">objectMapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        <span class="comment">// 指定要序列化的域(field,get,set)，访问修饰符(public,private,protected)</span></span><br><span class="line">        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);</span><br><span class="line">        objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL);</span><br><span class="line">        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);</span><br><span class="line">        <span class="comment">//value</span></span><br><span class="line">        redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line"></span><br><span class="line">        redisTemplate.setHashKeySerializer(stringRedisSerializer);</span><br><span class="line">        redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line"></span><br><span class="line">        redisTemplate.afterPropertiesSet();</span><br><span class="line">        <span class="keyword">return</span> redisTemplate;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Import"><a href="#Import" class="headerlink" title="@Import"></a>@Import</h3><p>我们在翻看<code>Spring</code>源码的过程中，经常会看到<code>@Import</code>注解，它也可以用来将第三方<code>jar</code>包注入<code>Spring</code>，但是它只可以作用在<strong>类</strong>上。</p>
<p>例如在注解<code>EnableSpringConfigured</code>上就包含了<code>@Import</code>注解，用于将<code>SpringConfiguredConfiguration</code>配置文件加载进<code>Spring</code>容器。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Import(SpringConfiguredConfiguration.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> EnableSpringConfigured &#123;&#125;</span><br></pre></td></tr></table></figure>

<p><code>@Import</code>的<code>value</code>值是一个数组，一个一个注入比较繁琐，因此我们可以搭配<code>ImportSelector</code>接口来使用，用法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@Import(MySelector.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConfig</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySelector</span> <span class="keyword">implements</span> <span class="title class_">ImportSelector</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String[] selectImports(AnnotationMetadata importingClassMetadata) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;org.springframework.data.redis.core.RedisTemplate&quot;</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中<code>selectImports</code>方法返回的数组就会通过<code>@Import</code>注解注入到<code>Spring</code>容器中。</p>
<p>无独有偶，<code>ImportBeanDefinitionRegistrar</code>接口也为我们提供了注入<code>bean</code>的方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Import(AspectJAutoProxyRegistrar.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> EnableAspectJAutoProxy &#123;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们点击<code>AspectJAutoProxyRegistrar</code>类，发现它实现了<code>ImportBeanDefinitionRegistrar</code>接口，它的<code>registerBeanDefinitions</code>方法便是注入<code>bean</code>的过程，可以参考下。</p>
<p>如果觉得源代码比较难懂，可以看一下我们自定义的类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@Import(value = &#123;MyImportBeanDefinitionRegistrar.class&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConfig</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyImportBeanDefinitionRegistrar</span> <span class="keyword">implements</span> <span class="title class_">ImportBeanDefinitionRegistrar</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">registerBeanDefinitions</span><span class="params">(AnnotationMetadata importingClassMetadata,</span></span><br><span class="line"><span class="params">                                        BeanDefinitionRegistry registry)</span> &#123;</span><br><span class="line">            <span class="type">RootBeanDefinition</span> <span class="variable">tDefinition</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RootBeanDefinition</span>(Teacher.class);</span><br><span class="line">            <span class="comment">// 注册 Bean，并指定bean的名称和类型</span></span><br><span class="line">            registry.registerBeanDefinition(<span class="string">&quot;teacher&quot;</span>, tDefinition);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样我们就把<code>Teacher</code>类注入到<code>Spring</code>容器中了。</p>
<h2 id="FactoryBean"><a href="#FactoryBean" class="headerlink" title="FactoryBean"></a>FactoryBean</h2><p>提到<code>FactoryBean</code>，就不得不与<code>BeanFactory</code>比较一番。</p>
<ul>
<li><code>BeanFactory</code> : 是 <code>Factory</code>， <code>IOC</code>容器或者对象工厂，所有的<code>Bean</code>都由它进行管理</li>
<li><code>FactoryBean</code> : 是<code>Bean</code> ，是一个能产生或者修饰对象生成的工厂 <code>Bean</code>，实现与工厂模式和修饰器模式类似</li>
</ul>
<p>那么<code>FactoryBean</code>是如何实现<code>bean</code>注入的呢？</p>
<p>先定义实现了<code>FactoryBean</code>接口的类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TeacherFactoryBean</span> <span class="keyword">implements</span> <span class="title class_">FactoryBean</span>&lt;Teacher&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回此工厂管理的对象实例</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Teacher <span class="title function_">getObject</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Teacher</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回此 FactoryBean 创建的对象的类型</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Class&lt;?&gt; getObjectType() &#123;</span><br><span class="line">        <span class="keyword">return</span> Teacher.class;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后通过 @Configuration + @Bean的方式将<code>TeacherFactoryBean</code>加入到容器中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> TeacherFactoryBean <span class="title function_">teacherFactoryBean</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">TeacherFactoryBean</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意：我们没有向容器中注入<code>Teacher</code>, 而是直接注入的<code>TeacherFactoryBean</code>，然后从容器中拿<code>Teacher</code>这个类型的<code>bean</code>，成功运行。</p>
<h2 id="BDRegistryPostProcessor"><a href="#BDRegistryPostProcessor" class="headerlink" title="BDRegistryPostProcessor"></a>BDRegistryPostProcessor</h2><p>看到这个接口，不知道对于翻看过<code>Spring</code>源码的你来说熟不熟悉。如果不熟悉的话请往下看，要是熟悉的话就再看一遍吧😃。</p>
<h3 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">BeanDefinitionRegistryPostProcessor</span> <span class="keyword">extends</span> <span class="title class_">BeanFactoryPostProcessor</span> &#123;</span><br><span class="line">    <span class="comment">// 注册bean到spring容器中</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">postProcessBeanDefinitionRegistry</span><span class="params">(BeanDefinitionRegistry registry)</span> <span class="keyword">throws</span> BeansException;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">BeanFactoryPostProcessor</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">postProcessBeanFactory</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>BeanFactoryPostProcessor</code>接口是<code>BeanFactory</code>的后置处理器，方法<code>postProcessBeanFactory</code>对<code>bean</code>的定义进行控制。今天我们重点来看看<code>postProcessBeanDefinitionRegistry</code>方法：它的参数是<code>BeanDefinitionRegistry</code>，顾名思义就是与<code>BeanDefinition</code>注册相关的。</p>
<p><img src="/2022/12/01/Bean%E6%B3%A8%E5%85%A5%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F-bean%E6%B3%A8%E5%85%A5%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F/0_jpg-43676f4ff0144f669b179cba83a80b61.jpg" alt="0_jpg"></p>
<p>通过观察该类，我们发现它里边包含了<code>registerBeanDefinition</code>方法，这个不就是我们想要的吗？为了能更好的使用该接口来达到注入<code>bean</code>的目的，我们先来看看<code>Spring</code>是如何操作此接口的。</p>
<p><img src="/2022/12/01/Bean%E6%B3%A8%E5%85%A5%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F-bean%E6%B3%A8%E5%85%A5%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F/1_jpg-2bc8a40570474895a3ada3f73ac531d4.jpg"></p>
<p>看下<code>invokeBeanFactoryPostProcessors</code>方法，会发现没有实现<code>PriorityOrdered</code>和<code>Ordered</code>的<code>bean</code>（这种跟我们自定义的实现类有关）会执行以下代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (reiterate) &#123;</span><br><span class="line">    ......</span><br><span class="line">    invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>进入该方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">invokeBeanDefinitionRegistryPostProcessors</span><span class="params">(</span></span><br><span class="line"><span class="params">    Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, </span></span><br><span class="line"><span class="params">    BeanDefinitionRegistry registry)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123;</span><br><span class="line">        postProcessor.postProcessBeanDefinitionRegistry(registry);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>会发现实现了<code>BeanDefinitionRegistryPostProcessor</code>接口的<code>bean</code>，其<code>postProcessBeanDefinitionRegistry</code>方法会被调用，也就是说如果我们自定义接口实现该接口，它的<code>postProcessBeanDefinitionRegistry</code>方法也会被执行。</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>话不多说，直接上代码。自定义接口实现类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyBeanDefinitionRegistryPostProcessor</span> <span class="keyword">implements</span> <span class="title class_">BeanDefinitionRegistryPostProcessor</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化过程中先执行</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">postProcessBeanDefinitionRegistry</span><span class="params">(BeanDefinitionRegistry registry)</span> <span class="keyword">throws</span> BeansException &#123;</span><br><span class="line">        <span class="type">RootBeanDefinition</span> <span class="variable">rootBeanDefinition</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RootBeanDefinition</span>(Teacher.class);</span><br><span class="line">        <span class="comment">//Teacher 的定义注册到spring容器中</span></span><br><span class="line">        registry.registerBeanDefinition(<span class="string">&quot;teacher&quot;</span>, rootBeanDefinition);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化过程中后执行</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">postProcessBeanFactory</span><span class="params">(ConfigurableListableBeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动类代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    <span class="type">AnnotationConfigApplicationContext</span> <span class="variable">context</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AnnotationConfigApplicationContext</span>();</span><br><span class="line">    <span class="type">MyBeanDefinitionRegistryPostProcessor</span> <span class="variable">postProcessor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyBeanDefinitionRegistryPostProcessor</span>();</span><br><span class="line">    <span class="comment">//将自定义实现类加入 Spring 容器</span></span><br><span class="line">    context.addBeanFactoryPostProcessor(postProcessor);</span><br><span class="line">    context.refresh();</span><br><span class="line">    <span class="type">Teacher</span> <span class="variable">bean</span> <span class="operator">=</span> context.getBean(Teacher.class);</span><br><span class="line">    System.out.println(bean);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动并打印结果</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">org.springframework.demo.model.Teacher@2473d930</span><br></pre></td></tr></table></figure>

<p>发现已经注入到<code>Spring</code>容器中了。</p>
]]></content>
  </entry>
  <entry>
    <title>ClickHouse 中其它常见的表引擎(八)</title>
    <url>/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/</url>
    <content><![CDATA[<h1 id="ClickHouse-中其它常见的表引擎-八"><a href="#ClickHouse-中其它常见的表引擎-八" class="headerlink" title="ClickHouse 中其它常见的表引擎(八)"></a>ClickHouse 中其它常见的表引擎(八)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>Everything is table（万物皆为表）是 ClickHouse 的一个非常有意思的设计思路，正因为 ClickHouse 是一款数据库，所以自然而然数据表就是它的武器，是它与外部进行交互的接口层。在数据表背后无论连接的是本地文件、HDFS、zookeeper，还是其它服务，终端用户只需要面对数据表，只需要使用 SQL 查询语言。</strong></p>
<p><strong>下面就来介绍一下其它类型的表引擎，它们以表为接口，极大地丰富了 ClickHouse 的查询能力。这些表引擎各自特点突出，或是独立地应用于特定场景，或是能够与 MergeTree 搭配使用。例如外部存储系列的表引擎，能够直接读取其它系统的数据，ClickHouse 自身只负责元数据的管理，类似使用外部表的形式；内存系列的表引擎，能够充当数据分发的临时存储载体或消息通道；日志文件系列的表引擎，拥有简单易用的特点；接口系列的表引擎，能够串联已有数据表，起到粘合剂的作用。那么下面我们就来分门别类的介绍一下，这些表引擎各自的使用特点。</strong></p>
<h3 id="外部存储类型"><a href="#外部存储类型" class="headerlink" title="外部存储类型"></a>外部存储类型</h3><p><strong>顾名思义，外部存储表引擎能够直接从其它的存储系统读取数据，例如直接读取 HDFS 的文件或者 MySQL 数据库的表，这些表引擎只负责元数据管理和数据查询，而它们自身通常不负责数据的写入，数据文件直接由外部系统提供。</strong></p>
<h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p><strong>HDFS 是一款分布式文件存储系统，可以说是 Hadoop 生态的基石，而 ClickHouse 提供的 HDFS 表引擎则可以与之对接，读取 HDFS 内的文件。关于 HDFS 的安装这里不赘述了，这里假设已经安装完毕。但是注意，我们需要关闭 HDFS 的 Kerberos 认证，因为 HDFS 表引擎还不支持 Kerberos，然后在 HDFS 上创建用于存放文件的目录。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfs -mkdir /clickhouse</span><br></pre></td></tr></table></figure>

<p><strong>最后在 HDFS 上给 clickhouse 用户授权：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfs -chown -R clickhouse:clickhouse /clickhouse</span><br></pre></td></tr></table></figure>

<p><strong>然后我们创建 HDFS 数据表，而 ClickHouse 的一张 HDFS 数据表，对应 HDFS 文件系统上的一个文件：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hdfs_table1 (</span><br><span class="line">    id UInt32,</span><br><span class="line">    code String,</span><br><span class="line">    name String</span><br><span class="line">) ENGINE <span class="operator">=</span> HDFS(<span class="string">&#x27;hdfs://localhost:6666/clickhouse/hdfs_table1&#x27;</span>, <span class="string">&#x27;CSV&#x27;</span>)</span><br><span class="line"><span class="comment">-- HDFS(&#x27;HDFS 的文件存储路径&#x27;, &#x27;文件格式，如 CSV、TSV、JSON 等等&#x27;)</span></span><br><span class="line"><span class="comment">-- 注：数据表的名字和 HDFS 文件系统上的文件名可以不一致</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：我们这里虽然创建了一张表 hdfs_table1，但 HDFS 文件系统上还并没有 hdfs_table1 这个文件，而当我们往表中插入数据时，表对应的文件就会在 HDFS 文件系统上创建、同时将数据写进去。因此我们写入数据虽然表面上是通过 HDFS 数据表，但实际上数据是存储在 HDFS 文件系统上的，而 ClickHouse 在这里只负责元数据的管理。可能有人发现了，这不就是 Hive 嘛，是的，ClickHouse 在这里所干的事情和 Hive 是一样的。下面写入一批数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> hdfs_table1 </span><br><span class="line"><span class="keyword">SELECT</span> number, concat(<span class="string">&#x27;code&#x27;</span>, toString(number)), concat(<span class="string">&#x27;n&#x27;</span>, toString(number))</span><br><span class="line"><span class="keyword">FROM</span> numbers(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p><strong>此时在 HDFS 文件系统的 &#x2F;clickhouse 下面会创建一个文件，也叫 hdfs_table1，同时将数据写进去。然后我们就可以通过数据表查询，注意：因为数据存在 HDFS 文件系统上，所以查询实际上就是 ClickHouse 读取 HDFS 文件系统的一个过程。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002619076-698383201.png" alt="img"></p>
<p><strong>然后我们再来看看 HDFS 上文件：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002626203-1247824117.png" alt="img"></p>
<p><strong>可以发现通过 HDFS 表引擎，ClickHouse 在 HDFS 的指定目录下创建了一个名为 hdfs_table1 的文件，并且按照 CSV 格式写入了数据。注意：这里创建的数据表类似于 hive 中的外部表，也就是说将 HDFS 数据表删除（删除元数据），并不会影响 HDFS 文件系统上的文件。</strong></p>
<p><strong>以上就是 ClickHouse 和 HDFS 之间的交互，不过我们知道 ClickHouse 具有分片功能（后面说），所以它完全不需要借助于 HDFS 存储系统来存储数据，而且使用 HDFS 的话，那么 ClickHouse 的列式存储、数据压缩、索引等一系列高级特性就都用不上了，反而会严重拖慢 ClickHouse 的效率。但 ClickHouse 之所以还提供和 HDFS 的交互，主要是考虑到 Hadoop 生态圈已经存在多年了，在 HDFS 之上已经存储了大量的数据，所以提供了和 HDFS 交互的接口。通过 HDFS 数据表将 HDFS 文件系统上的数据读取出来之后，导入到 MergeTree 数据表中，然后进行数据分析。</strong></p>
<p><strong>所以 HDFS 数据表虽然既负责写又负责读，就像我们上面演示的那样，但很明显我们基本不会用 HDFS 数据表写数据。因此当涉及 ClickHouse 和 HDFS 的交互时，都是数据已经存在于 HDFS 文件系统之上，我们只是创建一个 HDFS 数据表将数据从 HDFS 文件系统上读取出来罢了。所以此时创建 HDFS 数据表就需要根据文件内容来创建了。</strong></p>
<p><strong>比如 HDFS 上存在一个 CSV 文件，这个文件里面有 4 列，那么我们创建的数据表就应该有 4 个字段。举个栗子：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002633883-1719103428.png" alt="img"></p>
<p><strong>此时 HDFS 上有一个 TSV 格式的文件（CSV 文件的分隔符为逗号，TSV 文件的分隔符为 \t），这个时候我们需要使用 ClickHouse 将其读取出来。具体做法显然是创建一张 HDFS 数据表，然后指定数据文件在 HDFS 上存储路径即可，但问题是表字段要如何设计呢？没错，显然要根据文件的存储内容来进行设计，比如这里有 4 个列，那么 HDFS 数据表就应该要有 4 个字段，然后再根据存储的内容指定字段的类型，那么这个 HDFS 数据表就可以这么定义：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hdfs_table2 (</span><br><span class="line">    a UInt32,</span><br><span class="line">    b String,</span><br><span class="line">    c UInt32,</span><br><span class="line">    d String</span><br><span class="line">) ENGINE <span class="operator">=</span> HDFS(<span class="string">&#x27;hdfs://localhost:6666/clickhouse/hdfs_table2&#x27;</span>, <span class="string">&#x27;TSV&#x27;</span>);</span><br><span class="line"><span class="comment">-- 文件类型要指定 TSV，因为分隔符是 \t</span></span><br><span class="line"><span class="comment">-- 注：这里字段名叫什么完全由我们自己定义，我们也可以起一个有意义的名字</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hdfs_table2_new (</span><br><span class="line">    id UInt32,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt32,</span><br><span class="line">    place String</span><br><span class="line">) ENGINE <span class="operator">=</span> HDFS(<span class="string">&#x27;hdfs://localhost:6666/clickhouse/hdfs_table2&#x27;</span>, <span class="string">&#x27;TSV&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>这里我们的两张 HDFS 数据表都指向 HDFS 文件系统上的同一个文件：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002641127-2080962518.png" alt="img"></p>
<p><strong>还是比较简单的，这里的 ClickHouse 完全就充当了 Hive 的角色，甚至比 Hive 还要好用不少。不过 ClickHouse 支持的还不止这些，在指定 HDFS 文件路径的时候 ClickHouse 支持多种方式：</strong></p>
<ul>
<li><code>绝对路径：会读取指定路径的单个文件，比如HDFS(&#39;hdfs://localhost:6666/clickhouse/hdfs_table2&#39;, &#39;TSV&#39;)，会读取 clickhouse 目录下的 hdfs_table2 文件</code></li>
<li><code>* 通配符：匹配任意数量的任意字符，比如 HDFS(&#39;hdfs://localhost:6666/clickhouse/*&#39;, &#39;TSV&#39;)，会读取 clickhouse 目录下的所有文件</code></li>
<li><code>? 通配符：匹配单个任意字符，比如 ENGINE = HDFS(&#39;hdfs://localhost:6666/clickhouse/hdfs_table?&#39;, &#39;TSV&#39;)，会读取 clickhouse 目录下所有匹配 hdfs_table? 的文件</code></li>
<li><code>&#123;M..N&#125; 数字区间：匹配指定数字的文件，例如 HDFS(&#39;hdfs://localhost:6666/clickhouse/hdfs_table&#123;1..3&#125;&#39;, &#39;TSV&#39;)，会读取 clickhouse 目录下的 hdfs_table1、hdfs_table2、hdfs_table3</code></li>
</ul>
<p><strong>我们来测试一下，我们上面的文件都没有后缀名，但有后缀名也是可以的。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002647181-598571969.png" alt="img"></p>
<p><strong>这里我们将之前的 hdfs_table2 拷贝 3 份，并上传至 HDFS，然后创建数据表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> girls (</span><br><span class="line">    id UInt32,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt32,</span><br><span class="line">    place String</span><br><span class="line">) ENGINE <span class="operator">=</span> HDFS(<span class="string">&#x27;hdfs://localhost:6666/clickhouse/girls_&#123;1..3&#125;.tsv&#x27;</span>, <span class="string">&#x27;TSV&#x27;</span>);</span><br><span class="line"><span class="comment">-- 这里写成 girls_?.tsv 也是可以的</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> girls_new (</span><br><span class="line">    id UInt32,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt32,</span><br><span class="line">    place String</span><br><span class="line">) ENGINE <span class="operator">=</span> HDFS(<span class="string">&#x27;hdfs://localhost:6666/clickhouse/girls_?.tsv&#x27;</span>, <span class="string">&#x27;TSV&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>然后进行查询：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002654059-705168788.png" alt="img"></p>
<p><strong>显然使用 girls 和 girls_new 都是可以查询到数据的，由于是 3 个文件，因此会以 3 个分区的形式合并返回。</strong></p>
<p><strong>以上就是 HDFS 数据表的相关内容，可以看到使用起来还是非常方便的，但还是像我们之前说的那样，ClickHouse 完全独立于 Hadoop 生态圈，并不需要借助 HDFS 存储数据。但之所以还提供 HDFS 数据表，主要是为了读取 HDFS 文件系统上已存在的数据，不然的话我们需要先手动将数据从 HDFS 上下载下来，然后再导入到 ClickHouse 中，会比较麻烦，因此 ClickHouse 通过表引擎的形式直接支持我们访问 HDFS 文件系统。</strong></p>
<p><strong>当然不光是 HDFS，ClickHouse 还支持很多其它常见的外部存储系统，当然支持的目的都是为了读取这些存储系统中已存在的数据。</strong></p>
<h4 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h4><p><strong>MySQL 表引擎可以和 MySQL 数据库中的数据表建立映射，并通过 SQL 向其发起远程查询，包括 SELECT 和 INSERT，声明方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = MySQL(&#x27;host:port&#x27;, &#x27;database&#x27;, &#x27;table&#x27;, &#x27;user&#x27;, &#x27;password&#x27;[, replace_query, on_duplicate_clause])</span><br></pre></td></tr></table></figure>

<p><strong>假设我们要访问 MySQL 的 default 库下的 trade_info 表，那么可以这么做：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> clickhouse_trade_info (</span><br><span class="line">    id UInt32,</span><br><span class="line">    column1 type,</span><br><span class="line">    column2 type,</span><br><span class="line">    ......</span><br><span class="line">) ENGINE <span class="operator">=</span> MySQL(<span class="string">&#x27;localhost:3306&#x27;</span>, <span class="string">&#x27;default&#x27;</span>, <span class="string">&#x27;trade_info&#x27;</span>, <span class="string">&#x27;root&#x27;</span>, <span class="string">&#x27;123456&#x27;</span>)</span><br><span class="line"><span class="comment">-- 显然这几个参数的含义不需要多说，但还有两个可选参数 replace_query 和 on_duplicate_clause</span></span><br><span class="line"><span class="comment">-- replace_query 默认为 0，如果设置为 1，会用 REPLACE INTO 代替 INSERT INTO</span></span><br><span class="line"><span class="comment">-- on_duplicate_clause 默认为 0，对应 MySQL 的 ON DUPLICATE KEY 语法，如果想启用该设置，那么需要设置为 1</span></span><br></pre></td></tr></table></figure>

<p><strong>创建成功之后，我们就可以通过 ClickHouse 的数据表来读取 MySQL 数据表的数据了，当然插入数据也是可以的。由于 MySQL 还是比较简单的，这里就不实际演示了，可以自己测试一下。</strong></p>
<p><strong>当然重点是，我们可以搭配物化视图一起使用：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> trade_info_view</span><br><span class="line">ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> clickhouse_trade_info</span><br><span class="line"><span class="comment">-- 这里指定数据表的时候一定要指定 ClickHouse 的数据表，不是 MySQL 的</span></span><br><span class="line"><span class="comment">-- 所以这里我们刻意将数据表其名为 clickhouse_trade_info</span></span><br></pre></td></tr></table></figure>

<p><strong>不过遗憾的是，目前 MySQL 表引擎不支持 UPDATE 和 DELETE 操作，如果需要数据更新的话，可以考虑使用 CollapsingMergeTree 作为视图的表引擎。不过还是之前所说，使用外部存储系统基本上都是为了读数据，很少会有插入、更新和删除之类的场景出现。</strong></p>
<h4 id="JDBC"><a href="#JDBC" class="headerlink" title="JDBC"></a>JDBC</h4><p><strong>相比 MySQL 表引擎，JDBC 表引擎不仅可以读取 MySQL 数据库，还能读取 PostgreSQL、SQLite 和 H2 数据库。但是光有 JDBC 表引擎还不够，它还需要依赖一个基于 Java 语言实现的 SQL 代理服务，名为 clickhouse-jdbc-bridge，它可以为 ClickHouse 代理访问数据库。</strong></p>
<p><strong>但 clickhouse-jdbc-bridge 需要使用 Maven 进行构建，而我本人不是 Java 方向的，只知道 Java 如何安装，甚至不知道如何用 Java 写一个 Hello World，所以更别提使用 Maven 构建项目了，因此这部分内容有兴趣可以自己了解一下。总之创建 JDBC 表引擎和 MySQL 表引擎是类似的：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = JDBC(&#x27;jdbc:url&#x27;, &#x27;database&#x27;, &#x27;table&#x27;)</span><br></pre></td></tr></table></figure>

<p><strong>不同的数据库使用不同的 url，可以自己测试一下。</strong></p>
<h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p><strong>Kafka 是大数据领域非常流行的一款分布式消息系统，而 ClickHouse 也提供了 Kafka 表引擎与之对接，进而订阅 Kafka 中的主题并实时接收消息数据。而总所周知，在消息系统中存在三层语义：</strong></p>
<ul>
<li><code>最多一次（At Most Once）：可能出现消息丢失的情况，因为在这种情形下，一条消息在消费端最多被接收一次</code></li>
<li><code>最少一次（At Least Once）：可能出现消息重复的情况，因为在这种情形下，一条消息在消费端允许被接收多次</code></li>
<li><code>精确一次（Exactly Once）：数据不多不少，一条消息在消费端恰好被消费一次，这也是最理想的情况，因为消息不可能百分之百不丢失</code></li>
</ul>
<p><strong>虽然 Kafka 本身能够支持上述三种语义，但是目前 ClickHouse 还不支持精确一次语义，因为这需要应用端和 Kafka 深度配合才可以实现。kafka 使用 Offset 标志位来记录主题数据被消费的位置信息，当应用端接收到消息之后，通过自动提交或手动提交当前的位移信息，以保障消息的语义，但 ClickHouse 在这方面还有进步的空间。</strong></p>
<p><strong>Kafka 表引擎的声明方式如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ENGINE <span class="operator">=</span> Kafka()</span><br><span class="line">SETTINGS kafka_broker_list <span class="operator">=</span> <span class="string">&#x27;host:port,...&#x27;</span>,</span><br><span class="line">         kafka_topic_list <span class="operator">=</span> <span class="string">&#x27;topic1,topic2&#x27;</span>,</span><br><span class="line">         kafka_group_name <span class="operator">=</span> <span class="string">&#x27;group_name&#x27;</span>,</span><br><span class="line">         kafka_format <span class="operator">=</span> <span class="string">&#x27;data_format[,]&#x27;</span>,</span><br><span class="line">         [kafka_row_delimiter <span class="operator">=</span> <span class="string">&#x27;delimiter_symbol&#x27;</span>,]</span><br><span class="line">         [kafka_schema <span class="operator">=</span> <span class="string">&#x27;&#x27;</span>,]</span><br><span class="line">         [kafka_num_consumers <span class="operator">=</span> N,]</span><br><span class="line">         [kafka_skip_broken_message <span class="operator">=</span> N,]</span><br><span class="line">         [kafka_commit_every_batch <span class="operator">=</span> N]</span><br></pre></td></tr></table></figure>

<p><strong>其中带有方括号的表示选填项，下面依次介绍这些参数的作用：</strong></p>
<ul>
<li><strong>kafka_broker_list：表示 Broker 服务的地址列表，多个地址之间使用逗号分割</strong></li>
<li><strong>kafka_topic_list：表示订阅的消息主题的名称列表，多个主题之间使用逗号分割，多个主题中的数据均被消费</strong></li>
<li><strong>kafka_group_name：表示消费者组的名称，表引擎会依据此名称创建消费者组</strong></li>
<li><strong>kafka_format：表示用于解析消息的数据格式，在消息的发送端，必须按照此格式发送消息。而数据格式也必须是 ClickHouse 提供的格式之一，例如 TSV、JSONEachRow 和 CSV 等</strong></li>
<li><strong>kafka_row_delimiter：表示判定一行数据的结束符，默认为 ‘\0’</strong></li>
<li><strong>kafka_schema：对应 Kafka 的 schema 参数</strong></li>
<li><strong>kafka_num_consumers：表示消费者的数据量，默认值为 1，表引擎会依据此参数在消费者组中开启相应数量的消费者线程，当然线程数不要超过分区数，否则没有意义。因为在 kafka 的主题中，一个分区只能被某个消费者组里面的一个消费者消费（如果想被多个消费者消费，那么这些消费者一定要隶属于不同的消费者组）</strong></li>
<li><strong>kafka_skip_broken_message：当表引擎按照预定格式解析数据出现错误时，允许跳过失败的数据的行数，默认值为 0，即不允许任何格式错误的情形发生。在此种情形下，只要 kafka 主题中存在无法解析的数据，数据表都将不会接收任何数据。如果将其设置成非 0 的正整数，例如设置为 10，则表示只要 kafka 主题中存在无法解析的数据的总数小于 10，数据表就能正常接收消息数据，而解析错误的数据会被自动跳过</strong></li>
<li><strong>kafka_commit_every_batch：表示执行 kafka commit 的频率，因此这里提交偏移量的方式是手动提交，默认值为 0，即当一整个 Block 块完全写入数据表后才执行一次 commit。如果设置为 1，则每写完一个 Batch 批次的数据就会执行一次 kakfa commit（一次 Block 写入操作，由多次 Batch 写入操作而成）</strong></li>
</ul>
<p><strong>因此 ClickHouse 在对接 Kakfa 的时候是会将消息写入到数据表中的，所以还有一些配置参数可以调整表引擎的行为，比如 stream_poll_timeout_ms，它表示拉取数据的间隔时间。默认值为 500 毫秒，所以 Kafka 表引擎每隔 500 毫秒拉取一次数据，而拉取的数据会先被放入缓存当中，在时机成熟的时候，会被刷新到数据表。</strong></p>
<p><strong>而触发 Kakfa 表引擎刷新缓存的条件有两个，当满足其中任何一个时，便会触发刷新动作：</strong></p>
<ul>
<li><strong>当一个数据块写入完成的时候，一个数据块的大小由 kafka_max_block_size 参数控制，默认情况下大小为 65536</strong></li>
<li><strong>等待间隔超过 7500 毫秒，由 stream_fush_interval_ms 控制</strong></li>
</ul>
<p><strong>Kafka 表引擎底层负责和 Kafka 通信的部分是基于 librdkafka 实现的，这是一个由 C++ 实现的 Kafka 库，项目地址为 <a href="https://github.com/edenhill/librdkafka">https://github.com/edenhill/librdkafka</a> 。librdkafka 提供了许多自定义的配置参数，例如在默认情况下，每次只会读取 kafka 中最新的数据，如果将 auto.offset.reset 改成 earliest（默认是 latest），数据将从会从最近一次提交的偏移位置开始读取。当然里面还支持很多其它的参数，可以通过项目中的 CONFIGURATION.md 进行查看。</strong></p>
<p><strong>ClickHouse 对 librdkafka 的自定义参数也提供了良好的扩展支持，在 ClickHouse 的全局设置中，提供了一组 Kafka 标签，专门用于定义 librdkafka 的自定义参数。不过需要注意的是，librdkafka 的原生参数中使用了点连接符，而在 ClickHouse 中需要改成下划线的形式，例如：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">kafka</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- librdkafka 中，参数名是 auto.offset.reset，在这里需要使用下划线进行分割 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">auto_offset_reset</span>&gt;</span>earliest<span class="tag">&lt;/<span class="name">auto_offset_reset</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">kafka</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>下面我们就来测试一下，首先使用 Go 来连接 kafka，创建一个主题，并写入几条数据：</strong></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;encoding/json&quot;</span></span><br><span class="line">    <span class="string">&quot;github.com/Shopify/sarama&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    config := sarama.NewConfig()</span><br><span class="line">    cluster, _ := sarama.NewClusterAdmin([]<span class="type">string</span>&#123;<span class="string">&quot;47.94.174.89:9092&quot;</span>&#125;, config)</span><br><span class="line">    <span class="comment">// 创建主题，该主题有三个分区    </span></span><br><span class="line">    _ = cluster.CreateTopic(<span class="string">&quot;heroes&quot;</span>, &amp;sarama.TopicDetail&#123;NumPartitions: <span class="number">3</span>, ReplicationFactor: <span class="number">1</span>&#125;, <span class="literal">false</span>)</span><br><span class="line">    <span class="comment">// 写入消息，每个分区写入两条    </span></span><br><span class="line">    config.Producer.Return.Successes = <span class="literal">true</span></span><br><span class="line">    config.Producer.Return.Errors = <span class="literal">true</span></span><br><span class="line">    config.Producer.Partitioner = sarama.NewManualPartitioner</span><br><span class="line">    producer, _ := sarama.NewAsyncProducer([]<span class="type">string</span>&#123;<span class="string">&quot;47.94.174.89:9092&quot;</span>&#125;, config)</span><br><span class="line">    messages := []<span class="keyword">map</span>[<span class="type">string</span>]<span class="keyword">interface</span>&#123;&#125;&#123;</span><br><span class="line">        &#123;<span class="string">&quot;id&quot;</span>: <span class="number">1</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;麦克雷&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">37</span>, <span class="string">&quot;weapon&quot;</span>: <span class="string">&quot;维和者&quot;</span>, <span class="string">&quot;ultimate&quot;</span>: <span class="string">&quot;午时已到&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;id&quot;</span>: <span class="number">2</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;源氏&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">35</span>, <span class="string">&quot;weapon&quot;</span>: <span class="string">&quot;镖&quot;</span>, <span class="string">&quot;ultimate&quot;</span>: <span class="string">&quot;斩&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;id&quot;</span>: <span class="number">3</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;半藏&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">38</span>, <span class="string">&quot;weapon&quot;</span>: <span class="string">&quot;弓&quot;</span>, <span class="string">&quot;ultimate&quot;</span>: <span class="string">&quot;龙&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;id&quot;</span>: <span class="number">4</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;士兵76&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">55</span>, <span class="string">&quot;weapon&quot;</span>: <span class="string">&quot;脉冲步枪&quot;</span>, <span class="string">&quot;ultimate&quot;</span>: <span class="string">&quot;战术目镜&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;id&quot;</span>: <span class="number">5</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;死神(谐星)&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">57</span>, <span class="string">&quot;weapon&quot;</span>: <span class="string">&quot;*弹枪&quot;</span>, <span class="string">&quot;ultimate&quot;</span>: <span class="string">&quot;死亡绽放&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;id&quot;</span>: <span class="number">6</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;路霸&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">48</span>, <span class="string">&quot;weapon&quot;</span>: <span class="string">&quot;爆裂枪&quot;</span>, <span class="string">&quot;ultimate&quot;</span>: <span class="string">&quot;鸡飞狗跳&quot;</span>&#125;,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> i, message := <span class="keyword">range</span> messages &#123;</span><br><span class="line">        value, _ := json.Marshal(message)</span><br><span class="line">        <span class="comment">// 将 map 转成 json        </span></span><br><span class="line">        <span class="keyword">if</span> i &lt; <span class="number">2</span> &#123;</span><br><span class="line">            producer.Input() &lt;- &amp;sarama.ProducerMessage&#123;Topic: <span class="string">&quot;heroes&quot;</span>, Partition: <span class="number">0</span>,</span><br><span class="line">                Value: sarama.StringEncoder(value)&#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> i &lt; <span class="number">4</span> &#123;</span><br><span class="line">            producer.Input() &lt;- &amp;sarama.ProducerMessage&#123;Topic: <span class="string">&quot;heroes&quot;</span>, Partition: <span class="number">1</span>,</span><br><span class="line">                Value: sarama.StringEncoder(value)&#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            producer.Input() &lt;- &amp;sarama.ProducerMessage&#123;Topic: <span class="string">&quot;heroes&quot;</span>, Partition: <span class="number">2</span>,</span><br><span class="line">                Value: sarama.StringEncoder(value)&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> &lt;-producer.Successes():</span><br><span class="line">        <span class="keyword">case</span> &lt;-producer.Errors():</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>以上我们就创建一个主题叫 heroes，该主题有三个分区，每个分区写入了两条数据。当然你也可以使用其它语言提供的 API 实现，下面我们通过 kafka 控制台查看一下数据有没有写入成功。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002823891-539220090.png" alt="img"></p>
<p><strong>显然写入成功了，上面的 172.24.60.6 是我的内网 IP，然后我们就来创建 kafka 数据表获取数据。由于数据已经写入了，所以在读取的时候必须指定 auto.offset.reset 为 earliest。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">kafka</span>&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;<span class="name">auto_offset_reset</span>&gt;</span>earliest<span class="tag">&lt;/<span class="name">auto_offset_reset</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">kafka</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>我们修改 config.xml，然后 clickhouse restart 重启服务。下面开始创建 Kakfa 数据表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> kafka_test (</span><br><span class="line">    id UInt32,    </span><br><span class="line">    name String,    </span><br><span class="line">    age UInt8,   </span><br><span class="line">    weapon String,   </span><br><span class="line">    ultimate String) </span><br><span class="line">ENGINE <span class="operator">=</span> Kafka() <span class="comment">-- 由于当前 ClickHouse 和 Kakfa 在同一个节点上，所以这里用内网 IP 也是可以的</span></span><br><span class="line">SETTINGS kafka_broker_list <span class="operator">=</span> <span class="string">&#x27;47.94.174.89:9092&#x27;</span>,         </span><br><span class="line">         kafka_topic_list <span class="operator">=</span> <span class="string">&#x27;heroes&#x27;</span>,         </span><br><span class="line">         kafka_group_name <span class="operator">=</span> <span class="string">&#x27;my_group&#x27;</span>,         </span><br><span class="line">         kafka_format <span class="operator">=</span> <span class="string">&#x27;JSONEachRow&#x27;</span>,         </span><br><span class="line">         kafka_num_consumers <span class="operator">=</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p><strong>创建成功之后，我们来查询数据，看看能不能读取：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002832713-1985022276.png" alt="img"></p>
<p><strong>整体都很顺利，但问题是第二次查询的时候发现数据没了，原因就是 kafka 表引擎在执行完查询之后就会删除表内的数据。注意这里删除的数据是 Kakfa 表引擎从 kafka 中拖下来写入表中的数据，至于 kafka 上面的数据还在。不过很明显这不是我们期望的，因为不能每次查询都临时从 kafka 上拖吧。</strong></p>
<p><strong>所以真正的使用方式如下：</strong></p>
<ul>
<li><code>首先创建 Kafka 数据表 A，它充当的是数据管道，负责从 kafka 上拖数据</code></li>
<li><code>然后是另外一张任意引擎的数据表 B，它充当的角色是面向终端用户的查询表，在生产环境中通常是 MergeTree 系列</code></li>
<li><code>最后是一张物化视图 C，它负责将表 A 的数据实时同步到表 B</code></li>
</ul>
<p><strong>下面具体操作一波：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> kafka_queue (</span><br><span class="line">    id UInt32,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt8,</span><br><span class="line">    weapon String,</span><br><span class="line">    ultimate String</span><br><span class="line">) ENGINE <span class="operator">=</span> Kafka()</span><br><span class="line">SETTINGS kafka_broker_list <span class="operator">=</span> <span class="string">&#x27;47.94.174.89:9092&#x27;</span>,</span><br><span class="line">         kafka_topic_list <span class="operator">=</span> <span class="string">&#x27;heroes&#x27;</span>,</span><br><span class="line">         kafka_group_name <span class="operator">=</span> <span class="string">&#x27;my_group&#x27;</span>,</span><br><span class="line">         kafka_format <span class="operator">=</span> <span class="string">&#x27;JSONEachRow&#x27;</span>,</span><br><span class="line">         kafka_num_consumers <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line">         </span><br><span class="line"><span class="comment">-- 然后是面向终端用户的查询表，这里使用 MergeTree 引擎</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> kafka_table (</span><br><span class="line">    id UInt32,</span><br><span class="line">    name String,</span><br><span class="line">    age UInt8,</span><br><span class="line">    weapon String,</span><br><span class="line">    ultimate String</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 最后是一张物化视图，用于将数据从 kafka_queue 同步到 kafka_table</span></span><br><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> queue_to_table_view <span class="keyword">TO</span> kafka_table</span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">SELECT</span> id, name, age, weapon, ultimate <span class="keyword">FROM</span> kafka_queue</span><br></pre></td></tr></table></figure>

<p><strong>至此全部的工作就完成了，当数据进入 kafka_queue 的时候，物化视图 queue_to_table_view 会将数据从 kafka_queue 同步到 kafka_table，即使 kafka_queue 中的数据被删掉也不影响，因为数据已经进入了 kafka_table，而 kafka_table 才是负责面向数据查询的表。</strong></p>
<blockquote>
<p><strong>说白了数据删除的问题并没有得到本质上的解决，只是换了一种曲线救国的方式，通过物化视图将数据放在了另一张表中。至于 kafka 数据表在查询之后数据为什么被删除，我们就不深究了。</strong></p>
</blockquote>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002840055-450004326.png" alt="img"></p>
<blockquote>
<p><strong>注意：从 kafka 上面拖数据是有一定过程的，如果往 kafka 写完数据之后就立刻查询 kafka_table，不一定能查询得到数据，这之间会有一定的延迟。</strong></p>
</blockquote>
<p><strong>如果想停止数据同步，可以删除视图：DROP TABEL queue_to_table_view，或者卸载视图：DETACH TABLE queue_to_table_view。这里我们将视图卸载掉，然后再将之前的数据重新写入一次，并进行查询：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002845471-147057865.png" alt="img"></p>
<p><strong>我们发现数据并没有被同步过来，这是理所当然的，因为视图被卸载了。如果想继续同步，那么将卸载之后的视图重新装载进来即可：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ATTACH MATERIALIZED <span class="keyword">VIEW</span> queue_to_table_view <span class="keyword">TO</span> kafka_table</span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">SELECT</span> id, name, age, weapon, ultimate <span class="keyword">FROM</span> kafka_queue</span><br></pre></td></tr></table></figure>

<p><strong>和创建视图类似，只需要将 CREATE 换成 ATTACH 即可，然后再进行查询：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002852594-1910988304.png" alt="img"></p>
<p><strong>此时数据就又同步过来了（如果没有同步过来就等一小会儿），但是切记：在重新装载物化视图之前一定不要查询 kakfa_queue，因为一旦查询数据就没了，物化视图就没法同步了。</strong></p>
<h4 id="File"><a href="#File" class="headerlink" title="File"></a>File</h4><p><strong>File 表引擎能够直接读取本地文件的数据，通常被作为一种扩展手段来使用，例如它可以读取由其它系统生成的数据文件，如果外部系统直接修改了文件，则变相达到了数据更新的目的；还可以将 ClickHouse 数据导出为本地文件；以及用于数据格式转换等场景。除此之外，File 表引擎也被应用于 clickhouse-local 工具，之前介绍过。</strong></p>
<p><strong>File 表引擎的声明方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = File(format)</span><br></pre></td></tr></table></figure>

<p><strong>其中 format 表示文件的数据格式，同样必须是 ClickHouse 支持的格式，例如 TSV、CSV、JSONEachRow 等。可以发现在 File 表引擎的定义参数中，并没有包含文件路径这一选项，因此 File 表引擎的数据文件只能保存在 config.xml 配置中由 path 指定的路径下，也就是和其它的数据表在同一个路径下。</strong></p>
<p><strong>每张 File 数据表均由目录和文件组成，其中目录以表的名称命名，而数据文件则以 data. 命名，比如 data.CSV、data.TSV 等等。而创建 File 表的方式有自动和手动两种，首先介绍自动创建的方式，即由 File 表引擎全权负责表目录和数据文件的创建：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> file_table (  </span><br><span class="line">    name String,    </span><br><span class="line">    <span class="keyword">value</span> UInt32</span><br><span class="line">) ENGINE <span class="operator">=</span> File(<span class="string">&#x27;CSV&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>和其它表引擎一样，当执行完上面的语句后，会在 &#x2F;var&#x2F;lib&#x2F;clickhouse&#x2F;data&#x2F;default 中创建相应的目录，但是里面还没有数据文件，我们接着写入数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> file_table <span class="keyword">VALUES</span> (<span class="string">&#x27;one&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;two&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;three&#x27;</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p><strong>在数据写入之后，file_table 下面便会生成一个 data.CSV 数据文件：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># cat /var/lib/clickhouse/data/default/file_table/data.CSV &quot;one&quot;,1&quot;two&quot;,2&quot;three&quot;,3</span></span><br><span class="line">[root@satori ~]<span class="comment"># </span></span><br></pre></td></tr></table></figure>

<p><strong>可以看到数据被写入了文件之中，但这种情况比较少见，因为写入数据我们基本上都不会使用外部存储系列的表引擎，它们存在的目的更多是为了读取现有的数据。所以接下来介绍手动创建的方式，也就是目录和里面的文件都已经存在了，它们是由 ClickHouse 之外的其它系统创建的，而我们需要使用 ClickHouse 读取它。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002901308-37798833.png" alt="img"></p>
<p><strong>以上是一个文本文件，如果我们想要读取它该怎么做呢？首先要根据内部数据创建和合适表结构，这里我们应该选择 JSONEachRow：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> file_table_new (</span><br><span class="line">    id UInt32,    </span><br><span class="line">    name String,   </span><br><span class="line">    place String</span><br><span class="line">) </span><br><span class="line">ENGINE <span class="operator">=</span> File(<span class="string">&#x27;JSONEachRow&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>创建完之后，可以查询一下试试，不出意外是会报错的，原因就是 file_table_new 下面没有 data.JSONEachRow 文件。不同于 MergeTree，MergeTree 数据表创建完之后如果不写入数据，那么查询结果是空，并不会报错。但 File 表引擎，它要求目录下必须有相应的 data.format 文件，所以我们将刚才的 girls.txt 拷贝过去：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># cp girls.txt /var/lib/clickhouse/data/default/file_table_new/data.JSONEachRow</span></span><br></pre></td></tr></table></figure>

<p><strong>拷贝的时候记得重命名，文件必须叫 data.，拷贝之后再执行一下查询：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002907468-1401770015.png" alt="img"></p>
<p><strong>当然我们也可以继续向表中追加数据，都是没有问题的。这里可能会有人好奇，如果我们不建表，而是手动创建一个 file_table_new 目录，然后将文件拷贝过去可不可以呢。答案是不可以，因为一张表除了对应一个物理目录之外，还有部分的元信息，这些元信息是在创建表的时候产生的。所以一定要先建表，然后自动生成对应的目录之后，再将文件拷贝过去。</strong></p>
<p><strong>以上就是 File 表引擎的基础用法，可以看到 ClickHouse 想的还是比较周全的，为了已经存在的数据存储也提供了相应的接口。</strong></p>
<h3 id="内存类型"><a href="#内存类型" class="headerlink" title="内存类型"></a>内存类型</h3><p><strong>之前介绍的表引擎，它们都有一个共同的特点：数据是在磁盘中被访问的，而接下来我们会介绍几种内存类型的表引擎，数据会从内存中被直接访问。当然，虽然它们是内存表引擎，但并不意味着不支持物理存储（落盘），事实上除了 Memory 表引擎之外，其余的几款内存表引擎都会将数据写入磁盘，因为为了防止数据丢失，所以也提供了这种故障恢复手段。而在数据表被加载时，它们会将数据全部加载至内存，以供查询。而将数据全量放在内存中，显然是一把双刃剑，因为在提升查询性能的同时增大了内存消耗。</strong></p>
<h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h4><p><strong>Memory 表引擎直接将数据保存在内存中，数据既不会被压缩也不会被格式转换，数据在内存中保存的形态与查询时看到的如出一辙。正因为如此，当 ClickHouse 服务重启的时候，Memory 表内的数据会全部丢失。所以在一些场合，会将 Memory 作为测试表使用。由于不需要磁盘读取、序列化以及反序列化操作，所以 Memory 表引擎支持并行查询，并且在简单的查询场景中能够达到与 MergeTree 旗鼓相当的查询性能（一亿行数据以内）。Memory 表创建方法如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sweet_memory_1 (id UInt64) ENGINE <span class="operator">=</span> Memory()</span><br></pre></td></tr></table></figure>

<p><strong>当数据被写入之后，磁盘上不会创建任何数据文件，如果服务重启，那么这张表就没了。比较简单，这里就不测试了，但最后需要说明的是，Memory 数据表不单单被用作测试，它还被广泛应用在 ClickHouse 的内部，它会作为集群间分发数据的存储载体来使用。例如在分布式 IN 查询的场合中，会利用 Memory 临时表保存 IN 字句的查询结果，并通过网络将它传输到远端节点，关于这部分内容后续介绍。</strong></p>
<h4 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h4><p><strong>Set 表引擎是拥有物理存储的，数据首先会被写入内存，然后被同步到磁盘文件中。所以服务重启之后它的数据不会丢失，当数据表被重新状态时，文件数据会再次被全量加载到内存。而 Set 我们知道它内部的数据是唯一的，对于有 Python 经验的人应该再熟悉不过了，也就是说 Set 表引擎具有数据去重的功能。在数据写入的过程中，重复的数据会被自动忽略。然而 Set 表引擎的使用场景即特殊又有限，它虽然支持正常的 INSERT 写入，但并不能直接使用 SELECT 进行查询，Set 表只能间接作为 IN 查询的右侧条件被查询使用。</strong></p>
<p><strong>Set 表引擎的存储结构由两部分组成，它们分别是：</strong></p>
<ul>
<li><strong>[num].bin 数据文件：保存了所有列字段的数据，其中 num 是一个自增 id，从 1 开始。伴随着每一批数据的写入（每一次 INSERT），都会生成一个新的 .bin 文件，num 也会随之加 1</strong></li>
<li><strong>tmp 临时目录：数据文件首先会被写到这个目录，当一批数据写入完毕之后，数据文件会被移出此目录</strong></li>
</ul>
<p><strong>下面就来创建一个 Set 数据表测试一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002915489-338948178.png" alt="img"></p>
<p><strong>正确的做法是将 Set 数据表作为 IN 查询的右侧条件，例如：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002921253-215978823.png" alt="img"></p>
<p><strong>再来查询一下 set_table 的物理目录结构：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori set_table]<span class="comment"># ls</span></span><br><span class="line">1.bin  tmp</span><br><span class="line">[root@satori set_table]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p><strong>结果和我们分析的是一样的。</strong></p>
<h4 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h4><p><strong>Join 表引擎显然是为 JOIN 查询而生的，它等同于将 JOIN 查询进行了一层简单的封装。在 Join 表引擎的底层实现中，它与 Set 表引擎共用了大部分的处理逻辑，所以 Join 和 Set 表引擎拥有众多相似之处。例如 Join 表引擎的物理存储也由 [num].bin 数据文件和 tmp 临时目录两部分组成；数据首先会被写入内存，然后被同步到磁盘文件，但相比 Set 表引擎，Join 表引擎有着更加广泛的使用场景，它既能够作为 JOIN 查询的连接表，也能够被直接查询使用。</strong></p>
<p><strong>Join 表引擎的声明方式如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = Join(join_strictness, join_type, key1[, key2, ...])</span><br></pre></td></tr></table></figure>

<p><strong>其中各参数的含义如下：</strong></p>
<ul>
<li><code>join_strictness：连接精度，它决定了 JOIN 查询在连接数据时所使用的策略，目前支持 ALL、ANY、SEMI、ANTI 四种类型</code></li>
<li><code>join_type：连接类型，它决定了 JOIN 查询在组合左右两个数据集合的策略，目前支持 INNER、LEFT、RIGHT 和 FULL 四种类型</code></li>
<li><code>join_key：连接键，它决定了使用哪个列字段进行关联</code></li>
</ul>
<p><strong>上面这些参数，每一条都对应了 JOIN 查询字句的语法规则，关于 JOIN 查询后续展开，我们首先创建相关数据表测试一下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 首先创建主表，引擎为 Log，关于 Log 数据表一会说</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> join_table (</span><br><span class="line">    id UInt8,</span><br><span class="line">    name String,</span><br><span class="line">    <span class="type">time</span> DateTime</span><br><span class="line">) ENGINE <span class="operator">=</span> <span class="built_in">Log</span>();</span><br><span class="line"><span class="comment">-- 写入数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> join_table</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;古明地觉&#x27;</span>, <span class="string">&#x27;2020-05-01 12:00:00&#x27;</span>),</span><br><span class="line">       (<span class="number">2</span>, <span class="string">&#x27;雾雨魔理沙&#x27;</span>, <span class="string">&#x27;2020-05-01 12:30:00&#x27;</span>),</span><br><span class="line">       (<span class="number">3</span>, <span class="string">&#x27;琪露诺&#x27;</span>, <span class="string">&#x27;2020-05-01 13:00:00&#x27;</span>);</span><br><span class="line">       </span><br><span class="line"><span class="comment">-- 接着创建 Join 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> id_join_table (</span><br><span class="line">    id UInt8,</span><br><span class="line">    score UInt8,</span><br><span class="line">    <span class="type">time</span> DateTime</span><br><span class="line">) ENGINE <span class="operator">=</span> <span class="keyword">Join</span>(<span class="keyword">ANY</span>, <span class="keyword">LEFT</span>, id);</span><br><span class="line"><span class="comment">-- 如果 join_strictness 为 ANY，那么 join_key 重复的数据会自动被忽略</span></span><br><span class="line"><span class="comment">-- 所以下面虽然写了两条 id 为 1 数据，但只有第一条会保留，因为写入第二条的时候发现 id 为 1 的数据已经存在了，所以会停止写入</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> id_join_table</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="number">100</span>, <span class="string">&#x27;2020-05-01 11:55:00&#x27;</span>),</span><br><span class="line">       (<span class="number">1</span>, <span class="number">105</span>, <span class="string">&#x27;2020-05-01 11:10:00&#x27;</span>),</span><br><span class="line">       (<span class="number">2</span>, <span class="number">90</span>, <span class="string">&#x27;2020-05-01 12:01:00&#x27;</span>),</span><br><span class="line">       (<span class="number">3</span>, <span class="number">80</span>, <span class="string">&#x27;2020-05-01 13:10:00&#x27;</span>),</span><br><span class="line">       (<span class="number">5</span>, <span class="number">70</span>, <span class="string">&#x27;2020-05-01 14:00:00&#x27;</span>),</span><br><span class="line">       (<span class="number">6</span>, <span class="number">60</span>, <span class="string">&#x27;2020-05-01 13:50:00&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>我们查询一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002929823-522994560.png" alt="img"></p>
<p><strong>我们看到是可以查询成功的，Join 数据表支持查询，但这种查询方式并不是 Join 数据表的主战场，它的主战场应该是 Join 查询，例如：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002935024-890100815.png" alt="img"></p>
<p><strong>当然 Join 数据表除了可以直接使用 SELECT 和 JOIN 之外，还可以通过 join 函数访问：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002941690-331743065.png" alt="img"></p>
<p><strong>目前还没有涉及到 JOIN 查询，所以一些细节我们还没有解释，目前只需要知道有这么个引擎即可，具体内容在后面介绍查询的时候再详细说。</strong></p>
<h4 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h4><p><strong>Buffer 表引擎完全使用内存装载数据，不支持文件的持久化机制，所以当服务重启之后，表内的数据会被清空。Buffer 表引擎不是为了面向查询场景而设计的，它的作用是充当缓冲区的角色。假设有这样一种场景，我们需要将数据写入目标 MergeTree 表 A，由于写入的并发数很高，这可能导致表 A 的合并速度慢于写入速度，因为每次 INSERT 都会生成一个新的分区目录。此时便可引入 Buffer 数据表来缓解这类问题，将 Buffer 表作为数据写入的缓冲区，数据首先会被写入 Buffer 表，当满足预设条件时，Buffer 表会自动将数据刷新到目标表。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002949593-1004963799.png" alt="img"></p>
<p><strong>Buffer 表引擎的声明方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = Buffer(database, table, num_layers, min_time, max_time, min_rows, max_rows, min_bytes, max_bytes)</span><br></pre></td></tr></table></figure>

<p><strong>里面参数的作用如下：</strong></p>
<ul>
<li><code>database：目标表的数据库</code></li>
<li><code>table：目标表，Buffer 表内的数据会自动刷新到目标表</code></li>
<li><code>num_layers：可以理解为线程数，Buffer 表会按照 num_layers 的数量开启线程，以并行的方式将数据刷新到目标表，官方建议设置为 16</code></li>
</ul>
<p><strong>Buffer 表并不是实时刷新数据的，只有在阈值条件满足时才会刷新，阈值条件由三个最小和最大值组成，含义如下：</strong></p>
<ul>
<li><code>min_time 和 max_time：时间条件的最小值和最大值，单位为秒，从第一次向表内写入数据时开始计算</code></li>
<li><code>min_rows 和 max_rows：数据行数条件的最小值和最大值</code></li>
<li><code>min_bytes 和 max_bytes：数据大小的最小值和最大值，单位为字节</code></li>
</ul>
<p><strong>针对以上条件，Buffer 表刷新数据的判断依据有三个，满足其中任意一个就会刷新数据：</strong></p>
<ul>
<li><code>三组条件中所有最小阈值都已满足，则触发刷新动作</code></li>
<li><code>三组条件中有一个最大阈值满足（这里是超过最大值），则触发刷新动作</code></li>
<li><code>如果写入一批数据的行数大运 max_rows 或者数据大小大于 max_bytes，则数据直接写入目标表</code></li>
</ul>
<p><strong>还有一点需要注意，上述三组条件在每一个 layer 中都是单独的计算的，假设 num_layers 为 16，则 Buffer 表最多开启 16 个线程来响应数据的写入，它们以轮训的方式接收请求，在每个线程内会独立进行上述判断的过程。也就是说，假设一张 Buffer 表的 max_bytes 为 100 MB，num_layers 为 16，那么这张 Buffer 表能够同时处理的最大数据量约为 1600 MB。</strong></p>
<p><strong>下面来测试一下它的用法，首先创建一个 Memory 数据表，再创建一张 Buffer 数数据表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> memory_table (id UInt64) ENGINE <span class="operator">=</span> Memory();</span><br><span class="line"><span class="comment">-- 创建 Buffer 表，用于往 Memory 表里面写入数据</span></span><br><span class="line"><span class="comment">-- 注意这里 Buffer 表的创建语法，后面必须要有 AS，并且这里的 AS 还不是别名的意思</span></span><br><span class="line"><span class="comment">-- 因为创建 Buffer 数据表的时候我们没有指定字段，那么这张表的结构长什么样呢？不用想肯定和 Memory 数据表一样</span></span><br><span class="line"><span class="comment">-- 因为数据就是要往它里面导，所以 AS memory_table 表示将表 memory_table 的结构作为表 buffer_to_memory_table 的结构</span></span><br><span class="line"><span class="comment">-- 当然除了 memory_table 还可以是其它的数据表，不过一般和目标表保持一致，因为数据就是要刷到目标表里面的</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> buffer_to_memory_table <span class="keyword">AS</span> memory_table</span><br><span class="line">ENGINE <span class="operator">=</span> Buffer(<span class="keyword">default</span>, memory_table, <span class="number">16</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">10000</span>, <span class="number">1000000</span>, <span class="number">10000000</span>, <span class="number">100000000</span>);</span><br><span class="line"><span class="comment">-- 接下来向 Buffer 表里面写入 100 万行数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> buffer_to_memory_table <span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">1000000</span>);</span><br></pre></td></tr></table></figure>

<p><strong>此时 buffer_to_memory_table 内部有数据，但 memory_table 里面没有，因为三个条件，没有一个达到最大阈值（准确的说是超过）。而在 100 秒之后才会有数据，可以验证一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901002957742-783985999.png" alt="img"></p>
<p><strong>然后我们再写入一批数据，此时数据量改为 100 万零 1 条：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003004810-426340530.png" alt="img"></p>
<p><strong>可以看到此时不会等待，Buffer 会立即将数据写入目标表。</strong></p>
<h3 id="日志类型"><a href="#日志类型" class="headerlink" title="日志类型"></a>日志类型</h3><p><strong>如果使用的数据量很小（例如 100 万以下），面对的数据查询场景也比较简单，并且是一次写入多次查询的模式，那么使用日志家族系列的表引擎将会是一种不错的选择。与合并树家族表引擎类似，日志家族系列的表引擎也有一些共性特征：比如均不支持索引、分区等高级特性，不支持并发读写等等。当针对一张日志表写入数据时，针对这张表的查询会被阻塞，直至写入动作结束。但它们同时也拥有切实的物理存储，数据会被保存到本地文件中，当然除了这些共同的特征职位啊啊，日志家族系列的表引擎也有这各自的特点。接下来就从性能由低到高的顺序，一依次介绍这些表引擎的使用方法。</strong></p>
<h4 id="TinyLog"><a href="#TinyLog" class="headerlink" title="TinyLog"></a>TinyLog</h4><p><strong>TinyLog 是日志家族中性能最低的表引擎，它的存储结构由数据文件和元数据两部分组成。其中数据文件是按列存储的，也就是说每个字段都有与之对应的 .bin 文件，这种结构和 MergeTree 有些相似，但 TinyLog 既不支持分区，也没有 .mrk 标记文件。由于没有标记文件，它自然无法支持 .bin 文件的并行读取操作，所以它只适合在非常简单的场景下使用。下面就来创建一张 TinyLog 数据表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tiny_log_table (</span><br><span class="line">    id UInt64,   </span><br><span class="line">    code UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> TinyLog(); </span><br><span class="line"><span class="comment">-- 接着写入数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> tiny_log_table <span class="keyword">SELECT</span> number, number <span class="operator">+</span> <span class="number">1</span> <span class="keyword">FROM</span> numbers(<span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<p><strong>数据写入之后就能通过 SELECT 语句对它进行查询了，这里就不展示查询结果了，都能想到是什么，我们来看一下物理存储：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003011837-135493468.png" alt="img"></p>
<p><strong>可以看到 id 和 code 各自生成了对应的 .bin 数据文件，然后还有一个 sizes.json，里面通过 JSON 格式记录了每个 .bin 文件内对应的数据大小信息。</strong></p>
<h4 id="StripeLog"><a href="#StripeLog" class="headerlink" title="StripeLog"></a>StripeLog</h4><p><strong>StripeLog 表引擎的存储结构由固定的三个文件组成，分别是：</strong></p>
<ul>
<li><code>data.bin：数据文件，所有的列字段使用同一个文件保存，所有数据均会写入 data.bin，类似于数据量没超过阈值的 MergeTree 表</code></li>
<li><code>index.mrk：数据标记，保存了数据在 data.bin 文件中的位置信息，利用数据标记能够使用多个线程以并行的方式读取 data.bin 内的压缩数据块，从而提升数据查询的性能</code></li>
<li><code>sizes.json：元数据文件，记录了 data.bin 和 index.mrk 大小的信息</code></li>
</ul>
<p><strong>从上述信息能够得知，相比 TinyLog 而言，StripeLog 拥有更高的查询性能（因为具有 .mrk 文件，支持并行查询），同时其使用了更少的文件描述符（所有列都使用同一个文件保存）。下面来创建 StripeLog 数据表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> stripe_log_table ( </span><br><span class="line">    id UInt64,    </span><br><span class="line">    code UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> StripeLog();</span><br><span class="line"><span class="comment">-- 然后写入数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> stripe_log_table <span class="keyword">SELECT</span> number, number <span class="operator">+</span> <span class="number">100</span> <span class="keyword">FROM</span> numbers(<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>数据写入之后即可进行查询，这里我们还是直接查看一下物理存储目录：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003018972-1358099321.png" alt="img"></p>
<p><strong>里面只有三个文件，其代表的含义显然无需解释了。</strong></p>
<h4 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h4><p><strong>Log 表引擎结合了 TinyLog 和 StripeLog 两个表引擎的长处，是日志家族系列中性能最高的表引擎，Log 表引擎的存储结构由 3 个部分组成：</strong></p>
<ul>
<li><code>[column].bin：数据文件，数据文件按列独立存储，每一个列字段都拥有一个与之对应的 .bin 文件</code></li>
<li><code>__marks.mrk：数据标记，统一保存了数据在各个 [column].bin 文件中的位置信息，利用数据标记能够使用多个线程以并行的方式读取 [column].bin 内的压缩数据块，从而提升数据查询的性能</code></li>
<li><code>sizes.json：元数据文件，记录了 [column].bin 和 __marks.mrk 大小的信息</code></li>
</ul>
<p><strong>下面创建 Log 数据表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> log_table (  </span><br><span class="line">    id UInt64,    </span><br><span class="line">    code UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> <span class="built_in">Log</span>();</span><br><span class="line"><span class="comment">-- 然后写入数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> log_table <span class="keyword">SELECT</span> number, number <span class="operator">+</span> <span class="number">100</span> <span class="keyword">FROM</span> numbers(<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>数据写入之后即可进行查询，相信都能看出 TinyLog、StripeLog、Log 之间是高度相似的，我们还是只看一下目录结构：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003025726-1365104681.png" alt="img"></p>
<p><strong>以上就是日志类型的表引擎，个人觉得算是最简单的了，甚至比内存类型的表引擎还要简单。</strong></p>
<h3 id="接口类型"><a href="#接口类型" class="headerlink" title="接口类型"></a>接口类型</h3><p><strong>有这么一类表引擎，它们自身并不存储任何数据，而是像粘合剂一样可以整合其它的数据表。在使用这类表引擎的时候，我们不用担心底层的复杂性，它们就像接口一样，为用户提供了统一的访问界面，所以将它们归为接口类表引擎。</strong></p>
<h4 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h4><p><strong>假设有这样一种场景：在数据仓库的设计中，数据按年分表存储，例如 test_table_2018、test_table_2019 和 test_table_2020，但是现在需要跨年度查询这些数据，应该如何实现呢？在这种情形下，使用 Merge 表引擎就是一种很合适的选择了。</strong></p>
<p><strong>Merge 表引擎就如同一层使用了门面模式的代理，它本身不存储任何数据，也不支持数据写入，它的作用就如同它的名字，即负责合并多个查询结果集。Merge 表引擎可以代理查询任意数量的数据表，这些查询会异步且并行执行，并最终合并成一个结果集返回。被代理查询的数据表被要求处于同一个数据库内，且拥有相同的表结构，但它们可以使用不同的表引擎以及不同的分区定义（对于 MergeTree 而言）。</strong></p>
<p><strong>Merge 表引擎的声明方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = Merge(database, table_name)</span><br></pre></td></tr></table></figure>

<p><strong>其中 database 为数据库的名称，table_name 为数据表的名称，它支持使用正式则表达式，比如 ^ 表示合并所有以 test 为前缀的数据表。下面我们来简单说明一下 Merge 的使用方法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- test_table_2018 保存了 2018 年的数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_table_2018 (</span><br><span class="line">    id String,</span><br><span class="line">    create_time DateTime,</span><br><span class="line">    code String</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 然后是 test_table_2019，它的结构和 test_table_2018 相同，但使用了不同的表引擎</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_table_2019 (</span><br><span class="line">    id String,</span><br><span class="line">    create_time DateTime,</span><br><span class="line">    code String</span><br><span class="line">) ENGINE <span class="operator">=</span> <span class="built_in">Log</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 然后创建 Merge 表将上面两张表结合，这里的 AS 相当于为 merge_test_table_2018_and_2019 指定表结构</span></span><br><span class="line"><span class="comment">-- 显然这里会复制 test_table_2018 的表结构</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> merge_test_table_2018_and_2019 <span class="keyword">AS</span> test_table_2018</span><br><span class="line">ENGINE <span class="operator">=</span> <span class="keyword">Merge</span>(currentDatabase(), <span class="string">&#x27;^test_table_201&#x27;</span>)</span><br><span class="line"><span class="comment">-- currentDatabase() 表示获取当前的数据库</span></span><br></pre></td></tr></table></figure>

<p><strong>然后我们来写入一些数据，然后进行查询：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003033723-71170041.png" alt="img"></p>
<p><strong>通过返回的结果集可以印证，所有以 test_table_201 开头的数据表都被分别查询，然后合并返回了。值得一提的是，对于 Merge 数据表而言，会有一个虚拟字段 _table，它表示某行数据的来源表。所以通过 _table 我们可以实现表的过滤，比如我们新创建了 test_table_2017 表示 2017 的数据，但当前我们并且不需要 2017 的数据，那么就可以将其作为查询条件给过滤掉，比如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> merge_test_table_2018_and_2019 <span class="keyword">WHERE</span> _table <span class="operator">!=</span> <span class="string">&#x27;test_table_2017&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>还是蛮方便的，此时 _table 将等同于索引，Merge 表忽略那些被排除在外的表，不会向他们发起查询请求。</strong></p>
<h4 id="Dictionary"><a href="#Dictionary" class="headerlink" title="Dictionary"></a>Dictionary</h4><p><strong>这里涉及到了数据字典，关于数据字典我们会专门放在后面说，目前可以先了解一下。Dictionary 表引擎是数据字典的一层代理封装，它可以取代字典函数，让用户通过数据表查询字典。字典内的数据被加载后，会全部保存到内存中，所以使用 Dictionary 对字典性能没有任何影响。声明 Dictionary 数据表的方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = Dictionary(dict_name)</span><br></pre></td></tr></table></figure>

<p><strong>其中 dict_name 对应一个已被加载的字典名称，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tb_test_flat_dict ( </span><br><span class="line">    id UInt64,    </span><br><span class="line">    code String,  </span><br><span class="line">    name String</span><br><span class="line">) ENGINE <span class="operator">=</span> Dictionary(test_flat_dict)  </span><br></pre></td></tr></table></figure>

<p><strong>tb_test_flat_dict 等同于数据字典 test_flat_dict 的代理表，对它进行 SELECT 查询即可获取内部的数据。</strong></p>
<h4 id="Distributed"><a href="#Distributed" class="headerlink" title="Distributed"></a>Distributed</h4><p><strong>在数据库领域，当面对海量业务数据的时候，一种主流的做法是实施 Sharding 方案，即将一张数据表横向扩展到多个数据库实例。其中每个数据库实例称为一个 Shard 分片，数据在写入时，需要按照预定的业务规则均匀地写至各个 Shard 分片；而在数据查询时，则需要在每个 Shard 分片上分别查询，最后归并结果集。所以为了实现 Sharding 方案，一款支持分布式数据库的中间件是必不可少的，例如 Apache ShardingSphere。</strong></p>
<p><strong>ClickHouse 作为一款性能卓越的分布式数据库，自然也是支持 Sharding 方案的，而 Distributed 表引擎就等同于 Sharding 方案中的数据库中间件。Distributed 表引擎自身不存储任何数据，它能够作为分布式表的一层透明代理，在集群内部自动开展数据的写入分发以及查询路由工作。关于 Distributed 表引擎的详细介绍，将会在后续展开。</strong></p>
<h3 id="其它类型"><a href="#其它类型" class="headerlink" title="其它类型"></a>其它类型</h3><p><strong>接下来将要介绍的几款表引擎，由于各自用途迥异，所以只好把它们归为其它类型。最然这些表引擎的使用场景并不广泛，但仍建议了解它们的特性和使用方法，因为这些表引擎扩充了 ClickHouse 的能力边界。在一些特殊的场合，它们也能够发挥重要作用。</strong></p>
<h4 id="Live-View"><a href="#Live-View" class="headerlink" title="Live View"></a>Live View</h4><p><strong>虽然 ClickHouse 已经提供了准实时的数据处理手段，例如 Kafka 表引擎和物化视图，但是在应用层面，一直缺乏开放给用户的事件监听机制。所以从 19.14 版本开始，ClickHouse 提供了一种全新的视图：Live View。</strong></p>
<p><strong>Live View 是一种特殊的视图，虽然它并不属于表引擎，但是因为它与数据表息息相关，所以还是把 LiveView 归类到了这里。Live View 的作用类似事件监听器，它能够将一条 SQL 查询结果作为监控目标，当目标数据增加时，LiveView 可以及时发出响应。若要使用 Live View，首先需要将 allow_experimental_live_view 参数设置为 1，可以执行如下语句确认参数是否设置正确：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003041543-1642442471.png" alt="img"></p>
<p><strong>现在来举例说明，首先创建一张数据表，它将作为 Live View 的监听目标：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> origin_table (</span><br><span class="line">    id UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> <span class="built_in">Log</span>();</span><br><span class="line"><span class="comment">-- 紧接着创建一个 Live View</span></span><br><span class="line"><span class="keyword">CREATE</span> LIVE <span class="keyword">VIEW</span> lv_origin <span class="keyword">AS</span> <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> origin_table;</span><br><span class="line"><span class="comment">-- 然后执行 watch 命令开启监听模式</span></span><br><span class="line"><span class="comment">-- 以后每当 origin_table 中的数据发生变化，就会执行 SELECT COUNT(*)</span></span><br><span class="line">WATCH lv_origin;</span><br></pre></td></tr></table></figure>

<p><strong>如此一来 Live View 就进入监听模式了，首先 origin_table 里面是没有数据的，所以显示结果为 0：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003047770-2122133580.png" alt="img"></p>
<p><strong>然后再开启一个客户端，向 origin_table 里面写入数据，假设写入 10 条。数据写入之后会发现 Live View 做出了实时响应，查询的值变成了 10，并且虚拟字段 _version 会伴随着每一次的响应增加 1。</strong></p>
<h4 id="Null"><a href="#Null" class="headerlink" title="Null"></a>Null</h4><p><strong>Null 表引擎的功能与作用，与 Unix 系统的空设备 &#x2F;dev&#x2F;null 很相似，如果用户向 Null 表写入数据，系统会正确返回，但数据会被 Null 表自动忽略，永远不会将它们保存。如果用户向 Null 表发起查询，那么它将返回空。在使用物化视图的时候，如果不希望保留源表的数据，那么将源表设置成 Null 引擎将会是非常好的选择。下面就来举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 首先创建一张 Null 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> null_table (id UInt8) ENGINE <span class="operator">=</span> <span class="keyword">Null</span>();</span><br><span class="line"><span class="comment">-- 接着以 null_table 为源表，建立一张物化视图</span></span><br><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> view_table</span><br><span class="line">ENGINE <span class="operator">=</span> TinyLog() <span class="keyword">AS</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> null_table</span><br></pre></td></tr></table></figure>

<p><strong>如果往 null_table 里面写数据，那么数据会被顺利同步到 view_table 中，但是 null_table 中是查询不到数据的。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003056841-1947455603.png" alt="img"></p>
<h4 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h4><p><strong>URL 表引擎的作用等价于 HTTP 客户端，它可以通过 HTTP&#x2F;HTTPS 协议，直接访问远端的 REST 服务。当执行 SELECT 查询的时候，底层会将其转换为 GET 请求的远程调用；而执行 INSERT 查询的时候，会将其转成 POST 请求的远程调用，并将数据以字节流的形式传递。URL 表引擎的声明方式如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = URL(&#x27;url&#x27;, format)</span><br></pre></td></tr></table></figure>

<p><strong>其中 url 表示远端的服务地址，而 format 则是 ClickHouse 支持的数据格式，如 TSV、CSV 和 JSON 等。</strong></p>
<p><strong>这里我们用 Python 的 FastAPI 编写一个 web 服务：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request, Response</span><br><span class="line"><span class="keyword">import</span> orjson</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line">table = []</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/girls&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get</span>():</span><br><span class="line">    response = Response(orjson.dumps(table),</span><br><span class="line">                        media_type=<span class="string">&quot;application/json&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/girls&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">post</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment"># 如果插入多行数据，那么这些数据之间会以 \n 进行分割</span></span><br><span class="line">    data = re.split(<span class="string">rb&quot;(?&lt;=&#125;)\n(?=&#123;)&quot;</span>, <span class="keyword">await</span> request.body())</span><br><span class="line">    rows = [orjson.loads(_) <span class="keyword">for</span> _ <span class="keyword">in</span> data]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(rows, <span class="built_in">dict</span>):</span><br><span class="line">        table.append(rows)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        table.extend(rows)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(<span class="string">&quot;main:app&quot;</span>, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">5555</span>)</span><br></pre></td></tr></table></figure>

<p><strong>启动之后我们来创建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> url_table (</span><br><span class="line">    id UInt32,</span><br><span class="line">    name String,</span><br><span class="line">    place String</span><br><span class="line">) ENGINE <span class="operator">=</span> URL(<span class="string">&#x27;http://localhost:5555/girls&#x27;</span>, JSONEachRow)</span><br></pre></td></tr></table></figure>

<p><strong>以后每执行一次 SELECT 都相当于发起了一次 GET 请求，执行一次 INSERT 相当于发起了一次 POST 请求，我们来测试一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E5%85%B6%E5%AE%83%E5%B8%B8%E8%A7%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E(%E5%85%AB)/1229382-20210901003104903-1326901560.png" alt="img"></p>
<p><strong>可以看出 ClickHouse 想的真是无比周到，考虑了大量的数据源，以上就是其它表引擎的全部内容。至于 Dictionary 和 Distributed 两个表引擎我们后面再说，因为涉及了还没介绍的内容。</strong></p>
<p><strong>到目前为止我们知道了除了 MergeTree 家族表引擎之外还有另外 5 种表引擎，这些表引擎丰富了 ClickHouse 的使用场景，扩充了 ClickHouse 的使用界限。下面再总结一下：</strong></p>
<ul>
<li><strong>外部存储类型的表引擎和 Hive 的外部表很类似，它们只负责元数据的管理和数据查询，自身并不负责数据的生成，数据文件直接由外部系统维护。它们可以直接读取 HDFS、本地文件、常见关系型数据库以及 Kafka 的数据。</strong></li>
<li><strong>内存类型的表引擎中的数据是常驻内存的，所以它们拥有堪比 MergeTree 的查询性能（1 亿数据量以内），其中 Set 和 Join 表引擎拥有物理存储，数据在写入内存的同时也会被刷到磁盘；而 Memory 和 Buffer 表引擎在服务重启之后，数据便会被清空。内存类表引擎是一把双刃剑，在数据大于 1 亿的场景下不建议使用内存类型的表引擎。</strong></li>
<li><strong>接口类型的表引擎自身并不存储任何数据，而是像粘合剂一样可以整合其它的数据表，其中 Merge 表引擎能够合并查询任意两张表结构相同的数据表；Dictionary 表引擎能够代理查询数据字典；而 Distributed 表引擎的作用类似分布式数据库的分表中间件，能够帮助用户简化数据的分发和路由工作。</strong></li>
<li><strong>其它类型的表引擎用途各不相同，其中 Live View 是一种特殊的视图，能够对 SQL 查询进行实时监听；Null 表引擎类似于 Linux 系统的空设备 &#x2F;dev&#x2F;null，通常和物化视图一起搭配使用；而 URL 表引擎类似于 HTTP 客户端，能够代理调用远端的 REST 服务。</strong></li>
</ul>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 中的数据查询以及各种子句(九)</title>
    <url>/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/</url>
    <content><![CDATA[<h1 id="ClickHouse-中的数据查询以及各种子句-九"><a href="#ClickHouse-中的数据查询以及各种子句-九" class="headerlink" title="ClickHouse 中的数据查询以及各种子句(九)"></a>ClickHouse 中的数据查询以及各种子句(九)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><p><strong>作为一款 OLAP 型的数据库，它的查询功能可谓是重中之重，而且我相信大家在绝大部分时间都在使用它的查询功能，事实上，在日常运转的过程中，数据查询也是 ClickHouse 的主要工作之一。ClickHouse 完全使用 SQL 作为查询语言，能够以 SELECT 查询语句的形式从数据库中选取数据，这也是它具备流行潜质的重要原因。虽然 ClickHouse 拥有优秀的查询性能，但是我们也不能滥用查询，掌握 ClickHouse 所支持的各种查询子句，并选择合理的查询形式是很有必要的。使用不恰当的 SQL 语句进行查询不仅会带来低性能，还可能导致不可预知的系统错误。</strong></p>
<p><strong>虽然在上面的示例中，我们已经见识过一些查询语句的用法，但那些都是为了演示效果简化后的代码，与真正的生产环境中的代码相差较大。例如在绝大部分场景中，都应该避免使用 SELECT * 来查询数据，因为通配符 * 对于采用列式存储的 ClickHouse 而言没有任何好处。假如面对一张拥有数百个列字段的数据表，下面这两条 SELECT 语句的性能可能会相差 100 倍之多：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span>;</span><br><span class="line"><span class="keyword">SELECT</span> col <span class="keyword">FROM</span> <span class="keyword">table</span>;</span><br></pre></td></tr></table></figure>

<p><strong>使用通配符 * 和按列查询相比，性能可能相差 100 倍，另外 ClickHouse 对于 SQL 语句的解析是大小写敏感的，这意味着 SELECT a 和 SELECT A 表示的语义是不相同的，但关键字大小写不敏感，不过还是建议遵循规范使用大写。此外 ClickHouse 的类型也大小写敏感，比如：UInt8 不可以写成 uint8，String 不可以写成 string；还有大部分函数也是大小写敏感，这些函数都是 ClickHouse 独有的，或者说你在其它关系型数据库中见不到的，但是像 min、max、length、sum、count 等等这些在其它关系型库中也能看到的函数，在 ClickHouse 中则是大小写不敏感的。</strong></p>
<p><strong>下面介绍 ClickHouse 的查询语法，ClickHouse 支持的查询子句和我们平常使用的关系型数据库非常类似，但是在此基础上又提供了很多新的功能，我们来看一下。</strong></p>
<blockquote>
<p><strong>虽然 ClickHouse 的查询是重中之重，但毕竟采用的是 SQL 语法，因此像什么如何起别名、比较运算符、条件运算符等等，这些比较基础的内容就不说了。</strong></p>
</blockquote>
<h2 id="WITH-子句"><a href="#WITH-子句" class="headerlink" title="WITH 子句"></a>WITH 子句</h2><p><strong>ClickHouse 支持 CTE（Common Table Expression，公共表表达式），以增强查询语句的表达。例如下面的函数嵌套：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> pow(pow(<span class="number">2</span>, <span class="number">2</span>), <span class="number">3</span>); </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─pow(pow(2, 2), 3)─┐</span></span><br><span class="line"><span class="comment">│                64 │</span></span><br><span class="line"><span class="comment">└───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>在改用 CTE 的形式后，可以极大地提高语句的可读性和可维护性，简化后的语句如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> pow(<span class="number">2</span>, <span class="number">2</span>) <span class="keyword">AS</span> a <span class="keyword">SELECT</span> pow(a, <span class="number">3</span>); </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─pow(a, 3)─┐</span></span><br><span class="line"><span class="comment">│        64 │</span></span><br><span class="line"><span class="comment">└───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>在 ClickHouse 中的 CTE 通过 WITH 子句表示，而语法格式显然很简单，想象一下编程语言中的变量定义，一般都类似于：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var = 表达式</span><br></pre></td></tr></table></figure>

<p><strong>在后续的的代码编写中，可以使用 var 来代替相应的表达式，而在 ClickHouse 中也是同理：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WITH 表达式 AS var</span><br></pre></td></tr></table></figure>

<p><strong>通过 WITH，我们即可在查询中使用 var 来代替表达式，而根据表达式的不同，可以有以下几种用法：</strong></p>
<h4 id="1-表达式为常量"><a href="#1-表达式为常量" class="headerlink" title="1. 表达式为常量"></a>1. 表达式为常量</h4><p><strong>此时相当于为常量起了一个有意义的名字，这些名字能够在后续的查询子句中被直接访问。例如下面示例中的 start，被直接用在紧接着的 WHERE 子句中：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="number">10</span> <span class="keyword">AS</span> <span class="keyword">start</span></span><br><span class="line"><span class="keyword">SELECT</span> number <span class="keyword">FROM</span> system.numbers <span class="comment">-- 这是一张系统表</span></span><br><span class="line"><span class="keyword">WHERE</span> number <span class="operator">&gt;</span> <span class="keyword">start</span> LIMIT <span class="number">5</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─number─┐</span></span><br><span class="line"><span class="comment">│     11 │</span></span><br><span class="line"><span class="comment">│     12 │</span></span><br><span class="line"><span class="comment">│     13 │</span></span><br><span class="line"><span class="comment">│     14 │</span></span><br><span class="line"><span class="comment">│     15 │</span></span><br><span class="line"><span class="comment">└────────┘</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><strong>如果没有 WITH 子句，那么直接把 start 换成 10 即可，只不过通过 WITH 我们给 10 这个常量起了一个有意义的名字。当然常量不仅是整数，字符串、浮点数、甚至数组都是可以的。</strong></p>
<h4 id="2-表达式为函数调用"><a href="#2-表达式为函数调用" class="headerlink" title="2. 表达式为函数调用"></a>2. 表达式为函数调用</h4><p><strong>感觉此时就类似于替换，例如在下面的示例中，对 data_uncompressed_bytes 使用聚合函数求和后，又紧接着在 SELECT 子句中对其进行了格式化处理。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="built_in">SUM</span>(data_uncompressed_bytes) <span class="keyword">AS</span> bytes</span><br><span class="line"><span class="keyword">SELECT</span> database, formatReadableSize(bytes) <span class="keyword">AS</span> format</span><br><span class="line"><span class="keyword">FROM</span> system.columns</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> database</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> bytes <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─database─┬─format───┐</span></span><br><span class="line"><span class="comment">│ system   │ 5.32 GiB │</span></span><br><span class="line"><span class="comment">│ default  │ 0.00 B   │</span></span><br><span class="line"><span class="comment">└──────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果不使用 WITH 子句，那么 SELECT 里面出现的就是 formatReadableSize(SUM(data_uncompressed_bytes))，这样读起来不是很方便，所以使用 WITH 子句将里面的聚合函数调用起一个名字叫 bytes，那么后面的查询直接使用 bytes 即可。</strong></p>
<h4 id="3-表达式为子查询"><a href="#3-表达式为子查询" class="headerlink" title="3. 表达式为子查询"></a>3. 表达式为子查询</h4><p><strong>表达式也可以是一个子查询，例如在下面的示例中，借助子查询可以得出各 database 未压缩数据大小与数据总和大小的比例的排名：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- SELECT sum(data_uncompressed_bytes) FROM system.columns 会得到一个数值</span></span><br><span class="line"><span class="comment">-- 因此本质上和表达式为常量是类似的，只不过多了一个计算的过程</span></span><br><span class="line"><span class="keyword">WITH</span> (<span class="keyword">SELECT</span> <span class="built_in">sum</span>(data_uncompressed_bytes) <span class="keyword">FROM</span> system.columns) <span class="keyword">AS</span> total_bytes</span><br><span class="line"><span class="keyword">SELECT</span> database, </span><br><span class="line">       (<span class="built_in">sum</span>(data_uncompressed_bytes) <span class="operator">/</span> total_bytes) <span class="operator">*</span> <span class="number">100</span> <span class="keyword">AS</span> database_disk_usage</span><br><span class="line"><span class="keyword">FROM</span> system.columns</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> database</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> database_disk_usage <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─database─┬─database_disk_usage─┐</span></span><br><span class="line"><span class="comment">│ system   │                 100 │</span></span><br><span class="line"><span class="comment">│ default  │                   0 │</span></span><br><span class="line"><span class="comment">└──────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>使用 WITH 子句时有一点需要特别注意，表达式只能返回的数据不能超过 1 行，否则会抛出异常。我们举个栗子：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155856488-1272004322.png" alt="img"></p>
<p><strong>这里的 WITH AS 就类似于编程语言中的变量赋值，但你不可能让一个变量指代多个值，如果想这么做，那么就将这些值放在一个容器（列表、集合、字典等等）里面。同理，如果 WITH 的表达式返回了多行数据，那么可以将其变成一个数组：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 这里见到了一个函数 groupArray，我们可以把它当成是普通的聚合函数来理解</span></span><br><span class="line"><span class="comment">-- 类似于 sum，sum 是对同一组的元素进行求和，groupArray 是将同一组的元素组合成数组</span></span><br><span class="line"><span class="keyword">WITH</span> (<span class="keyword">SELECT</span> groupArray(number) <span class="keyword">FROM</span> numbers(<span class="number">10</span>)) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arr;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arr───────────────────┐</span></span><br><span class="line"><span class="comment">│ [0,1,2,3,4,5,6,7,8,9] │</span></span><br><span class="line"><span class="comment">└───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>显然此时就没问题了，并且相比关系型数据库，ClickHouse 在行列转换的时候尤为方便。</strong></p>
<h4 id="4-在子查询中重复使用WITH"><a href="#4-在子查询中重复使用WITH" class="headerlink" title="4. 在子查询中重复使用WITH"></a>4. 在子查询中重复使用WITH</h4><p><strong>在子查询中可以嵌套使用 WITH 子句，例如在下面的示例中，在计算出各 database 未压缩数据大小与数据总和的比例之后，又进行了取整函数的调用：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> round(database_disk_usage) <span class="keyword">AS</span> database_disk_usage_v1</span><br><span class="line"><span class="keyword">SELECT</span> database, database_disk_usage, database_disk_usage_v1</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">    <span class="comment">-- 嵌套</span></span><br><span class="line">    <span class="keyword">WITH</span> (<span class="keyword">SELECT</span> <span class="built_in">sum</span>(data_uncompressed_bytes) <span class="keyword">FROM</span> system.columns) <span class="keyword">AS</span> total_bytes</span><br><span class="line">    <span class="keyword">SELECT</span> database, (<span class="built_in">sum</span>(data_uncompressed_bytes) <span class="operator">/</span> total_bytes) <span class="operator">*</span> <span class="number">100</span> <span class="keyword">AS</span> database_disk_usage</span><br><span class="line">    <span class="keyword">FROM</span> system.columns <span class="keyword">GROUP</span> <span class="keyword">BY</span> database <span class="keyword">ORDER</span> <span class="keyword">BY</span> database_disk_usage <span class="keyword">DESC</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>虽然看起来有点复杂，但是不难理解，不考虑 WITH 的话，那么就是一个嵌套子查询：SELECT … FROM (SELECT … FROM)，只不过两个 SELECT 里面的 database_disk_usage_v1、total_bytes 是用 WITH 声明的变量。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155847398-1492024351.png" alt="img"></p>
<p><strong>而且我们看到如果子查询是作为一张表使用的，那么在关系型数据库中应该起一个别名，但在 ClickHouse 可以不用。</strong></p>
<p><strong>总的来说，WITH 子句就相当于起一个别名，如果你看某个表达式长得不顺眼，那么就可以使用 WITH 将它替换掉，就这么简单。而且一个 WITH 子句是可以为多个表达式起别名的，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="number">1</span> <span class="keyword">AS</span> a, <span class="number">2</span> <span class="keyword">AS</span> b <span class="keyword">SELECT</span> a <span class="operator">+</span> b; </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─plus(a, b)─┐</span></span><br><span class="line"><span class="comment">│          3 │</span></span><br><span class="line"><span class="comment">└────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="其它关系型数据库的-WITH-子句"><a href="#其它关系型数据库的-WITH-子句" class="headerlink" title="其它关系型数据库的 WITH 子句"></a>其它关系型数据库的 WITH 子句</h4><p><strong>ClickHouse 的 WITH 语句和其它的关系型数据库还是有很大差别的，比如 PostgreSQL。如果 PostgreSQL 的话，那么 AS 之后的结果是会被当成是一张表，举个例子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 假设存在一张表叫 girls, 如果是 PostgreSQL 的话</span></span><br><span class="line"><span class="keyword">WITH</span> tmp <span class="keyword">AS</span> (</span><br><span class="line">	<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> girls <span class="keyword">WHERE</span> id <span class="operator">&lt;</span> <span class="number">100</span> </span><br><span class="line">)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tmp <span class="keyword">WHERE</span> age <span class="operator">&gt;</span> <span class="number">20</span>;</span><br><span class="line"><span class="comment">-- 这么做的话, 在 PostgreSQL 中是完全正确的做法，此时的 tmp 就是 table 中 id 小于 100 的记录组成的结果集</span></span><br><span class="line"><span class="comment">-- 并且它可以作为一张临时表来使用</span></span><br><span class="line"><span class="comment">-- 我们这个示例比较简单, 但是当子查询比较复杂的时候, 通过将子查询当做一张临时表, 可以使查询逻辑更加清晰</span></span><br><span class="line"><span class="comment">-- 并且查询结束之后, 这张临时表也就不存在了</span></span><br><span class="line"><span class="comment">-- 上面这段代码和下面都是等价的</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> girls <span class="keyword">WHERE</span> id <span class="operator">&lt;</span> <span class="number">100</span> <span class="keyword">AND</span> age <span class="operator">&gt;</span> <span class="number">20</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> girls <span class="keyword">WHERE</span> id <span class="operator">&lt;</span> <span class="number">100</span>) tmp <span class="keyword">WHERE</span> age <span class="operator">&gt;</span> <span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<p><strong>所以 ClickHouse 的 WITH 中的表达式必须只能有一行，它就等价于为某个复杂的表达式起一个别名，不可以放在 FROM 后面作为临时表来使用。而 PostgreSQL 的 WITH 中的表达式没有任何限制，可以返回任何数据，行数不限，并且可以当成临时表放在 FROM 后面。除此之外，ClickHouse 和 PostgreSQL 的 WITH 语句还有一处不同，那就是 ClickHouse 中别名在 AS 后面，而 PostgreSQL 中别名在 AS 前面。</strong></p>
<blockquote>
<p><strong>注意：WITH 中的表达式如果是子查询，那么会提前计算好，在使用别名的时候使用的是已经计算好的结果。</strong></p>
</blockquote>
<p><strong>问题来了，既然行数有限制，那列数有没有限制呢？我们试一下就知道了，首先创建一张 Memory 数据表，内容如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> women</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─name─────┬─age─┐</span></span><br><span class="line"><span class="comment">│  1 │ 古明地觉  │  17 │</span></span><br><span class="line"><span class="comment">│  2 │ 芙兰朵露  │ 144 │</span></span><br><span class="line"><span class="comment">│  3 │ 琪露诺    │  58 │</span></span><br><span class="line"><span class="comment">└────┴──────────┴─────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>然后我们来进行查询：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155837104-1321089989.png" alt="img"></p>
<p><strong>同理通过 WITH，我们还可以实现为字段起别名的效果，举个栗子：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155830593-127511004.png" alt="img"></p>
<p><strong>不过这种做法显然没有太大意义，除非字段名太长了，想起一个短点儿的。</strong></p>
<p><strong>以上就是 WITH 子句，非常简单，核心就一句话：给表达式起别名，后续使用别名来对表达式进行替换。</strong></p>
<h2 id="FROM-子句"><a href="#FROM-子句" class="headerlink" title="FROM 子句"></a>FROM 子句</h2><p><strong>FROM 子句表示从何处读取数据，目前支持如下 3 种形式。</strong></p>
<p><strong>1. 从数据表中取数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> name <span class="keyword">FROM</span> people</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>2. 从子查询中取数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> max_id <span class="keyword">FROM</span></span><br><span class="line">(<span class="keyword">SELECT</span> <span class="built_in">max</span>(id) <span class="keyword">AS</span> max_id <span class="keyword">FROM</span> people)</span><br><span class="line"><span class="comment">-- 在其它关系型数据库中, 如果子查询作为一张表来使用, 那么必须要起一个别名</span></span><br><span class="line"><span class="comment">-- 但是在 ClickHouse 中不需要, 个人觉得这是个不错的决定，因为起别名我们又不用</span></span><br></pre></td></tr></table></figure>

<hr>
<p><strong>3. 从表函数中取数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(N) <span class="comment">-- 会返回 0 到 N - 1 </span></span><br></pre></td></tr></table></figure>

<p><strong>另外 FROM 关键字可以省略，我们在介绍 WITH 子句的时候多次省略 FROM，因为 SELECT 后面是标量，此时会从虚拟表中取值。在 ClickHouse 中，并没有数据库中常见的 DUAL 虚拟表，取而代之的是 system.one。举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 等价于 SELECT 1, 2, 3 FROM system.one，</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>;  </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─1─┬─2─┬─3─┐</span></span><br><span class="line"><span class="comment">│ 1 │ 2 │ 3 │</span></span><br><span class="line"><span class="comment">└───┴───┴───┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span> <span class="operator">+</span> <span class="number">2</span>, <span class="number">2</span> <span class="operator">*</span> <span class="number">3</span>;  <span class="comment">-- 此时可以当成计算器来使用</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─plus(1, 2)─┬─multiply(2, 3)─┐</span></span><br><span class="line"><span class="comment">│          3 │              6 │</span></span><br><span class="line"><span class="comment">└────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;KOMEIJI SATORI&#x27;</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─[1, 2, 3]─┬─&#x27;KOMEIJI SATORI&#x27;─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3]   │ KOMEIJI SATORI   │</span></span><br><span class="line"><span class="comment">└───────────┴──────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h2 id="ARRAY-JOIN-子句"><a href="#ARRAY-JOIN-子句" class="headerlink" title="ARRAY JOIN 子句"></a>ARRAY JOIN 子句</h2><p><strong>ARRAY JOIN 子句允许在数据表的内部，与数组或嵌套类型的字段进行 JOIN 操作，从而将一行数组展开为多行。接下来让我们看看它的基础用法，首先新建一张包含 Array 数组字段的测试表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1 (</span><br><span class="line">    title String,</span><br><span class="line">    <span class="keyword">value</span> <span class="keyword">Array</span>(UInt8)</span><br><span class="line">) ENGINE <span class="operator">=</span> Memory();</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 然后写入数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span> (<span class="string">&#x27;food&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), (<span class="string">&#x27;fruit&#x27;</span>, [<span class="number">3</span>, <span class="number">4</span>]), (<span class="string">&#x27;meat&#x27;</span>, []);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t1;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─value───┐</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3] │</span></span><br><span class="line"><span class="comment">│ fruit │ [3,4]   │</span></span><br><span class="line"><span class="comment">│ meat  │ []      │</span></span><br><span class="line"><span class="comment">└───────┴─────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>在一条 SELECT 语句中，只能存在一个 ARRAY JOIN（使用子查询除外），目前支持 INNER 和 LEFT 两种 JOIN 策略：</strong></p>
<h4 id="INNER-ARRAY-JOIN"><a href="#INNER-ARRAY-JOIN" class="headerlink" title="INNER ARRAY JOIN"></a>INNER ARRAY JOIN</h4><p><strong>ARRAY JOIN 在默认情况下使用的是 INNER JOIN 策略，例如下面的语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, <span class="keyword">value</span> <span class="keyword">FROM</span> t1 <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> <span class="keyword">value</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─value─┐</span></span><br><span class="line"><span class="comment">│ food  │     1 │</span></span><br><span class="line"><span class="comment">│ food  │     2 │</span></span><br><span class="line"><span class="comment">│ food  │     3 │</span></span><br><span class="line"><span class="comment">│ fruit │     3 │</span></span><br><span class="line"><span class="comment">│ fruit │     4 │</span></span><br><span class="line"><span class="comment">└───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>从查询结果可以发现，最终的数据基于 value 数组被展开成了多行，并且排除掉了空数组，同时会自动和其它字段进行组合（相当于按行合并）。在使用 ARRAY JOIN 时，如果还想访问展开前的数组字段，那么只需为原有的数组字段添加一个别名即可，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 如果不给 ARRAY JOIN 后面的 value 起一个别名，那么 value 就是展开后的结果</span></span><br><span class="line"><span class="comment">-- 如果给 ARRAY JOIN 后面的 value 起一个别名 val，那么 value 就还是展开前的数组字段</span></span><br><span class="line"><span class="comment">-- 而 val 才是展开后的结果，所以再反过来，让 val 出现在 SELECT 中即可</span></span><br><span class="line"><span class="keyword">SELECT</span> title, <span class="keyword">value</span>, val <span class="keyword">FROM</span> t1 <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> <span class="keyword">value</span> <span class="keyword">AS</span> val;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─value───┬─val─┐</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3] │   1 │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3] │   2 │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3] │   3 │</span></span><br><span class="line"><span class="comment">│ fruit │ [3,4]   │   3 │</span></span><br><span class="line"><span class="comment">│ fruit │ [3,4]   │   4 │</span></span><br><span class="line"><span class="comment">└───────┴─────────┴─────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们看到 ClickHouse 的确是当之无愧的最强 OLAP 数据库，不单单是速度快，最重要的是，它提供的查询语法也很方便。如果你用过 Hive 的话，会发现这里特别像里面的 lateral view explode 语法。</strong></p>
<h4 id="LEFT-ARRAY-JOIN"><a href="#LEFT-ARRAY-JOIN" class="headerlink" title="LEFT ARRAY JOIN"></a>LEFT ARRAY JOIN</h4><p><strong>ARRAY JOIN 子句支持 LEFT 连接策略，例如执行下面的语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, <span class="keyword">value</span>, val <span class="keyword">FROM</span> t1 <span class="keyword">LEFT</span> <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> <span class="keyword">value</span> <span class="keyword">AS</span> val;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─value───┬─val─┐</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3] │   1 │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3] │   2 │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3] │   3 │</span></span><br><span class="line"><span class="comment">│ fruit │ [3,4]   │   3 │</span></span><br><span class="line"><span class="comment">│ fruit │ [3,4]   │   4 │</span></span><br><span class="line"><span class="comment">│ meat  │ []      │   0 │</span></span><br><span class="line"><span class="comment">└───────┴─────────┴─────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>在改为 LEFT 连接查询后，可以发现，在 INNER JOIN 中被排除掉的空数组出现在了返回的结果集中。但此时的 val 是零值，所以 LEFT ARRAY JOIN 个人觉得不是很常用，一般都是用 ARRAY JOIN。</strong></p>
<h4 id="关于数组的一些骚操作"><a href="#关于数组的一些骚操作" class="headerlink" title="关于数组的一些骚操作"></a>关于数组的一些骚操作</h4><p><strong>在关系型数据库里面我们一般都不太喜欢用数组，但是在 ClickHouse 中数组会用的非常多，并且操作起来非常简单。ClickHouse 里面提供了非常多的函数，用好了的话，就相当于分布式的 pandas。下面就先来看一下关于数组的一些函数，这里先介绍一部分，提前感受一下 ClickHouse 的强大，首先我们创建一张新表，并写入测试数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t2;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─────────dt─┬─cash───────┐</span></span><br><span class="line"><span class="comment">│ 2020-01-01 │ [10,10,10] │</span></span><br><span class="line"><span class="comment">│ 2020-01-02 │ [20,20,20] │</span></span><br><span class="line"><span class="comment">│ 2020-01-01 │ [10,10,10] │</span></span><br><span class="line"><span class="comment">│ 2020-01-02 │ [20,20]    │</span></span><br><span class="line"><span class="comment">│ 2020-01-03 │ []         │</span></span><br><span class="line"><span class="comment">│ 2020-01-03 │ [30,30,30] │</span></span><br><span class="line"><span class="comment">└────────────┴────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>groupArray</strong></p>
<p><strong>这个函数已经出现过一次了，我们说它是把多行数据合并成一个数组，相当于是聚合函数的一种。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> dt, groupArray(cash) <span class="keyword">FROM</span> t2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> dt;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─────────dt─┬─groupArray(cash)────────┐</span></span><br><span class="line"><span class="comment">│ 2020-01-01 │ [[10,10,10],[10,10,10]] │</span></span><br><span class="line"><span class="comment">│ 2020-01-02 │ [[20,20,20],[20,20]]    │</span></span><br><span class="line"><span class="comment">│ 2020-01-03 │ [[],[30,30,30]]         │</span></span><br><span class="line"><span class="comment">└────────────┴─────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们看到 groupArray 就等同于类似 count、sum 这样的聚合函数，将同一组的数据组合成一个新的数组。由于本来的元素就是数组，所以这里就是数组嵌套数组。</strong></p>
<p><strong>除了 groupArray 之外，还有一个 groupUniqArray，在组合的时候会对元素进行去重：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> dt, groupUniqArray(cash) <span class="keyword">FROM</span> t2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> dt;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─────────dt─┬─groupUniqArray(cash)─┐</span></span><br><span class="line"><span class="comment">│ 2020-01-01 │ [[10,10,10]]         │</span></span><br><span class="line"><span class="comment">│ 2020-01-02 │ [[20,20],[20,20,20]] │</span></span><br><span class="line"><span class="comment">│ 2020-01-03 │ [[],[30,30,30]]      │</span></span><br><span class="line"><span class="comment">└────────────┴──────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们看到 ‘2020-01-01’ 这行数据被去重了。</strong></p>
<p><strong>arrayFlatten</strong></p>
<p><strong>从名字上应该能猜出来，直接看例子就明白了。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> dt, </span><br><span class="line">       groupArray(cash),</span><br><span class="line">       arrayFlatten(groupArray(cash)) <span class="keyword">FROM</span> t2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> dt;</span><br></pre></td></tr></table></figure>

<p><strong>我们在 groupArray(cash) 基础上又调用了 arrayFlatten：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155811386-223388004.png" alt="img"></p>
<p><strong>相信该函数的作用显而易见的，就是将多个嵌套数组扁平化，另外这里的查询语句还可以美化一下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 使用 WITH 子句，提前将 groupArray(cash) 起一个别名</span></span><br><span class="line"><span class="keyword">WITH</span> groupArray(cash) <span class="keyword">AS</span> group_cash</span><br><span class="line"><span class="keyword">SELECT</span> dt, </span><br><span class="line">       group_cash,</span><br><span class="line">       arrayFlatten(group_cash) <span class="keyword">FROM</span> t2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> dt;</span><br><span class="line">       </span><br><span class="line"><span class="comment">-- 或者这么做</span></span><br><span class="line"><span class="keyword">SELECT</span> dt,</span><br><span class="line">       groupArray(cash) <span class="keyword">AS</span> group_cash,</span><br><span class="line">       arrayFlatten(group_cash) <span class="keyword">FROM</span> t2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> dt;</span><br><span class="line"><span class="comment">-- 我们看到即使是在 SELECT 里面起的别名也是可以被使用的</span></span><br><span class="line"><span class="comment">-- 另外顺序也没有限制，比如下面的做法也是合法的</span></span><br><span class="line"><span class="keyword">SELECT</span> dt, </span><br><span class="line">       arrayFlatten(group_cash), </span><br><span class="line">       groupArray(cash) <span class="keyword">AS</span> group_cash <span class="keyword">FROM</span> t2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> dt;</span><br></pre></td></tr></table></figure>

<p><strong>splitByChar</strong></p>
<p><strong>将字符串按照指定字符分割成数组：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> splitByChar(<span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;komeiji^koishi&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─splitByChar(&#x27;^&#x27;, &#x27;komeiji^koishi&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;komeiji&#x27;,&#x27;koishi&#x27;]               │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayJoin</strong></p>
<p><strong>该函数和 ARRAY JOIN 子句的作用非常类似：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155803358-2134270761.png" alt="img"></p>
<p><strong>arrayMap</strong></p>
<p><strong>对数组中的每一个元素都以相同的规则进行映射：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- arrayMap(x -&gt; x * 2, value) 表示将 value 中的每一个元素都乘以 2，然后返回一个新数组</span></span><br><span class="line"><span class="comment">-- 而 mapV 就是变换过后的新数组，直接拿来用即可</span></span><br><span class="line"><span class="keyword">SELECT</span> title, arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">*</span> <span class="number">2</span>, <span class="keyword">value</span>) <span class="keyword">AS</span> mapV, v</span><br><span class="line"><span class="keyword">FROM</span> t1 <span class="keyword">LEFT</span> <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> mapV <span class="keyword">as</span> v</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─mapV────┬─v─┐</span></span><br><span class="line"><span class="comment">│ food  │ [2,4,6] │ 2 │</span></span><br><span class="line"><span class="comment">│ food  │ [2,4,6] │ 4 │</span></span><br><span class="line"><span class="comment">│ food  │ [2,4,6] │ 6 │</span></span><br><span class="line"><span class="comment">│ fruit │ [6,8]   │ 6 │</span></span><br><span class="line"><span class="comment">│ fruit │ [6,8]   │ 8 │</span></span><br><span class="line"><span class="comment">│ meat  │ []      │ 0 │</span></span><br><span class="line"><span class="comment">└───────┴─────────┴───┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 另外展开的字段也可以不止一个</span></span><br><span class="line"><span class="keyword">SELECT</span> title, </span><br><span class="line">       arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">*</span> <span class="number">2</span>, <span class="keyword">value</span>) <span class="keyword">AS</span> mapV, v,</span><br><span class="line">       <span class="keyword">value</span>, v_1</span><br><span class="line"><span class="keyword">FROM</span> t1 <span class="keyword">LEFT</span> <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> mapV <span class="keyword">as</span> v, <span class="keyword">value</span> <span class="keyword">AS</span> v_1</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─mapV────┬─v─┬─value───┬─v_1─┐</span></span><br><span class="line"><span class="comment">│ food  │ [2,4,6] │ 2 │ [1,2,3] │   1 │</span></span><br><span class="line"><span class="comment">│ food  │ [2,4,6] │ 4 │ [1,2,3] │   2 │</span></span><br><span class="line"><span class="comment">│ food  │ [2,4,6] │ 6 │ [1,2,3] │   3 │</span></span><br><span class="line"><span class="comment">│ fruit │ [6,8]   │ 6 │ [3,4]   │   3 │</span></span><br><span class="line"><span class="comment">│ fruit │ [6,8]   │ 8 │ [3,4]   │   4 │</span></span><br><span class="line"><span class="comment">│ meat  │ []      │ 0 │ []      │   0 │</span></span><br><span class="line"><span class="comment">└───────┴─────────┴───┴─────────┴─────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="嵌套类型"><a href="#嵌套类型" class="headerlink" title="嵌套类型"></a>嵌套类型</h4><p><strong>在前面介绍数据定义时曾介绍过，嵌套数据类型的本质是数组，所以 ARRAY JOIN 也支持嵌套数据类型。接下来继续用一组示例说明，首先新建一张包含嵌套类型的测试表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t3(</span><br><span class="line">    title String,</span><br><span class="line">    nested Nested</span><br><span class="line">    (</span><br><span class="line">        v1 UInt32,</span><br><span class="line">        v2 UInt64</span><br><span class="line">    )</span><br><span class="line">) ENGINE <span class="operator">=</span> <span class="built_in">Log</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 接着写入测试数据</span></span><br><span class="line"><span class="comment">-- 在写入嵌套数据类型时，记得同一行数据中各个数组的长度需要对齐，而对多行数据之间的数组长度没有限制</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t3</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;food&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>]),</span><br><span class="line">       (<span class="string">&#x27;fruit&#x27;</span>, [<span class="number">4</span>, <span class="number">5</span>], [<span class="number">40</span>, <span class="number">50</span>]),</span><br><span class="line">       (<span class="string">&#x27;meat&#x27;</span>, [], [])</span><br></pre></td></tr></table></figure>

<p><strong>对嵌套类型数据的访问，ARRAY JOIN 既可以直接使用字段列名：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155751689-560561486.png" alt="img"></p>
<p><strong>也可以使用点访问符的形式：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- nested 只有 v1 和 v2</span></span><br><span class="line"><span class="comment">-- 所以 ARRAY JOIN nested.v1, nested.v2 等价于 ARRAY JOIN nested</span></span><br><span class="line"><span class="keyword">SELECT</span> title, nested.v1, nested.v2 <span class="keyword">FROM</span> t3 <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> nested.v1, nested.v2</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─nested.v1─┬─nested.v2─┐</span></span><br><span class="line"><span class="comment">│ food  │         1 │        10 │</span></span><br><span class="line"><span class="comment">│ food  │         2 │        20 │</span></span><br><span class="line"><span class="comment">│ food  │         3 │        30 │</span></span><br><span class="line"><span class="comment">│ fruit │         4 │        40 │</span></span><br><span class="line"><span class="comment">│ fruit │         5 │        50 │</span></span><br><span class="line"><span class="comment">└───────┴───────────┴───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>嵌套类型也支持 ARRAY JOIN 部分嵌套字段：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, nested.v1, nested.v2 <span class="keyword">FROM</span> t3 <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> nested.v1</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─nested.v1─┬─nested.v2──┐</span></span><br><span class="line"><span class="comment">│ food  │         1 │ [10,20,30] │</span></span><br><span class="line"><span class="comment">│ food  │         2 │ [10,20,30] │</span></span><br><span class="line"><span class="comment">│ food  │         3 │ [10,20,30] │</span></span><br><span class="line"><span class="comment">│ fruit │         4 │ [40,50]    │</span></span><br><span class="line"><span class="comment">│ fruit │         5 │ [40,50]    │</span></span><br><span class="line"><span class="comment">└───────┴───────────┴────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>可以看到，在这种情形下，只有被 ARRAY JOIN 的数组才会展开。</strong></p>
<p><strong>在查询嵌套类型时也能够通过别名的形式访问原始数组：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, </span><br><span class="line">       nested.v1, nested.v2, </span><br><span class="line">       n.v1, n.v2  </span><br><span class="line"><span class="keyword">from</span> t3 <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> nested <span class="keyword">AS</span> n;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─nested.v1─┬─nested.v2──┬─n.v1─┬─n.v2─┐</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3]   │ [10,20,30] │    1 │   10 │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3]   │ [10,20,30] │    2 │   20 │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3]   │ [10,20,30] │    3 │   30 │</span></span><br><span class="line"><span class="comment">│ fruit │ [4,5]     │ [40,50]    │    4 │   40 │</span></span><br><span class="line"><span class="comment">│ fruit │ [4,5]     │ [40,50]    │    5 │   50 │</span></span><br><span class="line"><span class="comment">└───────┴───────────┴────────────┴──────┴──────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 所以 ARRAY JOIN nested 后面如果没有 AS，那么这个 nested.v1 和 nest.v2 就是展开后的值</span></span><br><span class="line"><span class="comment">-- 如果 ARRAY JOIN nested AS n，起了一个别名，那么 nested.v1 和 nest.v2 就是展开前值，也就是数组本身</span></span><br><span class="line"><span class="comment">-- 而 n.v1 和 n.v2 才是展开后的值</span></span><br><span class="line"><span class="comment">-- 另外 ARRAY JOIN nested AS n，这个 n 可以不使用</span></span><br><span class="line"><span class="keyword">SELECT</span> title, </span><br><span class="line">       nested.v1, nested.v2</span><br><span class="line"><span class="keyword">from</span> t3 <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> nested <span class="keyword">AS</span> n;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─title─┬─nested.v1─┬─nested.v2──┐</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3]   │ [10,20,30] │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3]   │ [10,20,30] │</span></span><br><span class="line"><span class="comment">│ food  │ [1,2,3]   │ [10,20,30] │</span></span><br><span class="line"><span class="comment">│ fruit │ [4,5]     │ [40,50]    │</span></span><br><span class="line"><span class="comment">│ fruit │ [4,5]     │ [40,50]    │</span></span><br><span class="line"><span class="comment">└───────┴───────────┴────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h2 id="JOIN-子句"><a href="#JOIN-子句" class="headerlink" title="JOIN 子句"></a>JOIN 子句</h2><p><strong>JOIN 子句可以对左右两张表的数据进行连接，这是最常用的查询子句之一，它的语法包含连接精度和连接类型两部分。目前 ClickHouse 支持的 JOIN 子句形式如图所示：</strong></p>
<p><strong>由上图可知，连接精度分为 ALL、ANY 和 ASOF 三种（准确的说是五种，还有 SEMI 和 ANTI，这两个过会再提），而连接类型也可分为外连接、内连接和交叉连接三种。</strong></p>
<p><strong>除此之外，JOIN 查询还可以根据其执行策略被划分为本地查询和远程查询。关于远程查询的内容放在后续章节进行说明，这里着重讲解本地查询。</strong></p>
<h4 id="连接精度"><a href="#连接精度" class="headerlink" title="连接精度"></a>连接精度</h4><p><strong>连接精度决定了 JOIN 查询在连接数据时所使用的策略，目前支持 ALL、ANY 和 ASOF 三种类型。如果不主动声明，则默认是 ALL。可以通过 join_default_strictness 配置参数修改默认的连接精度类型。</strong></p>
<p><strong>那么这个连接精度指的是啥呢？举个栗子就明白了。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_1;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─count─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │    30 │</span></span><br><span class="line"><span class="comment">│  2 │ A002  │    28 │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │    32 │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_2;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code2─┬─count─┐</span></span><br><span class="line"><span class="comment">│  1 │ B001  │    35 │</span></span><br><span class="line"><span class="comment">│  1 │ B001  │    29 │</span></span><br><span class="line"><span class="comment">│  3 │ B003  │    31 │</span></span><br><span class="line"><span class="comment">│  4 │ B004  │    38 │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>以上是用于测试的表数据，下面进行测试：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2 </span><br><span class="line"><span class="keyword">FROM</span> tbl_1 <span class="keyword">AS</span> t1 </span><br><span class="line"><span class="keyword">ALL</span> <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_2 <span class="keyword">AS</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">-- 一切正常，跟一般的关系型数据库是类似的，但如果将 ALL 改成 ANY</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2 </span><br><span class="line"><span class="keyword">FROM</span> tbl_1 <span class="keyword">AS</span> t1 </span><br><span class="line"><span class="keyword">ANY</span> <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_2 <span class="keyword">AS</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>所以结论很清晰了，如果左表内的一行数据，在右表中有多行数据与之连接匹配，那么当连接精度为 ALL，会返回右表中全部连接的数据；当连接精度为 ANY，会仅返回右表中第一行连接的数据</strong></p>
<p><strong>这就是连接精度，没什么好稀奇的，不过在关系型数据库中则没有连接精度的概念，因为当出现这种情况，只有一个策略，那就是直接返回右表中匹配的全部数据。而在 ClickHouse 中，给了我们自由选择的权利。</strong></p>
<p><strong>除了 ALL 和 ANY 之外还有一个 ASOF，它是做什么的呢？首先无论 ALL 还是 ANY，在连接的时候必须是等值连接。比如上面的 t1.id &#x3D; t2.id，如果改成 t1.id &gt;&#x3D; t2.id 就是错误的，如果是多个连接条件，那么这些连接条件都必须是等值连接。但 ASOF 表示模糊连接，也就是它允许你在等值连接的后面加上一个非等值连接，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2, t1.count <span class="keyword">AS</span> count1, t2.count <span class="keyword">AS</span> count2</span><br><span class="line"><span class="keyword">FROM</span> tbl_1 <span class="keyword">AS</span> t1 </span><br><span class="line"><span class="keyword">ALL</span> <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_2 <span class="keyword">AS</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┬─count1─┬─count2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │     30 │     35 │</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │     30 │     29 │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │     32 │     31 │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┴────────┴────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2, t1.count <span class="keyword">AS</span> count1, t2.count <span class="keyword">AS</span> count2</span><br><span class="line"><span class="keyword">FROM</span> tbl_1 <span class="keyword">AS</span> t1 </span><br><span class="line">ASOF <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_2 <span class="keyword">AS</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id <span class="keyword">AND</span> t1.count <span class="operator">&gt;</span> t2.count;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┬─count1─┬─count2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │     30 │     29 │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │     32 │     31 │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┴────────┴────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2, t1.count <span class="keyword">AS</span> count1, t2.count <span class="keyword">AS</span> count2</span><br><span class="line"><span class="keyword">FROM</span> tbl_1 <span class="keyword">AS</span> t1 </span><br><span class="line">ASOF <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_2 <span class="keyword">AS</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id <span class="keyword">AND</span> t1.count <span class="operator">&lt;</span> t2.count;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┬─count1─┬─count2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │     30 │     35 │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┴────────┴────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>所以结论很清晰，如果连接精度为 ALL 或者 ANY，那么所有的连接条件必须为等值连接，如果出现了非等值连接则报错。而这两者的唯一区别就在于：</strong></p>
<ul>
<li><code>ALL：如果右表有多条数据匹配，返回所有的匹配的数据</code></li>
<li><code>ANY：如果右表有多条数据匹配，返回第一条匹配的数据</code></li>
</ul>
<p><strong>如果连接精度为 ASOF，那么允许在等值连接条件后面追加一个非等值连接，所以上面的 t1.id &#x3D; t2.id 是等值连接，t1.count &gt; t2.count 是非等值连接。但需要注意的是：使用非等值连接时，这个非等值可以是 &gt;、&gt;&#x3D;、&lt;、&lt;&#x3D;，但不能是 !&#x3D;；并且对于 ASOF 而言，连接条件必须是等值连接和非等值连接的组合，两者缺一不可。</strong></p>
<blockquote>
<p><strong>对于 ASOF 而言，如果右表中有多行数据匹配，只会返回第一行。</strong></p>
</blockquote>
<h4 id="连接类型"><a href="#连接类型" class="headerlink" title="连接类型"></a>连接类型</h4><p><strong>连接类型就比较简单了，这个和关系型数据库是完全类似的。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 省略连接精度，默认为 ALL</span></span><br><span class="line"><span class="comment">-- 左连接</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2 </span><br><span class="line"><span class="keyword">FROM</span> tbl_1 t1 <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tbl_2 t2 </span><br><span class="line"><span class="keyword">USING</span>(id); <span class="comment">-- 等价于 t1.id = t2.id</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  2 │ A002  │       │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 右连接</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2 </span><br><span class="line"><span class="keyword">FROM</span> tbl_1 t1 <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> tbl_2 t2 </span><br><span class="line"><span class="keyword">USING</span>(id);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  4 │       │ B004  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 全连接</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2 </span><br><span class="line"><span class="keyword">FROM</span> tbl_1 t1 <span class="keyword">FULL</span> <span class="keyword">JOIN</span> tbl_2 t2 </span><br><span class="line"><span class="keyword">USING</span>(id);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  1 │ A001  │ B001  │</span></span><br><span class="line"><span class="comment">│  2 │ A002  │       │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  4 │       │ B004  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>和关系型数据库类似，但有一点区别，就是当没有与之匹配的记录时，会使用对应类型的空值进行补全，而不是 Null。这里没有指定连接精度，默认为 ALL，此外 LEFT &#x2F; RIGHT &#x2F; FULL JOIN 后面都可以加上一个 OUTER，不过也可以不加。最后是交叉连接，交叉连接直接会去笛卡尔积，不需要任何的连接条件。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155733180-1723661310.png" alt="img"></p>
<h4 id="SEMI-和-ANTI"><a href="#SEMI-和-ANTI" class="headerlink" title="SEMI 和 ANTI"></a>SEMI 和 ANTI</h4><p><strong>我们之前说连接精度不止 ALL、ANY、ASOF 三种，还有 SEMI 和 ANTI，只不过这两个比较特殊，因为它们只能用在 LEFT JOIN 和 RIGHT JOIN 上面，所以我们单独介绍。</strong></p>
<ul>
<li><code>t1 SEMI LEFT JOIN t2 USING(id)：遍历 t1 中的 id，如果存在于 t2 中，则输出</code></li>
<li><code>t1 SEMI RIGHT JOIN t2 USING(id)：遍历 t2 中的 id，如果存在于 t1 中，则输出</code></li>
<li><code>t1 ANTI LEFT JOIN t2 USING(id)：遍历 t1 中的 id，如果不存在于 t2 中，则输出</code></li>
<li><code>t1 ANTI RIGHT JOIN t2 USING(id)：遍历 t2 中的 id，如果不存在于 t1 中，则输出</code></li>
</ul>
<p><strong>我们举个栗子：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155724985-600169291.png" alt="img"></p>
<p><strong>ANTI 则与之类似，只不过它的策略是不出现才输出，可以自己尝试一下。另外可能有人发现，这个 SEMI 的功能貌似有些重复了，因为我们使用 ALL 和 ANY 完全可以取代。其实如果你用过 hive 的话，会发现 SEMI LEFT JOIN 和 ANTI LEFT JOIN 是 IN&#x2F;EXISTS 的一种更加高效的实现：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 这种子查询应该非常常见了，查询一张表，而过滤的条件该表的某个字段的取值要出现在另一张表的某个字段中</span></span><br><span class="line"><span class="keyword">SELECT</span> id, code1 <span class="keyword">FROM</span> tbl_1 <span class="keyword">WHERE</span> id <span class="keyword">in</span> (<span class="keyword">SELECT</span> id <span class="keyword">FROM</span> tbl_2);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │</span></span><br><span class="line"><span class="comment">└────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 而通过 SEMI LEFT JOIN 的话，效率会更高一些</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1 <span class="keyword">FROM</span> tbl_1 t1 </span><br><span class="line">SEMI <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tbl_2 t2 <span class="keyword">USING</span>(id)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┐</span></span><br><span class="line"><span class="comment">│  1 │ A001  │</span></span><br><span class="line"><span class="comment">│  3 │ A003  │</span></span><br><span class="line"><span class="comment">└────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- ANTI 则是为了 NOT IN/EXISTS </span></span><br></pre></td></tr></table></figure>

<p><strong>两者的输出是一致的，所以 SEMI &#x2F; ANTI LEFT JOIN 是为了 IN&#x2F;EXISTS 这类场景而设计的，至于 SEMI RIGHT JOIN、ANTI RIGHT JOIN 就用的不是很多了。</strong></p>
<p><strong>Hive 里有一个 LEFT SEMI JOIN，单词顺序调换了一下，用途是类似的，不过它的局限性要比 ClickHouse 中的 SEMI LEFT JOIN 大很多。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Hive，这个 t2.xxx 只能出现在 ON 子句中用于连接，不可用在其它地方</span></span><br><span class="line">t1 <span class="keyword">LEFT</span> SEMI <span class="keyword">JOIN</span> t2 <span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ClickHouse，t2.xxx 除了可以出现在 ON 子句中，可以出现在 SELECT 子句中，WHERE 子句中</span></span><br><span class="line">t1 SEMI <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> t2 <span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 举个栗子：</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2 </span><br><span class="line"><span class="keyword">FROM</span> tbl_1 t1 SEMI </span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tbl_2 t2 </span><br><span class="line"><span class="keyword">USING</span>(id) <span class="keyword">where</span> t2.code2 <span class="operator">=</span> <span class="string">&#x27;B003&#x27;</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─id─┬─code1─┬─code2─┐</span></span><br><span class="line"><span class="comment">│  3 │ A003  │ B003  │</span></span><br><span class="line"><span class="comment">└────┴───────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>另外 Hive 里面只有 LEFT SEMI JOIN，没有其它的，但 ClickHouse 的选择就多了很多。</strong></p>
<h4 id="多表连接"><a href="#多表连接" class="headerlink" title="多表连接"></a>多表连接</h4><p><strong>在进行多张数据表的连接查询时，ClickHouse 会将它们转为两两连接的形式。我们首先再创建一张表：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155714466-1251789186.png" alt="img"></p>
<p><strong>然后对三张测试表进行连接查询：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2, t3.code3</span><br><span class="line"><span class="keyword">FROM</span> tbl_1 <span class="keyword">AS</span> t1 <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_2 <span class="keyword">AS</span> t2 <span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tbl_3 <span class="keyword">AS</span> t3 <span class="keyword">ON</span> t1.id <span class="operator">=</span> t3.id</span><br></pre></td></tr></table></figure>

<p><strong>在执行上述查询时，tbl_1 和 tbl_2 会先进行内连接，之后再将它们的结果集合 tbl_3 进行左连接。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155706262-2109411026.png" alt="img"></p>
<p><strong>另外 ClickHouse 也支持关联查询的语法，只不过会自动转成指定的连接查询，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 关联查询，如果没有 WHERE，那么三张表会做笛卡尔积</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2, t3.code3</span><br><span class="line"><span class="keyword">FROM</span> tbl_1 t1, tbl_2 t2, tbl_3 t3 </span><br><span class="line"><span class="keyword">WHERE</span> t1.id <span class="operator">=</span> t2.id <span class="keyword">AND</span> t1.id <span class="operator">=</span> t3.id</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─t1.id─┬─t1.code1─┬─t2.code2─┬─t3.code3─┐</span></span><br><span class="line"><span class="comment">│     3 │ A003     │ B003     │ C003     │</span></span><br><span class="line"><span class="comment">└───────┴──────────┴──────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>以上就是关联查询，虽然也能实现，不过还是不推荐这种做法，因为此时连接条件和过滤条件都写在了 WHERE 子句里面，看起来会比较混乱。所以更推荐连接查询（ClickHouse 会自动转化），也就是 JOIN ON 的形式，此时 ON 后面写连接条件，而数据过滤条件写 WHERE 里面（当然我们这里不需要过滤）。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> t1.id, t1.code1, t2.code2, t3.code3</span><br><span class="line"><span class="keyword">FROM</span> tbl_1 t1 <span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_2 t2 <span class="keyword">ON</span> t1.id <span class="operator">=</span> t2.id</span><br><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> tbl_3 t3 <span class="keyword">ON</span> t1.id <span class="operator">=</span> t3.id</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─t1.id─┬─t1.code1─┬─t2.code2─┬─t3.code3─┐</span></span><br><span class="line"><span class="comment">│     3 │ A003     │ B003     │ C003     │</span></span><br><span class="line"><span class="comment">└───────┴──────────┴──────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><p><strong>最后，还有两个关于 JOIN 查询的注意事项。</strong></p>
<p><strong>1. 关于性能</strong></p>
<p><strong>最后，还有两个关于 JOIN 查询的注意事项。为了能够优化 JOIN 查询性能，首先应该遵循左大右小的原则，即数据量小的表要放在右侧。这是因为在执行 JOIN 查询时，无论使用的是哪种连接方式，右表都会被全部加载到内存中与左表进行比较。</strong></p>
<p><strong>其次，JOIN 查询目前没有缓存的支持，这意味着每一次 JOIN 查询，即便是连续执行相同的 SQL，也都会生成一次全新的执行计划。如果应用程序会大量使用 JOIN 查询，则需要进一步考虑借助上层应用侧的缓存服务或使用 JOIN 表引擎来改善性能。</strong></p>
<p><strong>最后，如果是在大量维度属性补全的查询场景中，则建议使用字典代替 JOIN 查询。因为在进行多表的连接查询时，查询会转换成两两连接的形式，而这种滚雪球式的查询很可能带来性能问题。</strong></p>
<p><strong>2. 空值策略</strong></p>
<p><strong>在之前的介绍中，连接查询的空值（那些未被连接的数据）是由默认值填充的，这与其他数据库所采取的策略不同（由Null 填充）。连接查询的空值策略通过 join_use_nulls 参数指定的，默认为 0。当参数值为 0 时，空值由数据类型的默认值填充；而当参数值为 1 时，空值由 Null 填充。</strong></p>
<h2 id="WHERE-与-PREWHERE-子句"><a href="#WHERE-与-PREWHERE-子句" class="headerlink" title="WHERE 与 PREWHERE 子句"></a>WHERE 与 PREWHERE 子句</h2><p><strong>WHERE 子句基于条件表达式来实现数据过滤，如果过滤条件恰好是主键字段，则能够进一步借助索引过滤数据区间，从而加速查询，所以 WHERE 子句是一条查询语句能否启用索引的判断依据，前提是表引擎支持索引特性。</strong></p>
<p><strong>除了 WHERE，ClickHouse 还支持全新的 PREWHERE 子句，PREWHERE 目前只能用于 MegeTee 系列的表引擎，它可以看作对是 WHERE 的一种优化，其作用与 WHERE 相同，均是用来过滤数据。但它们的不同之处在于。使用 PREWHERE 时，首先只会读取 PREWHERE 指定的列字段数据，用于数据过滤的条件判断。待数据过滤之后再读取 SELECT 声明的列字段以补全其余属性。所以在一些场合下，PREWHERE 相比 WHERE 而言，处理的数据量更少，性能更高。</strong></p>
<p><strong>既然 WHERE 子句性能更优，那么是否需要将所有的 WHERE 子句都替换成 PREWHERE 子句呢？其实大可不必，因为 ClickHouse 实现了自我优化的功能，会在条件合适的情况下将 WHERE 替换为 PREWHERE。如果想开启这项特性，只需要将 optimize_move_to_prewhere 设置为 1 即可，当然默认就为 1，即开启状态。</strong></p>
<p><strong>但凡事也有例外，以下情形不会自动优化：</strong></p>
<p><strong>1）使用了常量表达式：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> id, code <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> <span class="number">1</span> <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p><strong>2）使用了默认值为 ALIAS 类型的字段：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 假设 code 的默认值类型是 ALIAS</span></span><br><span class="line"><span class="keyword">SELECT</span> id, code <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> code <span class="operator">=</span> <span class="string">&#x27;A000&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>3）包含了 arrayJoin、globalIn、globalNotIn 或者 indexHint 查询的：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, nested.v1, nested.v2 <span class="keyword">FROM</span> tbl <span class="keyword">ARRAY</span> <span class="keyword">JOIN</span> nested <span class="keyword">WHERE</span> nested.v1 <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p><strong>4）SELECT 查询的列字段和 WHERE 谓词相同：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> v3 <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> v3 <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p><strong>5）使用了主键字段：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> id <span class="keyword">FROM</span> tbl <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="string">&#x27;A000&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>虽然在上述情形中 ClickHouse 不会自动将谓词移动到 PREWHERE，但仍然可以主动使用 PREWHERE。以主键字段为例，当使用 PREWHERE 进行主键查询时，首先会通过稀疏索引过滤数据区间（index_granularity 粒度），接着会读取 PREWHERE 指定的条件列进一步过滤，这样一来就有可能截掉数据区间的尾巴，从而返回低于 index_granularity 粒度的数据范围。但即便如此，相比其他场合移动谓词所带来的性能提升，这类效果还是比较有限的，所以目前 ClickHouse 在这类场合下仍然保持不移动的处理方式。</strong></p>
<h2 id="GROUP-BY-子句"><a href="#GROUP-BY-子句" class="headerlink" title="GROUP BY 子句"></a>GROUP BY 子句</h2><p><strong>GROUP BY 又称聚合查询，是最常用的子句之一，它是让 ClickHouse 最凸显卓越性能的地方。在 GROUP BY 后声明的表达式，通常称为聚合键或者 Key，数据会按照聚合键进行聚合。ClickHouse 的聚合查询中，和关系型数据库也是类似的。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 只有聚合函数，可以省略 GROUP BY</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">sum</span>(data_compressed_bytes) <span class="keyword">AS</span> compressed,</span><br><span class="line">       <span class="built_in">sum</span>(data_uncompressed_bytes) <span class="keyword">AS</span> undata_compressed_bytes</span><br><span class="line"><span class="keyword">FROM</span> system.parts;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- SELECT 子句中的字段要么出现在 GROUP BY 子句中，要么出现在聚合函数中</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">table</span>, <span class="built_in">count</span>() <span class="keyword">FROM</span> system.parts <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">table</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 错误的语法，rows 既没有出现在 GROUP BY 中，也没有出现在聚合函数中</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">table</span>, <span class="built_in">count</span>(), <span class="keyword">rows</span>() <span class="keyword">FROM</span> system.parts <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">table</span>;</span><br></pre></td></tr></table></figure>

<p><strong>如果聚合键对应的列包含 Null 值，那么所有的 Null 会被归为同一组。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155652085-2037142784.png" alt="img"></p>
<p><strong>我们看到所有的 Null 被分为了一组，但是注意：count(字段) 不会把 Null 计算在内，所以直接 count() 就行。</strong></p>
<p><strong>比较简单，但除了上述特性之外，聚合查询还能配合 WITH ROLLUP、WITH CUBE、WITH TOTALS 三种修饰符获取额外的汇总信息。</strong></p>
<h4 id="WITH-ROLLUP"><a href="#WITH-ROLLUP" class="headerlink" title="WITH ROLLUP"></a>WITH ROLLUP</h4><p><strong>测试数据如下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155645759-481178151.png" alt="img"></p>
<p><strong>以上是普通的 GROUP BY，没什么难的，然后看看它和 WITH ROLLUP 搭配会有什么效果：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155638394-350610817.png" alt="img"></p>
<p><strong>我们注意到，多了四条数据，上面三条，就是按照 product、channel 汇总之后，再单独按 product 汇总，而此时会给对应的 channel 设为零值（这里是空字符串，关系型数据库中为 Null）。同理最后一条数据是全量汇总，不需要指定 product 和 channel，所以显示为 product 和 channel 都显示为零值。我们看到这就相当于按照 product 单独聚合然后再自动拼接在上面了，排好序，并且自动将 channel 赋值为零值，同理最后一条数据也是如此。当然我们也可以写多个语句，然后通过 UNION 也能实现上面的效果，有兴趣可以自己试一下。但是 ClickHouse 提供了 WITH ROLLUP 这个非常方便的功能，我们就要利用好它。</strong></p>
<blockquote>
<p><strong>GROUP BY 子句加上 WITH ROLLUP 选项时，首先按照全部的分组字段进行分组汇总；然后从右往左依次去掉一个分组字段再进行分组汇总，被去掉的字段显示为零值；最后，将所有的数据进行一次汇总，所有的分组字段都显示为零值。</strong></p>
</blockquote>
<h4 id="WITH-CUBE"><a href="#WITH-CUBE" class="headerlink" title="WITH CUBE"></a>WITH CUBE</h4><p><strong>CUBE 代表立方体，它用于对分组字段进行各种可能的组合，能够产生多维度的交叉统计结果，CUBE 通常用于数据仓库中的交叉报表分析。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155630214-2072640677.png" alt="img"></p>
<p><strong>从以上结果可以看出，CUBE 返回了更多的分组数据，其中不仅包含了 ROLLUP 汇总的结果，还包含了相当于按照 channel 进行聚合的记录。因此随着分组字段的增加，CUBE 产生的组合将会呈指数级增长。</strong></p>
<h4 id="WITH-TOTALS"><a href="#WITH-TOTALS" class="headerlink" title="WITH TOTALS"></a>WITH TOTALS</h4><p><strong>WITH TOTALS 反而是最简单的，只包含一个全局汇总的结果。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155623477-1060377326.png" alt="img"></p>
<h2 id="HAVING-子句"><a href="#HAVING-子句" class="headerlink" title="HAVING 子句"></a>HAVING 子句</h2><p><strong>HAVING 子句要和 GROUP BY 子句同时出现，不能单独使用，它能够在聚合计算之后实现数据的二次过滤。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155618015-611567566.png" alt="img"></p>
<p><strong>对于上面的栗子，使用 WHERE 比使用 HAVING 的效率更高，因为 WHERE 等同于使用了谓词下推，在聚合之前就减少了数据过滤，从而减少了后续聚合时需要处理的数据量。</strong></p>
<p><strong>所以使用 HAVING 进行过滤，那么应该是对聚合之后的结果进行过滤。如果不是聚合之后的，那么使用 WHERE 就好，举个栗子：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155609969-370614629.png" alt="img"></p>
<p><strong>因为 WHERE 的优先级大于 GROUP BY，所以如果按照聚合值进行统计，那么就必须要借助于 HAVING。</strong></p>
<h2 id="ORDER-BY-子句"><a href="#ORDER-BY-子句" class="headerlink" title="ORDER BY 子句"></a>ORDER BY 子句</h2><p><strong>ORDER BY子句通过声明排序键来指定查询数据返回的顺序，通过先前的介绍我们知道，在 MergeTree 表引擎中也有 ORDER BY 参数用于指定排序键，那么这两者有何不同呢？在 MergeTree 中指定 ORDER BY 后，数据在各个分区内会按照其定义的规则排序，这是一种分区内的局部排序。如果在查询时数据跨越了多个分区，则它们的返回顺序是无法预知的，每一次查询返回的顺序都有可能不同。在这种情况下，如果需要数据总是能够按照期望的顺序范围，就需要借助 ORDER BY 子句来指定全局顺序。</strong></p>
<p><strong>ORDER BY 在使用时可以定义多个排序键，每个排序键后需紧跟 ASC（升序）或  DESC（降序）来确定排列顺序。如若不写，则默认为 ASC。例如下面的两条语句即是等价的：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">ORDER</span> <span class="keyword">BY</span> v1 <span class="keyword">ASC</span>, v2 <span class="keyword">DESC</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl <span class="keyword">ORDER</span> <span class="keyword">BY</span> v1, v2 <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<p><strong>数据首先会按照 v1 升序，如果 v1 字段中出现了相同的值，那么再按照 v2 降序。</strong></p>
<p><strong>然后是 Null 值的排序，目前 ClickHouse 有 Null 值最后和 Null 值最前两种策略，可以通过如下进行设置：</strong></p>
<h4 id="1-NULLS-LAST"><a href="#1-NULLS-LAST" class="headerlink" title="1. NULLS LAST"></a>1. NULLS LAST</h4><p><strong>Null 值排在最后，无论升序还是降序，这也是默认的行为。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">value -&gt; NaN -&gt; Null</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155600186-1068645033.png" alt="img"></p>
<h4 id="2-NULLS-FIRST"><a href="#2-NULLS-FIRST" class="headerlink" title="2. NULLS FIRST"></a>2. NULLS FIRST</h4><p><strong>Null 值排在最后，无论升序还是降序。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">NULL -&gt; NaN -&gt; value</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155551570-1492398706.png" alt="img"></p>
<p><strong>经过测试不难发现，对于 NaN 而言，它总是跟在 Null 的身边。</strong></p>
<h2 id="LIMIT-BY-子句"><a href="#LIMIT-BY-子句" class="headerlink" title="LIMIT BY 子句"></a>LIMIT BY 子句</h2><p><strong>LIMIT BY 子句和大家常见的 LIMIT 有所不同，它运行于 ORDER BY 之后和 LIMIT 之前，它能够按照指定分组，最多返回前 n 行数据（少于 n 行则按照实际数量返回），常用于 TOP N 的查询场景。LIMIT BY 语法规则如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LIMIT n BY express</span><br></pre></td></tr></table></figure>

<p><strong>个人觉得这个 LIMIT BY 非常强大，我们举个栗子：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155503458-270715071.png" alt="img"></p>
<p><strong>当然聚合之后没有排序，我们还可以排一下序：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    product,</span><br><span class="line">    channel,</span><br><span class="line">    <span class="built_in">sum</span>(amount) <span class="keyword">AS</span> amount</span><br><span class="line"><span class="keyword">FROM</span> sales_data</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">    product,</span><br><span class="line">    channel</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> amount <span class="keyword">ASC</span></span><br><span class="line">LIMIT <span class="number">1</span> <span class="keyword">BY</span> channel</span><br></pre></td></tr></table></figure>

<p><strong>此时会选择每个渠道对应的金额最高的数据，当然我们也可以 LIMIT 多条数据、也可以 BY 多个字段。这个功能可以说是非常常用了，我们平时使用的 LIMIT，一般是全局排序之后选择前 N 条数据，而这里的 LIMIT BY 是按照指定的字段分组，然后每一组选择前 N 条数据。</strong></p>
<blockquote>
<p><strong>LIMIT BY 会从上往下在每个组中选择指定条数的数据，因此使用 LIMIT BY 应该同时指定 ORDER BY，否则拿出的数据没有太大意义，除非数据本身就是有序的。</strong></p>
</blockquote>
<p><strong>当然 LIMIT BY 也可以指定偏移量，因为不一定从一条开始选择，而指定偏移量有两种方式：</strong></p>
<ul>
<li><code>LIMIT N OFFSET M BY ...</code></li>
<li><code>LIMIT M, N BY ...</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155452951-107038302.png" alt="img"></p>
<h2 id="LIMIT-子句"><a href="#LIMIT-子句" class="headerlink" title="LIMIT 子句"></a>LIMIT 子句</h2><p><strong>LIMIT 子句用于返回指定的前 N 行数据，常用于分页场景，它的三种语法形式如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LIMIT N</span><br><span class="line">LIMIT N <span class="keyword">OFFSET</span> M</span><br><span class="line">LIMIT M, N</span><br></pre></td></tr></table></figure>

<p><strong>用法和 LIMIT BY 中的 LIMIT 一致，如果把 LIMIT BY 中的 BY 去掉，那么就变成了 LIMIT。比较简单，这里用一张图来介绍一下 LIMIT 和 LIMIT BY 之前的关系：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155444441-40300823.png" alt="img"></p>
<p><strong>比较简单，但是在使用 LIMIT 的时候需要注意一点，如果数据跨越了多个分区，那么在没有使用 ORDER BY 指定全局顺序的情况下，每次 LIMIT 查询所返回的数据可能有所不同。如果对返回的数据的顺序比较敏感，则应搭配 ORDER BY 一起使用。</strong></p>
<h2 id="SELECT-和-DISTINCT-子句"><a href="#SELECT-和-DISTINCT-子句" class="headerlink" title="SELECT 和 DISTINCT 子句"></a>SELECT 和 DISTINCT 子句</h2><p><strong>SELECT 子句决定了一次查询语句最终能返回哪些字段或表达式，与直观感受不同，虽然 SELECT 位于 SQL 语句的起始位置，但它的执行的顺序却排在了上面介绍的所有子句的后面。在其它子句执行之后，SELECT 会将选取的字段或表达式作用于每行数据之上，如果使用 * 通配符，则会返回所有字段。但正如开篇所言，大多数情况下都不建议这么做，因为对于一款列式存储数据库而言，这绝对是劣势而不是优势（我们这里在学习的过程就不算了）。</strong></p>
<p><strong>在选择列字段时，ClickHouse 还为特定场景提供了一种基于正则查询的形式，例如下面会选择以 n 开头和包含字母 p 的字段：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> COLUMNS(<span class="string">&#x27;^n&#x27;</span>), COLUMNS(<span class="string">&#x27;p&#x27;</span>) <span class="keyword">FROM</span> system.databases</span><br></pre></td></tr></table></figure>

<p><strong>DISTINCT 子句能够去除重复数据，使用场景也很广泛，很多人经常会拿它和 GROUP BY 进行对比：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155436201-311425704.png" alt="img"></p>
<p><strong>虽然顺序不同，但显然结果集的内容是一致的，那么这两者之间有什么区别呢？如果观察它们的执行计划（后面会说）不难发现，DISTINCT 子句的执行计划会更加简单，与此同时，DISTINCT 也能够和 GROUP BY 搭配使用，所以它们是互补而不是互斥的关系。</strong></p>
<p><strong>另外，如果使用了 LIMIT 且没有 ORDER BY 子句，那么 DISTINCT 在满足条件时能够立即结束查询。假设我只需要去重之后的前三条数据，那么 GROUP BY 会对全体数据进行分组，然后再选择前三条；而 DISTINCT 在去重时发现已经有三条了，于是直接返回，后面的数据就不需要看了，因为看了也没意义，LIMIT 决定了只返回三条。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155429111-1453572753.png" alt="img"></p>
<p><strong>两个查询返回的结果集不一样，这是因为 GROUP BY 和 DISTINCT 处理数据的顺序不同。一开始我们就看到了，如果没有 LIMIT，那么两个结果集顺序不同，但内容是一样的，只是这里加了 LIMIT，所以相当于选择了相同内容的不同部分。</strong></p>
<p><strong>如果有 ORDER BY，那么会先执行 DISTINCT，再执行 ORDER BY。并且对于 Null 而言，如果有多个 Null，那么 DISTINCT 之后只会保留一个 Null。</strong></p>
<h2 id="UNION-ALL-子句"><a href="#UNION-ALL-子句" class="headerlink" title="UNION ALL 子句"></a>UNION ALL 子句</h2><p><strong>UNION ALL 子句能够联合左右两边的两组子查询，将结果一并返回。在一次查询中可以声明多次 UNION ALL 以便联合多组查询，但 UNION ALL 不能直接使用其他子句（例如 ORDER BY、LIMIT 等），这些子句只能在它联合的子查询中使用。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> name, v1 <span class="keyword">FROM</span> union_v1</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> title, v1 <span class="keyword">FROM</span> union_v1</span><br></pre></td></tr></table></figure>

<p><strong>对于 UNION ALL 两侧的子查询有以下几点信息：首先，列字段的数量必须相同；其次，列字段的数据类型必须相同或相兼容；最后，列字段的名称可以不同，查询结果中的列名会以左边的子查询为准。</strong></p>
<p><strong>对于联合查询还有一点要说明，目前 ClickHouse 只支持 UNION ALL 子句，如果想得到 UNION DISTINCT 子句的效果，可以使用嵌套查询来变相实现，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> name <span class="keyword">FROM</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">SELECT</span> name, v1 <span class="keyword">FROM</span> union_v1</span><br><span class="line">    <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line">    <span class="keyword">SELECT</span> title, v1 <span class="keyword">FROM</span> union_v1</span><br><span class="line">)    </span><br></pre></td></tr></table></figure>

<h2 id="SAMPLE-子句"><a href="#SAMPLE-子句" class="headerlink" title="SAMPLE 子句"></a>SAMPLE 子句</h2><p><strong>SAMPLE 子句能够实现数据采样的功能，使查询仅返回采样数据而不是全部数据，从面有效减少查询负载。SAMPLE 子句的采样机制是一种幂等设计，也就是说在数据不发生变化的情况下，使用相同的采样规则总是能等返回相同的数据，所以这项特性非常适合在那些可以接受近似查询结果的场合使用。例如在数据量十分巨大的情况下，对查询时效性的要求大于准确性时就可以尝试使用 SAMPLE 子句。</strong></p>
<p><strong>SAMPLE 子句只能用于 MergeTree 系列引擎的数据表，并且要求在 CREATE TABLE 时声明 SAMPLE BY 表达式，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hits_v1 (</span><br><span class="line">    CounterID UInt64,</span><br><span class="line">    EventDate <span class="type">Date</span>,</span><br><span class="line">    UserID UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(EventDate)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (CounterID, intHash32(UserID))</span><br><span class="line"><span class="comment">-- SAMPLE BY 声明的表达式必须要包含在主键的声明中</span></span><br><span class="line">SAMPLE <span class="keyword">BY</span> intHash32(UserID)</span><br></pre></td></tr></table></figure>

<p><strong>SAMPLE BY 表示 hits_v1内的数据，可以按照 intHash32(UserID) 分布后的结果采样查询。但需要注意：SAMPLE BY 所声明的表达式必须同时包含在主键的声明内，并且选择的字段必须是 Int 类型，如果不是 ClickHouse 在建表的时候也不会报错，但查询的时候会出异常。</strong></p>
<p><strong>SAMPLE 子句目前支持如下 3 种用法：</strong></p>
<h4 id="1-SAMPLE-factor"><a href="#1-SAMPLE-factor" class="headerlink" title="1. SAMPLE factor"></a>1. SAMPLE factor</h4><p><strong>SAMPLE factor 表示按因子系数采样，其中 factor 表示采样因子，它的取值支持0~1 之间的小数。如果 factor 设置为 0 或者 1，则效果等同于不进行数据采样。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CounterID <span class="keyword">FROM</span> hits_v1 SAMPLE <span class="number">0.1</span></span><br></pre></td></tr></table></figure>

<p><strong>factor 也支持使用十进制的形式表述。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CounterID <span class="keyword">FROM</span> hits_v1 SAMPLE <span class="number">1</span> <span class="operator">/</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p><strong>如果在进行统计查询时，为了得到最终的近似结果，需要将得到的直接结果乘以采样系数。例如想按照 0.1 的因子采样数据，则需要将统计结果放大 10 倍。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>() <span class="operator">*</span> <span class="number">10</span> <span class="keyword">FROM</span> hits_v1 SAMPLE <span class="number">0.1</span></span><br></pre></td></tr></table></figure>

<p><strong>一种更为优雅的方法是借助虚拟字段 _sample_factor 来获取采样系数，并以此代替硬编码的形式，_sample_factor 可以发那会当前查询所对应的采样系数。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>() <span class="operator">*</span> <span class="keyword">any</span>(_sample_factor) <span class="keyword">FROM</span> hits_v1 SAMPLE <span class="number">0.1</span></span><br></pre></td></tr></table></figure>

<h4 id="2-SAMPLE-rows"><a href="#2-SAMPLE-rows" class="headerlink" title="2. SAMPLE rows"></a>2. SAMPLE rows</h4><p><strong>SAMPLE rows 表示按样本数量采样，其中 rows 表示至少采样多少行数据，它的取值必须是大于 1 的整数。如果 rows 的取值大于表内数据的总行数，则效果等于 rows &#x3D; 1，也就是不使用采样。</strong></p>
<p><strong>比如我们采样 10000 行数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>() <span class="keyword">FROM</span> hits_v1 SAMPLE <span class="number">10000</span>;</span><br></pre></td></tr></table></figure>

<p><strong>虽然我们采样 10000 行，但是不一定就返回 10000 行，因为数据采样是一个近似范围，这是由于采样数据的最小粒度由 index_granularity 索引粒度所决定的。由此可知，设置一个小于索引粒度或者较小的 rows 没有什么意义，应该设置一个比较大的值。另外，同样可以使用虚拟字段 _sample_factor 来获取当前查询对应的采样系数。</strong></p>
<h4 id="4-SAMPLE-factor-OFFSET-n"><a href="#4-SAMPLE-factor-OFFSET-n" class="headerlink" title="4. SAMPLE factor OFFSET n"></a>4. SAMPLE factor OFFSET n</h4><p><strong>SAMPLE factor OFFSET n 表示按因子系数和偏移量采样，其中 factor 表示采样因子，n 表示偏移多少数据后才开始采样，它们两个的取值都是 0~1 之间的小数。例如下面的语句表示偏移量为 0.5 并按 0.4 的系数采样：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CounterID <span class="keyword">FROM</span> hits_v1 SAMPEL <span class="number">0.4</span> <span class="keyword">OFFSET</span> <span class="number">0.5</span></span><br></pre></td></tr></table></figure>

<p><strong>上述查询会从数据的二分之一处开始，按照 0.4 的系数采样数据：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155409003-1169057178.png" alt="img"></p>
<p><strong>如果在计算 OFFSET 偏移量后，按照 SAMPLE 比例采样出现了溢出，则数据会被自动截断。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E5%AD%90%E5%8F%A5(%E4%B9%9D)/1229382-20210903155401456-2508167.png" alt="img"></p>
<p><strong>当然这种做法也支持虚拟字段。</strong></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><strong>以上就是 ClickHouse 关于查询方面的内容，可以肯定的是内容绝对不止这些，因为和关系型数据库重叠的部分这里自动省略或者一笔带过了，比如空值如何处理（nullif、coalesce）、IN 查询、LIKE 查询、什么是子查询、CASE WHEN 语句等等等等。如果大部分的关系型数据库都支持的语法，那么在 ClickHouse 中基本也是支持的。所以个人觉得有 MySQL 相关经验的话，至少在 ClickHouse 的查询方面，绝对是非常好上手的，没事多写一写就行。</strong></p>
<p><strong>接下来我会介绍 ClickHouse 中关于操作数组的函数，到时候也会刻意地融入更多的语法（这里介绍的，和没有介绍的）。因为 ClickHouse 中提供了大量的函数，通过这些函数 ClickHouse 在处理数据就能够变得所向披靡，但我们不可能一下全说完，这里就先拿数组开刀，因为它相对更复杂一些。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 之 MergeTree 家族中的其它表引擎(七)</title>
    <url>/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/</url>
    <content><![CDATA[<h1 id="ClickHouse-之-MergeTree-家族中的其它表引擎-七"><a href="#ClickHouse-之-MergeTree-家族中的其它表引擎-七" class="headerlink" title="ClickHouse 之 MergeTree 家族中的其它表引擎(七)"></a>ClickHouse 之 MergeTree 家族中的其它表引擎(七)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<p><strong>目前在 ClickHouse 中，按照特点可以将表引擎分为 6 个系列，分别是合并树、外部存储、内存、文件、接口和其它，每一个系列的表引擎都有独自的特点和使用场景。而其中最核心的当属 MergeTree 系列，因为它们拥有最为强大的性能和最为广泛的使用场景。</strong></p>
<p><strong>经过之前的介绍，我们知道 MergeTree 有两种含义：</strong></p>
<ul>
<li><code>1. 表示合并树表引擎家族</code></li>
<li><code>2. 表示合并树表引擎家族中最基础的 MergeTree 表引擎</code></li>
</ul>
<p><strong>而在整个家族中，除了基础表引擎 MergeTree 之外，常用的表引擎还有 ReplacingMergeTree、SummingMergeTree、AggregatingMergeTree、CollapsingMergeTree、VersionedCollapsingMergeTree。从名字也能看出来，每一种合并树的变种，在继承了 MergeTree 的基础能力后，又增加了独有的特性，而这些独有的特性都是在触发合并的过程中被激活的。</strong></p>
<h3 id="MergeTree"><a href="#MergeTree" class="headerlink" title="MergeTree"></a>MergeTree</h3><p><strong>MergeTree 作为家族系列最基础的表引擎，提供了数据分区、一级索引和二级索引等功能，至于它们的运行机理我们之前已经介绍过了。这里我们来介绍一下 MergeTree 的另外两个功能：数据 TTL 和 存储策略。</strong></p>
<h4 id="数据-TTL"><a href="#数据-TTL" class="headerlink" title="数据 TTL"></a>数据 TTL</h4><p><strong>TTL 即 Time To Live，表示数据的存活时间，而在 MergeTree 中可以为某个列字段或整张表设置 TTL。当时间到达时，如果是列字段级别的 TTL，则会删除这一列的数据；如果是整张表级别的 TTL，则会删除整张表的数据；如果同时设置，则会以先到期的为主。</strong></p>
<p><strong>无论是列级别还是表级别的 TTL，都需要依托某个 DateTime 或 Date 类型的字段，通过对这个时间字段的 INTERVAL 操作来表述 TTL 的过期时间，下面我们看一下设置的方式。</strong></p>
<p><strong>1）列级别设置 TTL</strong></p>
<p><strong>如果想要设置列级别的 TTL，则需要在定义表字段的时候为它们声明 TTL 表达式，主键字段不能被声明 TTL，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> ttl_table_v1 (</span><br><span class="line">    id String,</span><br><span class="line">    create_time DateTime,</span><br><span class="line">    code String TTL create_time <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">10</span> <span class="keyword">SECOND</span>,</span><br><span class="line">    type UInt8 TTL create_time <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">10</span> <span class="keyword">SECOND</span> </span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p><strong>其中 create_time 是日期类型，列字段 code 和 type 均被设置了 TTL，它们的存活时间在 create_time 取值的基础之上向后延续 10 秒。假设某一条数据的 create_time 的值为 dt，那么当系统时间超过了 dt + 10 秒，该条数据的 code、type 就会过期。</strong></p>
<blockquote>
<p><strong>除了 SECOND 之外，还有 MINUTE、HOUR、DAY、WEEK、MONTH、QUARTER 和 YEAR。</strong></p>
</blockquote>
<p><strong>现在写入两条测试数据，其中第一条的 create_time 取当前的系统时间，第二条的 create_time 比第一条多 5 分钟。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> ttl_table_v1 </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A000&#x27;</span>, now(), <span class="string">&#x27;C1&#x27;</span>, <span class="number">1</span>), </span><br><span class="line">       (<span class="string">&#x27;A000&#x27;</span>, now() <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">5</span> <span class="keyword">MINUTE</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>然后马上进行查询（手速要快），然后等 10 秒过后（从写入数据的那一刻起），再查询一次。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829182030888-1275351927.png" alt="img"></p>
<p><strong>再次查询 ttl_table_v1 会看到，由于第一条数据满足 TTL 过期时间（当前系统时间 &gt;&#x3D; create_time + 10 秒），它们的 code 和 type 会被还原为数据类型的零值。</strong></p>
<p><strong>如果想要修改列字段的 TTL，或者为已有字段添加 TTL（不可以是主键字段），都可以使用 ALTER 语句，举个栗子：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TABLE ttl_table_v1 MODIFY COLUMN code String TTL create_time + INTERVAL 1 DAY</span><br></pre></td></tr></table></figure>

<p><strong>2）表级别设置 TTL</strong></p>
<p><strong>如果想为整张表设置 TTL，需要在 MergeTree 的表参数中增加 TTL 表达式，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> ttl_table_v2 (</span><br><span class="line">    id String,</span><br><span class="line">    create_time DateTime,</span><br><span class="line">    code String TTL create_time <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">MINUTE</span>,</span><br><span class="line">    type UInt8</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> create_time</span><br><span class="line">TTL create_time <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">DAY</span></span><br></pre></td></tr></table></figure>

<p><strong>ttl_table_v2 整张表被设置了 TTL，当触发 TTL 清理时，那些满足过期时间的数据行将被整行删除。同样，表级别的 TTL 也支持修改，方法如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TABLE ttl_table_v2 MODIFY TTL create_time INTERVAL + 3 DAY</span><br></pre></td></tr></table></figure>

<p><strong>另外表级别的 TTL 也不支持取消。</strong></p>
<p><strong>3）TTL 运行机理</strong></p>
<p><strong>在了解了列级别和表级别 TTL 的运行机理后，现在简单聊一聊 TTL 的运行机理。如果一张 MergeTree 表被设置了 TTL 表达式，那么在写入数据时会以分区为单位，在每个分区目录内生成 ttl.txt 文件。以上面的 ttl_table_v2 为例，它被设置了列级别的 TTL，也被设置了表级别的 TTL，那么在写入数据之后，它的每个分区目录内都会生成 ttl.txt 文件。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829182020856-1939143318.png" alt="img"></p>
<p><strong>我们查看 ttl.txt 的内容发现，原来 MergeTree 是通过一串 JSON 保存了 TTL 的相关信息，其中：</strong></p>
<ul>
<li><code>columns 用于保存列级别的 TTL 信息</code></li>
<li><code>table 用于表级别的 TTL 信息</code></li>
<li><code>min 和 max 则保存了当前数据分区内，TTL 指定日期字段的最小值和最大值分别与 INTERVAL 表达式计算后的时间戳</code></li>
</ul>
<p><strong>如果将 table 属性中的 min 和 max 时间戳格式化，并分别与 create_time 最小值与最大值进行对比：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829182013609-1828101509.png" alt="img"></p>
<p><strong>则能够印证，ttl.txt 中记录的极值区间恰好等于当前分区内 create_time 的最小值、最大值加 1 天（86400 秒），与 TTL 表达式 create_time + INTERVAL 1 DAY 相符合，同理 ttl_min 和 ttl_max 分别减去一天即可得到 create_time 这一列的最小值和最大值。</strong></p>
<p><strong>在知道了 TTL 信息的记录方式之后，再来看看它的处理逻辑。</strong></p>
<ul>
<li><code>1. MergeTree 以分区目录为单位，通过 ttl.txt 文件记录过期时间，并将其作为后续的判断依据</code></li>
<li><code>2. 每当写入一批数据时，都会基于 INTERVAL 表达式的计算结果为这个分区生成 ttl.txt 文件</code></li>
<li><code>3. 只有 MergeTree 在对属于相同分区的多个分区目录进行合并时，才会触发删除 TTL 过期数据的逻辑</code></li>
<li><code>4. 在选择删除的分区时，会使用贪婪算法，它的算法规则是尽可能找到会最早过期的、同时年纪又是最老的分区（合并次数更多，MaxBlockNum 更大的）</code></li>
<li><code>5. 如果一个分区内某一列数据因为 TTL 到期全部被删除了，那么在合并之后生成的新分区目录中，将不会再包含该列对应的 bin 文件和 mrk 文件，如果列数据分开存储的话</code></li>
</ul>
<p><strong>TTL 默认的合并频率由 MergeTree 的 merge_with_ttl_timeout 参数所控制，默认为 86400 秒、也就是 1 天。它维护的是一个专有的 TTL 任务队列，有别于 MergeTree 的常规合并任务，这个值如果设置的过小，可能会带来性能损耗。当然除了被动触发 TTL 合并外，也可以使用 optimize 强制触发合并：</strong></p>
<ul>
<li><code>optimize TABLE table_name PARTITION 分区名：触发一个分区合并</code></li>
<li><code>optimize TABLE table_name FINAL：触发所有分区合并</code></li>
</ul>
<p><strong>最后，ClickHouse 虽然没有提供删除 TTL 的声明方法，但是提供了控制 TTL 合并任务的启停方法。</strong></p>
<ul>
<li><code>SYSTEM STOP/START TTL MERGES：控制全局 MergeTree 表启停</code></li>
<li><code>SYSTEM STOP/START TTL MERGES table_name：控制指定 MergeTree 启停</code></li>
</ul>
<h4 id="多路径存储策略"><a href="#多路径存储策略" class="headerlink" title="多路径存储策略"></a>多路径存储策略</h4><p><strong>在 ClickHouse 19.15 版本之前，MergeTree 只支持单路径存储，所有的数据都会被写入 config.xml 配置中的 path 指定的路径下。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829182004024-1343945799.png" alt="img"></p>
<p><strong>即使服务器挂载了多块磁盘，也无法有效利用这些存储空间。为了解决这个痛点，从 19.15 版本开始，MergeTree 实现了自定义存储策略的功能，支持以数据分区为最小移动单元，将分区目录写入多块磁盘目录。</strong></p>
<p><strong>而根据配置策略的不同，目前大致有三类存储策略。</strong></p>
<ul>
<li><strong>默认策略：MergeTree 原本的存储策略，无需任何配置，所有分区会自动保存到 config.xml 配置中 path 指定的路径下。</strong></li>
<li><strong>JBOD 策略：这种策略适合服务器挂载了多块磁盘，但没有做 RAID 的场景。JBOD 的全称是 Just a Bunch of Disks，它是一种轮询策略，每执行一次 INSERT 或者 MERGE，所产生的新分区会轮询写入各个磁盘。这种策略的效果类似于 RAID 0，可以降低单块磁盘的负载，在一定条件下能够增加数据并行读写的性能。如果单块磁盘发生故障，则会丢掉应用 JBOD 策略写入的这部分数据，但这又会造成数据丢失，因此我们还需要利用副本机制来保障数据的可靠性（副本机制后面说）。</strong></li>
<li><strong>HOT&#x2F;COLD 策略：这种策略适合服务器挂载了不同类型磁盘的场景，将存储磁盘分为 HOT 和 COLD 两类区域。HOT 区域使用 SSD 这类高性能存储媒介，注重存储性能；COLD 区域则使用 HDD 这类高容量存储媒介，注重存储经济性。数据在写入 MergeTree 之初，会在 HOT 区域创建分区目录用于保存数据，当分区数据大小累积到阈值时，数据会自动移动到 COLD 区域。而在每个区域的内部，也支持定义多个磁盘，所以在单个区域的写入过程中，也能应用 JBOD 策略。</strong></li>
</ul>
<p><strong>存储配置需要预先定义在 config.xml 配置文件中，由 storage_configuration 表示，而 storage_configuration 之下又分为 disks 和 policies 两组标签，分别表示磁盘与存储策略。格式如下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">storage_configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">disks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_name_a</span>&gt;</span> <span class="comment">&lt;!-- 自定义磁盘名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/ch/data1<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">keep_free_space_bytes</span>&gt;</span>1073741824<span class="tag">&lt;/<span class="name">keep_free_space_bytes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_name_a</span>&gt;</span>	</span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_name_b</span>&gt;</span> <span class="comment">&lt;!-- 自定义磁盘名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/ch/data2<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">keep_free_space_bytes</span>&gt;</span>1073741824<span class="tag">&lt;/<span class="name">keep_free_space_bytes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_name_b</span>&gt;</span>	</span><br><span class="line">    <span class="tag">&lt;/<span class="name">disks</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">policies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">policie_name_a</span>&gt;</span> <span class="comment">&lt;!-- 自定义策略名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">volumes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">volume_name_a</span>&gt;</span>  <span class="comment">&lt;!-- 自定义卷名称 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_name_a<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_name_b<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">max_data_part_size_bytes</span>&gt;</span>disk_name_a<span class="tag">&lt;/<span class="name">max_data_part_size_bytes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">volume_name_a</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">volumes</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">move_factor</span>&gt;</span>0.2<span class="tag">&lt;/<span class="name">move_factor</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">policie_name_a</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="tag">&lt;<span class="name">policie_name_b</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">policie_name_b</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">policies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">storage_configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>解释一下里面标签的含义，首先是 disks 标签：</strong></p>
<ul>
<li><code>，必填项，必须全局唯一，表示磁盘的自定义名称，显然可以定义多块磁盘</code></li>
<li><code>，必填项，用于指定磁盘路径</code></li>
<li><code>：选填项，以字节为单位，用于定义磁盘的预留空间</code></li>
</ul>
<p><strong>然后是 policies 标签，在 policies 标签里面需要引用已经定义的 disks 磁盘，并且同样支持定义多个策略：</strong></p>
<ul>
<li><code>，必填项，必须全局唯一，表示策略的自定义名称</code></li>
<li><code>，必须填，比如全局唯一，表示卷的自定义名称</code></li>
<li><code>，必填项，用于关联  配置内的磁盘，可以声明多个 disk，MergeTree 会按照声明的顺序选择 disk</code></li>
<li><code>，选填项，以字节为单位，表示在这个卷的单个 disk 磁盘中，一个数据分区的最大分区阈值。如果当前分区的数据大小超过阈值，则之后的分区会写入下一个 disk 磁盘</code></li>
<li><code>，选填项，默认为 0.1，如果当前卷的可用空间小于 factor 因子，并且定义了多个卷，则数据会自动向下一个卷移动</code></li>
</ul>
<p><strong>1. JBOD 策略演示</strong></p>
<p><strong>注意：storage_configuration 在 config.xml 里面是没有的，我们需要手动加进去。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">storage_configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">disks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_hot1</span>&gt;</span> <span class="comment">&lt;!-- 自定义磁盘名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/root/hotdata1/<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_hot1</span>&gt;</span>	</span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_hot2</span>&gt;</span> <span class="comment">&lt;!-- 自定义磁盘名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/root/hotdata2/<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_hot2</span>&gt;</span>	</span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_cold</span>&gt;</span> <span class="comment">&lt;!-- 自定义磁盘名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/root/colddata/<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">keep_free_space_bytes</span>&gt;</span>1073741824<span class="tag">&lt;/<span class="name">keep_free_space_bytes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_cold</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">disks</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 配置存储策略，在 volumes 卷下面引用上面定义的两块磁盘，组成磁盘组 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">policies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">jbod_policies</span>&gt;</span> <span class="comment">&lt;!-- 自定义策略名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">volumes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">jbod</span>&gt;</span>  <span class="comment">&lt;!-- 自定义卷名称 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_hot1<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_hot2<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">jbod</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">volumes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">jbod_policies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">policies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">storage_configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>至此一个支持 JBOD 的存储策略就配置好了，但在正式应用之前我们还需要做一些准备工作。首先我们要将目录创建好，然后将路径授权，让 ClickHouse 用户拥有相应的读写权限：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># mkdir hotdata1 hotdata2 colddata</span></span><br><span class="line">[root@satori ~]<span class="comment"># sudo chown clickhouse:clickhouse -R /root</span></span><br></pre></td></tr></table></figure>

<p><strong>由于存储配置不支持动态更新，为了使配置生效，还需要重启 ClickHouse 服务，直接 clickhouse restart 即可。重启之后可以查询系统表来验证配置是否生效：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181952844-2036224644.png" alt="img"></p>
<p><strong>通过 system.disks 系统表可以看到刚才声明的三块磁盘配置已经生效，接着验证配置策略：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181945403-153314088.png" alt="img"></p>
<p><strong>通过 system.storage_policies 系统表可以看到刚才配置的存储策略也已经生效了，现在创建一张 MergeTree 表，用于测试 jbod_policies 存储策略的效果。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181936302-1008011642.png" alt="img"></p>
<p><strong>在定义 MergeTree 数据表时，可以使用 storage_policy 配置项指定刚才的 jbod_policies 存储策略，注意：存储策略一旦设置，就不能再修改了。下面来测试一下效果：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181927735-1046606557.png" alt="img"></p>
<p><strong>可以看到第一块分区写入了第一块磁盘 disk_hot1，然后我们再来写入第二批数据，此时会创建第二个分区目录：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181919064-149165324.png" alt="img"></p>
<p><strong>插入数据之后再次查看分区系统表，可以看到第二个分区写入了第二块磁盘。最后再触发一次分区合并动作，生成一个合并后的新分区目录：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181911463-1216561303.png" alt="img"></p>
<p><strong>还是查询分区系统表，可以看到合并后生成的 all_1_2_1 分区再次写入了第一块磁盘 disk_hot1。</strong></p>
<p><strong>相信此时应该解释清除 JBOD 策略的工作方式了，在这个策略中，由多个磁盘组成一个磁盘组，即 volume 卷。每当生成一个新数据分区的时候，分区目录会依照 volume 卷中磁盘定义的顺序，依次轮询并写入各个磁盘。</strong></p>
<p><strong>2. HOT&#x2F;COLD 策略演示</strong></p>
<p><strong>现在介绍 HOT&#x2F;COLD 策略的使用方法，我们将 JBOD 策略对应的配置原封不动的拷贝过来，然后在里面加一个新策略。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">storage_configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">disks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_hot1</span>&gt;</span> </span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/root/hotdata1/<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_hot1</span>&gt;</span>	</span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_hot2</span>&gt;</span> </span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/root/hotdata2/<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_hot2</span>&gt;</span>	</span><br><span class="line">        <span class="tag">&lt;<span class="name">disk_cold</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">path</span>&gt;</span>/root/colddata/<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">keep_free_space_bytes</span>&gt;</span>1073741824<span class="tag">&lt;/<span class="name">keep_free_space_bytes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">disk_cold</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">disks</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">policies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">jbod_policies</span>&gt;</span> </span><br><span class="line">            <span class="tag">&lt;<span class="name">volumes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">jbod</span>&gt;</span>  </span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_hot1<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_hot2<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">jbod</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">volumes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">jbod_policies</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">&lt;!-- 添加新策略 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">moving_from_hot_to_cold</span>&gt;</span>  <span class="comment">&lt;!-- 自定义策略名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">volumes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">hot</span>&gt;</span> <span class="comment">&lt;!-- 自定义名称，hot 区域磁盘 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_hot1<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">max_data_part_size_bytes</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">max_data_part_size_bytes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">hot</span>&gt;</span>        </span><br><span class="line">                <span class="tag">&lt;<span class="name">cold</span>&gt;</span> <span class="comment">&lt;!-- 自定义名称，cold 区域磁盘 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">disk</span>&gt;</span>disk_cold<span class="tag">&lt;/<span class="name">disk</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">cold</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">volumes</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">move_factor</span>&gt;</span>0.2<span class="tag">&lt;/<span class="name">move_factor</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">moving_from_hot_to_cold</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">policies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">storage_configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>用新配置将之前的 JBOD 配置给替换掉，或者直接将我们新加的部分添加到配置文件中即可，然后重启 ClickHouse。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181901836-1655234789.png" alt="img"></p>
<p><strong>可以看到新配置的存储策略已经生效了，moving_from_hot_to_cold 存储策略拥有 hot 和 cold 两个磁盘卷，在每个卷下各拥有一块磁盘。注意：hot 磁盘卷的 max_data_part_size 列显示的值为 1MB，这个值的含义为，在这个磁盘卷下，如果一个分区的大小超过 1MB，则它需要被移动到紧邻的下一个磁盘。当然这里为了演示效果，实际工作中不会配置的这么小的。</strong></p>
<p><strong>那么下面还是创建一张 MergeTree 表，用于测试 moving_from_hot_to_cold 存储策略的效果。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hot_cold_table (id UInt64)</span><br><span class="line">ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br><span class="line">SETTINGS storage_policy <span class="operator">=</span> <span class="string">&#x27;moving_from_hot_to_cold&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>在定义 MergeTree 时，使用 storage_policy 配置项指定刚才定义的存储策略，当然存储策略一旦定义就不能再修改了。那么接下来就来测试一下效果，首先写入第一批数据（小于 1MB），创建一个分区目录：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181852306-1069889650.png" alt="img"></p>
<p><strong>查询分区系统表，可以看到第一个分区写入了 hot 卷。那么下面就来写入第二批数据，数据大小和上次一样，当然此时会创建第二个分区目录：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181842923-483729542.png" alt="img"></p>
<p><strong>这是我们看到第二个分区仍然写入了 hot 卷，因为 hot 卷的 max_data_part_size 是 1MB，而每次写入数据的大小没有超过 1MB，所以自然都保存到了该磁盘下。那么接下来触发一次分区的合并动作，会生成一个新的分区目录。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181835354-1979918308.png" alt="img"></p>
<p><strong>当两个分区合并之后，所创建的新分区的大小超过了 1MB，所以它会被写入 cold 卷。当然一次性写入大于 1MB 的数据，分区也会被写入 cold 卷。</strong></p>
<p><strong>至此我们算是明白了 HOT&#x2F;COLD 策略的工作方式了，在这个策略中，由多个磁盘卷（volume 卷）组成一个 volume 组。每当生成一个新数据分区的时候，按照阈值大小（max_data_part_size），分区目录会依照 volume 组中磁盘定义的顺序，依次轮询并写入各个卷下的磁盘。</strong></p>
<p><strong>另外，虽然 MergeTree 的存储策略是不能修改的，但分区目录却支持移动，例如将某个分区移动至当前存储策略中 volume 卷下的其它 disk 磁盘：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> hot_cold_table MOVE PART <span class="string">&#x27;all_1_2_1&#x27;</span> <span class="keyword">TO</span> DISK <span class="string">&#x27;disk_hot1&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>或者将某个分区移动至当前存储策略中其它的 volume 卷：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> hot_cold_table MOVE PART <span class="string">&#x27;all_1_2_1&#x27;</span> <span class="keyword">TO</span> VOLUME <span class="string">&#x27;cold&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181828118-1564848043.png" alt="img"></p>
<h3 id="ReplacingMergeTree"><a href="#ReplacingMergeTree" class="headerlink" title="ReplacingMergeTree"></a>ReplacingMergeTree</h3><p><strong>虽然 MergeTree 拥有主键，但是它的主键却没有唯一的约束，这意味着即便多行数据的主键相同，依旧能够正确写入。而在某些场合我们不希望数据表中有重复的数据，那么这个时候 ReplacingMergeTree 就登场了，它就是为数据去重而设计的，可以在合并分区时删除重复的数据。因此它的出现，确实在一定程度上解决了重复数据的问题，啊嘞嘞，为啥是一定程度？先卖个关子。</strong></p>
<p><strong>创建一张 ReplacingMergeTree 数据表的语法和创建普通 MergeTree 表别无二致，只需要将 ENGINE 换一下即可：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = ReplacingMergeTree(ver)</span><br></pre></td></tr></table></figure>

<p><strong>里面的参数 ver 是选填的，可以指定一个整型、Date、DateTime 的字段作为版本号，这个参数决定了去除重复数据时所使用的算法。那么下面我们就来创建一张 ReplacingMergeTree 数据表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> replace_table (</span><br><span class="line">    id String,</span><br><span class="line">    code String,</span><br><span class="line">    create_time DateTime</span><br><span class="line">) ENGINE <span class="operator">=</span> ReplacingMergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (id, code)</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY id</span><br></pre></td></tr></table></figure>

<p><strong>这里的 ORDER BY 是去除重复数据的关键，不是 PRIMARY KEY，ORDERR BY 声明的表达式是后续判断数据是否重复的依据。在这个栗子中，数据会基于 id 和 code 两个字段进行去重，我们写入几条数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> replace_table </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-10 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-11 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C100&#x27;</span>, <span class="string">&#x27;2020-11-12 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C200&#x27;</span>, <span class="string">&#x27;2020-11-13 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A002&#x27;</span>, <span class="string">&#x27;C2&#x27;</span>, <span class="string">&#x27;2020-11-14 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A003&#x27;</span>, <span class="string">&#x27;C3&#x27;</span>, <span class="string">&#x27;2020-11-15 15:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>我们插入了 6 条数据，但 create_time 为 2020-11-10 15:00:00、2020-11-11 15:00:00 的两条数据的 id 和 code 是重复的，因此会进行去重，只保留重复数据的最后一条，所以最终只会有 5 条数据。但需要注意的是，我们这 6 条数据是使用一个 INSERT 语句导入的，所以在导入的时候直接就去重了。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181813167-935728819.png" alt="img"></p>
<p><strong>我们看到只保留了最后一条重复数据，因为使用的是一个 INSERT，所以这批数据会写入到同一个分区目录。如果是同一分区的不同分区目录（分多批导入），那么数据是不会去重的，只有在进行合并的时候才会进行去重。举个栗子，我们再写入几条数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> replace_table </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-03 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-02 15:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>显然这两条数据会写入新的分区目录，但它们的 id 和 code 也是重复的，因此会去进行去重，最终新生成的分区目录中只会有一条数据。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181805763-97212981.png" alt="img"></p>
<p><strong>ClickHouse 的控制台做的还是很人性化的，不同分区目录的数据是分开显示的，当然我们在获取到的数据本身是连在一起的，只是 ClickHouse 的控制台方便你观察而分开显示了。我们看到第二个分区目录中只有一条数据，因为导入的两条数据的 id 和 code 是重复的，在写入同一个分区目录的时候会先对数据进行去重。但是不同分区目录的之间的数据是可以重复的，因为去重是以分区目录为单位的，而一个分区可以对应多个分区目录，所以上面出现了两个 A001、C1，因为它们位于不同的分区目录。只有当这些分区目录进行合并、生成新的分区目录时才会进行去重。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181759317-1132408541.png" alt="img"></p>
<p><strong>当不同分区目录的数据进行合并时，数据再次进行了去重，会保留后创建的分区目录中的数据，因此 create_time 为 2020-11-02 15:00:00 的数据保留了下来。并且我们也可以看到，ReplacingMergeTree 在去除重复数据时，确实是以排序键为单位的。如果以主键去重的话，那么就不会有 3 条 A001 了。</strong></p>
<p><strong>所以暂时可以得出如下结论：</strong></p>
<ul>
<li><code>1. 去重是以排序键为准</code></li>
<li><code>2. 当数据写入同一个分区目录时，会直接对重复数据进行去重，并且保留的是最后一条</code></li>
<li><code>3. 同一分区、但位于不同分区目录的数据不会进行去重，只有在合并成新的分区目录时才会进行去重，并且保留的是最后一个分区的数据</code></li>
</ul>
<p><strong>不过问题来了，要是不同分区的数据会不会去重呢？其实在开头我们就已经埋下伏笔了，因为我们在开头说了 ReplacingMergeTree 是在一定程度上解决了数据重复的问题，所以不同分区的数据重复它是无法解决的。</strong></p>
<p><strong>我们上面所有的数据都位于 2020-11 这个分区中，那么下面再插入一条数据、创建一个新的分区：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INSERT INTO replace_table VALUES (&#x27;A001&#x27;, &#x27;C1&#x27;, &#x27;2010-11-17 15:00:00&#x27;)</span><br></pre></td></tr></table></figure>

<p><strong>我们将 2020 改成 2010，然后测试一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181751295-1246488673.png" alt="img"></p>
<p><strong>因此不同分区的数据是无法进行去重的，这也算是 ReplacingMergeTree 的一个局限性。当然说局限性感觉也不是很合适，因为分区的目的就是为了减小查询时的数据量，如果往一个分区导入数据还要在乎其它分区、看数据是否在其它分区中已出现，那这不就相当于丧失了分区的意义了吗？</strong></p>
<p><strong>但是问题来了，这里不同分区的数据先不考虑，因为它无法去重，我们再谈一下同一个分区中数据去重的逻辑。我们说当数据重复时会保留最后一条，但有时我们希望某个字段的值最大的那一条保留下来，这时该怎么做呢？还记得我们之前说在指定 ReplacingMergeTree 的时候可以指定参数吗？</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> replace_table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> replace_table (</span><br><span class="line">    id String,</span><br><span class="line">    code String,</span><br><span class="line">    create_time DateTime</span><br><span class="line">    <span class="comment">-- 指定参数，以后去重的时候会保留 create_time 最大的那一条数据</span></span><br><span class="line">) ENGINE <span class="operator">=</span> ReplacingMergeTree(create_time)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (id, code)</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY id</span><br></pre></td></tr></table></figure>

<p><strong>然后插入几条数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> replace_table </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-10 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-21 15:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-11 15:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>显示此时会保留 create_time 为 2020-11-21 15:00:00 的记录，因为的值最大，我们测试一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181742777-356270348.png" alt="img"></p>
<p><strong>然后再插入两条记录：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> replace_table </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-28 15:00:00&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> replace_table </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;2020-11-27 15:00:00&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>注意：我们要分两批导入，然后进行合并，显然 2020-11-28 15:00:00 这条会保留下来，而不是最后一个分区目录中数据。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181736300-18731632.png" alt="img"></p>
<p><strong>所以最后再总结一下 ReplacingMergeTree 的使用逻辑：</strong></p>
<ul>
<li><code>1. 使用 ORDER BY 排序键作为判断数据重复的唯一键</code></li>
<li><code>2. 当导入同一分区目录时，会直接进行去重</code></li>
<li><code>3. 当导入不同分区目录时，不会进行去重，只有当分区目录合并时，属于同一分区内的重复数据才会去重；但是不同分区内的重复数据不会被删除</code></li>
<li><code>4. 在进行数据去重时，因为分区内的数据已经是基于 ORDER BY 排好序的，所以能很容易地找到那些相邻的重复的数据</code></li>
<li><code>5. 数据去重策略有两种：如果没有设置 ver 版本号，则保留同一组重复数据中的最后一条；如果设置了 ver 版本号，则保留同一组重复数据中 ver 字段取值最大的那一行</code></li>
</ul>
<h3 id="SummingMergeTree"><a href="#SummingMergeTree" class="headerlink" title="SummingMergeTree"></a>SummingMergeTree</h3><p><strong>假设有这样一种查询需求，终端用户只需要查询数据的汇总结果，不关心明细数据，并且数据的汇总条件是预先明确的（GROUP BY 条件明确，且不会随意改变）。对于这样的查询场景，ClickHouse 要如何解决呢？</strong></p>
<p><strong>最直接的方案就是使用 MergeTree 存储数据，然后通过 GROUP BY 聚合查询，并利用 SUM 函数汇总结果。这种方案本身完全行的通，但是有两个不完美之处：</strong></p>
<ul>
<li><code>存在额外的存储开销：终端用户不会查询任何明细数据，只关心汇总结果，所以不应该一直保存所有的明细数据</code></li>
<li><code>存在额外的查询开销：终端用户只关心汇总结果，虽然 MergeTree 性能强大，但是每次查询都进行实时聚合计算也是一种性能消耗</code></li>
</ul>
<p><strong>而 SummingMergeTree 就是为了应对这类查询场景而生的，顾名思义它能够在合并分区的时候按照预先定义的的条件汇总数据，将同一分组下的多行数据汇总成一行，这样既减少了数据行，又降低了后续汇总查询的开销。</strong></p>
<p><strong>在之前我们说过，MergeTree 的每个分区内，数据都会按照 ORDER BY 表达式排好序，主键索引都会按照 PRIMARY KEY 取值并排好序。而默认情况下 ORDER BY 可以代指 PRIMARY KEY，所以一般情况下我们只需要声明 ORDER BY 即可。但如果需要同时定义 ORDER BY 和 PRIMARY KEY，通常只有一种可能，那就是明确希望 ORDER BY 和 PRIMARY KEY 不同，而这种情况只会在使用 SummingMergeTree 和 AggregatingMergeTree 时才会出现，因为这两者的聚合都是根据 ORDER BY 进行的。</strong></p>
<p><strong>假设有一张 SummingMergeTree 数据表，里面有 A、B、C、D、E、F 六个字段，如果需要按照 A、B、C、D 汇总，那么在创建表结构的时候需要指定：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (A, B, C, D)</span><br></pre></td></tr></table></figure>

<p><strong>但是这样主键也被定义成了 A、B、C、D，而在业务层面其实只需要对业务字段 A 进行查询过滤，所以应该只使用 A 字段创建主键。所以我们应该这么定义：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (A, B, C, D)</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY A</span><br></pre></td></tr></table></figure>

<p><strong>但如果同时声明了 ORDER BY 和 PRIMARY KEY，那么 MergeTree 会强制要求 PRIMARY KEY 必须是 ORDER BY 的前缀，所以：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 不行</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (B, C)</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY A</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 行</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (B, C)</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY B</span><br></pre></td></tr></table></figure>

<p><strong>这种强制约束保障了即便在定义不同的情况下，主键仍然是排序键的前缀，不会出现索引与数据顺序混乱的问题。假设现在业务发生了细微的变化，需要减少字段，将先前的 A、B、C、D 改为按照 A、B 汇总，则可按照如下方式修改排序键：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TABLE table_name MODIFY ORDER BY (A, B)</span><br></pre></td></tr></table></figure>

<p><strong>但是需要注意，如果减少字段的话，只能从右往左减少。怎么理解呢？我们之前是按照 A、B、C、D 进行的汇总，那么减少字段的话，最终可以按照 A、B、C 汇总、可以按照 A、B 汇总、可以按照 A 汇总，但是不能按照 A、C 或者 A、D、或者 A、C、D 等等进行汇总。所以减少字段一定是从右往左依次减少，不能出现跳跃。</strong></p>
<p><strong>除此之外，ORDER BY 只能在现有字段的基础上减少字段，如果新增字段，则只能添加通过 ALTER ADD COLUMN 新增的字段。但 ALTER 是一种元数据级别的操作，修改成本很低，相比不能修改的主键，已经非常便利了。</strong></p>
<p><strong>那么介绍 SummingMergeTree 数据表的创建方式，显然都已经猜到了，因为 MergeTree 家族的表引擎创建方式都是类似的，只不过引擎不同罢了。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">ENGINE <span class="operator">=</span> SummingMergeTree((col1, col2, col3, ...))</span><br></pre></td></tr></table></figure>

<p><strong>其中 col1、col2 为 columns 参数值，这是一个选填参数，用于设置除主键外的其它数值类型字段，以指定被 SUM 汇总的列字段。如果不填写此参数，则会将所有非主键的数值类型字段进行汇总，下面就来创建一张 SummingMergeTree 表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> summing_table (</span><br><span class="line">    id String,</span><br><span class="line">    city String,</span><br><span class="line">    v1 UInt32,</span><br><span class="line">    v2 Float64,</span><br><span class="line">    create_time DateTime</span><br><span class="line">) ENGINE <span class="operator">=</span> SummingMergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (id, city)</span><br></pre></td></tr></table></figure>

<p><strong>接下来插入几条数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> summing_table</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="number">10</span>, <span class="number">20.1</span>, <span class="string">&#x27;2020-05-10 17:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="number">20</span>, <span class="number">30.2</span>, <span class="string">&#x27;2020-05-20 17:00:00&#x27;</span>),</span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;shanghai&#x27;</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="string">&#x27;2020-05-10 17:00:00&#x27;</span>);</span><br><span class="line">       </span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> summing_table</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="string">&#x27;2020-05-01 17:00:00&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> summing_table</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="number">60</span>, <span class="number">50</span>, <span class="string">&#x27;2020-10-10 17:00:00&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>显然此时会创建三个分区目录，202005_1_\1_0、202005_2_\2_0、202010_1_\1_0。另外 SummingMergeTree 和 ReplacingMergeTree 类似，如果导入同一分区目录的数据有重复的，那么直接就聚合了，不同分区目录则不会聚合，而是在合并生成新分区目录的时候，再对属于同一分区的多个分区目录里的数据进行聚合。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181722193-2107011356.png" alt="img"></p>
<p><strong>我们看到第一个分区目录中的三条数据聚合成了两条，然后手动触发合并动作：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181715636-1448937195.png" alt="img"></p>
<p><strong>不同分区目录（属于同一分区）里的数据聚合在一起了，至于不在汇总字段之列的 create_time 则取了同组内第一行数据的值；而不同分区对应的分区目录就不会被聚合了，因为不在同一个分区内。</strong></p>
<p><strong>另外 SummingMergeTree 也支持嵌套类型的字段，在使用嵌套类型字段时，需要被 SUM 汇总的字段必须以以 Map 后缀结尾，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> summing_table_nested (</span><br><span class="line">    id String,</span><br><span class="line">    nestMap Nested (</span><br><span class="line">        id UInt32,</span><br><span class="line">        key UInt32,</span><br><span class="line">        val UInt64</span><br><span class="line">    ),</span><br><span class="line">    create_time DateTime</span><br><span class="line">) ENGINE <span class="operator">=</span> SummingMergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p><strong>在使用嵌套数据类型时，默认会以嵌套类型中第一个字段作为聚合条件 Key，写入测试数据：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181705340-308252351.png" alt="img"></p>
<p><strong>我们看到写入的时候就聚合了，并且按照 nestMap 里面的 id 聚合的，之前我们说过：嵌套类型本质是一种多维数组的结构，里面的每个字段都是一个数组，并且长度要相等。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181659994-1690687124.png" alt="img"></p>
<p><strong>然后我们再写一条数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> summing_table_nested <span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, [<span class="number">2</span>], [<span class="number">300</span>], [<span class="number">600</span>], <span class="string">&#x27;2020-08-10 17:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>显然此时会新创建一个分区目录，然后我们手动触发合并：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181654283-926470290.png" alt="img"></p>
<p><strong>合并的结果显然符合我们的预期，当然如果分区不同，那么就无法合并了。</strong></p>
<p><strong>当然我们上面默认是按 id 进行聚合的，或者说是按嵌套类型中的第一个字段进行聚合，但 ClickHouse 也支持使用复合字段（Key）作为数据聚合的条件。为了使用复合 Key，在嵌套类型的字段中，除了第一个字段以外，任何名称是以 Key、Id 或者 Type 结尾的字段，都将和第一个字段一起组成复合 Key。例如我们将上面的建表逻辑改一下，将小写 key 改成大写 Key：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> summing_table_nested (</span><br><span class="line">    id String,</span><br><span class="line">    nestMap Nested (</span><br><span class="line">        id UInt32,</span><br><span class="line">        Key UInt32,  <span class="comment">-- 大写 Key</span></span><br><span class="line">        val UInt64</span><br><span class="line">    ),</span><br><span class="line">    create_time DateTime</span><br><span class="line">) ENGINE <span class="operator">=</span> SummingMergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p><strong>该栗子中会以 id 和 Key 作为聚合条件，因此以上就是 SummingMergeTree，我们再来总结一下它的处理逻辑：</strong></p>
<ul>
<li><code>只有 ORDER BY 排序键作为聚合数据的条件 Key</code></li>
<li><code>写入同一分区目录的数据会聚合之后在写入，而属于同一分区的不同分区目录的数据，则会在合并触发时进行汇总</code></li>
<li><code>不同分区的数据不会汇总到一起</code></li>
<li><code>如果在定义引擎时指定了 columns 汇总列（非主键的数值类型字段），则 SUM 会汇总这些列字段；如果未指定，则聚合所有非主键的数值类型字段</code></li>
<li><code>在进行数据汇总时，因为分区内的数据已经基于 ORDER BY 进行排序，所以很容易找到相邻也拥有相同 Key 的数据</code></li>
<li><code>在汇总数据时，同一分区内相同聚合 key 的多行数据会合并成一行，其中汇总字段会进行 SUM 计算；对于那些非汇总字段，则会使用第一行数据的取值</code></li>
<li><code>支持嵌套结构，但列字段名称必须以 Map 后缀结尾，并且默认以第一个字段作为聚合 Key。并且除了第一个字段以外，任何名称以 key、Id 或者 Type 为后缀结尾的字段都会和第一个字段组成复合 Key</code></li>
</ul>
<h3 id="AggregatingMergeTree"><a href="#AggregatingMergeTree" class="headerlink" title="AggregatingMergeTree"></a>AggregatingMergeTree</h3><p><strong>有过数仓建设经验的你一定知道数据立方体的概念，这是一个在数仓领域十分常见的模型，它通过以空间换时间的方式提升查询性能，将需要聚合的数据预先计算出来（预聚合）并保存，在后续需要聚合查询到的时候，直接使用保存好的结果数据。</strong></p>
<blockquote>
<p><strong>Kylin 就是一个典型的使用预聚合的数据仓库，提供 Hadoop&#x2F;Spark 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据。它的核心逻辑就是在数据集上定义一个星形模型或者雪花模型，然后基于模型搭建数据立方体（cube）并将结果存储在 HBase 中，最后使用标准 SQL 以及其它 API 进行查询，由于数据已经提前计算好，所以仅需亚秒级响应时间即可获得查询结果。</strong></p>
</blockquote>
<p><strong>AggregatingMergeTree 就有些数据立方体的意思，它能够在合并分区的时候按照预先定义的条件聚合数据。同时，根据预先定义的聚合函数计算数据并通过二进制的格式存入表内。通过将同一分组下的多行数据预先聚合成一行，既减少了数据行，又降低了后续聚合查询的开销。可以说 AggregatingMergeTree 是 SummingMergeTree 的升级版，它们的许多设计思路和特性是一致的，例如同时定义 ORDER BY 和 PRIMARY KEY 的原因和目的。但是在用法上两者存在明显差异，应该说 AggregatingMergeTree 的定义方式是 MergeTree 家族中最为特殊的一个。声明使用 AggregatingMergeTree 的方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = AggregatingMergeTree()</span><br></pre></td></tr></table></figure>

<p><strong>AggregatingMergeTree 没有任何额外的设置参数，在分区合并时，在每个数据分区内，会按照 ORDER BY 聚合。而使用何种聚合函数，以及针对哪些列字段进行计算，则是通过定义 AggregateFunction 数据类型实现的。以下面的语句为例：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> agg_table (</span><br><span class="line">    id String,</span><br><span class="line">    city String,</span><br><span class="line">    code AggregateFunction(uniq, String),</span><br><span class="line">    <span class="keyword">value</span> AggregateFunction(sum, UInt32),</span><br><span class="line">    create_time DateTime</span><br><span class="line">) ENGINE <span class="operator">=</span> AggregatingMergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (id, city)</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY id </span><br></pre></td></tr></table></figure>

<p><strong>上述的 id 和 city 是聚合条件，等同于在 SQL 语句中指定 GROUP BY id, city；而 code 和 value 聚合字段，其语义等同于 uniq(code)、sum(value)。</strong></p>
<p><strong>AggregateFunction 是 ClickHouse 提供的一种特殊的数据结构，它能够以二进制的形式存储中间状态结果。其使用方法也十分特殊，对于 AggregateFunction 类型的列字段，数据的查询和写入都与众不同。在写入数据时需要调用 *State 函数，查询数据时则调用相应的 *Merge 函数。其中 * 表示定义时使用的聚合函数，例如上面的建表语句中使用了 uniq 和 sum 函数。</strong></p>
<p><strong>那么在写入数据时，需要调用对应的 uniqState 和 sumState 函数，并使用 INSERT SELECT 语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> agg_table </span><br><span class="line"><span class="keyword">SELECT</span> (<span class="string">&#x27;A000&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, uniqState(<span class="string">&#x27;code1&#x27;</span>), sumState(toUInt32(<span class="number">100</span>)), <span class="string">&#x27;2020-08-10 17:00:00&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;A000&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, uniqState(<span class="string">&#x27;code1&#x27;</span>), sumState(toUInt32(<span class="number">100</span>)), <span class="string">&#x27;2020-08-10 17:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>而在查询数据时，如果使用列名 code、value 进行访问的话，虽然也能查询到数据，只不过显示的是无法阅读的二进制，我们需要调用对应的 uniqMerge 和 sumState 函数。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> id, city, uniqMerge(code), sumMerge(<span class="keyword">value</span>)</span><br><span class="line"><span class="keyword">FROM</span> agg_table </span><br><span class="line"><span class="comment">-- 在 SQL 语句中聚合语句肯定要用 GROUP BY</span></span><br><span class="line"><span class="comment">-- 但在定义表结构的时候，聚合字段是使用 ORDER BY 表示的，当然它指定的也是排序字段</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> id, city</span><br></pre></td></tr></table></figure>

<p><strong>下面来测试一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181639262-723234817.png" alt="img"></p>
<p><strong>看到这里你可能觉得 AggregatingMergeTree 使用起来有些过去繁琐了，连正常数据写入还要借助 INSERT SELECT、并且调用特殊函数才能实现，没错，如果是上面这种做法的话，确实有些麻烦了。不过无须担心，当前这种用法并不是主流用法。</strong></p>
<p><strong>AggregatingMergeTree 的主流用法是结合物化视图使用，将它作为物化视图的表引擎，这里的物化视图是作为其它数据表上层的一种查询视图。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181631184-1254707137.png" alt="img"></p>
<p><strong>接下来用一组示例进行说明，首先创建明细数据表，也就是俗称的底表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> agg_table_basic (</span><br><span class="line">    id String,</span><br><span class="line">    city String,</span><br><span class="line">    code String,</span><br><span class="line">    <span class="keyword">value</span> UInt32</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> city</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (id, city)</span><br></pre></td></tr></table></figure>

<p><strong>通常使用 MergeTree 作为底表，用于存储全量的明细数据，并以此对外提供实时查询。接着，创建一张物化视图：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> agg_view </span><br><span class="line">ENGINE <span class="operator">=</span> AggregatingMergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> city</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (id, city)</span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">SELECT</span></span><br><span class="line">    id, city,</span><br><span class="line">    uniqState(code) <span class="keyword">AS</span> code,</span><br><span class="line">    sumState(<span class="keyword">value</span>) <span class="keyword">AS</span> <span class="keyword">value</span></span><br><span class="line"><span class="keyword">FROM</span> agg_table_basic</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> id, city</span><br></pre></td></tr></table></figure>

<p><strong>物化视图使用 AggregatingMergeTree 表引擎，用于特定场景的数据查询，相比 MergeTree，它拥有更高的性能。但在新增数据时，面向的对象是底表 MergeTree：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> agg_table_basic </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A000&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="string">&#x27;code1&#x27;</span>, <span class="number">100</span>),</span><br><span class="line">       (<span class="string">&#x27;A000&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="string">&#x27;code2&#x27;</span>, <span class="number">200</span>),</span><br><span class="line">       (<span class="string">&#x27;A000&#x27;</span>, <span class="string">&#x27;shanghai&#x27;</span>, <span class="string">&#x27;code1&#x27;</span>, <span class="number">200</span>)</span><br></pre></td></tr></table></figure>

<p><strong>数据会自动同步到物化视图，并按照 AggregatingMergeTree 的引擎的规则进行处理。而在查询数据时，面向的对象是物化视图 AggregatingMergeTree：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181622930-228367562.png" alt="img"></p>
<p><strong>以上就是 AggregatingMergeTree 的整个流程，最常见的用法是作为普通物化视图的表引擎，和普通 MergeTree 数据表搭配使用。</strong></p>
<h3 id="CollapsingMergeTree"><a href="#CollapsingMergeTree" class="headerlink" title="CollapsingMergeTree"></a>CollapsingMergeTree</h3><p><strong>假设现在需要设计一款数据库，该数据库支持需要支持对已经存在的数据实现行级粒度的修改和删除，你会怎么设计呢？一种最常见的想法是：首先找到保存数据的文件，接着修改这个文件，比如修改或删除那些需要变化的数据行。然而在大数据领域，对于 ClickHouse 这类高性能分析数据库而言，对数据源文件进行修改是一件非常奢侈且代价昂贵的操作。相较于直接修改源文件，将修改和删除操作转换为新增操作会更合适一些，也就是以增代删。</strong></p>
<p><strong>CollapsingMergeTree 就是一种通过以增代删的思路，支持行级数据修改和删除的表引擎。它通过定义一个 sign 标记位字段，记录数据行的状态。如果 sign 标记为 1，则表示这是一行有效数据；如果 sign 标记为 -1，则表示这行数据要被删除。当 CollapsingMergeTree 分区合并时，同一数据分区内，sign 标记为 1 和 -1 的一组数据（ORDER BY 字段对应的值相同）会被抵消删除。这种 1 和 -1 相互抵消的操作，犹如将一张瓦楞纸折叠了一般，这种直观的比喻，想必也是折叠合并树（CollapsingMergeTree）的由来。</strong></p>
<p><strong>声明 CollapsingMergeTree 的方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = CollapsingMergeTree(sign)</span><br></pre></td></tr></table></figure>

<p><strong>其中，sign 用于指定一个 Int8 类型的标志位字段，一个完整的 CollapsingMergeTree 数据表声明如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> collapse_table (</span><br><span class="line">    id String,</span><br><span class="line">    code Int32,</span><br><span class="line">    create_time DateTime,</span><br><span class="line">    sign Int8</span><br><span class="line">) ENGINE <span class="operator">=</span> CollapsingMergeTree(sign)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p><strong>与其它的 MergeTree 变种引擎一样，CollapsingMergeTree 同样是以 ORDER BY 排序键作为后续判断数据唯一性的依据。按照之前的介绍，对于上述 collapse_table 数据表而言，除了常规的新增操作之外，还能支持其它两种操作：</strong></p>
<p><strong>其一：删除一行数据</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 插入一条数据，后续对它进行删除</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A000&#x27;</span>, <span class="number">100</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>删除一条数据，显然不能像关系型数据库那样使用 DELETE，正确做法是插入一条”要删除的数据”的镜像数据，ORDER BY 字段与原数据相同（其它字段可以不同），然后 sign 取反为 -1，它会和原数据折叠，然后相互抵消。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A000&#x27;</span>, <span class="number">100</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>测试一下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line">Query id: f02e3e84<span class="number">-7837</span><span class="number">-4</span>db7<span class="operator">-</span>af2b<span class="operator">-</span>d42957c5a63b</span><br><span class="line"></span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A000 │  <span class="number">100</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A000 │  <span class="number">100</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │   <span class="number">-1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line"></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br></pre></td></tr></table></figure>

<p><strong>其二：修改一行数据</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 插入一条数据，后续对它进行修改</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="number">100</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>其中 code 的值是 100，我们要将其修改成 120，该怎么做呢？显然不能像关系型数据那样使用 UPDATE，正确的做法是以增代删。先创建镜像数据将原数据折叠，然后将修改后的原数据再插入到表中即可。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="number">100</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">-1</span>),</span><br><span class="line">       <span class="comment">-- 然后将原数据修改之后作为新数据，插入到表中，sign 为 1</span></span><br><span class="line">       (<span class="string">&#x27;A001&#x27;</span>, <span class="number">120</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>测试一下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line">Query id: bfb8afec<span class="operator">-</span>e672<span class="number">-416</span>f<span class="operator">-</span>a7b8<span class="number">-5</span>fcdf6470e59</span><br><span class="line"></span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A000 │  <span class="number">100</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A000 │  <span class="number">100</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │   <span class="number">-1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A001 │  <span class="number">100</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A001 │  <span class="number">100</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │   <span class="number">-1</span> │</span><br><span class="line">│ A001 │  <span class="number">120</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line"></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.003</span> sec. </span><br><span class="line"></span><br><span class="line">satori :) </span><br></pre></td></tr></table></figure>

<p><strong>还是很好理解的，然后 CollapsingMergeTree 在折叠数据时遵循如下规则：</strong></p>
<ul>
<li><code>如果 sign = 1 比 sign = -1 的数据多一行，则保留最后一行 sign = 1 的数据</code></li>
<li><code>如果 sign = -1 比 sign = 1 的数据多一行，则保留第一行 sign = -1 的数据</code></li>
<li><code>如果 sign = 1 和 sign = -1 的数据行一样多，并且最后一行是 sign = 1，则保留第一行 sign = -1 和最后一行 sign = 1 的数据</code></li>
<li><code>如果 sign = 1 和 sign = -1 的数据行一行多，并且最后一行是 sign = -1，则什么也不保留</code></li>
<li><code>其余情况，ClickHouse 会打印告警日志，但不会报错，在这种情形下打印结果不可预知</code></li>
</ul>
<p><strong>当然折叠数据并不是实时触发的，和所有的其它 MergeTree 变种表引擎一样，这项特性只有在多个分区目录合并的时候才会触发，触发时属于同一分区的数据会进行折叠。而在分区合并之前，用户还是可以看到旧数据的，就像上面演示的那样。</strong></p>
<p><strong>如果不想看到旧数据，那么可以在聚合的时候可以改变一下策略：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 原始 SQL 语句</span></span><br><span class="line"><span class="keyword">SELECT</span> id, <span class="built_in">sum</span>(code), <span class="built_in">count</span>(code), <span class="built_in">avg</span>(code), uniq(code) </span><br><span class="line"><span class="keyword">FROM</span> collapse_table <span class="keyword">GROUP</span> <span class="keyword">BY</span> id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 改成如下</span></span><br><span class="line"><span class="keyword">SELECT</span> id, <span class="built_in">sum</span>(code <span class="operator">*</span> sign), <span class="built_in">count</span>(code <span class="operator">*</span> sign), <span class="built_in">avg</span>(code <span class="operator">*</span> sign), uniq(code <span class="operator">*</span> sign)</span><br><span class="line"><span class="keyword">FROM</span> collapse_table <span class="keyword">GROUP</span> <span class="keyword">BY</span> id <span class="keyword">HAVING</span> <span class="built_in">sum</span>(sign) <span class="operator">&gt;</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p><strong>或者在查询数据之前使用 optimize TABLE table_name FINAL 命令强制分区合并，但是这种方法效率极低，在实际生产环境中慎用。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">0</span>cf9d813<span class="number">-5</span>dcc<span class="number">-4</span>a58<span class="operator">-</span>a02a<span class="operator">-</span>de3d6fb38c60</span><br><span class="line"></span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A001 │  <span class="number">120</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec. </span><br><span class="line"></span><br><span class="line">satori :) </span><br></pre></td></tr></table></figure>

<p><strong>我们看到 A000 的数据已经没有了，只剩下了 A001，并且 code 是 120，不是原来的 100。</strong></p>
<p><strong>另外只有相同分区内的数据才有可能被折叠，不过这项限制对于 CollapsingMergeTree 来说通常不是问题，因为修改或删除数据的时候，这些数据的分区规则通常都是一致的，并不会改变。但 CollapsingMergeTree 还有一个非常致命的限制，那就是对数据的写入顺序有着严格要求，举个例子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 先写入 sign = 1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A002&#x27;</span>, <span class="number">102</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">-- 先写入 sign = -1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A002&#x27;</span>, <span class="number">102</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>显然此时是可以正常折叠的，我们刚才已经实验过了，但如果将写入的顺序置换一下，就无法折叠了。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 先写入 sign = 1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A003&#x27;</span>, <span class="number">102</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">-1</span>)</span><br><span class="line"><span class="comment">-- 先写入 sign = -1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A003&#x27;</span>, <span class="number">102</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>我们测试一下，执行 optimize TABLE collapse_table FINAL，然后进行查询：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> collapse_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">3</span>aaf02d2<span class="number">-7089</span><span class="number">-42</span>f6<span class="number">-9</span>d3b<span class="operator">-</span>a697b196bd42</span><br><span class="line"></span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A001 │  <span class="number">120</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">│ A003 │  <span class="number">102</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │   <span class="number">-1</span> │</span><br><span class="line">│ A003 │  <span class="number">102</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line"></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec. </span><br><span class="line"></span><br><span class="line">satori :) </span><br></pre></td></tr></table></figure>

<p><strong>我们看到两个 A003 没办法进行折叠，原因就是这两条数据的 sign &#x3D; -1 在前、sign &#x3D; 1 在后，如果我们在写入一条 A003、sign &#x3D; -1 会有什么结果呢？显然会和 sign &#x3D; 1 的 A003 进行合并，只留下一条 sign &#x3D; -1 的 A003。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> collapse_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> collapse_table</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">82226926</span><span class="number">-6</span>f2a<span class="number">-4</span>ab8<span class="number">-80</span>b4<span class="operator">-</span>ce8980ec1eec</span><br><span class="line"></span><br><span class="line">┌─id───┬─code─┬─────────create_time─┬─sign─┐</span><br><span class="line">│ A001 │  <span class="number">120</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │    <span class="number">1</span> │</span><br><span class="line">│ A003 │  <span class="number">102</span> │ <span class="number">2020</span><span class="number">-02</span><span class="number">-20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> │   <span class="number">-1</span> │</span><br><span class="line">└──────┴──────┴─────────────────────┴──────┘</span><br><span class="line"></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec. </span><br><span class="line"></span><br><span class="line">satori :) </span><br></pre></td></tr></table></figure>

<p><strong>这种现象是 CollapsingMergeTree 的处理机制所导致的，因为它要求 sign &#x3D; 1 和 sign &#x3D; -1 的数据相邻，而分区内的数据严格按照 ORDER BY 排序，要实现 sign &#x3D; 1 和 sign &#x3D; -1 的数据相邻，则只能严格按照顺序写入。</strong></p>
<p><strong>如果数据的写入顺序是单线程执行的，则能够比较好的控制写入顺序；但如果需要处理的数据量很大，数据的写入程序通常是多线程的，那么此时就不能保障数据的写入顺序了。而在这种情况下，CollapsingMergeTree 的工作机制就会出现问题，而为了解决这个问题，ClickHouse 额外提供了一个名为 VersionedCollapsingMergeTree 的表引擎。</strong></p>
<h3 id="VersionedCollapsingMergeTree"><a href="#VersionedCollapsingMergeTree" class="headerlink" title="VersionedCollapsingMergeTree"></a>VersionedCollapsingMergeTree</h3><p><strong>VersionedCollapsingMergeTree 表引擎的作用和 CollapsingMergeTree 完全相同，它们的不同之处在于 VersionedCollapsingMergeTree 对数据的写入顺序没有要求，在同一个分区内，任意顺序的数据都可以完成折叠操作。那么 VersionedCollapsingMergeTree 是如何做到这一点的呢？其实从它的名字就能看出来，因为相比 CollapsingMergeTree 多了一个 Versioned，那么显然就是通过版本号（version）解决的。</strong></p>
<p><strong>在定义 VersionedCollapsingMergeTree 数据表的时候，除了指定 sign 标记字段之外，还需要额外指定一个 UInt8 类型的 ver 版本号字段。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = VersionedCollapsingMergeTree(sign, ver)</span><br></pre></td></tr></table></figure>

<p><strong>一个完整的 VersionedCollapsingMergeTree 表定义如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> ver_collapse_table (</span><br><span class="line">    id String,</span><br><span class="line">    code Int32,</span><br><span class="line">    create_time DateTime,</span><br><span class="line">    sign Int8,</span><br><span class="line">    ver UInt8</span><br><span class="line">) ENGINE <span class="operator">=</span> CollapsingMergeTree(sign, ver)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p><strong>那么 VersionedCollapsingMergeTree 是如何使用版本号字段的呢？其实很简单，在定义 ver 字段之后，VersionedCollapsingMergeTree 会自动将 ver 作为排序条件并增加到 ORDER BY 的末端。以上面的 ver_collapse_table 为例，在每个分区内，数据会按照 ORDER BY id, ver DESC 排序。所以无论写入时数据的顺序如何，在折叠处理时，都能回到正确的顺序。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 首先是删除数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> ver_collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A000&#x27;</span>, <span class="number">101</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">-1</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> ver_collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A000&#x27;</span>, <span class="number">101</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 然后是修改数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> ver_collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="number">101</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">-1</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> ver_collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="number">102</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> ver_collapse_table <span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="number">103</span>, <span class="string">&#x27;2020-02-20 00:00:00&#x27;</span>, <span class="number">1</span>, <span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<p><strong>以上数据均能正常折叠。</strong></p>
<h3 id="各种-MergeTree-之间的关系总结"><a href="#各种-MergeTree-之间的关系总结" class="headerlink" title="各种 MergeTree 之间的关系总结"></a>各种 MergeTree 之间的关系总结</h3><p><strong>经过上述介绍是不是觉得 MergeTree 特别丰富呢？但还是那句话，任何事都有两面性，功能丰富就意味着很容易被这么多表引擎弄晕，那么下面我们就以继承和组合这两种关系来理解整个 MergeTree。</strong></p>
<h4 id="继承关系"><a href="#继承关系" class="headerlink" title="继承关系"></a>继承关系</h4><p><strong>首先为了便于理解，可以使用继承关系来理解 MergeTree，MergeTree 表引擎向下派生出 6 个变种表引擎。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181601134-545853463.png" alt="img"></p>
<p><strong>在 ClickHouse 底层的实现方法中，上述 7 种表引擎的区别主要体现在 Merge 合并的逻辑部分，简化后的对象关系如下图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181553869-189950708.png" alt="img"></p>
<p><strong>可以看到在具体的实现部分，7 种 MergeTree 共用一个主体，而在触发 Merge 动作时，它们调用了各自独有的合并逻辑。</strong></p>
<p><strong>MergeTree 之外的其它 6 个变种表引擎的 Merge 合并逻辑，全部都是建立在 MergeTree 基础之上的，且均继承于 MergeTree 的 MergingSortedBlockInputStream，如下图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181548211-180815683.png" alt="img"></p>
<p><strong>MergingSortedBlockInputStream 的主要作用是按照 ORDER BY 的规则保证分区内数据的有序性，而其它 6 种变种 MergeTree 的合并逻辑，则是在有序的基础之上各有所长，例如将排序后相邻的重复数据消除，或者将重复数据累加汇总等等。</strong></p>
<h4 id="组合关系"><a href="#组合关系" class="headerlink" title="组合关系"></a>组合关系</h4><p><strong>了解完 7 种 MergeTree 的关系，下面再来说一下它们的组合，我们说如果 MergeTree 加上 Replicated 的话，则表示支持副本，那么 ReplicatedMergeTree 和普通的 MergeTree 有什么区别呢？</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181542392-1496501780.png" alt="img"></p>
<p><strong>上图中的虚线框部分是 MergeTree 的能力边界，而 ReplicatedMergeTree 则在 MergeTree 能力的基础之上增加了分布式协同的能力，其借助 zookeeper 的消息日志广播功能，实现了副本实例之间的数据同步功能。</strong></p>
<p><strong>ReplicatedMergeTree 系列可以用组合关系来理解，如下图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B9%8B%20MergeTree%20%E5%AE%B6%E6%97%8F%E4%B8%AD%E7%9A%84%E5%85%B6%E5%AE%83%E8%A1%A8%E5%BC%95%E6%93%8E(%E4%B8%83)/1229382-20210829181537938-2135925933.png" alt="img"></p>
<p><strong>当我们为 7 种 MergeTree 加上 Replicated 前缀之后，又能组合出 7 种新的表引擎，而这些 ReplicatedMergeTree 拥有副本协同的能力。关于 ReplicatedMergeTree，后续会详细说。</strong></p>
<p><strong>以上我们就介绍完了 MergeTree 以及整个家族系列的表引擎，MergeTree 系列表引擎在生产中是使用频率最高的表引擎，我们是非常有必要彻底掌握它的。但我们说除了 MergeTree，还有很多其它表引擎，虽然使用频率不是那么高，不过还是有适合自身的场景的，所以我们也需要掌握，那么后续就来看一看其它种类的表引擎。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 其它的一些操作函数 (十五)</title>
    <url>/2023/04/11/ClickHouse%20%E5%85%B6%E5%AE%83%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0%20(%E5%8D%81%E4%BA%94)/</url>
    <content><![CDATA[<h1 id="ClickHouse-其它的一些操作函数-十五"><a href="#ClickHouse-其它的一些操作函数-十五" class="headerlink" title="ClickHouse 其它的一些操作函数 (十五)"></a>ClickHouse 其它的一些操作函数 (十五)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>在 ClickHouse 中还存在一些其它比较有意思的函数，我们来看一下。</strong></p>
<p><strong>and：计算多个值逻辑与连接的结果</strong></p>
<p><strong>该函数只能接收 整型、浮点型和 Null，其逻辑和 Python 中的 and 类似</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">and</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="keyword">Null</span>, <span class="number">3</span>, <span class="number">5</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─and(1, 2, 0, NULL, 3, 5)─┐</span></span><br><span class="line"><span class="comment">│                        0 │</span></span><br><span class="line"><span class="comment">└──────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 等价于</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">AND</span> <span class="number">2</span> <span class="keyword">AND</span> <span class="number">0</span> <span class="keyword">AND</span> <span class="keyword">Null</span> <span class="keyword">AND</span> <span class="number">3</span> <span class="keyword">AND</span> <span class="number">5</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─and(1, 2, 0, NULL, 3, 5)─┐</span></span><br><span class="line"><span class="comment">│                        0 │</span></span><br><span class="line"><span class="comment">└──────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>or：计算多个值逻辑或连接的结果</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">or</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="keyword">Null</span>, <span class="number">3</span>, <span class="number">5</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─or(1, 2, 0, NULL, 3, 5)─┐</span></span><br><span class="line"><span class="comment">│                       1 │</span></span><br><span class="line"><span class="comment">└─────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 等价于</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">OR</span> <span class="number">2</span> <span class="keyword">OR</span> <span class="number">0</span> <span class="keyword">OR</span> <span class="keyword">Null</span> <span class="keyword">OR</span> <span class="number">3</span> <span class="keyword">OR</span> <span class="number">5</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─or(1, 2, 0, NULL, 3, 5)─┐</span></span><br><span class="line"><span class="comment">│                       1 │</span></span><br><span class="line"><span class="comment">└─────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>not：同样只能接收整型、浮点型、Null，用于逻辑取反</strong></p>
<p><strong>举个栗子：如果是非 0、非 Null，那么逻辑上就为真，因此调用 not 之后会得到假，也就是 0。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- not(0) 得到 1，not(Null) 还是 Null，not(非0、非 Null) 得到 0</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">not</span>(<span class="number">123</span>), <span class="keyword">not</span>(<span class="keyword">Null</span>), <span class="keyword">not</span>(<span class="number">0</span>), <span class="keyword">not</span>(<span class="number">333</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─not(123)─┬─not(NULL)─┬─not(0)─┬─not(333)─┐</span></span><br><span class="line"><span class="comment">│        0 │ ᴺᵁᴸᴸ      │      1 │        0 │</span></span><br><span class="line"><span class="comment">└──────────┴───────────┴────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 等价于</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NOT</span> <span class="number">123</span>, <span class="keyword">NOT</span> <span class="keyword">Null</span>, <span class="keyword">NOT</span> <span class="number">0</span>, <span class="keyword">NOT</span> <span class="number">333</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─not(123)─┬─not(NULL)─┬─not(0)─┬─not(333)─┐</span></span><br><span class="line"><span class="comment">│        0 │ ᴺᵁᴸᴸ      │      1 │        0 │</span></span><br><span class="line"><span class="comment">└──────────┴───────────┴────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>if：想象成编程语言中的三元表达式即可</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> number, if(number <span class="operator">&lt;</span> <span class="number">5</span>, <span class="string">&#x27;less than 5&#x27;</span>, <span class="string">&#x27;greater than or equal to 5&#x27;</span>) </span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">10</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─number─┬─if(less(number, 5), &#x27;less than 5&#x27;, &#x27;greater than or equal to 5&#x27;)─┐</span></span><br><span class="line"><span class="comment">│      0 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      1 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      2 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      3 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      4 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      5 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      6 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      7 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      8 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      9 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">└────────┴──────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 另外 ClickHouse 本身也支持三元表达式，底层依旧会转成 if</span></span><br><span class="line"><span class="keyword">SELECT</span> number, number <span class="operator">&lt;</span> <span class="number">5</span> ? <span class="string">&#x27;less than 5&#x27;</span> : <span class="string">&#x27;greater than or equal to 5&#x27;</span></span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">10</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─number─┬─if(less(number, 5), &#x27;less than 5&#x27;, &#x27;greater than or equal to 5&#x27;)─┐</span></span><br><span class="line"><span class="comment">│      0 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      1 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      2 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      3 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      4 │ less than 5                                                      │</span></span><br><span class="line"><span class="comment">│      5 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      6 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      7 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      8 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">│      9 │ greater than or equal to 5                                       │</span></span><br><span class="line"><span class="comment">└────────┴──────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>同样的，我们可以使用 CASE WHEN 语句实现。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> number, <span class="keyword">CASE</span> <span class="keyword">WHEN</span> number <span class="operator">&lt;</span> <span class="number">5</span> <span class="keyword">THEN</span> <span class="string">&#x27;less than 5&#x27;</span> <span class="keyword">ELSE</span> <span class="string">&#x27;greater than or equal to 5&#x27;</span> <span class="keyword">END</span></span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">10</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─number─┬─multiIf(less(number, 5), &#x27;less than 5&#x27;, &#x27;greater than or equal to 5&#x27;)─┐</span></span><br><span class="line"><span class="comment">│      0 │ less than 5                                                           │</span></span><br><span class="line"><span class="comment">│      1 │ less than 5                                                           │</span></span><br><span class="line"><span class="comment">│      2 │ less than 5                                                           │</span></span><br><span class="line"><span class="comment">│      3 │ less than 5                                                           │</span></span><br><span class="line"><span class="comment">│      4 │ less than 5                                                           │</span></span><br><span class="line"><span class="comment">│      5 │ greater than or equal to 5                                            │</span></span><br><span class="line"><span class="comment">│      6 │ greater than or equal to 5                                            │</span></span><br><span class="line"><span class="comment">│      7 │ greater than or equal to 5                                            │</span></span><br><span class="line"><span class="comment">│      8 │ greater than or equal to 5                                            │</span></span><br><span class="line"><span class="comment">│      9 │ greater than or equal to 5                                            │</span></span><br><span class="line"><span class="comment">└────────┴───────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们看到底层转化成了 multiIf，那么这个 multiIf 是做什么的呢？首先 if 函数的参数如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if(cond, then, else)</span><br></pre></td></tr></table></figure>

<p><strong>而 multiIf 函数的参数如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">multiIf(cond1, then1, cond2, then2, cond3, then3, ..., else)</span><br></pre></td></tr></table></figure>

<p><strong>所以从名字上也能看出来 multiIf 是干什么的，if 只能有一个条件，相当于编程语言中的 if … else；而 multiIf 可以接收多个条件，相当于编程语言中的 if … else if … else if … else。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 等价于 multiIf(number &lt; 5, &#x27;less than 5&#x27;, number = 5, &#x27;equal to 5&#x27;, &#x27;greater than 5&#x27;)</span></span><br><span class="line"><span class="keyword">SELECT</span> number, </span><br><span class="line">       <span class="keyword">CASE</span> <span class="keyword">WHEN</span> number <span class="operator">&lt;</span> <span class="number">5</span> <span class="keyword">THEN</span> <span class="string">&#x27;less than 5&#x27;</span> <span class="keyword">WHEN</span> number <span class="operator">=</span> <span class="number">5</span> <span class="keyword">THEN</span> <span class="string">&#x27;equal to 5&#x27;</span> <span class="keyword">ELSE</span> <span class="string">&#x27;greater than 5&#x27;</span> <span class="keyword">END</span></span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">10</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─number─┬─multiIf(less(number, 5), &#x27;less than 5&#x27;, equals(number, 5), &#x27;equal to 5&#x27;, &#x27;greater than 5&#x27;)─┐</span></span><br><span class="line"><span class="comment">│      0 │ less than 5                                                                                │</span></span><br><span class="line"><span class="comment">│      1 │ less than 5                                                                                │</span></span><br><span class="line"><span class="comment">│      2 │ less than 5                                                                                │</span></span><br><span class="line"><span class="comment">│      3 │ less than 5                                                                                │</span></span><br><span class="line"><span class="comment">│      4 │ less than 5                                                                                │</span></span><br><span class="line"><span class="comment">│      5 │ equal to 5                                                                                 │</span></span><br><span class="line"><span class="comment">│      6 │ greater than 5                                                                             │</span></span><br><span class="line"><span class="comment">│      7 │ greater than 5                                                                             │</span></span><br><span class="line"><span class="comment">│      8 │ greater than 5                                                                             │</span></span><br><span class="line"><span class="comment">│      9 │ greater than 5                                                                             │</span></span><br><span class="line"><span class="comment">└────────┴────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>根据返回的结果集的字段我们发现底层会变成函数调用：</strong></p>
<ul>
<li><code>a &lt; b 等价于 less(a, b)</code></li>
<li><code>a = b 等价于 equals(a, b)</code></li>
<li><code>a &gt; b 等价于 greater(a, b)</code></li>
<li><code>a &lt;= b 等价于 lessOrEquals(a, b)</code></li>
<li><code>a &gt;= b 等价于 greaterOrEquals(a, b)</code></li>
<li><code>a != b 等价于 notEquals(a, b)</code></li>
</ul>
<p><strong>但还是正如我们之前所说的，可以直接使用 CASE WHEN 进行实现，因为它也是关系型数据中非常常用的语法，这样读起来会更加的亲切。关于大小比较，我们也是直接使用操作符即可，没必要使用 less、equals、greater 等函数。</strong></p>
<h4 id="数学计算函数"><a href="#数学计算函数" class="headerlink" title="数学计算函数"></a>数学计算函数</h4><p><strong>以下是关于数学计算的一些函数，来看一下。</strong></p>
<p><strong>e：一个函数，调用之后返回底数 e</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────────────e()─┐</span></span><br><span class="line"><span class="comment">│ 2.718281828459045 │</span></span><br><span class="line"><span class="comment">└───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>pi：一个函数，调用之后返回圆周率 π</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> pi();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌──────────────pi()─┐</span></span><br><span class="line"><span class="comment">│ 3.141592653589793 │</span></span><br><span class="line"><span class="comment">└───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>exp：返回 e 的 x 次方</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">exp</span>(<span class="number">1</span>), <span class="built_in">exp</span>(<span class="number">2</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌────────────exp(1)─┬────────────exp(2)─┐</span></span><br><span class="line"><span class="comment">│ 2.718281828460626 │ 7.389056098924109 │</span></span><br><span class="line"><span class="comment">└───────────────────┴───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>除了 exp 之外，还有 exp2 返回 2 的 x 次方，exp10 返回 10 的 x 次方。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> exp2(<span class="number">2</span>), exp10(<span class="number">2</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─exp2(2)─┬─exp10(2)─┐</span></span><br><span class="line"><span class="comment">│       4 │      100 │</span></span><br><span class="line"><span class="comment">└─────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>log、ln：两者是等价的，都是以自然对数为底</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">log</span>(e()), <span class="built_in">ln</span>(e() <span class="operator">*</span> e());</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────────log(e())─┬─log(multiply(e(), e()))─┐</span></span><br><span class="line"><span class="comment">│ 0.9999999987491066 │        2.00000000029383 │</span></span><br><span class="line"><span class="comment">└────────────────────┴─────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>同理还有 log2 以 2 为底，log10 以 10 为底。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> log2(<span class="number">8</span>), <span class="built_in">log10</span>(<span class="number">1000</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─log2(8)─┬─log10(1000)─┐</span></span><br><span class="line"><span class="comment">│       3 │           3 │</span></span><br><span class="line"><span class="comment">└─────────┴─────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>sqrt：返回一个数的平方根</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">sqrt</span>(<span class="number">9</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─sqrt(9)─┐</span></span><br><span class="line"><span class="comment">│       3 │</span></span><br><span class="line"><span class="comment">└─────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>cbrt：返回一个数的立方根</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cbrt(<span class="number">27</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────────cbrt(27)─┐</span></span><br><span class="line"><span class="comment">│ 3.0000000000000004 │</span></span><br><span class="line"><span class="comment">└────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>pow：计算 x 的 y 次方</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- pow 也可以写成 power</span></span><br><span class="line"><span class="keyword">SELECT</span> pow(<span class="number">3</span>, <span class="number">4</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─pow(3, 4)─┐</span></span><br><span class="line"><span class="comment">│        81 │</span></span><br><span class="line"><span class="comment">└───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>sin、cos、tan：计算正弦值、余弦值、正切值</strong></p>
<p><strong>asin、acos、atan：计算反正弦值、反余弦值、反正切值</strong></p>
<p><strong>sinh、cosh、tanh：计算双曲正弦值、双曲余弦值、双曲正切值</strong></p>
<p><strong>asinh、acosh、atanh：计算反双曲正弦值、反双曲余弦值、反双曲正切值</strong></p>
<p><strong>atan2：atan 的增强版，具体细节可以百度或者谷歌</strong></p>
<p><strong>hypot：给定两个直角边，计算斜边长度，等于 x2+y2−−−−−−√�2+�2</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> hypot(<span class="number">3</span>, <span class="number">4</span>), hypot(<span class="number">6</span>, <span class="number">8</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hypot(3, 4)─┬─hypot(6, 8)─┐</span></span><br><span class="line"><span class="comment">│           5 │          10 │</span></span><br><span class="line"><span class="comment">└─────────────┴─────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>sign：小于 0 返回 -1、等于 0 返回 0、大于 0 返回 1</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> sign(<span class="number">-100</span>), sign(<span class="number">0</span>), sign(<span class="number">111</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─sign(-100)─┬─sign(0)─┬─sign(111)─┐</span></span><br><span class="line"><span class="comment">│         -1 │       0 │         1 │</span></span><br><span class="line"><span class="comment">└────────────┴─────────┴───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>floor、ceil（或者 ceiling）：返回小于等于 x 的最大整数、大于等于 x 的最小整数，注意：说返回整数其实不太准确，因为返回的仍是 Float64</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">floor</span>(<span class="number">3.14</span>), <span class="built_in">ceil</span>(<span class="number">3.14</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─floor(3.14)─┬─ceil(3.14)─┐</span></span><br><span class="line"><span class="comment">│           3 │          4 │</span></span><br><span class="line"><span class="comment">└─────────────┴────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 还可以选择精度，会保留一位，默认是一位都不保留</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">floor</span>(<span class="number">3.14</span>, <span class="number">1</span>), <span class="built_in">ceil</span>(<span class="number">3.14</span>, <span class="number">2</span>), <span class="built_in">ceiling</span>(<span class="number">3.14</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─floor(3.14, 1)─┬─ceil(3.14, 2)─┬─ceil(3.14, 3)─┐</span></span><br><span class="line"><span class="comment">│            3.1 │          3.14 │          3.14 │</span></span><br><span class="line"><span class="comment">└────────────────┴───────────────┴───────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>truncate、trunc：截断小数点</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> trunc(<span class="number">3.14</span>), trunc(<span class="number">-2.17</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─trunc(3.14)─┬─trunc(-2.17)─┐</span></span><br><span class="line"><span class="comment">│           3 │           -2 │</span></span><br><span class="line"><span class="comment">└─────────────┴──────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 仍然可以选择保留位数</span></span><br><span class="line"><span class="keyword">SELECT</span> trunc(<span class="number">3.14</span>, <span class="number">1</span>), trunc(<span class="number">-2.17</span>, <span class="number">1</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─trunc(3.14, 1)─┬─trunc(-2.17, 1)─┐</span></span><br><span class="line"><span class="comment">│            3.1 │            -2.1 │</span></span><br><span class="line"><span class="comment">└────────────────┴─────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>round：保留指定位数的小数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 不指定位数，将一位都不保留</span></span><br><span class="line"><span class="keyword">SELECT</span> round(<span class="number">3.1415926</span>, <span class="number">3</span>), round(<span class="number">3.1415926</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─round(3.1415926, 3)─┬─round(3.1415926)─┐</span></span><br><span class="line"><span class="comment">│               3.142 │                3 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴──────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：ClickHouse 中的 round 还有一种特殊用法，那就是对整数四舍五入。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 当指定为负数时，表示对整数或者小数点前面的进行四舍五入</span></span><br><span class="line"><span class="comment">-- -1 表示针对最后一位，所以 round(222, -1) 得到的结果是 220，round(228, -1) 得到的结果是 230</span></span><br><span class="line"><span class="keyword">SELECT</span> round(<span class="number">222</span>, <span class="number">-1</span>), round(<span class="number">228</span>, <span class="number">-1</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─round(222, -1)─┬─round(228, -1)─┐</span></span><br><span class="line"><span class="comment">│            220 │            230 │</span></span><br><span class="line"><span class="comment">└────────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- -2 表示针对最后两位，所以 round(-350, -2) 得到的结果是 -400，round(349, -2) 得到的结果是 300</span></span><br><span class="line"><span class="comment">-- 因为 50 达到了 100 的一半，49 没有达到 100 的一半</span></span><br><span class="line"><span class="keyword">SELECT</span> round(<span class="number">-350</span>, <span class="number">-2</span>), round(<span class="number">349</span>, <span class="number">-2</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─round(-350, -2)─┬─round(349, -2)─┐</span></span><br><span class="line"><span class="comment">│            -400 │            300 │</span></span><br><span class="line"><span class="comment">└─────────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- -3 表示针对最后三位，所以 round(499, -3) 得到的结果是 0，round(500, -3) 得到的结果是 1000</span></span><br><span class="line"><span class="comment">-- 因为 499 没有达到 1000 的一半，500 达到了 1000 的一半</span></span><br><span class="line"><span class="keyword">SELECT</span> round(<span class="number">499</span>, <span class="number">-3</span>), round(<span class="number">500</span>, <span class="number">-3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─round(499, -3)─┬─round(500, -3)─┐</span></span><br><span class="line"><span class="comment">│              0 │           1000 │</span></span><br><span class="line"><span class="comment">└────────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>roundToExp2：将数值转为某个最接近的 2 的整数次幂，比如 roundToExp2(33) 得到的就是 32，因为 32 是 2 的 5 次幂；roundToExp2(31) 得到的就是 16，因为 16 是 2 的 4 次幂</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 小于 1，返回 0</span></span><br><span class="line"><span class="keyword">SELECT</span> roundToExp2(<span class="number">33</span>), roundToExp2(<span class="number">31</span>), roundToExp2(<span class="number">1</span>), roundToExp2(<span class="number">-11</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─roundToExp2(33)─┬─roundToExp2(31)─┬─roundToExp2(1)─┬─roundToExp2(-11)─┐</span></span><br><span class="line"><span class="comment">│              32 │              16 │              1 │                0 │</span></span><br><span class="line"><span class="comment">└─────────────────┴─────────────────┴────────────────┴──────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>roundAge：如果一个数值小于 18，返回其本身；否则将其转成 18、25、35、45、55 当中与之最接近的一个值，很明显这个函数是针对 Yandex 公司的业务而专门设计的</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> roundAge(<span class="number">15</span>), roundAge(<span class="number">20</span>), roundAge(<span class="number">29</span>), roundAge(<span class="number">38</span>), roundAge(<span class="number">1000</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─roundAge(15)─┬─roundAge(20)─┬─roundAge(29)─┬─roundAge(38)─┬─roundAge(1000)─┐</span></span><br><span class="line"><span class="comment">│           17 │           18 │           25 │           35 │             55 │</span></span><br><span class="line"><span class="comment">└──────────────┴──────────────┴──────────────┴──────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>roundDown：将一个数值四舍五入到某个数组中与之最接近的值，如果数值小于数组中的最小值，那么等于最小值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">18</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">45</span>, <span class="number">55</span>] <span class="keyword">AS</span> arr</span><br><span class="line"><span class="keyword">SELECT</span> roundDown(<span class="number">15</span>, arr), roundDown(<span class="number">20</span>, arr), roundDown(<span class="number">29</span>, arr), roundDown(<span class="number">38</span>, arr), roundDown(<span class="number">1000</span>, arr)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─roundDown(15, arr)─┬─roundDown(20, arr)─┬─roundDown(29, arr)─┬─roundDown(38, arr)─┬─roundDown(1000, arr)─┐</span></span><br><span class="line"><span class="comment">│                 18 │                 18 │                 25 │                 35 │                   55 │</span></span><br><span class="line"><span class="comment">└────────────────────┴────────────────────┴────────────────────┴────────────────────┴──────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>rand、rand32：生成一个 UInt32 伪随机数</strong></p>
<p><strong>rand64：生成一个 UInt64 伪随机数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> rand32(), rand64();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───rand32()─┬─────────────rand64()─┐</span></span><br><span class="line"><span class="comment">│ 4261522186 │ 13571471280441249418 │</span></span><br><span class="line"><span class="comment">└────────────┴──────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>randConstant：生成一个 UInt32 伪随机数，但在一次查询中多次调用得到的结果一样</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> rand32(), randConstant() <span class="keyword">FROM</span> numbers(<span class="number">3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───rand32()─┬─randConstant()─┐</span></span><br><span class="line"><span class="comment">│ 3054555439 │      602145845 │</span></span><br><span class="line"><span class="comment">│ 1590396198 │      602145845 │</span></span><br><span class="line"><span class="comment">│ 2065566003 │      602145845 │</span></span><br><span class="line"><span class="comment">└────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="常见编码函数"><a href="#常见编码函数" class="headerlink" title="常见编码函数"></a>常见编码函数</h4><p><strong>以下是一些常见的编码函数，一起来看一下。</strong></p>
<p><strong>char：将 ASCII 码转成对应的字符，可以同时接收多个 ASCII 码</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="type">char</span>(<span class="number">97</span>), <span class="type">char</span>(<span class="number">97</span>, <span class="number">98</span>, <span class="number">99</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─char(97)─┬─char(97, 98, 99)─┐</span></span><br><span class="line"><span class="comment">│ a        │ abc              │</span></span><br><span class="line"><span class="comment">└──────────┴──────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>hex：将整型用 16 进制表示</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> hex(<span class="number">97</span>), hex(<span class="number">98</span>), hex(<span class="number">99</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hex(97)─┬─hex(98)─┬─hex(99)─┐</span></span><br><span class="line"><span class="comment">│ 61      │ 62      │ 63      │</span></span><br><span class="line"><span class="comment">└─────────┴─────────┴─────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>hex 除了接收整型之外，还可以接收字符串，将每个字符对应的 ASCII 码用 16 进制表示。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 十六进制：a -&gt; 61, b -&gt; 62, c-&gt;63</span></span><br><span class="line"><span class="keyword">SELECT</span> hex(<span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hex(&#x27;abc&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ 616263     │</span></span><br><span class="line"><span class="comment">└────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>unhex：hex 的逆运算，但只能接收字符串</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> unhex(<span class="string">&#x27;616263&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─unhex(&#x27;616263&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ abc             │</span></span><br><span class="line"><span class="comment">└─────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="其它函数"><a href="#其它函数" class="headerlink" title="其它函数"></a>其它函数</h4><p><strong>hostName：返回当前 ClickHouse Server 所在节点的主机名</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> hostName();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hostName()─┐</span></span><br><span class="line"><span class="comment">│ satori     │</span></span><br><span class="line"><span class="comment">└────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>getMacro：从服务器的宏配置中获取指定的值</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">macros</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>satori<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">macros</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>然后即可通过 getMacro(name) 获取，当然也可以查看所有的宏。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> system.macros;</span><br></pre></td></tr></table></figure>

<p><strong>fqdn：返回全限定域名，和我当前的主机名是一样的</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> fqdn();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─FQDN()─┐</span></span><br><span class="line"><span class="comment">│ satori │</span></span><br><span class="line"><span class="comment">└────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>basename：返回路径中最后一个 &#x2F; 或者 \ 后面的部分</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;/root/girls/1.csv&#x27;</span> file_path, basename(file_path) file_name;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─file_path─────────┬─file_name─┐</span></span><br><span class="line"><span class="comment">│ /root/girls/1.csv │ 1.csv     │</span></span><br><span class="line"><span class="comment">└───────────────────┴───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>visibleWidth：当以文本格式向控制台输出内容时，计算出所需要的宽度，用于美化输出</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> visibleWidth(<span class="number">3.1415</span>), visibleWidth(<span class="string">&#x27;satori&#x27;</span>), visibleWidth(<span class="keyword">Null</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─visibleWidth(3.1415)─┬─visibleWidth(&#x27;satori&#x27;)─┬─visibleWidth(NULL)─┐</span></span><br><span class="line"><span class="comment">│                    6 │                      6 │                  4 │</span></span><br><span class="line"><span class="comment">└──────────────────────┴────────────────────────┴────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> visibleWidth([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="keyword">Null</span>]), length(<span class="string">&#x27;[1,2,3,4,Null]&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─visibleWidth([1, 2, 3, 4, NULL])─┬─length(&#x27;[1,2,3,4,Null]&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                               14 │                       14 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────┴──────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>可以看到就是把内容当成纯文本，计算所占的长度。</strong></p>
<p><strong>toTypeName：返回一个值的类型</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> toTypeName([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), toTypeName(<span class="number">123</span>), toTypeName((<span class="number">11</span>, <span class="string">&#x27;22&#x27;</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toTypeName([1, 2, 3])─┬─toTypeName(123)─┬─toTypeName((11, &#x27;22&#x27;))─┐</span></span><br><span class="line"><span class="comment">│ Array(UInt8)          │ UInt8           │ Tuple(UInt8, String)   │</span></span><br><span class="line"><span class="comment">└───────────────────────┴─────────────────┴────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数组中如果包含 Null，那么 Array(...) 会变成 Array(Nullable(...))</span></span><br><span class="line"><span class="comment">-- 而 Null 的类型本身则是 Nullable(Nothing)</span></span><br></pre></td></tr></table></figure>

<p><strong>ignore：接收任何参数，包括 Null，但总是返回 0；然而该参数仍然会被考虑在内，因此一般用于基准测试</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ignore(<span class="number">11</span>), ignore([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), ignore(<span class="keyword">Null</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─ignore(11)─┬─ignore([1, 2, 3])─┬─ignore(NULL)─┐</span></span><br><span class="line"><span class="comment">│          0 │                 0 │            0 │</span></span><br><span class="line"><span class="comment">└────────────┴───────────────────┴──────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>currentDatabase：获取当前所在的数据库</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> currentDatabase();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─currentDatabase()─┐</span></span><br><span class="line"><span class="comment">│ default           │</span></span><br><span class="line"><span class="comment">└───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>currentUsere：获取当前的用户</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 当前的默认用户也叫 default</span></span><br><span class="line"><span class="keyword">SELECT</span> currentUser();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─currentUser()─┐</span></span><br><span class="line"><span class="comment">│ default       │</span></span><br><span class="line"><span class="comment">└───────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>以上就是 ClickHouse 的一些其它函数，当然还是那句话，ClickHouse 的提供的函数非常多，不止我们上面说的，只不过有很多个人觉得用不上，所以就不说了。当然如果你有兴趣的话可以去官网进行查看，链接： <a href="https://clickhouse.tech/docs/en/sql-reference/functions/">https://clickhouse.tech/docs/en/sql-reference/functions/</a> 。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 中最重要的表引擎：MergeTree 的深度原理解析(六)</title>
    <url>/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/</url>
    <content><![CDATA[<h1 id="ClickHouse-中最重要的表引擎：MergeTree-的深度原理解析-六"><a href="#ClickHouse-中最重要的表引擎：MergeTree-的深度原理解析-六" class="headerlink" title="ClickHouse 中最重要的表引擎：MergeTree 的深度原理解析(六)"></a>ClickHouse 中最重要的表引擎：MergeTree 的深度原理解析(六)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><p><strong>表引擎是 ClickHouse 中的一大特色，可以说表引擎决定了一张表最终的性格，比如数据表拥有何种特性、数据以何种形式被存储以及如何被加载。ClickHouse 拥有非常庞大的表引擎体系，总共有合并树、外部存储、内存、文件、接口和其它 6 大类 20 多种表引擎，而在这众多的表引擎中，又属合并树（MergeTree）表引擎及其家族系列（*MergeTree）最为强大，在生产环境中绝大部分场景都会使用此引擎。因为只有合并树系列的表引擎才支持主键索引、数据分区、数据副本、数据采样等特性，同时也只有此系列的表引擎支持 ALTER 相关操作。因此这里我们着重介绍合并树，因为它非常非常非常重要，并且难度也最高，至于其它的表引擎由于比较简单，所以我们放到后面再介绍。</strong></p>
<p><strong>当然我们说合并树家族自身也有很多表引擎的变种，其中 MergeTree 作为家族中最为基础的表引擎，提供了主键索引、数据分区、数据副本和数据采样等基本能力，而家族中的其它其它表引擎则在 MergeTree 的基础之上各有所长。比如 ReplacingMergeTree 表引擎具有删除重复数据的特性，而 SummingMergeTree 表引擎则会按照排序键自动聚合数据。如果再给合并树系列的表引擎加上 Replicated 前缀，又会得到一组支持数据副本的表引擎，例如 ReplicatedMergeTree、ReplicatedReplacingMergeTree、ReplicatedSummingMergeTree、ReplicatedAggregatingMergeTree 等等。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121005343-128425369.png" alt="img"></p>
<p><strong>虽然合并树的变种有很多，但 MergeTree 表引擎才是根基。作为合并树家族最基础的表引擎，MergeTree 具备了该系列其它表引擎共有的基本特征，吃透了 MergeTree 表引擎的基本原理，就掌握了该系列表引擎的精髓。</strong></p>
<h2 id="MergeTree-的创建方式与存储结构"><a href="#MergeTree-的创建方式与存储结构" class="headerlink" title="MergeTree 的创建方式与存储结构"></a>MergeTree 的创建方式与存储结构</h2><p><strong>MergeTree 在写入一批数据时，数据总会以数据片段的形式写入磁盘，且数据片段不可修改。而为了避免数据片段过多，ClickHouse 会通过后台线程定期的合并这些数据片段，属于相同分区的数据片段会被合并成一个新的数据片段，这种数据片段往复合并的过程，正是 MergeTree 名称的由来。</strong></p>
<h3 id="MergeTree-的创建方式"><a href="#MergeTree-的创建方式" class="headerlink" title="MergeTree 的创建方式"></a>MergeTree 的创建方式</h3><p><strong>创建数据表的方法我们上面介绍过，而创建 MergeTree 数据表只需要在创建表的时候将 ENGINE 指定为 MergeTree() 即可，其完整语法如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name(</span><br><span class="line">    name1 type [<span class="keyword">DEFAULT</span><span class="operator">|</span>MATERIALIZED<span class="operator">|</span>ALIAS expr],</span><br><span class="line">    name2 type [<span class="keyword">DEFAULT</span><span class="operator">|</span>MATERIALIZED<span class="operator">|</span>ALIAS expr],</span><br><span class="line">    ......</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line">[<span class="keyword">PARTITION</span> <span class="keyword">BY</span> expr]</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> expr</span><br><span class="line">[<span class="keyword">PRIMARY</span> KEY expr]</span><br><span class="line">[SAMPLE <span class="keyword">BY</span> expr]</span><br><span class="line">[SETTINGS name1<span class="operator">=</span>value1, name2<span class="operator">=</span>value2, ......]</span><br></pre></td></tr></table></figure>

<p><strong>我们看到 MergeTree 表引擎除了常规的参数之外，还有一些独有的配置选项，一会儿会详细介绍这几个重要的配置项，包括它们的使用方法和工作原理，目前先来大致看一下它们的作用。</strong></p>
<p><strong>1） PARTITON BY：选填，表示分区键，用于指定表数据以何种标准进行分区。分区键既可以是单个字段、也可以通过元组的形式指定多个字段，同时也支持使用列表达式。如果不支持分区键，那么 ClickHouse 会生成一个名称为 all 的分区，合理地使用分区可以有效的减少查询时数据量。最常见的莫过于按照时间分区了，数据量非常大的时候可以按照天来分区，一天一个分区，这样查找某一天的数据时直接从指定分区中查找即可。</strong></p>
<p><strong>2）ORDER BY：必填，表示排序键，用于指定在一个分区内，数据以何种标准进行排序。排序键既可以是单个字段，例如 ORDER BY CounterID，也可以是通过元组声明的多个字段，例如 ORDER BY (CounterID, EventDate)。如果是多个字段，那么会先按照第一个字段排序，如果第一个字段中有相同的值，那么再按照第二个字段排序，依次类推。总之在每个分区内，数据是按照分区键排好序的，但多个分区之间就没有这种关系了。</strong></p>
<p><strong>3）PRIMARY KEY：选填，表示主键，声明之后会依次按照主键字段生成一级索引，用于加速表查询。如果不指定，那么主键默认和排序键相同，所以通常直接使用 ORDER BY 代为指定主键，无须使用 PRIMARY KEY 声明。所以一般情况下，在每个分区内，数据与一级索引以相同的规则升序排列（因为数据是按照排序键排列的，而一级索引也是按排序键、也就是主键进行排列的）。和其它关系型数据库不同，MergeTree 允许主键有重复数据（可以通过 ReplacingMergeTree 实现去重）。</strong></p>
<p><strong>4）SAMPLE KEY：选填，抽样表达式。用于声明数据以何种标准进行采样，注意：如果声明了此配置项，那么主键的配置中也要声明同样的表达式。例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">    ......</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (CountID, EventDate, intHash32(UserID))</span><br><span class="line">SAMPLE <span class="keyword">BY</span> intHash32(UserID)</span><br><span class="line"><span class="comment">-- 抽样表达式需要配合 SAMPLE 子查询使用，该功能对选取抽样数据十分有用</span></span><br><span class="line"><span class="comment">-- 关于抽样查询，后面会在介绍查询的时候说</span></span><br></pre></td></tr></table></figure>

<p><strong>5）SETTINGS：选填，用于指定一些额外的参数，以 name&#x3D;value 的形式出现，name 主要包含 index_granularity、min_compress_block_size、index_granularity_bytes、enbale_mixed_granularity_parts、merge_with_ttl_timeout、storage_policy，比如：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">    ......</span><br><span class="line">) ENGINE = MergeTree()</span><br><span class="line">......</span><br><span class="line">SETTINGS index_granularity=8192, min_compress_block_size=6536</span><br></pre></td></tr></table></figure>

<p><strong>下面解释一下这些参数的含义：</strong></p>
<blockquote>
<p><strong>index_granularity：对于 MergeTree 而言是一个非常重要的参数，它表示索引的粒度，默认值为 8192。所以 ClickHouse 根据主键生成的索引实际上稀疏索引，默认情况下是每隔 8192 行数据才生成一条索引。类似于 kafka 的日志数据段，kafka 的每个数据段是由存储实际消息的数据文件，和用于加速消息查找的索引文件组成，而 kafka 的索引文件建立的也是稀疏索引。</strong></p>
<p><strong>min_compress_block_size：我们知道 ClickHouse 是会对数据进行压缩的，而 min_compress_block_size 表示的就是最小压缩的块大小，默认值为 65536。</strong></p>
<p><strong>index_granularity_bytes：在 19.11 版本之前 ClickHouse 只支持固定大小的索引间隔，由 index_granularity 控制，但是在新版本中增加了自适应间隔大小的特性，即根据每批次写入的数据的体量大小，动态划分间隔大小。而数据的体量大小，则由 index_granularity_bytes 参数控制的，默认为 10M，设置为 0 表示不启用自适应功能。</strong></p>
<p><strong>enbale_mixed_granularity_parts：表示是否开启自适应索引的功能，默认是开启的。</strong></p>
<p><strong>merge_with_ttl_timeout：从 19.6 版本开始 MergeTree 提供了数据的 TTL 功能，该部分后面详细说。</strong></p>
<p><strong>storage_policy：从 19.15 版本开始 MergeTree 提供了多路径的存储策略，该部分同样留到后面详细说。</strong></p>
</blockquote>
<h3 id="MergeTree-数据表的存储结构"><a href="#MergeTree-数据表的存储结构" class="headerlink" title="MergeTree 数据表的存储结构"></a>MergeTree 数据表的存储结构</h3><p><strong>我们说在 ClickHouse 中一张表对应一个目录，那么 MergeTree 数据表对应的目录结构如何呢？我们之前说表对应的目录里面存储的就是文本文件（数据在磁盘上的载体），但对于 MergeTree 数据表而言还不太一样，因为我们说 MergeTree 数据表是有分区的，所以表对应的目录里面存储的还是目录。并且每个目录对应一个分区，因此也叫分区目录，而分区目录里面存储的才是负责容纳数据的文本文件。</strong></p>
<p><strong>所以一张 MergeTree 数据表在磁盘上的物理结构分为三个层级，依次是数据表目录、分区目录、以及各分区目录下的数据文件。我们画一张图：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121016351-909176633.png" alt="img"></p>
<p><strong>分别解释一下它们的作用：</strong></p>
<p><strong>1）partition：分区目录，里面的各类数据文件（primary.idx、data.mrk、data.bin 等等）都是以分区目录的形式被组织存放的，属于相同分区的数据，最终会被合并到同一个分区目录，而不同分区的数据永远不会被合并在一起。关于数据分区的细节，后面会详细说。</strong></p>
<p><strong>2）checksums.txt：校验文件，使用二进制的格式进行存储，它保存了余下各类文件（primary.txt、count.txt 等等）的 size 大小以及哈希值，用于快速校验文件的完整性和正确性。</strong></p>
<p><strong>3）columns.txt：列信息文件，使用明文格式存储，用于保存此分区下的列字段信息，比如我们创建一张表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 该表负责存储用户参加过的活动，每参加一个活动，就会生成一条记录</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> user_activity_event (</span><br><span class="line">    ID UInt64,  <span class="comment">-- 表的 ID</span></span><br><span class="line">    UserName String,  <span class="comment">-- 用户名</span></span><br><span class="line">    ActivityName String,  <span class="comment">-- 活动名称</span></span><br><span class="line">    ActivityType String,  <span class="comment">-- 活动类型</span></span><br><span class="line">    ActivityLevel Enum(<span class="string">&#x27;Easy&#x27;</span> <span class="operator">=</span> <span class="number">0</span>, <span class="string">&#x27;Medium&#x27;</span> <span class="operator">=</span> <span class="number">1</span>, <span class="string">&#x27;Hard&#x27;</span> <span class="operator">=</span> <span class="number">2</span>),  <span class="comment">-- 活动难度等级</span></span><br><span class="line">    IsSuccess Int8,  <span class="comment">-- 是否成功</span></span><br><span class="line">    JoinTime <span class="type">DATE</span>  <span class="comment">-- 参加时间</span></span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(JoinTime)  <span class="comment">-- 按照 toYYYYMM(JoinTime) 进行分区</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> ID;  <span class="comment">-- 按照 ID 字段排序</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 插入一条数据</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> user_activity_event <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;张三&#x27;</span>, <span class="string">&#x27;寻找遗失的时间&#x27;</span>, <span class="string">&#x27;市场营销&#x27;</span>, <span class="string">&#x27;Medium&#x27;</span>, <span class="number">1</span>, <span class="string">&#x27;2020-05-13&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>然后查看相关信息：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># cat /var/lib/clickhouse/data/default/user_activity_event/202005_1_1_0/columns.txt </span></span><br><span class="line">columns format version: 1</span><br><span class="line">7 columns:</span><br><span class="line">`ID` UInt64</span><br><span class="line">`UserName` String</span><br><span class="line">`ActivityName` String</span><br><span class="line">`ActivityType` String</span><br><span class="line">`ActivityLevel` Enum8(<span class="string">&#x27;Easy&#x27;</span> = 0, <span class="string">&#x27;Medium&#x27;</span> = 1, <span class="string">&#x27;Hard&#x27;</span> = 2)</span><br><span class="line">`IsSuccess` Int8</span><br><span class="line">`JoinTime` Date</span><br><span class="line">[root@satori ~]<span class="comment"># </span></span><br></pre></td></tr></table></figure>

<p><strong>4）count.txt：计数文件，使用明文格式存储，用于记录当前分区下的数据总数。所以后续在查询数据总量的时候可以瞬间返回，因为已经提前记录好了。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># cat /var/lib/clickhouse/data/default/user_activity_event/202005_1_1_0/count.txt </span></span><br><span class="line">1</span><br></pre></td></tr></table></figure>

<p><strong>5）primary.idx：一级索引文件，使用二进制格式存储，用于存储稀疏索引，一张 MergeTree 表只能声明一次一级索引（通过 ORDER BY 或 PRIMARY KEY）。借助稀疏索引，在查询数据时能够排除主键条件范围之外的数据文件，从而有效减少数据扫描范围，加速查询速度。</strong></p>
<p><strong>6）data.bin：数据文件，使用压缩格式存储，默认为 LZ4 格式，用于存储表的数据。在老版本中每一个列字段都有自己独立的 .bin 数据文件，并以列字段命名，但是在新版本中只有一个 data.bin，也就是合并在一起了。</strong></p>
<p><strong>7）data.mrk：标记文件，使用二进制格式存储，标记文件中保存了 data.bin 文件中数据的偏移量信息，并且标记文件与稀疏索引对齐，因此 MergeTree 通过标记文件建立了稀疏索引（primary.idx）与数据文件（data.bin）之间的映射关系。而在读取数据的时候，首先会通过稀疏索引（primary.idx）找到对应数据的偏移量信息（data.mrk），因为两者是对齐的，然后再根据偏移量信息直接从 data.bin 文件中读取数据。</strong></p>
<p><strong>8）data.mrk3：如果使用了自适应大小的索引间隔，则标记文件会以 data.mrk3 结尾，但它的工作原理和 data.mrk 文件是相同的。</strong></p>
<p><strong>9）partition.dat 和 minmax_[Column].idx：如果使用了分区键，例如上面的 PARTITION BY toYYYYMM(JoinTime)，则会额外生成 partition.dat 与 minmax_JoinTime.idx 索引文件，它们均使用二进制格式存储。partition.dat 用于保存当前分区下分区表达式最终生成的值，而 minmax_[Column].idx 则负责记录当前分区下分区字段对应原始数据的最小值和最大值。举个栗子，假设我们往上面的 user_activity_event 表中插入了 5 条数据，JoinTime 分别 2020-05-05、2020-05-15、2020-05-31、2020-05-03、2020-05-24，显然这 5 条都会进入到同一个分区，因为 toYYYMM 之后它们的结果是相同的，都是 2020-05，而 partition.dat 中存储的就是 2020-05，也就是分区表达式最终生成的值；同时还会有一个 minmax_JoinTime.idx 文件，里面存储的就是 2020-05-03 2020-05-31，也就是分区字段对应的原始数据的最小值和最大值。</strong></p>
<p><strong>在这些分区索引的作用下，进行数据查询时能够快速跳过不必要的分区目录，从而减少最终需要扫描的数据范围。比如我们存储了 JoinTime 为 2020-01-01 到 2020-12-31 一整年用户参加活动的数据，那么 toYYYYMM 之后肯定就会有 12 个分区，然后按照 JoinTime 查找数据的时候，比如要查找 JoinTime 为 2020-06-12 的数据，那么直接去指定的分区（2020-06）中查找即可，也就是我们通过分区机制将查询范围限定在 2020-06，其余的 11 个月的数据我们压根不用看，因此大大减少了查询的数据量。</strong></p>
<p><strong>10）skp_idx_[IndexName].idx 和 skp_idx_[IndexName].mrk3：如果在建表语句中指定了二级索引（后面会说），则会额外生成相应的二级索引文件与标记文件，它们同样使用二进制存储。二级索引在 ClickHouse 中又被称为跳数索引，目前拥有 minmax、set、ngrambf_v1 和 token_v1 四种类型，这些种类的跳数索引的目的和一级索引都相同，都是为了进一步减少数据的扫描范围，从而加速整个查询过程。</strong></p>
<h2 id="数据分区"><a href="#数据分区" class="headerlink" title="数据分区"></a>数据分区</h2><p><strong>通过之前的介绍我们已经知道在 MergeTree 数据表中，数据是以分区目录的形式进行组织的，每个分区的数据独立分开存储。借助这种形式，MergeTree 在查询数据时，可以跳过无用的数据文件，只在最小分区目录子集中查询。这里再强调一次，在 ClickHouse 中存在数据分区（partition）和数据分片（shard），但它们是完全不同的概念。数据分区是针对本地数据而言的，相当于是对数据的一种纵向切分，就类似将关系型数据中的一张大高表切成多张个头没那么高的子表。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121030557-1616523231.png" alt="img"></p>
<p><strong>而数据分片则与 ClickHouse 集群相关，我们后面会说，我们目前都是单机的，所以不涉及数据分片。</strong></p>
<h3 id="数据的分区规则"><a href="#数据的分区规则" class="headerlink" title="数据的分区规则"></a>数据的分区规则</h3><p><strong>MergeTree 数据表的分区规则由分区 ID 决定，而具体到每个分区对应的 ID 则是由分区键的取值决定的。分区键支持使用任何一个或一组字段表达式声明，其业务语义可以是年、月、日或者组织单位等任何一种规则，而针对取值数据的类型不同，分区 ID 的生成逻辑目前拥有四种规则：</strong></p>
<ul>
<li><code>1. 不指定分区键：如果不使用分区键，即不使用 PARTITION BY 声明任何分区表达式，则分区 ID 默认为 all，所有的数据都会被写入 all 这个分区</code></li>
<li><code>2. 使用整型：如果分区键的取值为整型（UInt64、Int8 等等都算），且无法转成日期类型 YYYYMMDD 格式，则直接按照该整型的字符串形式作为分区 ID 的取值</code></li>
<li><code>3. 使用日期类型：如果分区键取值属于日期类型，或者是能够转换为 YYYYMMDD 格式的整型，则使用按照 YYYYMMDD 进行格式化后的字符串形式作为分区 ID 的取值</code></li>
<li><code>4. 使用其它类型：如果分区键取值既不是整型、也不是日期类型，比如 String、Float 等等。则通过 128 位 Hash 算法取其 Hash 值作为分区 ID 的取值</code></li>
</ul>
<p><strong>以我们之前的 PARTITION BY toYYYYMM(JoinTime) 为例，当写入一条 JoinTime 为 2020-09-18 的记录时，该记录就会落在分区 ID 为 202009 的分区中；如果是 PARTITION BY JoinTime，那么 JoinTime 为 2020-09-18 的记录就会落在分区 ID 为 20200918 的分区中；再比如 PARTITION BY age，当写入一条 age 为 16 的记录时，该数据就会落在分区 ID 为 16 的分区中；再比如 PARTITION BY length(name)，那么 name 为 “古明地觉” 的记录就会落在分区 ID 为 4 的分区中， name 为 “雾雨魔理沙” 的记录就会落在分区 ID 为 5 的分区中。</strong></p>
<p><strong>相信这个分区 ID 还是好理解的，但需要注意的是，如果分区字段有多个，那么会按照相同的规则为每个字段都生成一个分区 ID，最后再将这些分区 ID 使用减号合并起来，作为最终的分区 ID。</strong></p>
<blockquote>
<p><strong>比如：PARTITION BY (length(UserName), toYYYYMM(JoinTime))，那么 UserName 为 “张三”、JoinTime 为 2020-05-13 的记录就会落在分区 ID 为 2-202005 的分区中。</strong></p>
</blockquote>
<h3 id="分区目录的命名规则"><a href="#分区目录的命名规则" class="headerlink" title="分区目录的命名规则"></a>分区目录的命名规则</h3><p><strong>现在我们已经知道了分区 ID 生成规则，但如果进入数据表所在的磁盘目录时，会发现 MergeTree 分区目录的完整物理名称并不只有分区 ID，在 ID 的后面还跟着一串奇怪的数字，以我们之前创建的 user_activity_event 数据表为例，里面有一个分区，其名称就叫 202005_1_1_0。前面的 202005 显然就是分区 ID，那后面的部分代表啥含义呢？</strong></p>
<p><strong>首先对于 MergeTree 而言，其最大的特点就是分区目录的合并动作（至于怎么合并我们后面再说），而合并逻辑我们从分区目录的名称便可窥知一二。</strong></p>
<p><strong>首先分区目录的命名规则是：PartitionID_MinBlockNum_MaxBlockNum_Level</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121303260-1051906586.png" alt="img"></p>
<p><strong>下面来解释一下这几个部分：</strong></p>
<p><strong>1）PartitionID：分区 ID，这个应该无需多说。</strong></p>
<p><strong>2）MinBlockNum、MaxBlockNum：最小数据块编号和最大数据块编号，这里的命名很容易让人联想到后面要说的数据压缩块，甚至产生混淆，但实际上这两者没有任何关系。这里的 BlockNum 是一个自增的整数，从 1 开始，每当创建一个新的分区时就会自增 1，并且对于一个新的分区目录而言，它的 MinBlockNum 和 MaxBlockNum 是相等的。比如 202005_1_1_0、202006_2_2_0、202007_3_3_0，以此类推。但是也有例外，当分区目录发生合并的时候，那么其 MinBlockNum 和 MaxBlockNum 会有另外的规则，一会儿细说。</strong></p>
<p><strong>3）Level：合并的层级，可以理解为某个分区被合并的次数，这里的 Level 和 BlockNum 不同，它不是全局累加的。对于每个新创建的目录而言，其初始值都为 0，之后以分区为单位，如果相同分区发生合并动作，则该分区对应的 Level 加 1。可能有人不是很理解这里的 “相同分区发生合并” 到底是什么意思，我们下面就来介绍。</strong></p>
<h3 id="分区目录的合并过程"><a href="#分区目录的合并过程" class="headerlink" title="分区目录的合并过程"></a>分区目录的合并过程</h3><p><strong>MergeTree 的分区目录和其它传统意义上数据库有所不同，首先 MergeTree 的分区目录并不是在数据表被创建之后就存在的，而是在数据写入的过程中被创建的，如果一张表中没有任何数据，那么也就不会有任何的分区目录。也很好理解，因为分区目录的命名与分区 ID 有关，而分区 ID 又和分区键对应的值有关，而表中连数据都没有，那么何来分区目录呢。</strong></p>
<p><strong>其次，MergeTree 的分区目录也不是一成不变的，在其它数据库的设计中，追加数据的时候目录自身不会改变，只是在相同分区中追加数据文件。而 MergeTree 完全不同，伴随着每一次数据的写入，MergeTree 都会生成一批新的分区目录，即使不同批次写入的数据属于相同的分区，也会生成不同的分区目录。也就是说对于同一个分区而言，会存在对应多个分区目录的情况。而在之后的某个时刻（一般 10 到 15 分钟），ClickHouse 会通过后台任务将属于相同分区的多个目录合并（Merge）成一个新的目录，当然也可以通过 optimize TABLE table_name FINAL 语句立即合并，至于合并之前的旧目录会在之后的某个时刻（默认 8 分钟）被删除。</strong></p>
<p><strong>属于同一个分区的多个目录，在合并之后会生成一个全新的目录，目录中的索引和数据文件也会相应地进行合并。而新目录的名称的生成方式遵循如下规则：</strong></p>
<ul>
<li><code>PartitionID：不变</code></li>
<li><code>MinBlockNum：取同一分区内所有目录中最小的 MinBlockNum</code></li>
<li><code>MaxBlockNum：取同一分区内所有目录中最大的 MaxBlockNum</code></li>
<li><code>Level：取同一分区内最大 Level 值并加 1</code></li>
</ul>
<p><strong>我们举例说明一下，假设我们之前的 user_activity_event 表是空的，然后我们往里面分 3 批写入 3 条数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> user_activity_event <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;张三&#x27;</span>, <span class="string">&#x27;寻找遗失的时间&#x27;</span>, <span class="string">&#x27;市场营销&#x27;</span>, <span class="string">&#x27;Medium&#x27;</span>, <span class="number">1</span>, <span class="string">&#x27;2020-05-01&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> user_activity_event <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;李四&#x27;</span>, <span class="string">&#x27;寻找遗失的时间&#x27;</span>, <span class="string">&#x27;市场营销&#x27;</span>, <span class="string">&#x27;Medium&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;2020-05-02&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> user_activity_event <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;王五&#x27;</span>, <span class="string">&#x27;寻找遗失的时间&#x27;</span>, <span class="string">&#x27;市场营销&#x27;</span>, <span class="string">&#x27;Medium&#x27;</span>, <span class="number">1</span>, <span class="string">&#x27;2020-06-01&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>根据规则，ClickHouse 会创建 3 个分区目录，分区目录的 PartitionID 部分依次为 202005、202005、202006；而对于每个新创建的分区目录而言，它们的 MinBlockNum 和 MaxBlockNum 都是相等的，并且我们说 MinBlockNum 和 MaxBlockNum 是全局的，从 1 开始自增，所以三个分区目录的 MinBlockNum 和 MaxBlockNum 依次是 1 1、2 2、3 3；最后是 Level，每个新建的分区目录的初始 Level 都是0。因此三个分区目录的最终名称就是 202005_1_1_0、202005_2_2_0、202006_3_3_0。</strong></p>
<p><strong>之后在某一时刻 MergeTree 的合并动作开始了，那么属于同一分区的 202005_1_1_0、202005_2_2_0 将会发生合并，得到 202005_1_2_1（MinBlockNum 取最小值、MaxBlockNum 取最大值，Level 去最大值加 1）。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121347504-214244480.png" alt="img"></p>
<p><strong>然后我们再插入三条数据（分 3 批写入），JoinTime 分别为 2020-05-03、2020-06-02、2020-07-01，那么会再创建 3 个分区目录，分区 ID 分别为 202005、202006、202007：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121401101-615381315.png" alt="img"></p>
<p><strong>之后 MergeTree 的合并动作开始，属于相同分区的目录开始合并，202005_1_2_1 和 202005_4_4_0 会发生合并，得到 202005_1_4_2；202006_3_3_0 和 202006_5_5_0 发生合并，得到 202006_3_5_1。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121413700-789754349.png" alt="img"></p>
<p><strong>如果再写入数据的话，那么 MergeTree 依旧会发生合并，然后重复和上面的一样的动作。相信到这里已经明白分区 ID、目录命名、以及数据合并的相关规则。</strong></p>
<p><strong>但需要注意的是：我们上面显示的是目录合并之后的结果，至于旧的分区目录、也就是合并之前的目录会依旧保留一段时间，但已不再是激活状态（active &#x3D; 0），在数据查询的时候会被过滤掉。然后 ClickHouse 有一个后台任务会定时扫描（默认 8 分钟），负责将 active &#x3D; 0 的目录从物理磁盘上删除。</strong></p>
<h2 id="一级索引"><a href="#一级索引" class="headerlink" title="一级索引"></a>一级索引</h2><p><strong>MergeTree 的主键使用 PRIMARY KEY 定义，主键定义之后，MergeTree 会依据 index_granularity 间隔（默认 8192 行）为数据表生成一级索引并保存至 primary.idx 文件中，并按照主键进行排序。如果不指定 PAIMARY KEY，那么主键默认和排序键相同，在这种情况下，索引（primary.idx）和数据（data.bin）会按照完全相同的规则排序。</strong></p>
<blockquote>
<p><strong>使用 PRIMARY KEY 定义主键和使用 ORDER BY 代替定义主键，两者之间还是有点差别的，这个差别会在 SummingMergeTree 中有所体现，后续介绍 。</strong></p>
</blockquote>
<h3 id="稀疏索引"><a href="#稀疏索引" class="headerlink" title="稀疏索引"></a>稀疏索引</h3><p><strong>primary.idx 文件内的一级索引采用稀疏索引实现，既然有稀疏索引，那么是不是也有稠密索引呢？答案是还真有，稀疏索引和稠密索引之间的区别如下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121423507-1319491738.png" alt="img"></p>
<p><strong>从图中可以看到，在稠密索引中每一行数据都会对应一行唯一的索引；而在稀疏索引中只有部分数据会对应索引，也就是相邻索引对应的数据不相邻，中间会跨越一定行数的数据。那么问题来了，稀疏索引是如何准确定位数据的呢？</strong></p>
<p><strong>假设我要找第 10000 条数据，那么首先 ClickHouse 会进行一次二分查找，找到对应的索引。因为 0 -&gt; 0、1 -&gt; 8192、2 -&gt; 16384，而第 10000 条数据位于 8192 和 16384 之间，那么要找的索引就是 1，于是 ClickHouse 会再通过索引 1 找到第 8192 行数据，然后不断往后遍历，最终找到我们要数据。如果熟悉 kafka 的话，kafka 底层存储消息也是用到的稀疏索引，还是很好理解的。但是问题来了，为什么不用稠密索引呢？如果使用稠密索引的话，那么直接就可以定位到准确的数据，从而减少后续遍历所带来的磁盘 IO，可为什么不这么做呢。其实原因很简单，ClickHouse、kafka 都是应用在大数据场景下，由于数据量本身就很大，那么使用稠密索引带来的空间占用也会很大。而稀疏索引占空间小，因为不需要那么多行，以默认的索引粒度（8192）为例，MergeTree 只需要 12208 行索引标记就能为 1 亿行数据记录提供索引。虽然后续遍历会带来额外的磁盘 IO，但由于是顺序 IO，因此效率实际上是不低的，我们知道机械磁盘虽然不擅长随机读写，但顺序读写还是很快的，SSD 就更不必说了。</strong></p>
<p><strong>最关键的是，由于稀疏索引占用空间小，那么可以常驻内存，因此读取的速度非常快。如果使用稠密索引，那么由于空间占用过大而可能导致无法读进内存中，因此只能在磁盘上操作，这样在查找索引的时候也会带来磁盘 IO。因此综上所述，使用稀疏索引的性价比相较于稠密索引明显要更高，因为速度相差不大，但省下了大量的磁盘空间。</strong></p>
<blockquote>
<p><strong>注意：虽然我们说索引和数据之间是对应的，但我们知道它们不是直接对应的，我们之前介绍数据表的存储结构时说过，除了索引文件（primary.idx）和数据文件（data.bin）之外，还有一个标记文件（data.mrk）。标记文件中保存了 data.bin 文件中数据的偏移量信息，并且标记文件（或者说偏移量）与稀疏索引对齐，因此想要通过索引找到具体的数据还需要借助于 data.mrk 中偏移量。</strong></p>
</blockquote>
<h3 id="索引粒度"><a href="#索引粒度" class="headerlink" title="索引粒度"></a>索引粒度</h3><p><strong>索引粒度是建表的时候，在 SETTINGS 里面指定 index_granularity 控制的，虽然 ClickHouse 提供了自适应粒度大小的特性，但是为了便于理解，我们会使用固定的索引粒度进行介绍（8192）。索引粒度对于 MergeTree 而言是一个非常重要的概念，它就如同一把标尺，会丈量整个数据的长度，并依照刻度对数据进行标注，最终将数据标记成多个间隔的小段。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121431115-1300566604.png" alt="img"></p>
<p><strong>数据以 index_granularity 的粒度（默认 8192）被标记成多个小的区间，其中每个区间最多 8192 行数据，MergeTree 使用 MarkRange 表示一个具体的区间，并通过 start 和 end 表示其具体的范围。index_granularity 的名字虽然取了索引二字，但它不单单只作用于一级索引，同时还会影响数据标记文件（data.mrk）和数据文件（data.bin）。因为只有一级索引是无法完成查询工作的，它需要借助标记文件中的偏移量才能定位数据，所以一级索引和数据标记的间隔粒度（同为 index_granularity 行）相同，彼此对齐，而数据文件也会按照 index_granularity 的间隔粒度生成压缩数据块。</strong></p>
<h3 id="索引数据的生成规则"><a href="#索引数据的生成规则" class="headerlink" title="索引数据的生成规则"></a>索引数据的生成规则</h3><p><strong>由于是稀疏索引，所以 MergeTree 需要间隔 index_granularity 行数据才会生成一条索引记录，其索引值会依据声明的主键字段获取。这里我们创建一张表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hits_v1 (</span><br><span class="line">    CounterID Int64,</span><br><span class="line">    EventDate <span class="type">Date</span></span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY CounterID  <span class="comment">-- 也可以不写，默认和排序键保持一致</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> CounterID</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(EventDate)</span><br></pre></td></tr></table></figure>

<p><strong>显然 EventDate 为 2020 年 4 月的数据会被划分到同一个分区目录中，并且每隔 8192 条数据就会取一次 CounterID 的值（排好序的）作为索引值，写入 primary.idx 文件进行保存。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121445103-847797721.png" alt="img"></p>
<p><strong>例如第 0 行（8192 * 0）的 CounterID 取值为 57，第 8192 行（8192 * 1）的 CounterID 取值为 1635，第 16384 行（8192 * 2）的 CounterID 取值为 3266，最终索引数据将会是 5716353266……。</strong></p>
<p><strong>可以看到 MergeTree 对于稀疏索引的存储是非常紧凑的，索引值前后相连，按照主键字段顺序紧密地排列在一起。并且不仅是这里，ClickHouse 中很多数据结构都被设计的非常紧凑，比如使用位读取替代专门的标志位或状态码（假设 32 位整型存储的数据最多占用 20 个位，那么就可以只用 20 个位表示数据，然后剩余的位用来表示状态码），不浪费任何一个字节。所以 ClickHouse 性能出众不是没有原因的，每一步都做足了优化。</strong></p>
<p><strong>如果使用多个主键，例如 ORDER BY (CounterID, EventDate)，则每间隔 8192 行会同时取 CounterID 和 EventDate 两列的值作为索引值。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121453878-978279006.png" alt="img"></p>
<h3 id="索引的查询过程"><a href="#索引的查询过程" class="headerlink" title="索引的查询过程"></a>索引的查询过程</h3><p><strong>在说完索引的一些概念之后，接下来说明索引具体是如何工作的。首先我们需要了解什么是 MarkRange，MarkRange 在 ClickHouse 中是用于定义标记区间的对象。MergeTree 按照 index_granularity 的间隔粒度，将一段完整的数据划分成了多个小的间隔数据段，一个具体的数据段就是一个 MarkRange，并与索引编号对应，使用start 和 end 两个属性表示其范围。通过 start 和 end 对应的索引编号的取值，即可得到它所对应的数值区间，而数值区别表示了此 MarkRange 的数据范围。</strong></p>
<p><strong>如果只是这么干巴巴的介绍，可能会有些抽象，下面用一份示例数据来说明一下。假如现在有一份测试数据，共 192 行记录，其中主键 ID 为 String 类型，取值从 A000 开始，后面依次为 A001、A002、……，直到 A192 为止。MergeTree 的索引粒度 index_granularity 为 3，根据索引的生成规则，那么 primary.idx 文件的索引如下所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121503704-1600149797.png" alt="img"></p>
<p><strong>根据索引数据，MergeTree 会将此数据片段划分成 192&#x2F;3&#x3D;64 个小的 MarkRange，两个相邻的 MarkRange 相距的步长为 1。其中，所有 MarkRange（整个数据片段）的最大数值区间为 [A000, +inf)，完整示意图如下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121512266-468243103.png" alt="img"></p>
<p><strong>在引入了数值区间的概念之后，对于索引数据的查询过程就很好解释了，索引查询其实就是两个区间的交集判断。其中一个区间是由基于主键的查询条件转换而来的条件区间；另一个区间就是上面说的与 MarkRange 对应的数值区间。</strong></p>
<p><strong>所以整个查询可以分为三步：</strong></p>
<p><strong>1）生成查询区间：首先将查询条件转换为区间，即使是单个值也会转换为区间的形式，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WHERE</span> ID <span class="operator">=</span> <span class="string">&#x27;A003&#x27;</span> <span class="operator">-</span><span class="operator">&gt;</span> [<span class="string">&#x27;A003&#x27;</span>, <span class="string">&#x27;A003&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">WHERE</span> ID <span class="operator">&gt;</span> <span class="string">&#x27;A012&#x27;</span> <span class="operator">-</span><span class="operator">&gt;</span> (<span class="string">&#x27;A012&#x27;</span>, <span class="operator">+</span>inf]</span><br><span class="line"></span><br><span class="line"><span class="keyword">WHERE</span> ID <span class="operator">&lt;</span> <span class="string">&#x27;A185&#x27;</span> <span class="operator">-</span><span class="operator">&gt;</span> [<span class="operator">-</span>inf, <span class="string">&#x27;A185&#x27;</span>)</span><br><span class="line">                      </span><br><span class="line"><span class="keyword">WHERE</span> ID <span class="keyword">LIKE</span> <span class="string">&#x27;A006%&#x27;</span> <span class="operator">-</span><span class="operator">&gt;</span> [<span class="string">&#x27;A006&#x27;</span>, <span class="string">&#x27;A007&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>2）递归交集判断：以递归的形式，依次对 MarkRange 的数值区间与条件区间做交集判断，从最大的区间 [A000, +inf) 开始：</strong></p>
<ul>
<li><code>如果不存在交集，则直接通过剪枝算法优化此整段 MarkRange</code></li>
<li><code>如果存在交集，且 MarkRange 步长大于等于 8（end - start），则将此区间进一步拆分成 8 个子区间（由 merge_tree_coarse_index_granularity 指定，默认值为 8），然后重复此过程，继续做递归交集判断</code></li>
<li><code>如果存在交集，且 MarkRange 不可再分解（步长小于 8），则记录 MarkRange 并返回</code></li>
</ul>
<p><strong>3）合并 MarkRange 区间：将最终匹配的 MarkRange 聚在一起，合并它们的范围。</strong></p>
<p><strong>光说不好理解，我们画一张图，来展示一下上面的几个步骤，还以上面的测试数据为例，查询条件为 ID &#x3D; ‘A003’。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121523250-1848437617.png" alt="img"></p>
<p><strong>MergeTree 通过递归的形式持续向下拆分区间，最终将 MarkRange 定位到最细的粒度，以便在后续读取数据的时候，能够最小化数据的扫描范围。以上图为例，当查询条件为 ID &#x3D; ‘A003’ 的时候，最终只需要读取 [A000, A003] 和 [A003, A006] 两个区间的数据，它们对应 MarkRange(start:0, end:2) 范围，而其它无用区间都被裁剪掉了。由于 MarkRange 转换的数值区间是闭区间，所以会额外匹配到临近的一个区间。</strong></p>
<h2 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h2><p><strong>除了一级索引之外，MergeTree 同样支持二级索引，二级索引又称跳数索引，由数据的聚合信息构建而成。根据索引类型的不同，其聚合信息的内容也不同，当然跳数索引的作用和一级索引是一样的，也是为了查询时减少数据的扫描范围。</strong></p>
<p><strong>跳数索引需要在 CREATE 语句内定义，它支持使用元组和表达式的形式声明，其完整的定义语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_name (</span><br><span class="line">    column1 type,</span><br><span class="line">    column2 type,</span><br><span class="line">    ......</span><br><span class="line">    INDEX index_name expr TYPE index_type(...) GRANULARITY granularity</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>与一级索引一样，如果在建表语句中声明了跳数索引，则会额外生成相应的索引文件和标记文件（skp_idx_[Column].idx 与 skp_idx_[Column].idx）。</strong></p>
<h3 id="granularity-和-index-granularity-的关系"><a href="#granularity-和-index-granularity-的关系" class="headerlink" title="granularity 和 index_granularity 的关系"></a>granularity 和 index_granularity 的关系</h3><p><strong>不同的跳数索引之间，除了它们自身独有的参数之外，还都共同拥有 granularity 参数。初次接触时，很容易将 granularity 和 index_granularity 的概念弄混淆，对于跳数索引而言，index_granularity 定义了数据的粒度，而 granularity 定义了聚合信息汇总的粒度。换言之，granularity 定义了一行跳数索引能够跳过多少个 index_granularity 区间的数据。</strong></p>
<p><strong>要解释清除 granularity 的作用，就要成跳数索引的生成规则说起，其规则大致是如下：首先按照 index_granularity 粒度间隔将数据划分成 n 段，总共有 [0, n - 1] 个区间（n &#x3D; totol_rows &#x2F; index_granularity，向上取整）；接着根据索引定义时声明的表达式，从 0 区间开始依次按照 index_granularity 粒度从数据中获取聚合信息，每次向前移动一步，聚合信息聚合信息逐步累加。最后当移动 granularity 次区间时，则汇总并声称一行跳数索引数据。</strong></p>
<p><strong>以 minmax 索引为例，它的聚合信息是在一个 index_granularity 区间内数据的最小和最大极值。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121530948-1802107303.png" alt="img"></p>
<p><strong>以上图为例，假设 index_granularity &#x3D; 8192 且 granularity &#x3D; 3，则数据会按照 index_granularity 划分为 n 等份，MergeTree 从第 0 段分区开始，依次获取聚合信息。当获取到第 3 个分区时（granularity &#x3D; 3），则会汇总并生成第一行 minmax 索引（前 3 段 minmax 极值汇总后取值为 [1, 9]）。</strong></p>
<h3 id="跳数索引的类型"><a href="#跳数索引的类型" class="headerlink" title="跳数索引的类型"></a>跳数索引的类型</h3><p><strong>目前 MergeTree 共支持 4 种跳数索引，分别是：minmax、set、ngrambf_v1 和 tokenbf_v1，一张数据表支持同时声明多个跳数索引，比如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> skip_test</span><br><span class="line">(</span><br><span class="line">    ID        String,</span><br><span class="line">    URL       String,</span><br><span class="line">    Code      String,</span><br><span class="line">    EventTime <span class="type">Date</span>,</span><br><span class="line">    INDEX a ID TYPE minmax GRANULARITY <span class="number">5</span>,</span><br><span class="line">    INDEX b (length(ID) <span class="operator">*</span> <span class="number">8</span>) TYPE <span class="keyword">set</span>(<span class="number">100</span>) GRANULARITY <span class="number">5</span>,</span><br><span class="line">    INDEX c (ID, Code) TYPE ngrambf_v1(<span class="number">3</span>, <span class="number">256</span>, <span class="number">2</span>, <span class="number">0</span>) GRANULARITY <span class="number">5</span>,</span><br><span class="line">    INDEX d ID TYPE tokenbf_v1(<span class="number">256</span>, <span class="number">2</span>, <span class="number">0</span>) GRANULARITY <span class="number">5</span></span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()............</span><br></pre></td></tr></table></figure>

<p><strong>接下来就借助上面的栗子来介绍这几种跳数索引的用法：</strong></p>
<p><strong>1）minmax：minmax 索引记录了一段数据内的最小值和最大值，其索引的作用类似分区目录的 minmax 索引，能够快速跳过无用的数据区间。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INDEX a ID TYPE minmax GRANULARITY 5</span><br></pre></td></tr></table></figure>

<p><strong>上述示例中 minmax 索引会记录这段数据区间内 ID 字段的极值，极值的计算涉及每 5 个 index_granularity 区间中的数据。</strong></p>
<p><strong>2）set：set 索引直接记录了声明字段或表达式的取值（唯一值，无重复），其完整形式为 set(max_rows)，其中 max_rows 是一个阈值，表示在一个 index_granularity 内索引最多记录的数据行数。如果 max_rows &#x3D; 0，则表示无限制。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INDEX b (length(ID) * 8) TYPE set(100) GRANULARITY 5</span><br></pre></td></tr></table></figure>

<p><strong>上述实例中 set 索引会记录数据中 ID 的长度 * 8 后的取值，其中 index_granularity 内最多记录 100 条。</strong></p>
<p><strong>3）ngrambf_v1：ngrambf_v1 索引记录的是数据短语的布隆表过滤器，只支持 String 和 FixedString 数据类型。ngrambf_v1 只能够提升 in、notIn、like、equals 和 notEquals 查询的性能，其完整形式为：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ngrambf_v1(n, size_of_bloom_filter_in_bytes, number_of_hash_functions, random_seed)</span><br></pre></td></tr></table></figure>

<p><strong>这些参数是一个布隆过滤器的标准输入，如果你接触布隆过滤器，应该对此十分熟悉，它们的具体含义如下：</strong></p>
<ul>
<li><code>n：token 长度，依据 n 的长度将数据切割为 token 短语</code></li>
<li><code>size_of_bloom_filter_in_bytes：布隆过滤器的大小</code></li>
<li><code>number_of_hash_functions：布隆过滤器中使用 Hash 函数的个数</code></li>
<li><code>random_seed：Hash 函数的随机种子</code></li>
</ul>
<p><strong>例如在下面的栗子中，ngrambf_v1 索引会依照 3 的粒度将数据切割成短语 token，token 会经过 2 个 Hash 函数映射之后再被写入，布隆过滤器大小为 256 字节。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INDEX c (ID, Code) TYPE ngrambf_v1(3, 256, 2, 0) GRANULARITY 5</span><br></pre></td></tr></table></figure>

<p><strong>4）tokenbf_v1：tokenbf_v1 索引是 ngrambf_v1 的变种，同样也是一种布隆过滤器索引，但 tokenbf_v1 除了短语 token 的处理方法外，其它与 ngrambf_v1 是完全一样的。tokenbf_v1 会自动按照非字符的、数字的字符串分割 token，具体用法如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INDEX d ID TYPE tokenbf_v1(256, 2, 0) GRANULARITY 5</span><br></pre></td></tr></table></figure>

<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p><strong>此前已经多次提过，在 MergeTree 中数据是按列存储的，但具体细节到底如何我们还不清楚，那么下面就来解释一下。因为数据存储就好比一本书中的文字，在排版时不可能直接密密麻麻地把文字堆满，这样会导致难以阅读，正确的做法是将文字按照段落精心组织使其错落有致。数据存储也是同样的到底，数据也需要精心组织之后也存储到磁盘。</strong></p>
<h3 id="数据按列存储"><a href="#数据按列存储" class="headerlink" title="数据按列存储"></a>数据按列存储</h3><p><strong>在 MergeTree 中数据按列存储，在老版本中每个列也是独立存储的，也就是每个列字段都拥有一个与之对应的 .bin 文件；但是在新版本中这些列字段对应的 .bin 文件合并在一起了，只有一个 data.bin。正是 data.bin 文件，最终承载着物理存储。那么按列存储有什么好处呢？首先可以更好的进行数据压缩，因为相同类型的数据放在一起，对压缩更加友好；其实是能够最小化数据扫描的范围。</strong></p>
<p><strong>而对应到存储的具体实现方面，MergeTree 也并不是一股脑地将数据直接写入 data.bin 文件，而是经过了一番精心设计：首先数据是经过压缩的，目前支持 LZ4、ZSTD、Multiple 和 Delta 几种算法，默认使用 LZ4 算法；其次，数据会实现按照 ORDER BY 的声明排序；最后数据以压缩数据块的形式被组织并写入 data.bin 文件。</strong></p>
<p><strong>压缩数据块就好比一本书的文件段落，是组织文字的基本单元，这个概念非常重要，需要深入说明一下。</strong></p>
<h3 id="压缩数据块"><a href="#压缩数据块" class="headerlink" title="压缩数据块"></a>压缩数据块</h3><p><strong>一个压缩数据块由头信息和压缩数据两部分组成，头信息固定使用 9 位字节表示，具体由 1 个 UInt8（1 字节）和 2 个 UInt32（4 字节）组成，分别代表使用的压缩算法类型、压缩后的数据大小、压缩前的数据大小。所以虽然存储的是压缩后的数据，但是在头信息中将压缩前的数据大小也记录了下来。我们先创建一张表，然后写入一些数据测试一下。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121540506-1382470710.png" alt="img"></p>
<p><strong>然后用 Python 写入写入 10 万条数据：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> faker <span class="keyword">import</span> Faker</span><br><span class="line"><span class="keyword">from</span> clickhouse_driver <span class="keyword">import</span> Client</span><br><span class="line"></span><br><span class="line">f = Faker(<span class="string">&quot;ja_JP&quot;</span>)  <span class="comment"># 生成 1 万条测试数据，Age 均为 26</span></span><br><span class="line">data = [<span class="built_in">str</span>((<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span>, f.name(), <span class="number">26</span>, f.address())) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>)]</span><br><span class="line"></span><br><span class="line">sql = <span class="string">f&quot;INSERT INTO people VALUES <span class="subst">&#123;<span class="string">&#x27;, &#x27;</span>.join(data)&#125;</span>&quot;</span></span><br><span class="line">client = Client(host=<span class="string">&quot;47.94.174.89&quot;</span>, port=<span class="number">9000</span>)</span><br><span class="line">client.execute(sql)</span><br></pre></td></tr></table></figure>

<p><strong>显然会创建一个分区，根据我们之前介绍的规则，分区对应的分区目录为 26_1_1_0。但是注意，这里要使用 1 个 INSERT 语句，否则的话数据会分多批导入，这样的就会创建多个分区目录：26_1_1_0、26_2_2_0、26_3_3_0，……。而我们要的是合并后的结果，虽然属于相同分区的分区目录之后会自动合并，但是需要等一段时间，因此这里我们就一批次直接导入。</strong></p>
<p><strong>然后我们可以使用 clickhouse-compressor 查看数据大小：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121548304-1172775367.png" alt="img"></p>
<p><strong>其中每一行代表一个数据压缩块的头信息，分别表示该压缩块中 “压缩前的数据大小” 和 “压缩后的数据大小”，并且我们看到总共有 4 个压缩数据块。为什么有 4 个，原因是我们只有 4 个列，所以 data.bin 里面存储的就是对 4 个列压缩之后的结果，这是显而易见的。像第一列就是 ID，由于我们的 ID 是顺序自增的，几乎没有什么重复，所以压缩之后和压缩之前的的大小差别不大；但是后面几列的数据压缩之后就小很多了，尤其是第三行 Age 字段，因为每个值都是一个 UInt8，1 万条数据所以占 10000 个字节，但由于所有值都是 26，数据全部一样，而数据越相似压缩比越高，因此压缩之后变成了 59 个字节。至于压缩背后的算法我们这里不细究了， 只需要知道数据之间越相似、或者说重复率越高，压缩之后的数据就越小。</strong></p>
<p><strong>但是注意：我们这里的数据量比较少，每一列数据的大小不是很大，因此每一列只用一个压缩数据块即可存储。如果数据量再多一些，一个压缩数据块存储不下，那么就会对应多个压缩数据块。</strong></p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line">Column1 压缩数据块<span class="number">0</span></span><br><span class="line">Column2 压缩数据块<span class="number">0</span></span><br><span class="line">Column3 压缩数据块<span class="number">0</span></span><br><span class="line">......</span><br><span class="line">ColumnN 压缩数据块<span class="number">0</span></span><br><span class="line"></span><br><span class="line">Column1 压缩数据块<span class="number">1</span></span><br><span class="line">Column2 压缩数据块<span class="number">1</span></span><br><span class="line">Column3 压缩数据块<span class="number">1</span></span><br><span class="line">......</span><br><span class="line">ColumnN 压缩数据块<span class="number">1</span></span><br><span class="line"></span><br><span class="line">Column1 压缩数据块<span class="number">2</span></span><br><span class="line">Column2 压缩数据块<span class="number">2</span></span><br><span class="line">Column3 压缩数据块<span class="number">2</span></span><br><span class="line">......</span><br><span class="line">ColumnN 压缩数据块<span class="number">2</span></span><br><span class="line"></span><br><span class="line">Column1 压缩数据块<span class="number">3</span></span><br><span class="line">Column2 压缩数据块<span class="number">3</span></span><br><span class="line">Column3 压缩数据块<span class="number">3</span></span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p><strong>示意图如下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121555649-1327243137.png" alt="img"></p>
<p><strong>其中每一行数据都代表者一个压缩数据块的头信息，其分别表示该压缩块中未压缩数据和压缩数据的大小，注意：打印信息和物理存储的顺序刚好相反。</strong></p>
<p><strong>但是我们需要注意，之前我们说在早期的 ClickHouse 中每一列数据各自对应一个 .bin 文件，但是在新版本的时候合并在一起了，这是没错的，但前提是数据量不大。如果数据量大到一定程度，那么每一列的数据就会分开存储了，也就是各自对应一个 .bin 文件和一个 .mrk 文件，和 data.bin、data.mrk 的作用是完全等价的， 只不过一个是各列分开存储、一个是所有列合并在一起存储。</strong></p>
<p><strong>我们再执行一次上面的 Python 代码，但是将生成的数据改成 10 万条：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121602882-2030388856.png" alt="img"></p>
<p><strong>显然此时会创建一个 26_2_2_0 分区目录，里面就没有 data.bin 了，取而代之的时候 ID.bin、Name.bin、Age.bin、Place.bin，同理 .mrk 文件也是如此。当然除了 .mrk 之外还有一个 .mrk2，它和 .mrk3 作用相似，当使用了自适应大小的索引间隔，会出现此标记文件。</strong></p>
<p><strong>然后我们再来对每一个列对应的 .bin 文件查看一下大小：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121611426-1900498698.png" alt="img"></p>
<p><strong>如果每一列都对应单独的 .bin 文件的话，那么每一列都有自己的压缩数据块：块 0、块1、块2、……、块 n，这和 data.bin 原理相同，只不过 data.bin 在数据量没达到阈值的时候会将所有列对应的压缩数据块存储在一起：列 1 块 0、列 2 块 0、….、列 N 块 0、列 1 块 1、列 2 块 1、……、列 N 块 1、列 1 块 2、列 2 块 2、……、列 N 块 2、列 1 块 3、…….。</strong></p>
<p><strong>并且此时每个压缩数据块的大小，都被严格控制在 64KB 到 1MB 之间，其上下限分别由 min_compress_block_size（默认 65536）和 min_compress_block_size（默认值为 1048576）决定。比如 Age.bin，因为 10 万条数据所以 10 万个字节，第一个压缩数据块的大小就是 65536 字节，被压缩成了 276 字节，至于剩余的 34464 字节是因为只剩下这么多了，然后被压缩成了 155 字节。至于其它的列也是同理，只不过列不相同，所以压缩数据块的最终大小也不相同。</strong></p>
<p><strong>那么压缩数据块的大小是怎么计算出来的呢？首先压缩数据块的最终大小是和索引粒度（index_granularity）相关的，MergeTree 在具体的数据写入过程中，会依照索引粒度按批次获取数据并写入（由于索引粒度默认是 8192，所以每批次会获取 8192 行）。如果把一批未压缩的数据的大小设为 size，则整个数据的写入过程遵循如下规则：</strong></p>
<ul>
<li><strong>1）单个批次数据 size &lt; 64KB：如果单个批次数据小于 64KB，则继续获取下一批数据，直至累积到 size 大于等于 64KB 时，生成下一个压缩数据块。</strong></li>
<li><strong>2）单个批次数据 64KB &lt;&#x3D; size &lt;&#x3D; 1MB：如果单个批次数据在 64KB 到 1MB 之间，则直接生成下一个压缩数据块。</strong></li>
<li><strong>3）单个批次数据 size &gt; 1MB：如果单个批次数据直接超过 1MB，则首先按照 1MB 大小截断并生成下一个压缩数据块，然后剩余数据继续依照上述规则执行。因此，此时会出现一批次数据生成多个压缩数据块的情况。</strong></li>
</ul>
<p><strong>因此说白了就是 MergeTree 在获取数据的时候会依照索引粒度按批次获取数据，所以默认情况下就是每批获取 8192 行，然后一批一批获取。而如果设当前批次的数据大小为 size，那么会根据 size 的不同，走上面三个分支中的一个。我们以 Age.bin 为例，每批取 8912 行显然就是 8192 个字节，也就是 8 KB，小于 64 KB，因此会读取下一批。而当读到第 8 批时，发现数据加起来达到了 64 KB，因此生成一个压缩数据块，此时还剩下 34464（100000 减去 8 * 8192）、不到 34 KB，因此剩余的部分直接作为一个压缩数据块；当然其它列也很好分析，和 Age 是类似的，只不过 Age 最简单，每个值占 1 字节。而其它列因为存储的内容大小不固定（有的长有的短），所以不是很好计算，但存储的逻辑是不变的。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121621814-262052550.png" alt="img"></p>
<p><strong>因此一个 .bin 文件是由 1 到多个压缩数据块组成的，每个压缩块的大小是 64KB ~ 1MB 之间，多个数据压缩块之间按照写入顺序首尾相接，紧密地排在一起。</strong></p>
<p><strong>而在 .bin 文件中引入压缩数据块的目的有两个：</strong></p>
<ul>
<li><code>1. 虽然数据被压缩后能够有效减少数据大小，降低存储空间并加速传输效率，但数据的压缩和解压缩本身是会带来额外消耗的。所以要控制被压缩数据的大小，以便在性能损耗和压缩率之间寻求一种平衡</code></li>
<li><code>2. 在具体读取某一列数据时（.bin 文件），首先需要将压缩数据加载到内存中并解压，这样才能进行后续的数据处理。而通过数据压缩块，可以在不读取整个 .bin 文件的情况下将读取粒度降低到压缩数据块级别，从而进一步缩小数据读取范围</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121629063-1970946671.png" alt="img"></p>
<p><strong>所以压缩数据块是重点，每一次都是按块写入、同时也会按块读取。另外当数据量没有超过阈值的时候，所有的列会放在一起存储（data.bin），数据量超过阈值、那么每一列会单独存储。</strong></p>
<h2 id="数据标记文件（-mrk）"><a href="#数据标记文件（-mrk）" class="headerlink" title="数据标记文件（.mrk）"></a>数据标记文件（.mrk）</h2><p><strong>如果把 MergeTree 比作一本书，primary.idx（一级索引）就类似书的一级章节目录，但是这个目录具体对应书中（ .bin 文件）的哪一页呢？</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121636786-372556394.png" alt="img"></p>
<p><strong>显然每个目录后面的页码会告诉你，该目录位于书中的哪一页，而页码就相当于数据标记文件（.mrk）中记录的偏移量（数据标记），标记索引在数据文件中的具体位置。因此对于数据标记文件而言，它记录了两点关键信息：</strong></p>
<ul>
<li><code>1. 与一级章节目录对应的页码信息</code></li>
<li><code>2. 一段文字在某一页中的起始位置信息</code></li>
</ul>
<p><strong>这样一来，通过数据标记文件可以很快地从一本书中立即翻到关注内容所在的那一页，并知道从第几行开始阅读。</strong></p>
<h3 id="数据标记的生成规则"><a href="#数据标记的生成规则" class="headerlink" title="数据标记的生成规则"></a>数据标记的生成规则</h3><p><strong>数据标记作为衔接一级索引和数据的桥梁，像极了书签，而且书本总每一个章节目录都有各自的书签。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121645106-1424401301.png" alt="img"></p>
<p><strong>从图中我们可以看到，数据标记和索引区间是对齐的，均按照 index_granularity 的粒度间隔，如此一来只需要简单通过索引下标编号即可直接找到对应的数据标记。并且为了能够与数据衔接，.bin 文件和数据标记文件是一一对应的，即每一个 [Column].bin 文件都有一个 [Column].mrk 数据标记文件与之对应，用于记录数据在 .bin 文件中的偏移量信息。</strong></p>
<p><strong>一行标记数据使用一个元组表示，元组内包含两个整型数值的偏移量信息，分别表示在此段数据区间内：</strong></p>
<ul>
<li><code>1. 对应 .bin 压缩文件中，压缩数据块的起始偏移量</code></li>
<li><code>2. 将该数据块解压缩后，未压缩数据的起始偏移量</code></li>
</ul>
<p><strong>我们以之前 Age.bin 为例：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121652461-11019192.png" alt="img"></p>
<p><strong>每次按批读取 8192 行，因为一个 UInt 8 一字节，所以每次读取 8192 个字节，在读取 8 批之后会进行压缩得到一个压缩数据块。生成的第一个压缩数据块为 276 个字节，然后未压缩数据还剩下 34464 字节，小于 64KB，于是直接生成 155 字节的第二个压缩数据块。因此在 Age.bin 中两个偏移量的对应关系如下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121657840-402377603.png" alt="img"></p>
<p><strong>每一行标记数据都标记了一个片段的数据（默认 8192 行）在 .bin 压缩文件中的读取位置信息，因为 Age 占 1 字节，所以每次读取 8912 行相当于每次读取 8192 个字节，因此 “未压缩数据的起始偏移量” 就是 0、8192、16384、24576、……。但是需要注意图中的 57344，它表示第 8 批未压缩数据的起始偏移量，因为此时已经达到了 64KB，所以会生成一个压缩数据块，于是接下来读取第 9 批未压缩数据的时候就会对应新的压缩数据块，因此起始偏移量会重置为 0，而不是 65536。</strong></p>
<blockquote>
<p><strong>我们这里是 Age 字段为例，至于其它列也是同理，只不过由于每一行字符串的长度不同，所以我们很难计算每次读 8192 行的话会读多少个字节，但它们的原理是很明显都是一样的。</strong></p>
</blockquote>
<p><strong>然后是 “压缩数据块的起始偏移量”，因为读了 8 批才生成了第一个压缩数据块，因此前 8 行都是 0。然后由于第一个压缩数据块的大小是 276，因此第 9 行、即索引为 8 的位置，存储的值就是 276，表示第二个压缩数据块的起始偏移量。</strong></p>
<p><strong>以上就是标记文件的存储原理，但是标记文件和一级索引不同，它不能常驻内存，而是使用 LRU（最近最少使用）缓存淘汰策略加快其取用速度。</strong></p>
<h3 id="数据标记的工作方式"><a href="#数据标记的工作方式" class="headerlink" title="数据标记的工作方式"></a>数据标记的工作方式</h3><p><strong>MergeTree 在读取数据时，必须通过标记文件中的偏移量才能找到所需要的数据，因此整个查找过程可以分为读取压缩数据块和读取数据两个步骤。为了便于解释，这里继续使用刚才的 people 表的 Age 字段进行说明，因为 Age 字段的大小固定，最好分析，至于其它字段的查找过程与之完全类似。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121710168-599041568.png" alt="img"></p>
<p><strong>1）读取压缩数据块</strong></p>
<p><strong>在查询某一列数据时，MergeTree 无需加载整个 .bin 文件，而是可以根据需要只加载特定的压缩数据块，而这项特性则要借助 .mrk 文件中所保存的偏移量信息。</strong></p>
<p><strong>从图中可以看到，上下相邻的两个压缩数据块的起始偏移量，构成了与当前标记对应的压缩数据块的偏移量区间，说人话就是通过第 n 个压缩数据块的起始偏移量和第 n + 1 个压缩数据块的起始偏移量，可以获取第 n 个压缩数据块。具体做法就是从当前偏移量开始向下寻找（当前块的起始位置 start），直到找到不同的偏移量位置（当前块的下一个块的起始位置 next_start），此时 start 到 next_start 便是当前块对应的偏移量区间，比如图中的 0 到 276。通过偏移量区间，即可获得当前的压缩块。</strong></p>
<p><strong>2）读取数据</strong></p>
<p><strong>在读取解压后的数据时，MergeTree 并不需要一次性扫描整段解压数据，它可以根据需要，以 index_granularity 的粒度加载特定的一小段，而为了实现这种特性，需要借助标记文件中保存的解压数据块的偏移量。</strong></p>
<p><strong>通过偏移量，ClickHouse 可以按需读取数据，比如通过 [0, 8192] 即可读取压缩数据块 0 中第一个数据片段对应的解压数据。</strong></p>
<h2 id="分区、索引、标记和压缩数据的协同总结"><a href="#分区、索引、标记和压缩数据的协同总结" class="headerlink" title="分区、索引、标记和压缩数据的协同总结"></a>分区、索引、标记和压缩数据的协同总结</h2><p><strong>分区、索引、标记和压缩数据，就类似于 MergeTree 的一套组合拳，使用恰当的话威力无穷。那么在依次介绍了各自的特点之后，现在将它们聚在一起总结一下。</strong></p>
<h3 id="写入过程"><a href="#写入过程" class="headerlink" title="写入过程"></a>写入过程</h3><p><strong>数据写入的第一步是生成分区目录，伴随着每一批数据的写入，都会生成一个新的分区目录。在后续的某一时刻，属于相同分区的分区目录会被合并到一起。紧接着按照 index_granularity 索引粒度，会分别生成 primary.idx 一级索引（如果声明了二级索引，还会创建二级索引文件）、每一个列字段的压缩数据文件（.bin）和数据标记文件（.mrk），如果数据量不大，则是 data.bin 和 data.mrk 文件。</strong></p>
<p><strong>下面的示意图展示了 MergeTree 表在写入数据时，它的分区目录、索引、标记和压缩数据的生成。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121718621-4237534.png" alt="img"></p>
<p><strong>从分区目录 202006_1_34_3 能够得知，该分区数据总共分 34 批写入，期间发生过 3 次合并。在数据写入的过程中，依据 index_granularity 的粒度，依次为每个区间的数据生成索引、标记和压缩数据块。其中索引和标记区间是对齐的，而标记与压缩块则是根据区间大小的不同，会生成多对一、一对一、一对多的关系。</strong></p>
<h3 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h3><p><strong>数据查询的本质可以看做是一个不断减少数据范围的过程，在最理想的情况下，MergeTree 首先可以借助分区索引、一级索引和二级索引将数据扫描范围缩至最小。然后再借助数据标记，将需要解压与计算的数据范围缩至最小。以下图为例，该图展示了在最优的情况下，经过层层过滤，最终获取最小数据范围的过程。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E4%B8%AD%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%A1%A8%E5%BC%95%E6%93%8E%EF%BC%9AMergeTree%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90(%E5%85%AD)/1229382-20210826121725662-2046737993.png" alt="img"></p>
<p><strong>如果一条查询语句没有指定任何 WHERE 条件，或者指定了 WHERE 条件、但是没有匹配到任何的索引（分区索引、一级索引、二级索引），那么 MergeTree 就不能预先减少数据范围。在后续进行数据查询时，它会扫描所有分区目录，以及目录内索引段的最大区间。不过虽然不能减少数据范围，但 MergeTree 仍然能够借助数据标记，以多线程的形式同时读取多个压缩数据块，以提升性能。</strong></p>
<h3 id="数据标记与压缩数据块的对应关系"><a href="#数据标记与压缩数据块的对应关系" class="headerlink" title="数据标记与压缩数据块的对应关系"></a>数据标记与压缩数据块的对应关系</h3><p><strong>由于压缩数据块的划分，与一个间隔（index_granularity）内的数据大小相关，每个压缩数据块的体积都被严格控制在 64KB ~ 1MB 之间，而一个间隔（index_granularity）的数据，又只会产生一行数据标记。那么根据一个间隔内数据的实际字节大小，数据标记和压缩数据块之间会产生三种不同的对应关系：</strong></p>
<p><strong>1）多对一</strong></p>
<p><strong>多个数据标记对应一个压缩数据块，当一个间隔（index_granularity）内数据的未压缩大小小于 64KB 时，会出现这种对应关系。</strong></p>
<p><strong>2）一对一</strong></p>
<p><strong>一个数据标记对应一个压缩数据块，当一个间隔（index_granularity）内数据的未压缩大小大于等于 64KB 并小于等于 1MB 时，会出现这种对应关系。</strong></p>
<p><strong>3）一对多</strong></p>
<p><strong>一个数据标记对应多个压缩数据块，当一个间隔（index_granularity）内数据的未压缩大小大于 1MB 时，会出现这种对应关系。</strong></p>
<p><strong>以上就是 MergeTree 的工作原理，首先我们了解了 MergeTree 的基础属性和物理存储结构；接着，依次介绍了数据分区、一级索引、二级索引、数据存储和数据标记的重要特性；最后总结了 MergeTree 上述特性一起协同时工作过程。掌握了 MergeTree 即掌握了合并树系列表引擎的精髓，因为 MergeTree 本身也是一种表引擎。后面我们会介绍 MergeTree 家族中其它常见表引擎的使用方法，以及它们都有哪些特点、使用方式是什么</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 字符串的相关操作函数(十二)</title>
    <url>/2023/04/11/ClickHouse%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0(%E5%8D%81%E4%BA%8C)/</url>
    <content><![CDATA[<h1 id="ClickHouse-字符串的相关操作函数-十二"><a href="#ClickHouse-字符串的相关操作函数-十二" class="headerlink" title="ClickHouse 字符串的相关操作函数(十二)"></a>ClickHouse 字符串的相关操作函数(十二)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>下面来说一说字符串的相关操作。</strong></p>
<p><strong>empty：检测一个字符串是否为空，为空返回 1，不为空返回 0</strong></p>
<p><strong>notEmpty：检测一个字符串是否不为空，不为空返回 1，为空返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">empty</span>(<span class="string">&#x27;&#x27;</span>), <span class="keyword">empty</span>(<span class="string">&#x27;satori&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─empty(&#x27;&#x27;)─┬─empty(&#x27;satori&#x27;)─┐</span></span><br><span class="line"><span class="comment">│         1 │               0 │</span></span><br><span class="line"><span class="comment">└───────────┴─────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> notEmpty(<span class="string">&#x27;&#x27;</span>), notEmpty(<span class="string">&#x27;satori&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─notEmpty(&#x27;&#x27;)─┬─notEmpty(&#x27;satori&#x27;)─┐</span></span><br><span class="line"><span class="comment">│            0 │                  1 │</span></span><br><span class="line"><span class="comment">└──────────────┴────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>length：计算一个字符串占多少个字节</strong></p>
<p><strong>char_length：计算一个字符串占多少个字符</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="string">&#x27;satori&#x27;</span> <span class="keyword">AS</span> s1, <span class="string">&#x27;古明地觉&#x27;</span> <span class="keyword">AS</span> s2</span><br><span class="line"><span class="keyword">SELECT</span> length(s1), length(s2), <span class="keyword">char_length</span>(s1), <span class="keyword">char_length</span>(s2)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─length(s1)─┬─length(s2)─┬─CHAR_LENGTH(s1)─┬─CHAR_LENGTH(s2)─┐</span></span><br><span class="line"><span class="comment">│          6 │         12 │               6 │               4 │</span></span><br><span class="line"><span class="comment">└────────────┴────────────┴─────────────────┴─────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toString：将整型、日期转成字符串</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> toString(<span class="number">3</span>), <span class="built_in">cast</span>(<span class="number">3</span> <span class="keyword">AS</span> String);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toString(3)─┬─CAST(3, &#x27;String&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ 3           │ 3                 │</span></span><br><span class="line"><span class="comment">└─────────────┴───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>除了使用 cast 之外，每种数据类型都内置了相应的转换函数，格式为 to + 类型，比如 toInt8、toUInt32、toFloat64、toDecimal64 等等</strong></p>
<p><strong>lower、lcase：字符串转小写</strong></p>
<p><strong>upper、ucase：字符串转大写</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">lower</span>(<span class="string">&#x27;SAtoRI&#x27;</span>), <span class="built_in">upper</span>(<span class="string">&#x27;SAtoRI&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─lower(&#x27;SAtoRI&#x27;)─┬─upper(&#x27;SAtoRI&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ satori          │ SATORI          │</span></span><br><span class="line"><span class="comment">└─────────────────┴─────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>repeat：将字符串重复 n 次</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> repeat(<span class="string">&#x27;abc&#x27;</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─repeat(&#x27;abc&#x27;, 3)─┐</span></span><br><span class="line"><span class="comment">│ abcabcabc        │</span></span><br><span class="line"><span class="comment">└──────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>reverse：将字符串翻转</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> reverse(<span class="string">&#x27;satori&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─reverse(&#x27;satori&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ irotas            │</span></span><br><span class="line"><span class="comment">└───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：reverse 是按照字节翻转的，这意味着它不能用在中文上面，如果想翻转中文，那么要使用 reverseUTF8，可以试一下。</strong></p>
<p><strong>format：格式化字符串</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> format(<span class="string">&#x27;&#123;&#125;--&#123;&#125;&#x27;</span>, <span class="string">&#x27;hello&#x27;</span>, <span class="string">&#x27;world&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─format(&#x27;&#123;&#125;--&#123;&#125;&#x27;, &#x27;hello&#x27;, &#x27;world&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ hello--world                       │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- &#123;&#125; 的数量和格式化的字符串数量要匹配，当然下面这种情况例外</span></span><br><span class="line"><span class="keyword">SELECT</span> format(<span class="string">&#x27;&#123;0&#125;--&#123;1&#125;--&#123;0&#125;&#x27;</span>, <span class="string">&#x27;hello&#x27;</span>, <span class="string">&#x27;world&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─format(&#x27;&#123;0&#125;--&#123;1&#125;--&#123;0&#125;&#x27;, &#x27;hello&#x27;, &#x27;world&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ hello--world--hello                       │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>concat：拼接字符串</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> concat(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─concat(&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ abc                   │</span></span><br><span class="line"><span class="comment">└───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>当然拼接字符串还可以使用双竖线：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;a&#x27;</span> <span class="operator">||</span> <span class="string">&#x27;b&#x27;</span> <span class="operator">||</span> <span class="string">&#x27;c&#x27;</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─concat(&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ abc                   │</span></span><br><span class="line"><span class="comment">└───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>substring：字符串截取，也可以写成 mid、substr，用法和标准 SQL 中的 substring 一样，但有一点区别</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 从第 2 个元素开始截取，截取 3 个字节，注意：区别来了，截取的是字节</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">substring</span>(<span class="string">&#x27;abcdefg&#x27;</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─substring(&#x27;abcdefg&#x27;, 2, 3)─┐</span></span><br><span class="line"><span class="comment">│ bcd                        │</span></span><br><span class="line"><span class="comment">└────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 如果想按照字符截取，要使用 substringUTF8</span></span><br></pre></td></tr></table></figure>

<p><strong>appendTrailingCharIfAbsent：如果非空字符串 s 的末尾不包含字符 c，那么就在 s 的结尾填上字符 c</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> appendTrailingCharIfAbsent(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;i&#x27;</span>), </span><br><span class="line">       appendTrailingCharIfAbsent(<span class="string">&#x27;sator&#x27;</span>, <span class="string">&#x27;i&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─appendTrailingCharIfAbsent(&#x27;satori&#x27;, &#x27;i&#x27;)─┬─appendTrailingCharIfAbsent(&#x27;sator&#x27;, &#x27;i&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ satori                                    │ satori                                   │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────┴──────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>convertCharset：改变字符串的字符集</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> convertCharset(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;ascii&#x27;</span>, <span class="string">&#x27;utf8&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─convertCharset(&#x27;satori&#x27;, &#x27;ascii&#x27;, &#x27;utf8&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ satori                                    │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>base64Encode：对字符串进行 base64 编码</strong></p>
<p><strong>base64Decode：对 base64 编码的字符串进行 base64 解码</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> base64Encode(<span class="string">&#x27;satori&#x27;</span>) s1, base64Decode(s1);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─s1───────┬─base64Decode(base64Encode(&#x27;satori&#x27;))─┐</span></span><br><span class="line"><span class="comment">│ c2F0b3Jp │ satori                               │</span></span><br><span class="line"><span class="comment">└──────────┴──────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>还有一个 tryBase64Decode，和 base64Decode 类似，但解析失败时会返回空字符串。如果是 base64Decode，那么对一个非 base64 编码的字符串解析会得到乱码。</strong></p>
<p><strong>startsWith、endsWith：判断字符串是否以某个子串开头或结尾，如果是，返回 1；否则，返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> startsWith(<span class="string">&#x27;古明地觉&#x27;</span>, <span class="string">&#x27;古明&#x27;</span>) v1, endsWith(<span class="string">&#x27;古明地觉&#x27;</span>, <span class="string">&#x27;古明&#x27;</span>) v2;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v1─┬─v2─┐</span></span><br><span class="line"><span class="comment">│  1 │  0 │</span></span><br><span class="line"><span class="comment">└────┴────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>trim：去除字符串两端的字符</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">trim</span>(<span class="string">&#x27;   satori    &#x27;</span>) s, length(s);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─s──────┬─length(trimBoth(&#x27;   satori    &#x27;))─┐</span></span><br><span class="line"><span class="comment">│ satori │                                 6 │</span></span><br><span class="line"><span class="comment">└────────┴───────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 默认去除空格，也可以去除其它字符</span></span><br><span class="line"><span class="comment">-- 但此时必须指定是从 &quot;左边&quot; 去除，还是从 &quot;右边&quot; 去除，还是 &quot;两端&quot; 都去除</span></span><br><span class="line"><span class="comment">-- 左边是 LEADING，右边是 TRAILING，两端是 BOTH</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">trim</span>(<span class="keyword">BOTH</span> <span class="string">&#x27;ab&#x27;</span> <span class="keyword">FROM</span> <span class="string">&#x27;abxxxxxxbaaa&#x27;</span>) s1,</span><br><span class="line">       <span class="built_in">trim</span>(<span class="keyword">LEADING</span> <span class="string">&#x27;ab&#x27;</span> <span class="keyword">FROM</span> <span class="string">&#x27;abxxxxxxbaaa&#x27;</span>) s2,</span><br><span class="line">       <span class="built_in">trim</span>(<span class="keyword">TRAILING</span> <span class="string">&#x27;ab&#x27;</span> <span class="keyword">FROM</span> <span class="string">&#x27;abxxxxxxbaaa&#x27;</span>) s3;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─s1─────┬─s2─────────┬─s3───────┐</span></span><br><span class="line"><span class="comment">│ xxxxxx │ xxxxxxbaaa │ abxxxxxx │</span></span><br><span class="line"><span class="comment">└────────┴────────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>trim 如果只接收一个普通字符串，那么默认行为就是删除两端的空格，所以还有 trimLeft、trimRight，也是接收一个普通的字符串，然后去除左边、右边的空格。其中 trimLeft 也可以写作 ltrim，trimRight 也可以写作 rtrim。</strong></p>
<p><strong>CRC32：返回字符串的 CRC32 校验和，使用 CRC-32-IEEE 802.3 多项式，并且初始值为 0xFFFFFFFF</strong></p>
<p><strong>CRC32IEEE：返回字符串的 CRC32 校验和，使用 CRC-32-IEEE 802.3 多项式</strong></p>
<p><strong>CRC64：返回字符串的 CRC64 校验和，使用 CRC-64-ECMA 多项式</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CRC32(<span class="string">&#x27;satori&#x27;</span>), CRC32IEEE(<span class="string">&#x27;satori&#x27;</span>), CRC64(<span class="string">&#x27;satori&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─CRC32(&#x27;satori&#x27;)─┬─CRC32IEEE(&#x27;satori&#x27;)─┬─────CRC64(&#x27;satori&#x27;)─┐</span></span><br><span class="line"><span class="comment">│       379058543 │          2807388364 │ 1445885890712067336 │</span></span><br><span class="line"><span class="comment">└─────────────────┴─────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>encodeXMLComponent：对字符串进行转义，针对 &lt;、&amp;、&gt;、”、’ 五种符号</strong></p>
<p><strong>decodeXMLComponent：对字符串进行反转义，针对 &lt;、&amp;、&gt;、”、’ 五种符号</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> encodeXMLComponent(<span class="string">&#x27;&lt;name&gt;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─encodeXMLComponent(&#x27;&lt;name&gt;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ &amp;lt;name&amp;gt;                 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> decodeXMLComponent(<span class="string">&#x27;&amp;lt;name&amp;gt;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─decodeXMLComponent(&#x27;&amp;lt;name&amp;gt;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ &lt;name&gt;                             │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>position：查找某个子串在字符串当中的位置</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">position</span>(<span class="string">&#x27;abcdefg&#x27;</span>, <span class="string">&#x27;de&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─position(&#x27;abcdefg&#x27;, &#x27;de&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                         4 │</span></span><br><span class="line"><span class="comment">└───────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 也可以从指定位置查找</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">position</span>(<span class="string">&#x27;hello world&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="number">1</span>), <span class="built_in">position</span>(<span class="string">&#x27;hello world&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="number">7</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─position(&#x27;hello world&#x27;, &#x27;o&#x27;, 1)─┬─position(&#x27;hello world&#x27;, &#x27;o&#x27;, 7)─┐</span></span><br><span class="line"><span class="comment">│                               5 │                               8 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────┴─────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>该函数是大小写敏感的，如果想大小写不敏感，那么可以使用 positionCaseInsensitive。还有一点需要注意，该函数是按照字节统计的。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">position(&#x27;古明地觉A&#x27;, &#x27;A&#x27;) 得到的是 13，因为一个汉字 3 字节</span><br></pre></td></tr></table></figure>

<p><strong>如果包含中文，想按照字符统计，则需要使用 positionUTF8。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">positionUTF8(&#x27;古明地觉A&#x27;, &#x27;A&#x27;) 得到的就是 5</span><br></pre></td></tr></table></figure>

<p><strong>如果不存在，则返回 0</strong></p>
<p><strong>multiSearchAllPositions：查找多个子串在字符串当中的位置，多个子串组成数组进行传递</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> multiSearchAllPositions(<span class="string">&#x27;satori&#x27;</span>, [<span class="string">&#x27;sa&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;ri&#x27;</span>, <span class="string">&#x27;xxx&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─multiSearchAllPositions(&#x27;satori&#x27;, [&#x27;sa&#x27;, &#x27;to&#x27;, &#x27;ri&#x27;, &#x27;xxx&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [1,3,5,0]                                                    │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果想大小写不敏感，那么可以使用 multiSearchAllPositionsCaseInsensitive。同样的，该函数也是在字节序列上进行搜索，不考虑字符编码，如果想支持非 ASCII 字符，应该使用 multiSearchAllPositionsUTF8。</strong></p>
<p><strong>match：正则表达式匹配，如果给定的字符串匹配给定的表达式，则返回 1；不匹配，则返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 字符串放左边，模式方右边</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">match</span>(<span class="string">&#x27;123&#x27;</span>, <span class="string">&#x27;\\d&#123;1,3&#125;&#x27;</span>), <span class="keyword">match</span>(<span class="string">&#x27;abcd&#x27;</span>, <span class="string">&#x27;\\d&#123;1,3&#125;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─match(&#x27;123&#x27;, &#x27;\\d&#123;1,3&#125;&#x27;)─┬─match(&#x27;abcd&#x27;, &#x27;\\d&#123;1,3&#125;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                        1 │                         0 │</span></span><br><span class="line"><span class="comment">└──────────────────────────┴───────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们知道反斜杠本身代表转义，那么如果想表达 \d，应该使用 \d。同理如果我们想检测字符串是否包含反斜杠，那么应该这么做：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT match(s, &#x27;\\\\&#x27;);</span><br></pre></td></tr></table></figure>

<p><strong>因为反斜杠具有转义，那么四个反斜杠会变成两个普通的反斜杠，但我们知道反斜杠在正则中也具有含义，所以两个反斜杠会变成一个普通的反斜杠。</strong></p>
<p><strong>multiMatchAny：正则表达式匹配，但可以接收多个模式，有一个能匹配上，则返回 1；全都匹配不上，则返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">match</span>(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;xx&#x27;</span>), <span class="keyword">match</span>(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;satori&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─match(&#x27;satori&#x27;, &#x27;xx&#x27;)─┬─match(&#x27;satori&#x27;, &#x27;satori&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                     0 │                         1 │</span></span><br><span class="line"><span class="comment">└───────────────────────┴───────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> multiMatchAny(<span class="string">&#x27;satori&#x27;</span>, [<span class="string">&#x27;xx&#x27;</span>, <span class="string">&#x27;satori&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─multiMatchAny(&#x27;satori&#x27;, [&#x27;xx&#x27;, &#x27;satori&#x27;])─┐</span></span><br><span class="line"><span class="comment">│                                         1 │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>multiMatchAnyIndex：正则表达式匹配，接收多个模式，返回第一个匹配的模式的索引</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 显然 &#x27;satori&#x27; 可以匹配上，而它的索引为 3</span></span><br><span class="line"><span class="keyword">SELECT</span> multiMatchAnyIndex(<span class="string">&#x27;satori&#x27;</span>, [<span class="string">&#x27;yy&#x27;</span>, <span class="string">&#x27;xx&#x27;</span>, <span class="string">&#x27;satori&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─multiMatchAnyIndex(&#x27;satori&#x27;, [&#x27;yy&#x27;, &#x27;xx&#x27;, &#x27;satori&#x27;])─┐</span></span><br><span class="line"><span class="comment">│                                                    3 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果没有一个能匹配上则返回 0，因为索引从 1 开始，所以返回 0 代表没有一个匹配上。像一般的编程语言，由于索引从 0 开始，那么当匹配不上的时候返回的就是 -1。</strong></p>
<p><strong>multiMatchAllIndices：正则表达式匹配，接收多个模式，返回所有匹配的模式的索引</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 索引为 2、3 的模式都能匹配上，但只返回第一个匹配上的</span></span><br><span class="line"><span class="keyword">SELECT</span> multiMatchAnyIndex(<span class="string">&#x27;satori&#x27;</span>, [<span class="string">&#x27;yy&#x27;</span>, <span class="string">&#x27;sa&#x27;</span>, <span class="string">&#x27;satori&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─multiMatchAnyIndex(&#x27;satori&#x27;, [&#x27;yy&#x27;, &#x27;sa&#x27;, &#x27;satori&#x27;])─┐</span></span><br><span class="line"><span class="comment">│                                                    2 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 返回所有匹配上的</span></span><br><span class="line"><span class="keyword">SELECT</span> multiMatchAllIndices(<span class="string">&#x27;satori&#x27;</span>, [<span class="string">&#x27;yy&#x27;</span>, <span class="string">&#x27;sa&#x27;</span>, <span class="string">&#x27;satori&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─multiMatchAllIndices(&#x27;satori&#x27;, [&#x27;yy&#x27;, &#x27;sa&#x27;, &#x27;satori&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [2,3]                                                  │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>extract：返回使用正则表达式匹配的字符串</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 我们看到匹配使用的是贪婪模式</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">extract</span>(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;\\w&#123;1,3&#125;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─extract(&#x27;satori&#x27;, &#x27;\\w&#123;1,3&#125;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ sat                           │</span></span><br><span class="line"><span class="comment">└───────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 采用非贪婪模式</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">extract</span>(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;\\w&#123;1,3&#125;?&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─extract(&#x27;satori&#x27;, &#x27;\\w&#123;1,3&#125;?&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ s                              │</span></span><br><span class="line"><span class="comment">└────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>匹配不上，则返回空字符串。</strong></p>
<p><strong>extractAll：extract 只返回一个匹配的字符串，extractAll 则返回所有的</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">extract</span>(<span class="string">&#x27;abc abd abe&#x27;</span>, <span class="string">&#x27;ab.&#x27;</span>), extractAll(<span class="string">&#x27;abc abd abe&#x27;</span>, <span class="string">&#x27;ab.&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─extract(&#x27;abc abd abe&#x27;, &#x27;ab.&#x27;)─┬─extractAll(&#x27;abc abd abe&#x27;, &#x27;ab.&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ abc                           │ [&#x27;abc&#x27;,&#x27;abd&#x27;,&#x27;abe&#x27;]              │</span></span><br><span class="line"><span class="comment">└───────────────────────────────┴──────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>extractAllGroupsHorizontal、extractAllGroupsVertical：匹配组，举例说明最直接</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> extractAllGroupsHorizontal(<span class="string">&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;</span>, </span><br><span class="line">                                  <span class="string">&#x27;(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─extractAllGroupsHorizontal(&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;, &#x27;(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [[&#x27;2020&#x27;,&#x27;2020&#x27;,&#x27;2020&#x27;],[&#x27;01&#x27;,&#x27;02&#x27;,&#x27;11&#x27;],[&#x27;05&#x27;,&#x27;21&#x27;,&#x27;13&#x27;]]                                   │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> extractAllGroupsVertical(<span class="string">&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;</span>, </span><br><span class="line">                                <span class="string">&#x27;(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─extractAllGroupsVertical(&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;, &#x27;(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [[&#x27;2020&#x27;,&#x27;01&#x27;,&#x27;05&#x27;],[&#x27;2020&#x27;,&#x27;02&#x27;,&#x27;21&#x27;],[&#x27;2020&#x27;,&#x27;11&#x27;,&#x27;13&#x27;]]                                 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>ClickHouse 在匹配组的时候也给了两种选择，我们在使用编程语言进行组匹配的时候，一般返回都是第二种。而且事实上，extractAllGroupsVertical 的速度比 extractAllGroupsHorizontal 要快一些。</strong></p>
<p><strong>当匹配不上的时候，返回的是空列表。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> extractAllGroupsHorizontal(<span class="string">&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;</span>, </span><br><span class="line">                                  <span class="string">&#x27;(\\d&#123;10&#125;)-(\\d&#123;20&#125;)-(\\d&#123;20&#125;)&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─extractAllGroupsHorizontal(&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;, &#x27;(\\d&#123;10&#125;)-(\\d&#123;20&#125;)-(\\d&#123;20&#125;)&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [[],[],[]]                                                                                      │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> extractAllGroupsVertical (<span class="string">&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;</span>, </span><br><span class="line">                                 <span class="string">&#x27;(\\d&#123;10&#125;)-(\\d&#123;20&#125;)-(\\d&#123;20&#125;)&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─extractAllGroupsVertical(&#x27;2020-01-05 2020-02-21 2020-11-13&#x27;, &#x27;(\\d&#123;10&#125;)-(\\d&#123;20&#125;)-(\\d&#123;20&#125;)&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ []                                                                                            │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>extractAllGroupsHorizontal 相当于把多个组中按照顺序合并了，所以列表里面是 3 个空列表，因为我们匹配的组有三个。</strong></p>
<p><strong>like：where 语句里面有 LIKE，但 like 也是一个函数，两者规则是一样的</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- % 表示任意数量的任意字符；_ 表示单个任意字符</span></span><br><span class="line"><span class="comment">-- \ 表示转义</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">like</span>(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;sa%&#x27;</span>), <span class="keyword">like</span>(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;sa_&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>除了 like 之外，还有一个 notLike，以及不区分大小写的 ilike。</strong></p>
<p><strong>ngramDistance：计算两个字符串的相似度，取值为 0 到 1，越相似越接近 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ngramDistance(<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;satori&#x27;</span>)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─ngramDistance(&#x27;satori&#x27;, &#x27;satori&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                                 0 │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：如果某个字符串的长度超过了 32 KB，那么结果直接为 1，就不再计算相似度了。该函数在计算字符串相似度的时候是大小写敏感的，如果想要忽略大小写，可以使用 ngramDistanceCaseInsensitive。同理如果针对中文，那么可以使用 ngramDistanceUTF8，以及 ngramDistanceCaseInsensitiveUTF8。</strong></p>
<p><strong>countSubstrings：计算字符串中某个字串出现的次数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> countSubstrings(<span class="string">&#x27;aaaa&#x27;</span>, <span class="string">&#x27;aa&#x27;</span>), countSubstrings(<span class="string">&#x27;abc_abc&#x27;</span>, <span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─countSubstrings(&#x27;aaaa&#x27;, &#x27;aa&#x27;)─┬─countSubstrings(&#x27;abc_abc&#x27;, &#x27;abc&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                             2 │                                 2 │</span></span><br><span class="line"><span class="comment">└───────────────────────────────┴───────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 从指定位置开始查找</span></span><br><span class="line"><span class="keyword">SELECT</span> countSubstrings(<span class="string">&#x27;aabbaa&#x27;</span>, <span class="string">&#x27;aa&#x27;</span>), countSubstrings(<span class="string">&#x27;aabbaa&#x27;</span>, <span class="string">&#x27;aa&#x27;</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─countSubstrings(&#x27;aabbaa&#x27;, &#x27;aa&#x27;)─┬─countSubstrings(&#x27;aabbaa&#x27;, &#x27;aa&#x27;, 3)─┐</span></span><br><span class="line"><span class="comment">│                               2 │                                  1 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────┴────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果希望大小写敏感，那么可以使用 countSubstringsCaseInsensitive，针对中文可以使用 countSubstringsCaseInsensitiveUTF8。</strong></p>
<p><strong>countMatches：计算字符串中某个模式匹配的次数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> countSubstrings(<span class="string">&#x27;aaabbaa&#x27;</span>, <span class="string">&#x27;aa&#x27;</span>), countMatches(<span class="string">&#x27;aaabbaa&#x27;</span>, <span class="string">&#x27;a.&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─countSubstrings(&#x27;aaabbaa&#x27;, &#x27;aa&#x27;)─┬─countMatches(&#x27;aaabbaa&#x27;, &#x27;a.&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                                2 │                             3 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────┴───────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>replaceOne：对字符串中指定的部分进行替换，但只会替换第一次出现的部分</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> replaceOne(<span class="string">&#x27;hello cruel world, cruel&#x27;</span>, <span class="string">&#x27;cruel&#x27;</span>, <span class="string">&#x27;beautiful&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─replaceOne(&#x27;hello cruel world, cruel&#x27;, &#x27;cruel&#x27;, &#x27;beautiful&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ hello beautiful world, cruel                                 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果想全部替换，那么可以使用 replaceAll：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> replaceAll(<span class="string">&#x27;hello cruel world, cruel&#x27;</span>, <span class="string">&#x27;cruel&#x27;</span>, <span class="string">&#x27;beautiful&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─replaceAll(&#x27;hello cruel world, cruel&#x27;, &#x27;cruel&#x27;, &#x27;beautiful&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ hello beautiful world, beautiful                             │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>replaceRegexpOne：对字符串中指定的部分进行替换，但支持正则</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> replaceRegexpOne(<span class="string">&#x27;hello cruel world, cruel&#x27;</span>, <span class="string">&#x27;cru..&#x27;</span>, <span class="string">&#x27;beautiful&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─replaceRegexpOne(&#x27;hello cruel world, cruel&#x27;, &#x27;cru..&#x27;, &#x27;beautiful&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ hello beautiful world, cruel                                       │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果想全部替换，那么可以使用 replaceRegexpAll：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> replaceRegexpAll(<span class="string">&#x27;hello cruel world, cruel&#x27;</span>, <span class="string">&#x27;cru..&#x27;</span>, <span class="string">&#x27;beautiful&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─replaceRegexpAll(&#x27;hello cruel world, cruel&#x27;, &#x27;cru..&#x27;, &#x27;beautiful&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ hello beautiful world, beautiful                                   │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>


<p><strong>splitByChar：将字符串按照指定字符进行分解，返回数组</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 分隔符必须是单个字符</span></span><br><span class="line"><span class="keyword">SELECT</span> splitByChar(<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;ABC_def_fgh&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─splitByChar(&#x27;_&#x27;, &#x27;ABC_def_fgh&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;ABC&#x27;,&#x27;def&#x27;,&#x27;fgh&#x27;]             │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>splitByString：将字符串按照指定字符（串）进行分解，返回数组</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 分隔符必须是单个字符</span></span><br><span class="line"><span class="keyword">SELECT</span> splitByString(<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;ABC_def_fgh&#x27;</span>), splitByString(<span class="string">&#x27;__&#x27;</span>, <span class="string">&#x27;ABC__def__fgh&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─splitByString(&#x27;_&#x27;, &#x27;ABC_def_fgh&#x27;)─┬─splitByString(&#x27;__&#x27;, &#x27;ABC__def__fgh&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;ABC&#x27;,&#x27;def&#x27;,&#x27;fgh&#x27;]               │ [&#x27;ABC&#x27;,&#x27;def&#x27;,&#x27;fgh&#x27;]                  │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────┴──────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>从这里可以看出 splitByString 完全可以取代 splitByChar，因为它既可以按照单个字符分解，也可以按照字符串分解，当然单个字符在 ClickHouse 里面也是字符串。但 ClickHouse 既然提供了两个函数，那么个人建议，如果是按照单个字符分解的话，还是使用 splitByChar。</strong></p>
<p><strong>splitByRegexp：将字符串按照正则的模式进行分解，返回数组</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> splitByRegexp(<span class="string">&#x27;\\d+&#x27;</span>, <span class="string">&#x27;a12bc23de345f&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─splitByRegexp(&#x27;\\d+&#x27;, &#x27;a12bc23de345f&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;a&#x27;,&#x27;bc&#x27;,&#x27;de&#x27;,&#x27;f&#x27;]                    │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayStringConcat：将数组中的字符串进行拼接</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayStringConcat([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], <span class="string">&#x27;--&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayStringConcat([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;], &#x27;--&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ a--b--c--d                                    │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><strong>字符串算是非常常用的一个数据结构，它的操作自然也有很多，但都不是很难。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 数据表的增删改(五)</title>
    <url>/2023/03/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9(%E4%BA%94)/</url>
    <content><![CDATA[<h1 id="ClickHouse-数据表的增删改-五"><a href="#ClickHouse-数据表的增删改-五" class="headerlink" title="ClickHouse 数据表的增删改(五)"></a>ClickHouse 数据表的增删改(五)</h1><p>​																	本文来源： (<a href="https://www.cnblogs.com/traditional/p/15218565.html">https://www.cnblogs.com/traditional/p/15218565.html</a>) </p>
<h3 id="增"><a href="#增" class="headerlink" title="增"></a>增</h3><p><strong>跟绝大部分关系型数据库一样，ClickHouse 使用 INSERT 语句进行数据的插入。并且 INSERT语句支持三种语法范式，三种范式各有不同，可以根据写入的需求灵活运用。</strong></p>
<p><strong>其中，第一种是使用 VALUES 格式的常规语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 中括号表示里面的内容可以省略</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> [db.]table_name [(col1, col2, col3...)] <span class="keyword">VALUES</span> (val1, val2, val3, ...), (val1, val2, val3, ...), ...</span><br></pre></td></tr></table></figure>

<p><strong>这个和其它关系型数据库没什么两样，就不赘述了。</strong></p>
<p><strong>在使用 VALUES 格式的语法写入数据时，还支持加入表达式或函数，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> partizion_v2 <span class="keyword">VALUES</span>(<span class="string">&#x27;matsuri&#x27;</span>, toString(<span class="number">1</span><span class="operator">+</span><span class="number">2</span>), now())</span><br></pre></td></tr></table></figure>

<p><strong>第二种是使用指定格式的语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> [db.]table_name [(col1, col2, col3...)] FORMAT format_name data_set</span><br></pre></td></tr></table></figure>

<p><strong>ClickHouse 支持多种数据格式，以常用的 CSV 格式写入为例：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> partition_v2 FORMAT CSV \</span><br><span class="line">	<span class="string">&#x27;mea&#x27;</span>, <span class="string">&#x27;www.mea.com&#x27;</span>, <span class="string">&#x27;2019-01-01&#x27;</span></span><br><span class="line">	<span class="string">&#x27;nana&#x27;</span>, <span class="string">&#x27;www.nana.com&#x27;</span>, <span class="string">&#x27;2019-02-01&#x27;</span></span><br><span class="line">	<span class="string">&#x27;matsuri&#x27;</span>, <span class="string">&#x27;www.matsuri.com&#x27;</span>, <span class="string">&#x27;2019-03-01&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>第三种是使用 SELECT 子句形式的语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> [db.]table_name [(col1, col2, col3...)] <span class="keyword">SELECT</span> ...</span><br></pre></td></tr></table></figure>

<p><strong>通过 SELECT 子句可将查询结果写入数据表，假设需要将 partition_v1 的数据写入 partition_v2，则可以 使用下面的语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> partition_v2 <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> partition_v1</span><br></pre></td></tr></table></figure>

<p><strong>当然也可以这么做：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 加入表达式也是可以的，比如这里的 now()</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> partition_v2 <span class="keyword">SELECT</span> <span class="string">&#x27;aqua&#x27;</span>, <span class="string">&#x27;www.aqua.com&#x27;</span>, now()</span><br></pre></td></tr></table></figure>

<p><strong>虽然 VALUES 和 SELECT 子句的形式都支持声明表达式或函数，但是表达式或函数会带来额外的性能开销，从而导致写入性能下降。所以如果追求极致的写入性能，应该尽量避免使用它们。</strong></p>
<p><strong>在前面曾介绍过，ClickHouse 内部所有的数据操作都是面向 Block 数据块的，所以 INSERT 查询最终会将数据转换为 Block 数据块。也正因为如此，INSERT 语句在单个数据块的写入过程中是具有原子性的。在默认情况下，每个数据块最多可以写入 1048576 条数据（由 max_insert_block_size 参数控制）。也就是说，如果一条 INSERT 语句写入的数据行数少于 max_insert_block_size，那么这批数据的写入是具有原子性的，要么全部成功，要么全部失败。但是需要注意的是，只有在 ClickHouse 服务端处理数据的时候才具有这种原子写入的特性，例如使用 HTTP 接口，因为 max_insert_block_size 参数在使用 CLI 命令行或者 INSERT SELECT 子句写入时是不生效的。</strong></p>
<h3 id="删除与修改"><a href="#删除与修改" class="headerlink" title="删除与修改"></a>删除与修改</h3><p><strong>ClickHouse 提供了 DELETE 和 UPDATE 的能力，这类操作被称为 Mutation 查询，它可以看作 ALTER 语句的变种。虽然 Mutation 能最终实现修改和删除，但不能完全以通常意义上的 UPDATE 和 DELETE 来理解，我们必须清醒地认识到它的不同。首先，Mutation 语句是一种 “很重” 的操作，更适用于批量数据的修改和删除；其次，它不支持事务，一旦语句被提交执行，就会立刻对现有数据造成影响，无法回滚；最后，Mutation 语句的执行是一个异步的后台过程，语句被提交之后就会立即返回。所以这并不代表具体逻辑已经执行完毕，它的具体执行进度需要通过 system.mutations 系统表查询。</strong></p>
<p><strong>DELETE 语句的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> [db_name.]table_name <span class="keyword">DELETE</span> <span class="keyword">WHERE</span> filter_expr</span><br></pre></td></tr></table></figure>

<p><strong>数据删除的范围由 WHERE 查询子句决定。例如，执行下面语句可以删除 partition_v2 表内所有 ID 等于 ‘xxx’ 的数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> partition_v2 <span class="keyword">DELETE</span> <span class="keyword">WHERE</span> ID <span class="operator">=</span><span class="string">&#x27;xxx&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>如果数据很少的话，那么 DELETE 操作给人的感觉和常用的 OLTP 数据库无异，但我们心中应该要明白这是一个异步的后台执行动作。</strong></p>
<p><strong>下面我们来实际删除数据，就以 partition_v1 为例吧，先来看看对应目录（&#x2F;var&#x2F;lib&#x2F;clickhouse&#x2F;data&#x2F;default&#x2F;partition_v1）里面的内容：</strong></p>
<p><img src="/2023/03/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9(%E4%BA%94)/1229382-20210816173525150-1169637887.png" alt="img"></p>
<p><strong>执行该语句：ALTER TABLE partition_v1 DELETE WHERE ID &#x3D;’xxx’ 进行数据删除，执行完之后再看一下目录结构：</strong></p>
<p><img src="/2023/03/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9(%E4%BA%94)/1229382-20210816173531402-1147768169.png" alt="img"></p>
<p><strong>可以发现，在执行了 DELETE 操作后数据目录发生了一些变化，每一个原有的数据目录都额外增加了一个同名目录，并且在末尾处增加了 _3 后缀。此外，目录下还多了一个名为 mutation_3.txt 文件，里面的内容如下：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori partition_v1]<span class="comment"># cat mutation_3.txt</span></span><br><span class="line">format version: 1</span><br><span class="line">create time: 2021-08-16 14:55:41</span><br><span class="line">commands: DELETE WHERE ID = \<span class="string">&#x27;xxx\&#x27;</span></span><br><span class="line">[root@satori partition_v1]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p><strong>原来 mutation3.txt 是一个日志文件，它完整地记录了这次 DELETE 操作的执行语句和时间，而文件名的后缀 _3 与新增目录的后缀对应。那么后缀的数字从何而来呢？继续查询 system.mutations 系统表，一探究竟：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> database, <span class="keyword">table</span>, mutation_id, block_numbers.number <span class="keyword">as</span> num, is_done <span class="keyword">FROM</span> <span class="keyword">system</span> .mutations</span><br></pre></td></tr></table></figure>

<p><img src="/2023/03/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9(%E4%BA%94)/1229382-20210816173111584-5614938.png" alt="img"></p>
<p><strong>至此，整个 Mutation 操作的逻辑就比较清晰了。每执行一条 ALTER DELETE 语句，都会在 mutations 系统表中生成一条对应的执行计划，当 is_done 等于 1 时表示执行完毕。与此同时，在数据表的根目录下，会以 mutation_id 作为名字生成与之对应的日志文件用于记录相关信息。而数据删除的过程是以数据表的每个分区目录为单位，将所有目录重写为新的目录，新目录的命名规则是在原有名称上加上 system.mutations.block_numbers.number。数据在重写的过程中会将需要删除的数据去掉，旧的数据目录并不会立即删除，而是会被标记成非激活状态（active 为 0）。等到 MergeTree 引擎的下一次合并动作触发时，这些非激活目录才会被真正从物理意义上删除。</strong></p>
<p><strong>数据修改除了需要指定具体的要更新的列字段之外，整个逻辑与数据删除别无二致，它的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> [db_name.]table_name <span class="keyword">UPDATE</span> column1 <span class="operator">=</span> expr1 [, ...] <span class="keyword">WHERE</span> filter_expr</span><br></pre></td></tr></table></figure>

<p><strong>UPDATE 支持在一条语句中同时定义多个修改字段，但是分区键和主键不能作为修改字段。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 数据表、数据分区的相关操作，以及 DDL(四)</title>
    <url>/2023/02/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E3%80%81%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%EF%BC%8C%E4%BB%A5%E5%8F%8A%20DDL(%E5%9B%9B)/</url>
    <content><![CDATA[<h1 id="ClickHouse-数据表、数据分区的相关操作，以及-DDL-四"><a href="#ClickHouse-数据表、数据分区的相关操作，以及-DDL-四" class="headerlink" title="ClickHouse 数据表、数据分区的相关操作，以及 DDL(四)"></a>ClickHouse 数据表、数据分区的相关操作，以及 DDL(四)</h1><p>​																	本文来源： (<a href="https://www.cnblogs.com/traditional/p/15218664.html">https://www.cnblogs.com/traditional/p/15218664.html</a> </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>在知晓了 ClickHouse 的主要数据类型之后，接下来我们开始介绍 DDL 操作以及定义数据的方法，DDL 查询提供了数据表的创建、修改和删除操作，是最常用的功能之一。</strong></p>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p><strong>数据库起到了命名空间的作用，可以有效规避命名冲突的问题，也为后续的数据隔离提供了支撑。任何一张数据表，都必须归属在某个数据库之下。创建数据库的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> db_name[ENGINE <span class="operator">=</span> engine]</span><br></pre></td></tr></table></figure>

<p><strong>IF NOT EXISTS 表示如果已经存在一个同名的数据库，则会忽略后续的创建过程；[ENGINE &#x3D; engine] 表示数据库所使用的引擎类型（是的，你没看错，数据库也支持设置引擎）。</strong></p>
<p><strong>数据库目前一共支持 5 种引擎，如下所示。</strong></p>
<ul>
<li><code>Ordinary：默认引擎，在绝大多数情况下我们都会使用默认引擎，使用时无须刻意声明，在此数据库下可以使用任意类型的表引擎</code></li>
<li><code>Dictionary：字典引擎，此类数据库会自动为所有数据字典创建它们的数据表，关于数据字典的详细介绍会在后面展开</code></li>
<li><code>Memory：内存引擎，用于存放临时数据。此类数据库下的数据表只会停留在内存中，不会涉及任何磁盘操作，当服务重启后数据会被清除</code></li>
<li><code>Lazy：日志引擎，此类数据库下只能使用 Log 系列的表引擎，关于 Log 表引擎的详细介绍会后续章节展开</code></li>
<li><code>MySQL：MySQL 引擎，此类数据库下会自动拉取远端 MySQL 中的数据，并为它们创建 MySQL 表引擎的数据表，关于MySQL表引擎的详细介绍也会在后续章节展开。</code></li>
</ul>
<p><strong>在绝大多数情况下都只需使用默认的数据库引擎，例如执行下面的语句，便能够创建属于我们的第一个数据库：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE kagura_nana;</span><br></pre></td></tr></table></figure>

<p><strong>数据库的实质就是物理磁盘上的一个目录文件，所以在语句执行之后，ClickHouse 便会在安装路径下创建 kagura_nana 数据库的目录文件。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># ls /var/lib/clickhouse/data/</span></span><br><span class="line">default  kagura_nana  system</span><br><span class="line">[root@satori ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p><strong>与此同时，在 metadata 路径下也会一同创建用于恢复数据库的 kagura_nana.sql 文件：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># ls /var/lib/clickhouse/metadata/</span></span><br><span class="line">default  default.sql  kagura_nana  kagura_nana.sql  system  system.sql</span><br><span class="line">[root@satori ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p><strong>使用 SHOW DATABASES 查询，能够返回 ClickHouse 当前的数据库列表:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">SHOW</span> DATABASES;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> DATABASES</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">2</span>a4de6ad<span class="number">-535</span>f<span class="number">-489</span>f<span class="number">-955</span>e<span class="operator">-</span>dae511a18415</span><br><span class="line"></span><br><span class="line">┌─name────────┐</span><br><span class="line">│ <span class="keyword">default</span>     │</span><br><span class="line">│ kagura_nana │</span><br><span class="line">│ <span class="keyword">system</span>      │</span><br><span class="line">└─────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>使用 USE 查询可以实现在多个数据库之间进行切换，而通过 SHOW TABLES 查询可以查看当前数据库中存在的所以数据表。删除一个数据库，则需要用到下面的 DROP 查询。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> DATABASE [IF <span class="keyword">EXISTS</span>] db_name;</span><br></pre></td></tr></table></figure>

<h3 id="数据表"><a href="#数据表" class="headerlink" title="数据表"></a>数据表</h3><p><strong>我们说数据库在物理磁盘上对应一个目录文件，而表则是在数据库对应的目录文件里面再创建一个目录文件，比如我们在数据库 kagura_nana 里面创建一张表 t，那么相当于在 &#x2F;var&#x2F;lib&#x2F;clickhouse&#x2F;data&#x2F;kagura_nana 里面创建一个目录文件 t，而往表 t 里面写的数据则会在目录 t 中以文本文件的形式保存，所以整个逻辑还是比较清晰好理解的。而 ClickHouse 数据表的定义语法，是在标准 SQL 的基础之上建立的，所以熟悉数据库的你在看到接下来的语法时，应该会感到很熟悉。ClickHouse 目前提供了三种最基本的建表方法：</strong></p>
<p><strong>第一种是常规定义方法，它的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name (</span><br><span class="line">    column_name1 type [<span class="keyword">DEFAULT</span><span class="operator">|</span>MATERIALIZED<span class="operator">|</span>ALIAS expr],</span><br><span class="line">    column_name2 type [<span class="keyword">DEFAULT</span><span class="operator">|</span>MATERIALIZED<span class="operator">|</span>ALIAS expr],</span><br><span class="line">    ......</span><br><span class="line">) ENGINE <span class="operator">=</span> engine</span><br></pre></td></tr></table></figure>

<p><strong>使用 [db_name.] 参数可以为数据表指定数据库，如果不指定此参数，则默认会使用 default 数据库。注意结尾的 ENGINE 参数，它被用于指定数据表的引擎，表引擎决定了数据表的特性，也决定了数据将会被如何存储以及如何加载。例如 Memory 表引擎，它是 ClickHouse 最简单的表引擎，数据只会被保存在内存中，在服务重启时数据会丢失。我们会在后续章节详细介绍数据表引擎，此处暂不展开。</strong></p>
<p><strong>第二种定义方法是复制其他表的结构，具体语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name1.]table_name1 <span class="keyword">AS</span> [db_name2.]table_name2 [ENGINE <span class="operator">=</span> engine]</span><br></pre></td></tr></table></figure>

<p><strong>这种方式支持在不同的数据库之间复制表结构，例如下面的语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 将 A 库下的 a 表拷贝一份到 B 库下的 b 表, 注意：引擎可以更换</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> A.a <span class="keyword">AS</span> B.b ENGINE <span class="operator">=</span> TinyLog</span><br></pre></td></tr></table></figure>

<p><strong>第三种定义方法是通过 SELECT 子句的形式创建，它的完整语法如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name].table_name ENGINE <span class="operator">=</span> engine <span class="keyword">AS</span> <span class="keyword">SELECT</span> ...</span><br></pre></td></tr></table></figure>

<p><strong>在这种方式下，不仅会根据 SELECT 子句建立相应的表结构，同时还会将 SELECT 子句查询的数据顺带写入，例如执行下面的语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> db.not_exists_table ENGINE <span class="operator">=</span> Memory <span class="keyword">AS</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> db.exists_table</span><br></pre></td></tr></table></figure>

<p><strong>上述语句会将 SELECT * FROM db.exists_table 的查询结果一并写入数据表。</strong></p>
<p><strong>ClickHouse 和大多数数据库一样，使用 DESC 查询可以返回数据表的定义结构，另外如果想删除一张数据表，则可以使用下面的 DROP 语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> [IF <span class="keyword">EXISTS</span>] [db_name.]table_name</span><br></pre></td></tr></table></figure>

<h3 id="默认值表达式"><a href="#默认值表达式" class="headerlink" title="默认值表达式"></a>默认值表达式</h3><p><strong>表字段支持三种默认值表达式的定义方法，分别是 DEFAULT、MATERIALIZED 和 ALIAS。无论使用哪种形式，表字段一旦定义了默认值，那么便不再强制要求定义数据类型，因为 ClickHouse 会根据默认值进行类型推断。如果同时对表字段定义了数据类型和默认值表达式，则以明确定义的数据类型为主，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_name (    id String,    col1 <span class="keyword">DEFAULT</span> <span class="number">100</span>,    col2 String <span class="keyword">DEFAULT</span> col1) ENGINE<span class="operator">=</span>Memory</span><br></pre></td></tr></table></figure>

<p><strong>col1 字段没有定义数据类型，默认值为整型 1000；col2 字段定义了数据类型和默认值，且默认值等于 col1，现在写入测试数据。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name(id) <span class="keyword">VALUES</span>(<span class="string">&#x27;AAA&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>在写入之后执行以下查询：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">SELECT</span> id, col1, col2, toTypeName(col1), toTypeName(col2) <span class="keyword">from</span> table_nameSELECT    id,    col1,    col2,    toTypeName(col1),    toTypeName(col2)<span class="keyword">FROM</span> table_nameQuery id: d9114fe3<span class="number">-172</span>f<span class="number">-4e2</span>f<span class="operator">-</span>bd2a<span class="number">-13</span>b514015de9┌─id──┬─col1─┬─col2─┬─toTypeName(col1)─┬─toTypeName(col2)─┐│ AAA │  <span class="number">100</span> │ <span class="number">100</span>  │ UInt8            │ String           │└─────┴──────┴──────┴──────────────────┴──────────────────┘<span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.satori :)</span><br></pre></td></tr></table></figure>

<p><strong>由查询结果可以验证，默认值的优先级符合我们的预期，其中 col1 字段根据默认值被推断为 UInt16；而 col2 字段由于同时定义了数据类型和默认值，所以它最终的数据类型来自明确定义的 String。</strong></p>
<hr>
<p><strong>默认值表达式的三种定义方法之间也存在着不同之处，可以从如下三个方面进行比较。</strong></p>
<p><strong>1）数据写入：在数据写入时，只有 DEFAULT 类型的字段可以出现在 INSERT 语句中，而 MATERIALIZED 和 ALIAS 都不能被显式赋值，它们只能依靠计算取值。例如试图为 MATERIALIZED 类型的字段写入数据，将会得到如下的错误。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">DB::Exception: Cannot <span class="keyword">insert</span> <span class="keyword">column</span> URL,because it <span class="keyword">is</span> MATERIALIZED column..</span><br></pre></td></tr></table></figure>

<p><strong>2）数据查询：在数据查询时，只有 DEFAULT 类型的字段可以通过 SELECT * 返回，而 MATERIALIZED 和 ALIAS 类型的字段不会出现在 SELECT * 查询的返回结果集中。</strong></p>
<p><strong>3）数据存储：在数据存储时，只有 DEFAULT 和 MATERIALIZED 类型的字段才支持持久化。如果使用的表引擎支持物理存储（例如 TinyLog 表引擎)，那么这些列字段将会拥有物理存储。而 ALIAS 类型的字段不支持持久化，它的取值总是需要依靠计算产生，数据不会落到磁盘。</strong></p>
<p><strong>可以使用 ALTER 语句修改默认值，例如:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> [db_name.]table_name MODIFY COLOMN col_name DEFAUET <span class="keyword">value</span></span><br></pre></td></tr></table></figure>

<p><strong>修改动作并不会影响数据表内先前已经存在的数据，但是默认值的修改有诸多限制，例如在 MergeTree 表引擎中，它的主键字段是无法被修改的；而某些表引擎则完全不支持修改（例如 TinyLog）。</strong></p>
<h3 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h3><p><strong>ClickHouse 也有临时表的概念，创建临时表的方法是在普通表的基础之上添加 TEMPORARY 关键字，CREATE TEMPORARY TABLE…，剩余的部分和创建普通表完全一样。</strong></p>
<p><strong>相比普通表而言，临时表有如下两点特殊之处：</strong></p>
<ul>
<li><code>它的生命周期是会话绑定的，所以它只支持 Memory 表引擎，如果会话结束，数据表就会被销毁;</code></li>
<li><code>临时表不属于任何数据库，所以在它的建表语句中，既没有数据库参数也没有表引擎参数;</code></li>
</ul>
<p><strong>针对第二个特殊项，有人心中难免会产生一个疑问：既然临时表不属于任何数据库，如果临时表和普通表名称相同，会出现什么状况呢？接下来不妨做个测试。首先在 DEFAULT 数据库创建测试表并写入数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tmp_v1(title String) ENGINE <span class="operator">=</span> Memory;<span class="keyword">INSERT</span> <span class="keyword">INTO</span> tmp_v1 <span class="keyword">VALUES</span> (<span class="string">&#x27;xxx&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>接着创建一张名称相同的临时表并写入数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">TABLE</span> tmp_v1(num UInt8) ENGINE <span class="operator">=</span> Memory;<span class="keyword">INSERT</span> <span class="keyword">INTO</span> tmp_v1 <span class="keyword">VALUES</span> (<span class="number">22</span>);</span><br></pre></td></tr></table></figure>

<p><strong>现在查询 tmp_v1 看看会发生什么？</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tmp_v1</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> tmp_v1</span><br><span class="line"></span><br><span class="line">Query id: ad4b5094<span class="number">-3627</span><span class="number">-4</span>af7<span class="operator">-</span>a207<span class="operator">-</span>bbd8ef90617a</span><br><span class="line"></span><br><span class="line">┌─num─┐</span><br><span class="line">│  <span class="number">22</span> │</span><br><span class="line">└─────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>通过返回结果可以得出结论，临时表的优先级是大于普通表的。当两张数据表名称相同的时候，会优先读取临时表的数据。当然在 ClickHouse 的日常使用中，不会刻意地使用临时表，它更多被运用在 ClickHouse 的内部，是数据在集群之间传播的载体。</strong></p>
<h3 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h3><p><strong>数据分区（partition）和数据分片（shard）是完全不同的而个概念，数据分区是针对本地数据而言的，是数据的一种纵向切分；而数据分片是数据的一种横向切分（后续章节会详细说）。数据分区对于一款 OLAP 数据库而言意义非凡，借助数据分区，在后续的查询过程中能够跳过不必要的数据目录，从而提升查询的性能。合理地利用分区特性，还可以变相实现数据的更新操作，因为数据分区支持删除、替换和重置操作。假设数据表按照月份分区，那么数据就可以按月份的粒度被替换更新。</strong></p>
<p><strong>分区虽好，但不是所有的表引擎都可以使用这项特性，目前只有合并树（MergeTree）家族系列的表引擎才支持数据分区。接下来通过一个简单的例子演示分区表的使用方法，首先由 PARTITION BY 指定分区键，例如下面的数据表 partition_v1 使用了日期字段作为分区键，并将其格式化为年月的形式：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> partition_v1 (</span><br><span class="line">    ID String,</span><br><span class="line">    URL String,</span><br><span class="line">    EventDate <span class="type">Date</span></span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(EventDate)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> ID</span><br></pre></td></tr></table></figure>

<p><strong>接着写入不同月份的测试数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> partition_v1 <span class="keyword">VALUES</span> (<span class="string">&#x27;a1&#x27;</span>, <span class="string">&#x27;www.a1.com&#x27;</span>, <span class="string">&#x27;2019-05-01&#x27;</span>), (<span class="string">&#x27;a2&#x27;</span>, <span class="string">&#x27;www.a2.com&#x27;</span>, <span class="string">&#x27;2019-06-02&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>最后通过 system.parts 系统表，查询数据表的分区状态：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">table</span>, <span class="keyword">partition</span>, path <span class="keyword">FROM</span> system.parts <span class="keyword">WHERE</span> <span class="keyword">table</span> <span class="operator">=</span> <span class="string">&#x27;partition_v1&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/02/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E3%80%81%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%EF%BC%8C%E4%BB%A5%E5%8F%8A%20DDL(%E5%9B%9B)/1229382-20210816173455153-82548770.png" alt="img"></p>
<p><strong>可以看到，partition_v1 按年月划分后，目前拥有两个数据分区，且每个分区都对应一个独立的文件目录，用于保存各自部分的数据。</strong></p>
<p><strong>合理设计分区键非常重要，通常会按照数据表的查询场景进行针对性设计。例如在刚才示例中的数据表按年月分区，如果后续的查询按照分区键过滤，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> partition_v1 <span class="keyword">WHERE</span> EventDate <span class="operator">=</span><span class="string">&#x27;2019-05-01&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>那么在后续的查询过程中，可以利用分区索引跳过 6 月份的分区目录，只加载 5 月份的数据，从而带来查询的性能提升。</strong></p>
<p><strong>当然，使用不合理的分区键也会适得其反，分区键不应该使用粒度过细的数据字段。例如按照小时分区，将会带来分区数量的急剧增长，从而导致性能下降。关于数据分区更详细的原理说明，也会在后续章节进行。</strong></p>
<h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><p><strong>ClickHouse 拥有普通和物化两种视图，其中物化视图拥有独立的存储，我们一会说；而普通视图和关系型数据库中的视图类似，只是一层简单的查询代理。创建普通视图的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]view_name <span class="keyword">AS</span> SELECT...</span><br></pre></td></tr></table></figure>

<p><strong>普通视图不会存储任何数据，它只是一层单纯的 SELECT 查询映射，起着简化查询、明晰语义的作用，对查询性能不会有任何增强。假设有一张普通视图 view_tb_v1，它是基于数据表 tb_v1 的 id 和 name 两个字段创建的，那么下面的两条 SELECT 查询是完全等价的：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> view_tb_v1;</span><br><span class="line"><span class="keyword">SELECT</span> id, name <span class="keyword">FROM</span> tb_v1;</span><br></pre></td></tr></table></figure>

<p><strong>而物化视图需要指定表引擎，数据保存形式由它的表引擎决定，创建物化视图的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db.]view_name [<span class="keyword">TO</span> [db.]name] ENGINE <span class="operator">=</span> engine [POPULATE] <span class="keyword">AS</span> <span class="keyword">SELECT</span> ...</span><br></pre></td></tr></table></figure>

<p><strong>我们来对这些语法规则举例说明，我们先来创建一张物化视图：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 物化视图本质上可以看成是一张特殊的数据表，在创建的时候也需要指定引擎</span></span><br><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> girls_view_1 ENGINE<span class="operator">=</span>TinyLog()</span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">SELECT</span> id, name, age <span class="keyword">FROM</span> girls;</span><br></pre></td></tr></table></figure>

<p><strong>可以看到相较于普通视图，我们在创建物化的视图的时候，在 create 后面多写了一个 MATERIALIZED 来表示创建的是物化视图、以及指定了一个表引擎。但需要注意的是，物化视图是可以存储数据的。比如此时的物化视图 girls_view_1 是根据表 girls 的 id、name、age 三个字段创建的，如果之后再往 girls 里面写数据，那么新写入的数据对应的 id、name、age 就会同步到 girl_view_1 中。也就是说，物化视图创建好之后，如果源表被写入新数据，那么物化视图也会同步更新。</strong></p>
<p><strong>但需要注意的是，默认情况下，物化视图在创建时不会拷贝源表中的数据，它只会同步在此之后被写入源表的数据，所以当前 girls 里面的已存在的数据并没有写入到 girls_view_\1 中。如果希望在创建的物化视图的时候，就顺带把表中的数据也同步过去该怎么做呢？</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 只需要在 AS SELECT 的前面加上 POPULATE 即可</span></span><br><span class="line"><span class="comment">-- 此时表 girls 的数据，更准确的说是 SELECT 查询得到的结果集才会进入物化视图中</span></span><br><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> girls_view_1 ENGINE<span class="operator">=</span>TinyLog()</span><br><span class="line">POPULATE <span class="keyword">AS</span> <span class="keyword">SELECT</span> id, name, age <span class="keyword">FROM</span> girls;</span><br></pre></td></tr></table></figure>

<p><strong>所以 POPULATE 修饰符决定了物化视图的初始化策略：如果使用了 POPULATE 修饰符，那么在创建视图的过程中，会连带将源表中已存在的数据（更准确的说是 SELECT 查询得到的结果集）一并导入。反之，如果不使用 POPULATE 修饰符，那么物化视图在创建之后是没有数据的，它只会同步在此之后被写入源表的数据。</strong></p>
<p><strong>另外物化视图本质是一张特殊的数据表，如果存在的话，那么使用 SHOW TABLE 也能查看到。而如果删除一个视图，则直接使用 DROP TABLE 即可，注意：没有 DROP VIEW，只要是视图，删除语句都是 DROP TABLE，所以这也侧面说明了视图名和表名不可以重复。</strong></p>
<p><strong>然后物化视图还有一个用法，首先创建一个物化视图的时候其实本质上还是会创建一张表，默认名称是 “ .inner.物化视图名 “，只不过这张表是隐藏的，其作用就是负责保存物化视图从源表中同步过来的数据。那么问题来了，负责存储物化视图数据的表可不可以我们自己指定呢？答案是可以的。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> girls_view_1 <span class="keyword">TO</span> other_girls</span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">SELECT</span> id, name, age <span class="keyword">FROM</span> girls;</span><br></pre></td></tr></table></figure>

<p><strong>物化视图在同步数据的时候就会将数据写入到 other_girls 中，当然 other_girls 的表结构与 SELECT 选择的字段的类型、数量要相匹配，并且此时我们既可以通过物化视图查看数据，也可以通过 other_girls 来查看。这种用法，我们后面介绍表引擎的时候会说，目前先了解物化视图的用法。</strong></p>
<h3 id="数据表的基本操作"><a href="#数据表的基本操作" class="headerlink" title="数据表的基本操作"></a>数据表的基本操作</h3><p><strong>目前只有 MergeTree、Merge 和 Distributed 这三类表引擎支持 ALTER 查询，如果现在还不明白这些表引擎的作用也不必担心，目前只需简单了解这些信息即可，后面会对它们进行介绍。</strong></p>
<h4 id="追加新字段"><a href="#追加新字段" class="headerlink" title="追加新字段"></a>追加新字段</h4><p><strong>假如需要对一张数据表追加新的字段，可以使用如下语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] 字段名 [类型] [默认值] [插在哪个字段后面]</span><br></pre></td></tr></table></figure>

<h4 id="修改字段类型"><a href="#修改字段类型" class="headerlink" title="修改字段类型"></a>修改字段类型</h4><p><strong>如果需要改变表字段的数据类型或者默认值，需要使用下面的语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name MODIFY <span class="keyword">COLUMN</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] 字段名 [类型] [默认值]</span><br></pre></td></tr></table></figure>

<p><strong>修改某个字段的数据类型，实质上会调用相应的 toType 转型方法。如果当前的类型与期望的类型不能兼容，则修改类型失败。例如将 String 类型的 IP 字段转成 IPv4 类型是可行的，但是转成 UInt 则会出现错误。</strong></p>
<h4 id="修改备注"><a href="#修改备注" class="headerlink" title="修改备注"></a>修改备注</h4><p><strong>做好信息备注是保持良好编程习惯的美德之一，所以如果你还没有为列字段添加备注信息，那么就赶紧行动吧。追加备注的语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name COMMENT <span class="keyword">COLUMN</span> [IF <span class="keyword">EXISTS</span>] 字段名 <span class="string">&#x27;some comment&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/02/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E3%80%81%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%EF%BC%8C%E4%BB%A5%E5%8F%8A%20DDL(%E5%9B%9B)/1229382-20210816173503361-1995846816.png" alt="img"></p>
<h4 id="删除已有字段"><a href="#删除已有字段" class="headerlink" title="删除已有字段"></a>删除已有字段</h4><p><strong>假如要删除某个字段，可以使用下面的语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> <span class="keyword">COLUMN</span> [IF <span class="keyword">EXISTS</span>] name</span><br></pre></td></tr></table></figure>

<p><strong>如果某个字段被删除，那么对应的数据也就被删除了。</strong></p>
<h4 id="移动数据表"><a href="#移动数据表" class="headerlink" title="移动数据表"></a>移动数据表</h4><p><strong>在 Linux 系统中，mv 命令的本意是将一个文件从原始位置 A 移动到目标位置 B，但是如果位置 A 与位置 B 相同，则可以变相实现重命名的作用。ClickHouse 的 RENAME 查询就与之有着异曲同工之妙，RENAME 语句的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">RENAME <span class="keyword">TABLE</span> [db_name1.]table_name1 <span class="keyword">TO</span> [db_name2.]table_name2, [db_name1.]table_name3 <span class="keyword">TO</span> [db_name2.]table_name3......</span><br></pre></td></tr></table></figure>

<p><strong>RENAME 可以修改数据表的名称，如果将原始数据库与目标数据库设为不同的名称，那么就可以实现数据表在两个数据库之间移动的效果，并且还可以同时移动多张。</strong></p>
<p><strong>需要注意的是，数据表的移动只能在单个节点的范围内。换言之，数据表移动的目标数据库和原始数据库必须在同一个服务节点内，而不能是集群中的远程节点。</strong></p>
<h4 id="清空数据表"><a href="#清空数据表" class="headerlink" title="清空数据表"></a>清空数据表</h4><p><strong>假设需要将表内的数据全部清空，而不是直接删除这张表，则可以使用 TRUNCATE 语句，它的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">TRUNCATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">EXISTS</span>] [db_name.]table_name</span><br></pre></td></tr></table></figure>

<h3 id="数据分区的基本操作"><a href="#数据分区的基本操作" class="headerlink" title="数据分区的基本操作"></a>数据分区的基本操作</h3><p><strong>了解并善用数据分区益处颇多，熟练掌握它的使用方法，可以为后续的程序设计带来极大的灵活性和便利性，目前只有 MergeTree 系列的表引擎支持数据分区。</strong></p>
<h4 id="查询分区信息"><a href="#查询分区信息" class="headerlink" title="查询分区信息"></a>查询分区信息</h4><p><strong>ClickHouse 内置了许多 system 系统表，用于查询自身的状态信息，其中 parts 系统表专门用于查询数据表的分区信息。例如执行下面的语句，就能够得到数据表 partition_v1 的分区状况:</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E6%95%B0%E6%8D%AE%E8%A1%A8%E3%80%81%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%EF%BC%8C%E4%BB%A5%E5%8F%8A%20DDL(%E5%9B%9B)/1229382-20210816173511827-810044396.png" alt="img"></p>
<p><strong>如上所示，目前 partition_v1 共拥有 2 个分区，其中 partition_id 或者 name 等同于分区的主键，可以基于它们的取值确定一个具体的分区。</strong></p>
<h4 id="删除指定分区"><a href="#删除指定分区" class="headerlink" title="删除指定分区"></a>删除指定分区</h4><p><strong>合理地设计分区键并利用分区的删除功能，就能够达到数据更新的目的，删除一个指定分区的语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> partition_expr</span><br></pre></td></tr></table></figure>

<p><strong>假如现在需要更新 partition_v1 数据表整个 6 月份的数据，则可以先将 6 月份的分区删除；</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> partition_v1 <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> <span class="number">201906</span></span><br></pre></td></tr></table></figure>

<p><strong>然后将整个 6 月份的新数据重新写入，就可以达到更新的目的。</strong></p>
<h4 id="复制分区数据"><a href="#复制分区数据" class="headerlink" title="复制分区数据"></a>复制分区数据</h4><p><strong>ClickHouse 支持将 A 表的分区数据复制到 B 表，这项特性可以用于快速数据写入、多表间数据同步和备份等场景，它的完整语法如下：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> B REPLACE <span class="keyword">PARTITION</span> partition_expr <span class="keyword">FROM</span> A</span><br></pre></td></tr></table></figure>

<p><strong>不过需要注意的是，并不是任意数据表之间都能够相互复制，它们还需要满足两个前提条件：</strong></p>
<ul>
<li><code>两张表需要拥有相同的分区键;</code></li>
<li><code>它们的表结构完全相同;</code></li>
</ul>
<p><strong>假设有一个数据表 partition_v2，并且与之前 partition_v1 的分区键和表结构完全相同，那么如果想将 partition_v1 中 5 月份的数据导入到 partition_v2中，就可以这么做。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> partition_v2 REPLACE <span class="keyword">PARTITION</span> <span class="number">201905</span> <span class="keyword">FROM</span> partition_v1</span><br></pre></td></tr></table></figure>

<h4 id="重置分区数据"><a href="#重置分区数据" class="headerlink" title="重置分区数据"></a>重置分区数据</h4><p><strong>如果数据表某一列的数据有误，需要将其重置为默认值，此时可以使用下面的语句实现:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name CLEAR <span class="keyword">COLUMN</span> column_name <span class="keyword">IN</span> <span class="keyword">PARTITION</span> partition_expr</span><br></pre></td></tr></table></figure>

<p><strong>首先如果声明了默认值表达式，那么以表达式为准；否则以相应数据类型的默认值为准，比如 String 类型的默认值就是空字符串。</strong></p>
<h4 id="装载与卸载分区"><a href="#装载与卸载分区" class="headerlink" title="装载与卸载分区"></a>装载与卸载分区</h4><p><strong>表分区可以通过 DETACH 语句卸载，分区被卸载后，它的物理数据并没有删除，而是被转移到了当前数据表目录的 detached 子目录下。而装载分区则是反向操作，它能够将 detached 子目录下的某个分区重新装载回去。卸载与装载这一对伴生的操作，常用于分区数据的迁移和备份场景。卸载某个分区的语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name DETACH <span class="keyword">PARTITION</span> partition_expr</span><br></pre></td></tr></table></figure>

<p><strong>假设有一个分区表 partition_v3，里面有很多月的数据，那么执行下面的语句就可以将该表中整个 8 月份的分区卸载。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> partition_v3 DETACH <span class="keyword">PARTITION</span> <span class="number">201908</span></span><br></pre></td></tr></table></figure>

<p><strong>此时再次查询这张表，会发现其中 2019 年 8 月份的数据已经没有了。而进入 partition_v3 的磁盘目录，则可以看到被卸载的分区目录已经被移动到了 detached 目录中。</strong></p>
<p><strong>记住，一旦分区被移动到了 detached 子日录，就代表它已经脱离了 ClickHouse 的管理，ClickHouse 并不会主动清理这些文件。这此分区文件会一直存在，除非我们主动删除或者使用 ATTACH 语句重新装载它们。装载某个分区的完整语法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name ATTACH <span class="keyword">PARTITION</span> partition_expr</span><br></pre></td></tr></table></figure>

<p><strong>再次执行下面的语句，就可以将刚才已被卸载的 201908 分区重新装载回去:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> partition_v3 ATTACH <span class="keyword">PARTITION</span> <span class="number">201908</span></span><br></pre></td></tr></table></figure>

<h4 id="备份与还原文件"><a href="#备份与还原文件" class="headerlink" title="备份与还原文件"></a>备份与还原文件</h4><p><strong>关于分区数据的备份，可以通过 FREEZE 与 FETCH 实现，由于目前还缺少相关的背景知识，所以我们在后续章节介绍。</strong></p>
<h3 id="分布式-DDL-执行"><a href="#分布式-DDL-执行" class="headerlink" title="分布式 DDL 执行"></a>分布式 DDL 执行</h3><p><strong>ClickHouse 支持集群模式，一个集群拥有 1 到多个节点。CREATE、ALTER、DROP、RENMAE 及 TRUNCATE 这些 DDL 语句，都支持分布式执行。这意味着，如果在集群中任意一个节点上执行 DDL 语句，那么集群中的每个节点都会以相同的顺序执行相同的语句。这项特性意义非凡，它就如同批处理命令一样，省去了需要依次去单个节点执行 DDL 的烦恼。</strong></p>
<p><strong>将一条普通的 DDL 语句转换成分布式执行十分简单，只需加上 ON CLUSTER cluster_name 声明即可。例如，执行下面的语句后将会对 ch_cluster 集群内的所有节点广播这条 DDL 语句。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> partition_v4 <span class="keyword">ON</span> CLUSTER ch_cluster(</span><br><span class="line">    ID String,</span><br><span class="line">    URL String,</span><br><span class="line">    EventDate <span class="type">Date</span></span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree()</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(EventDate)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> ID</span><br></pre></td></tr></table></figure>

<p><strong>当然，如果现在执行这条语句是不会成功的。因为到目前为止还没有配置过 ClickHouse 的集群模式，目前还不存在一个名为 ch_cluster 的集群，这部内容会放到后续章节展开说明。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的 Map 类型以及相关操作(十四)</title>
    <url>/2023/04/11/ClickHouse%20%E7%9A%84%20Map%20%E7%B1%BB%E5%9E%8B%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C(%E5%8D%81%E5%9B%9B)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的-Map-类型以及相关操作-十四"><a href="#ClickHouse-的-Map-类型以及相关操作-十四" class="headerlink" title="ClickHouse 的 Map 类型以及相关操作(十四)"></a>ClickHouse 的 Map 类型以及相关操作(十四)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>之前在介绍数据类型的时候，有一种没有说，就是 Map。Map 是什么想必无需多言，简单来说的话就是维护键值对之间的映射关系，可以通过键迅速定位到值。</strong></p>
<p><strong>下面就先来创建一张表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 在定义 Map 的时候，必须要指定键值对的类型</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_map(a Map(String, UInt64)) ENGINE <span class="operator">=</span> Memory();</span><br></pre></td></tr></table></figure>

<p><strong>但是不出意外我们创建表的时候应该会报错，原因就是在表中支持定义 Map 类型的字段还只是试验性的，我们需要将 allow_experimental_map_type 设置为 1，这也是我们单独拿出来介绍的原因。然后我们插入数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> allow_experimental_map_type <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_map(a Map(String, UInt64)) ENGINE <span class="operator">=</span> Memory();</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_map </span><br><span class="line"><span class="keyword">VALUES</span> (&#123;<span class="string">&#x27;key1&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;key2&#x27;</span>: <span class="number">10</span>&#125;), (&#123;<span class="string">&#x27;key1&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;key2&#x27;</span>:<span class="number">20</span>&#125;), (&#123;<span class="string">&#x27;key1&#x27;</span>:<span class="number">3</span>,<span class="string">&#x27;key2&#x27;</span>:<span class="number">30</span>&#125;);</span><br></pre></td></tr></table></figure>

<p><strong>下面来对表进行查询：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> table_map;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─a────────────────────┐</span></span><br><span class="line"><span class="comment">│ &#123;&#x27;key1&#x27;:1,&#x27;key2&#x27;:10&#125; │</span></span><br><span class="line"><span class="comment">│ &#123;&#x27;key1&#x27;:2,&#x27;key2&#x27;:20&#125; │</span></span><br><span class="line"><span class="comment">│ &#123;&#x27;key1&#x27;:3,&#x27;key2&#x27;:30&#125; │</span></span><br><span class="line"><span class="comment">└──────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果想选择某个具体的键对应的 value，那么直接通过方括号即可，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a[<span class="string">&#x27;key1&#x27;</span>], a[<span class="string">&#x27;key2&#x27;</span>], a <span class="keyword">FROM</span> table_map;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayElement(a, &#x27;key1&#x27;)─┬─arrayElement(a, &#x27;key2&#x27;)─┬─a────────────────────┐</span></span><br><span class="line"><span class="comment">│                       1 │                      10 │ &#123;&#x27;key1&#x27;:1,&#x27;key2&#x27;:10&#125; │</span></span><br><span class="line"><span class="comment">│                       2 │                      20 │ &#123;&#x27;key1&#x27;:2,&#x27;key2&#x27;:20&#125; │</span></span><br><span class="line"><span class="comment">│                       3 │                      30 │ &#123;&#x27;key1&#x27;:3,&#x27;key2&#x27;:30&#125; │</span></span><br><span class="line"><span class="comment">└─────────────────────────┴─────────────────────────┴──────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果查询一个不在 Map 当中 key，那么会返回对应的零值。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a[<span class="string">&#x27;key3&#x27;</span>] <span class="keyword">FROM</span> table_map;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayElement(a, &#x27;key3&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                       0 │</span></span><br><span class="line"><span class="comment">│                       0 │</span></span><br><span class="line"><span class="comment">│                       0 │</span></span><br><span class="line"><span class="comment">└─────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>当然我们也可以根据现有的数组结构创建 Map：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] <span class="keyword">AS</span> key, [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>] <span class="keyword">AS</span> <span class="keyword">value</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">cast</span>((key, <span class="keyword">value</span>) <span class="keyword">AS</span> Map(UInt8, String));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─CAST(tuple(key, value), &#x27;Map(UInt8, String)&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ &#123;1:&#x27;a&#x27;,2:&#x27;b&#x27;,3:&#x27;c&#x27;&#125;                           │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">-- 从返回的结果集的字段名，我们可以看出，cast(val AS type) 等价于 cast(val, &#x27;type&#x27;)</span></span><br><span class="line"><span class="comment">-- 比如 cast(3 AS String) 和 cast(3, &#x27;String&#x27;) 是等价的，不过个人还是习惯前者</span></span><br></pre></td></tr></table></figure>

<p><strong>我们在选择的时候也可以只选择 key 或者 value。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.keys, a.values <span class="keyword">FROM</span> table_map;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─a.keys──────────┬─a.values─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [1,10]   │</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [2,20]   │</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [3,30]   │</span></span><br><span class="line"><span class="comment">└─────────────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h3 id="然后我们来看看字典都支持哪些函数操作"><a href="#然后我们来看看字典都支持哪些函数操作" class="headerlink" title="然后我们来看看字典都支持哪些函数操作"></a>然后我们来看看字典都支持哪些函数操作</h3><p><strong>map：我们除了可以通过大括号创建 Map，也可以通过 map 函数创建</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> map(<span class="string">&#x27;key1&#x27;</span>, number, <span class="string">&#x27;key2&#x27;</span>, number <span class="operator">*</span> <span class="number">2</span>) <span class="keyword">FROM</span> numbers(<span class="number">3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─map(&#x27;key1&#x27;, number, &#x27;key2&#x27;, multiply(number, 2))─┐</span></span><br><span class="line"><span class="comment">│ &#123;&#x27;key1&#x27;:0,&#x27;key2&#x27;:0&#125;                              │</span></span><br><span class="line"><span class="comment">│ &#123;&#x27;key1&#x27;:1,&#x27;key2&#x27;:2&#125;                              │</span></span><br><span class="line"><span class="comment">│ &#123;&#x27;key1&#x27;:2,&#x27;key2&#x27;:4&#125;                              │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">-- 注意：SELECT &#123;&#x27;key1&#x27;: number, &#x27;key2&#x27;: number * 2&#125; 是非法的，必须使用 map 函数创建</span></span><br></pre></td></tr></table></figure>

<p><strong>同理我们插入数据的时候也可以使用 map 函数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_map <span class="keyword">VALUES</span> (map(<span class="string">&#x27;key1&#x27;</span>, <span class="number">1</span>, <span class="string">&#x27;key2&#x27;</span>, <span class="number">10</span>));</span><br><span class="line"><span class="keyword">SELECT</span> a.keys, a.values <span class="keyword">FROM</span> table_map;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─a.keys──────────┬─a.values─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [1,10]   │</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [2,20]   │</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [3,30]   │</span></span><br><span class="line"><span class="comment">└─────────────────┴──────────┘</span></span><br><span class="line"><span class="comment">┌─a.keys──────────┬─a.values─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [1,10]   │</span></span><br><span class="line"><span class="comment">└─────────────────┴──────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>mapContains：检测 Map 里面是否包含某个 key</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> map(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>) <span class="keyword">AS</span> m</span><br><span class="line"><span class="keyword">SELECT</span> mapContains(m, <span class="number">1</span>), mapContains(m, <span class="number">3</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─mapContains(m, 1)─┬─mapContains(m, 3)─┐</span></span><br><span class="line"><span class="comment">│                 1 │                 0 │</span></span><br><span class="line"><span class="comment">└───────────────────┴───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>mapKeys：等价于 Map.keys</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.keys, mapKeys(a) <span class="keyword">FROM</span> table_map;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─a.keys──────────┬─mapKeys(a)──────┐</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [&#x27;key1&#x27;,&#x27;key2&#x27;] │</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [&#x27;key1&#x27;,&#x27;key2&#x27;] │</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [&#x27;key1&#x27;,&#x27;key2&#x27;] │</span></span><br><span class="line"><span class="comment">└─────────────────┴─────────────────┘</span></span><br><span class="line"><span class="comment">┌─a.keys──────────┬─mapKeys(a)──────┐</span></span><br><span class="line"><span class="comment">│ [&#x27;key1&#x27;,&#x27;key2&#x27;] │ [&#x27;key1&#x27;,&#x27;key2&#x27;] │</span></span><br><span class="line"><span class="comment">└─────────────────┴─────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>mapValues：等价于 Map.values</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.values, mapValues(a) <span class="keyword">FROM</span> table_map;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─a.values─┬─mapValues(a)─┐</span></span><br><span class="line"><span class="comment">│ [1,10]   │ [1,10]       │</span></span><br><span class="line"><span class="comment">│ [2,20]   │ [2,20]       │</span></span><br><span class="line"><span class="comment">│ [3,30]   │ [3,30]       │</span></span><br><span class="line"><span class="comment">└──────────┴──────────────┘</span></span><br><span class="line"><span class="comment">┌─a.values─┬─mapValues(a)─┐</span></span><br><span class="line"><span class="comment">│ [1,10]   │ [1,10]       │</span></span><br><span class="line"><span class="comment">└──────────┴──────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：mapKeys、mapValues 相当于数据全量读取，然后再选择所有的 key 或 value，所以建议还是使用 Map.keys、Map.values。但如果将 optimize_functions_to_subcolumns 设置为 1，那么会进行优化：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT mapKeys(m), mapValues(m) FROM table 会转化成 SELECT m.keys, m.values FROM table</span><br></pre></td></tr></table></figure>

<p><strong>以上就是 Map 的内容，总的来说还是很简单的。</strong></p>
<h3 id="JSON-的相关操作"><a href="#JSON-的相关操作" class="headerlink" title="JSON 的相关操作"></a>JSON 的相关操作</h3><p><strong>既然提到了 Map，那么就不能不提到 JSON，这两者在结构上有着非常高的相似之处，下面就来看看 JSON 支持哪些操作。</strong></p>
<p><strong>isValidJSON：检测 JSON 是否合法</strong></p>
<p><strong>JSON 本质上也是一个字符串，isValidJSON 则是检测该字符串是否符合 JSON 格式。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> isValidJSON(<span class="string">&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;</span>), isValidJSON(<span class="string">&#x27;&#123;1, 2, 3&#125;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─isValidJSON(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;)─┬─isValidJSON(&#x27;&#123;1, 2, 3&#125;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                                   1 │                        0 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────┴──────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>JSONHas：检测 JSON 是否包含指定的 key</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> JSONHas(<span class="string">&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;</span>, <span class="string">&#x27;a&#x27;</span>), JSONHas(<span class="string">&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;</span>, <span class="string">&#x27;a1&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─JSONHas(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;, &#x27;a&#x27;)─┬─JSONHas(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;, &#x27;a1&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                                    1 │                                     0 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────┴───────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>JSONLength：获取 JSON 的长度</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> JSONLength(<span class="string">&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─JSONLength(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: false&#125;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                                  2 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>JSONType：获取 JSON 中指定 value 的类型</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="string">&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: true, &quot;c&quot;: null, &quot;d&quot;: &quot;xx&quot;, &quot;e&quot;: [1, 2, 3], &quot;f&quot;: &#123;&quot;a&quot;: 1&#125;&#125;&#x27;</span> <span class="keyword">AS</span> j</span><br><span class="line"><span class="keyword">SELECT</span> JSONType(j, <span class="string">&#x27;a&#x27;</span>), JSONType(j, <span class="string">&#x27;b&#x27;</span>), JSONType(j, <span class="string">&#x27;c&#x27;</span>), </span><br><span class="line">       JSONType(j, <span class="string">&#x27;d&#x27;</span>), JSONType(j, <span class="string">&#x27;e&#x27;</span>), JSONType(j, <span class="string">&#x27;f&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─JSONType(j, &#x27;a&#x27;)─┬─JSONType(j, &#x27;b&#x27;)─┬─JSONType(j, &#x27;c&#x27;)─┬─JSONType(j, &#x27;d&#x27;)─┬─JSONType(j, &#x27;e&#x27;)─┬─JSONType(j, &#x27;f&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ Int64            │ Bool             │ Null             │ String           │ Array            │ Object           │</span></span><br><span class="line"><span class="comment">└──────────────────┴──────────────────┴──────────────────┴──────────────────┴──────────────────┴──────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toJSONString：将其它数据类型转成 JSON</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 不可以写成 &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: 2&#125;</span></span><br><span class="line"><span class="keyword">SELECT</span> toJSONString(map(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toJSONString(map(&#x27;a&#x27;, 1, &#x27;b&#x27;, 2))─┐</span></span><br><span class="line"><span class="comment">│ &#123;&quot;a&quot;:1,&quot;b&quot;:2&#125;                     │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>JSONExtract：根据 key，从 JSON 中解析出指定的 value，就类似于根据 key 获取 Map 中的 value 一样</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 在获取 value 的时候，必须要指定 value 是什么类型</span></span><br><span class="line"><span class="comment">-- ClickHouse 中的 Bool 是用整型表示的，所以转成 UInt8、16、32、64 也是可以的</span></span><br><span class="line"><span class="keyword">WITH</span> <span class="string">&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: true&#125;&#x27;</span> <span class="keyword">AS</span> j</span><br><span class="line"><span class="keyword">SELECT</span> JSONExtract(j, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;UInt8&#x27;</span>), JSONExtract(j, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;Bool&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─JSONExtract(j, &#x27;a&#x27;, &#x27;UInt8&#x27;)─┬─JSONExtract(j, &#x27;b&#x27;, &#x27;Bool&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                            1 │                           1 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┴─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WITH</span> <span class="string">&#x27;&#123;&quot;a&quot;: [null, 123], &quot;b&quot;: &#123;&quot;a&quot;: 1&#125;&#125;&#x27;</span> <span class="keyword">AS</span> j</span><br><span class="line"><span class="keyword">SELECT</span> JSONExtract(j, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;Array(UInt8)&#x27;</span>),</span><br><span class="line">       JSONExtract(j, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;Array(Nullable(UInt8))&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─JSONExtract(j, &#x27;a&#x27;, &#x27;Array(UInt8)&#x27;)─┬─JSONExtract(j, &#x27;a&#x27;, &#x27;Array(Nullable(UInt8))&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [0,123]                             │ [NULL,123]                                    │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────┴───────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果解析失败，那么会得到相应的零值，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="string">&#x27;&#123;&quot;a&quot;: [null, 123], &quot;b&quot;: &#123;&quot;a&quot;: 1&#125;&#125;&#x27;</span> <span class="keyword">AS</span> j</span><br><span class="line"><span class="keyword">SELECT</span> JSONExtract(j, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;UInt64&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─JSONExtract(j, &#x27;a&#x27;, &#x27;UInt64&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                             0 │</span></span><br><span class="line"><span class="comment">└───────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 日期时间的相关操作函数(十三)</title>
    <url>/2023/04/11/ClickHouse%20%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0(%E5%8D%81%E4%B8%89)/</url>
    <content><![CDATA[<h1 id="ClickHouse-日期时间的相关操作函数-十三"><a href="#ClickHouse-日期时间的相关操作函数-十三" class="headerlink" title="ClickHouse 日期时间的相关操作函数(十三)"></a>ClickHouse 日期时间的相关操作函数(十三)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>下面来说一说日期和时间的相关操作。</strong></p>
<p><strong>toDate、toDateTime：将字符串转成 Date、DateTime</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> toDate(<span class="string">&#x27;2020-11-11 12:12:12&#x27;</span>) v1, toDateTime(<span class="string">&#x27;2020-11-11 12:12:12&#x27;</span>) v2;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─────────v1─┬──────────────────v2─┐</span></span><br><span class="line"><span class="comment">│ 2020-11-11 │ 2020-11-11 12:12:12 │</span></span><br><span class="line"><span class="comment">└────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">-- 当然除了字符串，也可以传入 DateTime、Date</span></span><br><span class="line"><span class="keyword">WITH</span> toDate(<span class="string">&#x27;2020-11-11 12:12:12&#x27;</span>) <span class="keyword">AS</span> v1, toDateTime(<span class="string">&#x27;2020-11-11 12:12:12&#x27;</span>) <span class="keyword">AS</span> v2</span><br><span class="line"><span class="keyword">SELECT</span> v1, v2, toDateTime(v1) v3, toDate(v2) v4;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─────────v1─┬──────────────────v2─┬──────────────────v3─┬─────────v4─┐</span></span><br><span class="line"><span class="comment">│ 2020-11-11 │ 2020-11-11 12:12:12 │ 2020-11-11 00:00:00 │ 2020-11-11 │</span></span><br><span class="line"><span class="comment">└────────────┴─────────────────────┴─────────────────────┴────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 当然时间戳也是可以的</span></span><br><span class="line"><span class="keyword">SELECT</span> toDate(<span class="number">1605067932</span>), toDateTime(<span class="number">1605067932</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toDate(1605067932)─┬─toDateTime(1605067932)─┐</span></span><br><span class="line"><span class="comment">│         2020-11-11 │    2020-11-11 12:12:12 │</span></span><br><span class="line"><span class="comment">└────────────────────┴────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>对于 toDateTime 在转换的时候也可以指定时区：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Asia/Shanghai 为东八区，将 UTC 的时间转成 Asia/Shanghai 之后，会增加 8 小时</span></span><br><span class="line"><span class="keyword">SELECT</span> toDateTime(<span class="string">&#x27;2020-11-11 12:12:12&#x27;</span>, <span class="string">&#x27;UTC&#x27;</span>) v1, toDateTime(v1, <span class="string">&#x27;Asia/Shanghai&#x27;</span>) v2;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌──────────────────v1─┬──────────────────v2─┐</span></span><br><span class="line"><span class="comment">│ 2020-11-11 12:12:12 │ 2020-11-11 20:12:12 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>timeZone：返回当前服务器所在的时区</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> timeZone();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─timeZone()────┐</span></span><br><span class="line"><span class="comment">│ Asia/Shanghai │</span></span><br><span class="line"><span class="comment">└───────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toTimeZone：转换 DataTime 所在的时区</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 转换 DateTime 所在的时区</span></span><br><span class="line"><span class="keyword">SELECT</span> toDateTime(<span class="string">&#x27;2020-01-01 12:11:33&#x27;</span>, <span class="string">&#x27;UTC&#x27;</span>) v1, toTimeZone(v1, <span class="string">&#x27;Asia/Shanghai&#x27;</span>) v2;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌──────────────────v1─┬──────────────────v2─┐</span></span><br><span class="line"><span class="comment">│ 2020-01-01 12:11:33 │ 2020-01-01 20:11:33 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>timeZoneOf：返回 DateTime 所在的时区</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-01-01 12:11:33&#x27;</span>, <span class="string">&#x27;UTC&#x27;</span>) <span class="keyword">AS</span> v1, toTimeZone(v1, <span class="string">&#x27;Asia/Shanghai&#x27;</span>) <span class="keyword">AS</span> v2</span><br><span class="line"><span class="keyword">SELECT</span> timeZoneOf(v1), timeZoneOf(v2);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─timeZoneOf(v1)─┬─timeZoneOf(v2)─┐</span></span><br><span class="line"><span class="comment">│ UTC            │ Asia/Shanghai  │</span></span><br><span class="line"><span class="comment">└────────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>timeZoneOffset：返回某个时区和 UTC 之间的偏移量</strong></p>
<p><strong>比如 Asia&#x2F;Shanghai 和 UTC 之间查了 8 个小时，也就是 8 * 3600 秒</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 我们需要使用 timeZoneOffset 的时候，需要先使用 toTypeName 获取相应的类型</span></span><br><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-01-01 11:11:11&#x27;</span>, <span class="string">&#x27;Asia/Shanghai&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> toTypeName(v) type, timeZoneOffset(v) offset_second, offset_second <span class="operator">/</span> <span class="number">3600</span> offset_hour;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─type──────────────────────┬─offset_second─┬─offset_hour─┐</span></span><br><span class="line"><span class="comment">│ DateTime(&#x27;Asia/Shanghai&#x27;) │         28800 │           8 │</span></span><br><span class="line"><span class="comment">└───────────────────────────┴───────────────┴─────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 任何一个值的类型都可以通过 toTypeName 查看</span></span><br><span class="line"><span class="keyword">SELECT</span> toTypeName(<span class="number">123</span>), toTypeName(<span class="string">&#x27;你好&#x27;</span>), toTypeName([]), toTypeName((<span class="number">1</span>, <span class="number">2</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toTypeName(123)─┬─toTypeName(&#x27;你好&#x27;)─┬─toTypeName(array())─┬─toTypeName((1, 2))──┐</span></span><br><span class="line"><span class="comment">│ UInt8           │ String             │ Array(Nothing)      │ Tuple(UInt8, UInt8) │</span></span><br><span class="line"><span class="comment">└─────────────────┴────────────────────┴─────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toYear：获取 DateTime、Date 的年份</strong></p>
<p><strong>toMonth：获取 DateTime、Date 的月份</strong></p>
<p><strong>toQuarter：获取 DateTime、Date 的季度</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> toDate(<span class="string">&#x27;2020-08-21&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> toYear(v), toMonth(v), toQuarter(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toYear(v)─┬─toMonth(v)─┬─toQuarter(v)─┐</span></span><br><span class="line"><span class="comment">│      2020 │          8 │            3 │</span></span><br><span class="line"><span class="comment">└───────────┴────────────┴──────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toHour：获取 DateTime 的小时</strong></p>
<p><strong>toMinute：获取 DateTime 的分钟</strong></p>
<p><strong>toSecond：获取 DateTime 的秒</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-08-21 12:11:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> toHour(v), toMinute(v), toSecond(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toHour(v)─┬─toMinute(v)─┬─toSecond(v)─┐</span></span><br><span class="line"><span class="comment">│        12 │          11 │          33 │</span></span><br><span class="line"><span class="comment">└───────────┴─────────────┴─────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toDayOfYear：返回某个 DateTime、Date 是一年当中的第几天（1 ~ 366）</strong></p>
<p><strong>toDayOfMonth：返回某个 DateTime、Date 是一个月当中的第几天（1 ~ 31）</strong></p>
<p><strong>toDayOfWeek：返回某个 DateTime、Date 是一周当中的第几天（星期一是 1，星期天是 7）</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-08-21 12:11:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> toDayOfYear(v), toDayOfMonth(v), toDayOfWeek(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toDayOfYear(v)─┬─toDayOfMonth(v)─┬─toDayOfWeek(v)─┐</span></span><br><span class="line"><span class="comment">│            234 │              21 │              5 │</span></span><br><span class="line"><span class="comment">└────────────────┴─────────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toStartOfYear：返回一个 DateTime、Date 所在的年的第一天</strong></p>
<p><strong>toStartOfMonth：返回一个 DateTime、Date 所在的月的第一天</strong></p>
<p><strong>toStartOfQuarter：返回一个 DateTime、Date 所在的季度的第一天</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 2020-08-21 12:22:33 所在的年的第一天是 2020-01-01</span></span><br><span class="line"><span class="comment">-- 2020-08-21 12:22:33 所在的月的第一天是 2020-08-01</span></span><br><span class="line"><span class="comment">-- 2020-08-21 12:22:33 所在的季度的第一天是 2020-07-01，第三季度</span></span><br><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-08-21 12:22:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> toStartOfYear(v), toStartOfMonth(v), toStartOfQuarter(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toStartOfYear(v)─┬─toStartOfMonth(v)─┬─toStartOfQuarter(v)─┐</span></span><br><span class="line"><span class="comment">│       2020-01-01 │        2020-08-01 │          2020-07-01 │</span></span><br><span class="line"><span class="comment">└──────────────────┴───────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toMonday：返回一个距离指定 DateTime、Date 最近的星期一</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 2020-08-21 是星期五，所以最近的星期一是 2020-08-17</span></span><br><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-08-21 12:22:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> toDayOfWeek(v), toMonday(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toDayOfWeek(v)─┬─toMonday(v)─┐</span></span><br><span class="line"><span class="comment">│              5 │  2020-08-17 │</span></span><br><span class="line"><span class="comment">└────────────────┴─────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>dateTrunc：将 DateTime 按照指定部分进行截断，截断后的部分使用 0 填充</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 这里按小时截断，截断后的部分直接丢弃或者用 0 填充，所以会得到 2020-08-21 12:00:00</span></span><br><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-08-21 12:22:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> v, dateTrunc(<span class="string">&#x27;hour&#x27;</span>, v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────────────────v─┬─dateTrunc(&#x27;hour&#x27;, v)─┐</span></span><br><span class="line"><span class="comment">│ 2020-08-21 12:22:33 │  2020-08-21 12:00:00 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴──────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 总共可以按照 year、quarter、month、week、day、hour、minute、second 进行截断</span></span><br><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-08-21 12:22:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> dateTrunc(<span class="string">&#x27;year&#x27;</span>, v) year_trunc, </span><br><span class="line">       dateTrunc(<span class="string">&#x27;month&#x27;</span>, v) month_trunc, </span><br><span class="line">       dateTrunc(<span class="string">&#x27;quarter&#x27;</span>, v) quarter_trunc,</span><br><span class="line">       dateTrunc(<span class="string">&#x27;day&#x27;</span>, v) day_truc, </span><br><span class="line">       dateTrunc(<span class="string">&#x27;minute&#x27;</span>, v) minute_trunc</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─year_trunc─┬─month_trunc─┬─quarter_trunc─┬────────────day_truc─┬────────minute_trunc─┐</span></span><br><span class="line"><span class="comment">│ 2020-01-01 │  2020-08-01 │    2020-07-01 │ 2020-08-21 00:00:00 │ 2020-08-21 12:22:00 │</span></span><br><span class="line"><span class="comment">└────────────┴─────────────┴───────────────┴─────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>dateAdd、dateSub：给 DateTime、Date 加&#x2F;减 一个时间间隔</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2017-08-21 12:22:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> v, dateAdd(<span class="keyword">YEAR</span>, <span class="number">3</span>, v), dateAdd(<span class="keyword">YEAR</span>, <span class="number">-3</span>, v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────────────────v─┬─plus(v, toIntervalYear(3))─┬─plus(v, toIntervalYear(-3))─┐</span></span><br><span class="line"><span class="comment">│ 2017-08-21 12:22:33 │        2020-08-21 12:22:33 │         2014-08-21 12:22:33 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴────────────────────────────┴─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>dateSub 的用法与之一样，其实当 dateAdd 加的时间间隔为负数时，等同于 dateSub。时间间隔的单位可以是 year、quarter、month、week、day、hour、minute、second，并且除了使用函数之外，我们也可以直接相加。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--  v + INTERVAL 3 YEAR 等价于  v - INTERVAL -3 YEAR</span></span><br><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2017-08-21 12:22:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> v, v <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">3</span> <span class="keyword">YEAR</span>, v <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="number">-3</span> <span class="keyword">YEAR</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────────────────v─┬─plus(v, toIntervalYear(3))─┬─plus(v, toIntervalYear(-3))─┐</span></span><br><span class="line"><span class="comment">│ 2017-08-21 12:22:33 │        2020-08-21 12:22:33 │         2014-08-21 12:22:33 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴────────────────────────────┴─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>dataDiff：计算两个 DateTime、Date 的差值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2017-08-21 12:22:33&#x27;</span>) <span class="keyword">AS</span> v1, toDateTime(<span class="string">&#x27;2018-09-15 11:44:55&#x27;</span>) <span class="keyword">AS</span> v2</span><br><span class="line"><span class="keyword">SELECT</span> dateDiff(<span class="string">&#x27;YEAR&#x27;</span>, v1, v2), dateDiff(<span class="string">&#x27;MONTH&#x27;</span>, v1, v2), dateDiff(<span class="string">&#x27;HOUR&#x27;</span>, v1, v2);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─dateDiff(&#x27;YEAR&#x27;, v1, v2)─┬─dateDiff(&#x27;MONTH&#x27;, v1, v2)─┬─dateDiff(&#x27;HOUR&#x27;, v1, v2)─┐</span></span><br><span class="line"><span class="comment">│                        1 │                        13 │                     9359 │</span></span><br><span class="line"><span class="comment">└──────────────────────────┴───────────────────────────┴──────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>now：返回当前的 DateTime</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 默认是本地时区，当然我们也可以手动指定</span></span><br><span class="line"><span class="keyword">SELECT</span> now(), now(<span class="string">&#x27;Asia/Shanghai&#x27;</span>), now(<span class="string">&#x27;UTC&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌───────────────now()─┬─now(&#x27;Asia/Shanghai&#x27;)─┬──────────now(&#x27;UTC&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ 2021-09-07 12:27:31 │  2021-09-07 12:27:31 │ 2021-09-07 04:27:31 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴──────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>today：返回当前的 Date，类似于 toDate( now() )</strong></p>
<p><strong>yesterday：前一天，类似于 today() - INTERVAL 1 DAY</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> today(), yesterday(), today() <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">DAY</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌────today()─┬─yesterday()─┬─minus(today(), toIntervalDay(1))─┐</span></span><br><span class="line"><span class="comment">│ 2021-09-07 │  2021-09-06 │                       2021-09-06 │</span></span><br><span class="line"><span class="comment">└────────────┴─────────────┴──────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toYYYYMM：将 DateTime、Date 使用整型表示，保留到月</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> toYYYYMM(toDate(<span class="string">&#x27;2020-11-11&#x27;</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toYYYYMM(toDate(&#x27;2020-11-11&#x27;))─┐</span></span><br><span class="line"><span class="comment">│                         202011 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 同理还有 toYYYYMMDD 和 toYYYYMMDDhhmmss</span></span><br><span class="line"><span class="keyword">SELECT</span> toYYYYMMDD(toDate(<span class="string">&#x27;2020-11-11&#x27;</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toYYYYMMDD(toDate(&#x27;2020-11-11&#x27;))─┐</span></span><br><span class="line"><span class="comment">│                         20201111 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> toYYYYMMDDhhmmss(toDateTime(<span class="string">&#x27;2020-11-11 12:12:12&#x27;</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toYYYYMMDDhhmmss(toDateTime(&#x27;2020-11-11 12:12:12&#x27;))─┐</span></span><br><span class="line"><span class="comment">│                                      20201111121212 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>formatDateTime：讲一个 DateTime、Date 格式化成字符串</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> formatDateTime(toDateTime(<span class="string">&#x27;2020-01-01 11:11:11&#x27;</span>), <span class="string">&#x27;%F&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─formatDateTime(toDateTime(&#x27;2020-01-01 11:11:11&#x27;), &#x27;%F&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ 2020-01-01                                              │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> formatDateTime(toDateTime(<span class="string">&#x27;2020-01-01 11:11:11&#x27;</span>), <span class="string">&#x27;%Y年%m月%d日 %H时%M分%S秒&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─formatDateTime(toDateTime(&#x27;2020-01-01 11:11:11&#x27;), &#x27;%Y年%m月%d日 %H时%M分%S秒&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ 2020年01月01日 11时11分11秒                                                    │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>函数不难，主要是一些格式符号我们需要记忆，以下是一些常见的格式符号：</strong></p>
<ul>
<li><code>%Y: 对应年</code></li>
<li><code>%m: 对应月，01 ~ 12</code></li>
<li><code>%d: 对应天，01 ~ 31</code></li>
<li><code>%H: 对应小时，00 ~ 23</code></li>
<li><code>%M: 对应分钟，00 ~ 59</code></li>
<li><code>%S: 对应秒钟，00 ~ 59</code></li>
<li><code>%F: 对应年月日，相当于 %Y-%m-%d</code></li>
<li><code>%j: 一年中的第几天，001 ~ 366</code></li>
<li><code>%P: 对应上午还是下午</code></li>
<li><code>%Q: 对应季度，1 ~ 4</code></li>
<li><code>%R: 相当于 %H:%M</code></li>
<li><code>%u: 星期几，1 ~ 7</code></li>
<li><code>%V: 一年中的第几个星期，01 ~ 53</code></li>
</ul>
<p><strong>dateName：返回 DateTime 指定部分，得到的是字符串</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> toDateTime(<span class="string">&#x27;2020-09-17 11:22:33&#x27;</span>) <span class="keyword">AS</span> v</span><br><span class="line"><span class="keyword">SELECT</span> dateName(<span class="string">&#x27;year&#x27;</span>, v), dateName(<span class="string">&#x27;month&#x27;</span>, v), dateName(<span class="string">&#x27;quarter&#x27;</span>, v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─dateName(&#x27;year&#x27;, v)─┬─dateName(&#x27;month&#x27;, v)─┬─dateName(&#x27;quarter&#x27;, v)─┐</span></span><br><span class="line"><span class="comment">│ 2020                │ September            │ 3                      │</span></span><br><span class="line"><span class="comment">└─────────────────────┴──────────────────────┴────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>FROM_UNIXTIME：将一个时间戳转成时间</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 默认转换的格式是 年-月-日 时:分:秒，当然我们也可以指定格式</span></span><br><span class="line"><span class="keyword">SELECT</span> FROM_UNIXTIME(<span class="number">1600312953</span>), FROM_UNIXTIME(<span class="number">1600312953</span>, <span class="string">&#x27;%F %R&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─FROM_UNIXTIME(1600312953)─┬─FROM_UNIXTIME(1600312953, &#x27;%F %R&#x27;)─┐</span></span><br><span class="line"><span class="comment">│       2020-09-17 11:22:33 │ 2020-09-17 11:22                   │</span></span><br><span class="line"><span class="comment">└───────────────────────────┴────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>toUnixTimestamp：将一个 DateTime、Date 转成时间戳</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 里面除了字符串，也可以传递 DateTime、Date</span></span><br><span class="line"><span class="keyword">SELECT</span> toUnixTimestamp(<span class="string">&#x27;2020-09-17 11:22:33&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─toUnixTimestamp(&#x27;2020-09-17 11:22:33&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                             1600312953 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 同时也可以指定时区，默认使用本地时区，</span></span><br><span class="line"><span class="comment">-- UTC 时区的 2020-09-17 11:22:33 相当于 Asia/Shanghai 时区的 2020-09-17 19:22:33 </span></span><br><span class="line"><span class="keyword">SELECT</span> toUnixTimestamp(<span class="string">&#x27;2020-09-17 11:22:33&#x27;</span>, <span class="string">&#x27;UTC&#x27;</span>) v1, <span class="number">1600312953</span> <span class="operator">+</span> <span class="number">8</span> <span class="operator">*</span> <span class="number">3600</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─────────v1─┬─plus(1600312953, multiply(8, 3600))─┐</span></span><br><span class="line"><span class="comment">│ 1600341753 │                          1600341753 │</span></span><br><span class="line"><span class="comment">└────────────┴─────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 数组的相关操作函数，一网打尽(十)</title>
    <url>/2023/04/11/ClickHouse%20%E6%95%B0%E7%BB%84%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0%EF%BC%8C%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD(%E5%8D%81)/</url>
    <content><![CDATA[<h1 id="ClickHouse-数组的相关操作函数，一网打尽"><a href="#ClickHouse-数组的相关操作函数，一网打尽" class="headerlink" title="ClickHouse 数组的相关操作函数，一网打尽"></a>ClickHouse 数组的相关操作函数，一网打尽</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>在一般的关系型数据库，相信很多人都不怎么使用数组这个结构，如果真的需要数组，那么会选择将其变成数组格式的字符串进行存储。但在 ClickHouse 中，数组的使用频率是非常高的，因为它内置了大量和数组有关的函数。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> version();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─version()─┐</span></span><br><span class="line"><span class="comment">│ 21.7.3.14 │</span></span><br><span class="line"><span class="comment">└───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>() <span class="keyword">FROM</span> system.functions <span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;%array%&#x27;</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─count()─┐</span></span><br><span class="line"><span class="comment">│      48 │</span></span><br><span class="line"><span class="comment">└─────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>当前的 ClickHouse 是 21.7.3.14 版本，关于数组的函数有 48 个，通过这个 48 个函数，我们可以对数组进行各种骚操作。当然也有一些函数不是专门针对数组的，但是可以用在数组身上，我们就也放在一起说了，下面就来依次介绍相关函数的用法。</strong></p>
<p><strong>empty：判断数组是否为空，如果一个数组不包含任何元素，返回 1；否则返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">empty</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), <span class="keyword">empty</span>([]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─empty([1, 2, 3])─┬─empty(array())─┐</span></span><br><span class="line"><span class="comment">│                0 │              1 │</span></span><br><span class="line"><span class="comment">└──────────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>empty 不仅可以检测数组是否为空，还可以检测字符串。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">empty</span>(<span class="string">&#x27;satori&#x27;</span>), <span class="keyword">empty</span>(<span class="string">&#x27;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─empty(&#x27;satori&#x27;)─┬─empty(&#x27;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│               0 │         1 │</span></span><br><span class="line"><span class="comment">└─────────────────┴───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>notEmpty：判断数组是否不为空，如果一个数组包含至少一个元素，返回 1；不包含任何元素，则返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> notEmpty([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), notEmpty([]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─notEmpty([1, 2, 3])─┬─notEmpty(array())─┐</span></span><br><span class="line"><span class="comment">│                   1 │                 0 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 同样可以作用于字符串</span></span><br><span class="line"><span class="keyword">SELECT</span> notEmpty(<span class="string">&#x27;satori&#x27;</span>), notEmpty(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─notEmpty(&#x27;satori&#x27;)─┬─notEmpty(&#x27;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│                  1 │            0 │</span></span><br><span class="line"><span class="comment">└────────────────────┴──────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>length：返回数组的长度，该函数也可以返回字符串的长度</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> length([]), length([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), length(<span class="string">&#x27;satori&#x27;</span>), length(<span class="string">&#x27;&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─length(array())─┬─length([1, 2, 3])─┬─length(&#x27;satori&#x27;)─┬─length(&#x27;&#x27;)─┐</span></span><br><span class="line"><span class="comment">│               0 │                 3 │                6 │          0 │</span></span><br><span class="line"><span class="comment">└─────────────────┴───────────────────┴──────────────────┴────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>emptyArrayUInt8、emptyArrayUInt16、emptyArrayUInt32、emptyArrayUInt64、emptyArrayInt8、emptyArrayInt16、emptyArrayInt32、emptyArrayInt64、emptyArrayFloat32、emptyArrayFloat64、emptyArrayDate、emptyArrayDateTime、emptyArrayString：创建一个指定类型的空数组</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 数组元素的类型为 nothing，因为没有指定任何元素</span></span><br><span class="line"><span class="keyword">SELECT</span> [] v, toTypeName(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v──┬─toTypeName(array())─┐</span></span><br><span class="line"><span class="comment">│ [] │ Array(Nothing)      │</span></span><br><span class="line"><span class="comment">└────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 采用最小类型存储，因为 1 和 2 都在 UInt8 的范围内</span></span><br><span class="line"><span class="keyword">SELECT</span> [<span class="number">1</span>, <span class="number">2</span>] v, toTypeName(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v─────┬─toTypeName([1, 2])─┐</span></span><br><span class="line"><span class="comment">│ [1,2] │ Array(UInt8)       │</span></span><br><span class="line"><span class="comment">└───────┴────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 但是我们可以创建指定类型的数组</span></span><br><span class="line"><span class="keyword">SELECT</span> emptyArrayDateTime() v, toTypeName(v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v──┬─toTypeName(emptyArrayDateTime())─┐</span></span><br><span class="line"><span class="comment">│ [] │ Array(DateTime)                  │</span></span><br><span class="line"><span class="comment">└────┴──────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>range：类似于 Python 中的 range，看测试用例</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E6%95%B0%E7%BB%84%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0%EF%BC%8C%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD(%E5%8D%81)/1229382-20210904151126780-1273074293.png" alt="img"></p>
<p><strong>array：也是创建一个数组，和直接使用方括号类似。但是 array 函数要求必须至少传递一个常量，否则就不知道要创建哪种类型的数组。如果想创建指定类型的空数组，那么使用上面的 emptyArray* 系列函数即可</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 不管是使用 array 创建，还是使用 [] 创建，里面的元素都必须具有相同的类型，或者能够兼容</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─array(1, 2, 3)─┬─[1, 2, 3]─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3]        │ [1,2,3]   │</span></span><br><span class="line"><span class="comment">└────────────────┴───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayConat：将多个数组进行合并，得到一个新的数组</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- SELECT 中起的别名可以被直接其它字段所使用</span></span><br><span class="line"><span class="keyword">SELECT</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] v1, [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>] v2, [<span class="number">111</span>, <span class="number">222</span>, <span class="number">333</span>] v3, arrayConcat(v1, v2, v3);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v1────┬─v2──────┬─v3────────┬─arrayConcat([1, 2], [11, 22], [111, 222])─┐</span></span><br><span class="line"><span class="comment">│ [1,2] │ [11,22] │ [111,222] │ [1,2,11,22,111,222]                       │</span></span><br><span class="line"><span class="comment">└───────┴─────────┴───────────┴───────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayElement：查找指定索引的元素，索引从 1 开始，也可以通过方括号直接取值；另外也支持负数索引，-1 代表最后一个元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 索引从 1 开始，所以 arr[20] 就表示第 20 个元素，也就是 19</span></span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">range</span>(<span class="number">100</span>) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayElement(arr, <span class="number">20</span>), arr[<span class="number">20</span>];</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayElement(arr, 20)─┬─arrayElement(arr, 20)─┐</span></span><br><span class="line"><span class="comment">│                    19 │                    19 │</span></span><br><span class="line"><span class="comment">└───────────────────────┴───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">range</span>(<span class="number">100</span>) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayElement(arr, <span class="number">-1</span>), arr[<span class="number">-50</span>];</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayElement(arr, -1)─┬─arrayElement(arr, -50)─┐</span></span><br><span class="line"><span class="comment">│                    99 │                     50 │</span></span><br><span class="line"><span class="comment">└───────────────────────┴────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>has：判断数组里面是否包含某个元素，如果包含，返回 1；不包含，返回0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="keyword">Null</span>] <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> has(arr, <span class="number">2</span>), has(arr, <span class="number">0</span>), has(arr, <span class="keyword">Null</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─has(arr, 2)─┬─has(arr, 0)─┬─has(arr, NULL)─┐</span></span><br><span class="line"><span class="comment">│           1 │           0 │              1 │</span></span><br><span class="line"><span class="comment">└─────────────┴─────────────┴────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 嵌套数组也是可以的</span></span><br><span class="line"><span class="keyword">SELECT</span> has([[<span class="number">1</span>, <span class="number">2</span>]], [<span class="number">1</span>, <span class="number">2</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─has([[1, 2]], [1, 2])─┐</span></span><br><span class="line"><span class="comment">│                     1 │</span></span><br><span class="line"><span class="comment">└───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>hasAll：判断数组里面是否包含某个子数组，如果包含，返回 1；不包含，返回0</strong></p>
<p><strong>注意：空数组是任意数组的子集；Null 会被看成是普通的值；数组中的元素顺序没有要求；1.0 和 1 被视为相等</strong></p>
<ul>
<li><code>hasAll([], [])：返回 1</code></li>
<li><code>hasAll([1, Null], [Null])：返回 1</code></li>
<li><code>hasAll([1.0, 2.0, 3.0], [2.0, 3.0, 1.0])：返回 1，因为元素顺序无影响，并且 1.0 和 1 被视为相等</code></li>
<li><code>hasAll([&#39;a&#39;, &#39;b&#39;], [&#39;a&#39;])：返回 1</code></li>
<li><code>hasAll([&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;])：返回 0</code></li>
<li><code>hasAll([[1, 2], [3, 4]], [[1, 2], [3, 4]])：返回 1，嵌套数组也是可以的</code></li>
</ul>
<p><strong>在 has 函数里面也有嵌套数组，但是维度不同。比如 has(a, b)：如果 a 是维度为 N 的数组，那么 b 必须是维度为 N - 1 的数组；而 hasAll 则要求 a 和 b 的维度必须相同。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">11</span>, <span class="number">22</span>]] <span class="keyword">AS</span> arr, [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">11</span>, <span class="number">22</span>]] <span class="keyword">AS</span> <span class="keyword">subset</span> <span class="keyword">SELECT</span> hasAll(arr, <span class="keyword">subset</span>)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hasAll(arr, subset)─┐</span></span><br><span class="line"><span class="comment">│                   1 │</span></span><br><span class="line"><span class="comment">└─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 我们说 SELECT 里面别名可以给其它字段使用，因此下面这种做法也是合法的</span></span><br><span class="line"><span class="keyword">WITH</span> [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">11</span>, <span class="number">22</span>]] <span class="keyword">AS</span> arr, arr <span class="keyword">AS</span> <span class="keyword">subset</span> <span class="keyword">SELECT</span> hasAll(arr, <span class="keyword">subset</span>)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hasAll(arr, subset)─┐</span></span><br><span class="line"><span class="comment">│                   1 │</span></span><br><span class="line"><span class="comment">└─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>hasAny：判断两个数组里面是否有相同的元素，只要有 1 个相同的元素，返回 1；否则，返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> hasAny([<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">1</span>]), hasAny([<span class="keyword">Null</span>], [<span class="number">1</span>, <span class="keyword">Null</span>])</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hasAny([1., 2.], [1])─┬─hasAny([NULL], [1, NULL])─┐</span></span><br><span class="line"><span class="comment">│                     1 │                         1 │</span></span><br><span class="line"><span class="comment">└───────────────────────┴───────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> hasAny([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], [[<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hasAny([[1, 2], [3, 4]], [[3, 4]])─┐</span></span><br><span class="line"><span class="comment">│                                  1 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>hasSubstr：和 hasAll 类似，但是顺序有要求，hasAll(arr, subset) 要求的是 subset 中的元素在 arr 中都出现即可；但是 hasSubstr 函数则不仅要求 subset 中的元素在 arr 中都出现，并且还要以相同的顺序。举个栗子：</strong></p>
<ul>
<li><code>hasSubstr([1, 2, 3], [2, 3])：返回 1</code></li>
<li><code>hasSubstr([1, 2, 3], [3, 2])：返回 0</code></li>
<li><code>hasSubstr([[1, 2], [2, 1], [3, 2]], [[3, 2]])：返回 1</code></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 两个数组的维度必须相同</span></span><br><span class="line"><span class="keyword">SELECT</span> hasSubstr([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">2</span>]), hasSubstr([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">3</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─hasSubstr([1, 2, 3], [3, 2])─┬─hasSubstr([1, 2, 3], [2, 3])─┐</span></span><br><span class="line"><span class="comment">│                            0 │                            1 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┴──────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>indexOf：查找某个元素第一次在数组中出现的位置，索引从 1 开始；如果不存在，则返回 0</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="keyword">Null</span>, <span class="number">99</span>] <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> indexOf(arr, <span class="number">100</span>), indexOf(arr, <span class="number">99</span>), indexOf(arr, <span class="keyword">Null</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─indexOf(arr, 100)─┬─indexOf(arr, 99)─┬─indexOf(arr, NULL)─┐</span></span><br><span class="line"><span class="comment">│                 0 │                5 │                  4 │</span></span><br><span class="line"><span class="comment">└───────────────────┴──────────────────┴────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayCount：查找一个数组中非 0 元素的个数，该数组类的元素类型必须是 UInt8，并且不能包含 Null 值。因为一旦包含 Null，那么类型就不是 UInt8 了，而是 Nullable(UInt8)</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayCount([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), arrayCount([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayCount([1, 2, 3])─┬─arrayCount([1, 2, 3, 4, 0])─┐</span></span><br><span class="line"><span class="comment">│                     3 │                           4 │</span></span><br><span class="line"><span class="comment">└───────────────────────┴─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>此外 arrayCount 还有一种用法，就是接收一个函数和一个数组：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>] <span class="keyword">AS</span> arr </span><br><span class="line"><span class="keyword">SELECT</span> arrayCount(arr), </span><br><span class="line">       arrayCount(x <span class="operator">-</span><span class="operator">&gt;</span> <span class="built_in">cast</span>(x <span class="operator">+</span> <span class="number">1</span> <span class="keyword">AS</span> UInt8), arr)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayCount(arr)─┬─arrayCount(lambda(tuple(x), CAST(plus(x, 1), &#x27;UInt8&#x27;)), arr)─┐</span></span><br><span class="line"><span class="comment">│               4 │                                                            5 │</span></span><br><span class="line"><span class="comment">└─────────────────┴──────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*</span></span><br></pre></td></tr></table></figure>

<p><strong>ClickHouse 中的函数类似于 C++ 中的 lambda 表达式，x -&gt; x + 1 相当于将 arr 中的每一个元素都加上 1，但结果得到整型是 UInt16，所以需要使用 cast 转成 UInt8，否则报错。另外，加上 1 之后就没有为 0 的元素了，所以返回的结果是 5。</strong></p>
<p><strong>countEqual：返回某个元素在数组中出现的次数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="keyword">Null</span>, <span class="keyword">Null</span>] <span class="keyword">as</span> arr <span class="keyword">SELECT</span> countEqual(arr, <span class="number">1</span>), countEqual(arr, <span class="keyword">Null</span>)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─countEqual(arr, 1)─┬─countEqual(arr, NULL)─┐</span></span><br><span class="line"><span class="comment">│                  3 │                     2 │</span></span><br><span class="line"><span class="comment">└────────────────────┴───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayEnumerate：等价于先计算出数组的长度，假设为 N，然后返回 range(1, N + 1)</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayEnumerate([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayEnumerate([2, 2, 2, 2])─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3,4]                    │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayEnumerateUniq：从数组的第一个元素开始，每重复一次就加 1</strong></p>
<p><strong>光说不好理解，直接看例子，然后画图说明：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayEnumerateUniq([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayEnumerateUniq([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;c&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;b&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [1,2,1,1,2,3,2,3]                                            │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E6%95%B0%E7%BB%84%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0%EF%BC%8C%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD(%E5%8D%81)/1229382-20210904151135342-481015945.png" alt="img"></p>
<p><strong>arrayEnumerateUniq 还可以接收多个数组，这些数据具有相同的长度，相信你已经知道它的作用了：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayEnumerateUniq([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayEnumerateUniq([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;a&#x27;], [1, 2, 2, 1])─┐</span></span><br><span class="line"><span class="comment">│ [1,1,1,2]                                              │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 举个不恰当的例子</span></span><br><span class="line"><span class="comment">-- 你就可以理解为：arrayEnumerateUniq( [(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 2), (&#x27;b&#x27;, 2), (&#x27;a&#x27;, 1)] )</span></span><br><span class="line"><span class="comment">-- 此时会将多个数组作为一个整体来进行判断，因此这些数组都必须有相同的长度</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayPopBack：移除数组中的最后一个元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayPopBack([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayPopBack([1, 2, 3])─┐</span></span><br><span class="line"><span class="comment">│ [1,2]                   │</span></span><br><span class="line"><span class="comment">└─────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>显然它是可以被嵌套的：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayPopBack(arrayPopBack(arr))</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayPopBack(arrayPopBack(arr))─┐</span></span><br><span class="line"><span class="comment">│ [1]                             │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：对空数组使用 arrayPopBack 不会报错，得到的还是空数组。</strong></p>
<p><strong>arrayPopFront：移除数组中的第一个元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayPopFront([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayPopFront([1, 2, 3])─┐</span></span><br><span class="line"><span class="comment">│ [2,3]                    │</span></span><br><span class="line"><span class="comment">└──────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>和 arrayPopBack 一样，也可以被嵌套，并且对空数组使用也不会报错，还是得到空数组。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayPopFront(arrayPopFront(arr));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayPopFront(arrayPopFront(arr))─┐</span></span><br><span class="line"><span class="comment">│ [3]                               │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayPushBack：从数组的尾部塞进一个元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayPushBack([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="number">1</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayPushBack([1, 2, 3], 1)─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3,1]                   │</span></span><br><span class="line"><span class="comment">└─────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>添加的时候记得类型要匹配，如果添加了 Null，那么数组会变成 Nullable。</strong></p>
<p><strong>arrayPushFront：从数组的头部塞进一个元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayPushFront([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], <span class="string">&#x27;d&#x27;</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayPushFront([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], &#x27;d&#x27;)─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;d&#x27;,&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]                    │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>添加的时候记得类型要匹配，如果添加了 Null，那么数组会变成 Nullable。</strong></p>
<p><strong>arrayResize：改变数组的长度</strong></p>
<ul>
<li><code>如果指定的长度比原来的长度大，那么会用零值从尾部进行填充</code></li>
<li><code>如果指定的长度比原来的长度大，那么会从尾部进行截断</code></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayResize(<span class="keyword">range</span>(<span class="number">4</span>), <span class="number">7</span>), arrayResize(<span class="keyword">range</span>(<span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayResize(range(4), 7)─┬─arrayResize(range(4), 2)─┐</span></span><br><span class="line"><span class="comment">│ [0,1,2,3,0,0,0]          │ [0,1]                    │</span></span><br><span class="line"><span class="comment">└──────────────────────────┴──────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>在填充的时候，也可以使用指定的值进行填充：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayResize(<span class="keyword">range</span>(<span class="number">4</span>), <span class="number">7</span>, <span class="number">66</span>), arrayResize(<span class="keyword">range</span>(<span class="number">4</span>), <span class="number">7</span>, <span class="keyword">Null</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayResize(range(4), 7, 66)─┬─arrayResize(range(4), 7, NULL)─┐</span></span><br><span class="line"><span class="comment">│ [0,1,2,3,66,66,66]           │ [0,1,2,3,NULL,NULL,NULL]       │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┴────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arraySlice：返回数组的一个片段</strong></p>
<ul>
<li><code>arraySlice(arr, M)：返回从索引为 M 开始以及之后的所有元素</code></li>
<li><code>arraySlice(arr, M, N)：从索引为 M 的元素开始，总共返回 N 个元素</code></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arraySlice(<span class="keyword">range</span>(<span class="number">1</span>, <span class="number">10</span>), <span class="number">3</span>), arraySlice(<span class="keyword">range</span>(<span class="number">1</span>, <span class="number">10</span>), <span class="number">3</span>, <span class="number">4</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arraySlice(range(1, 10), 3)─┬─arraySlice(range(1, 10), 3, 4)─┐</span></span><br><span class="line"><span class="comment">│ [3,4,5,6,7,8,9]             │ [3,4,5,6]                      │</span></span><br><span class="line"><span class="comment">└─────────────────────────────┴────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arraySort：对数据进行排序，然后返回</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arraySort([<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>]), arraySort([<span class="string">&#x27;abc&#x27;</span>, <span class="string">&#x27;ab&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arraySort([2, 3, 1])─┬─arraySort([&#x27;abc&#x27;, &#x27;ab&#x27;, &#x27;c&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3]              │ [&#x27;ab&#x27;,&#x27;abc&#x27;,&#x27;c&#x27;]              │</span></span><br><span class="line"><span class="comment">└──────────────────────┴───────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>字符串会按照字典序排序返回，整型、浮点型、日期都会按照大小返回。</strong></p>
<p><strong>问题来了，如果我们希望按照字符串的长度排序该怎么办呢？所以 arraySort 还支持传递一个自定义函数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 按照数组中元素的长度进行排序</span></span><br><span class="line"><span class="keyword">SELECT</span> arraySort(x <span class="operator">-</span><span class="operator">&gt;</span> length(x),[<span class="string">&#x27;abc&#x27;</span>, <span class="string">&#x27;ab&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arraySort(lambda(tuple(x), length(x)), [&#x27;abc&#x27;, &#x27;ab&#x27;, &#x27;c&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;c&#x27;,&#x27;ab&#x27;,&#x27;abc&#x27;]                                           │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 先按照正负号排序，小于 0 的排在大于 0 的左边，然后各自再按照绝对值进行排序</span></span><br><span class="line"><span class="keyword">SELECT</span> arraySort(x <span class="operator">-</span><span class="operator">&gt;</span> (x <span class="operator">&gt;</span> <span class="number">0</span>, <span class="built_in">abs</span>(x)), [<span class="number">-3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">3</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arraySort(lambda(tuple(x), tuple(greater(x, 0), abs(x))), [-3, 1, 2, -1, -2, 3])─┐</span></span><br><span class="line"><span class="comment">│ [-1,-2,-3,1,2,3]                                                                 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我去，这 ClickHouse 也太强大了吧，这简直不像是在写 SQL 了，都有点像写 Python 代码了，所以 ClickHouse 这么火不是没有原因的。</strong></p>
<p><strong>另外当出现空值或 NaN 的话，它们的顺序如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-inf 普通数值 inf NaN Null</span><br></pre></td></tr></table></figure>

<p><strong>所以 arraySort 如果接收一个参数，那么该参数必须是一个数组，然后 ClickHouse 按照默认的规则进行排序；如果接收两个参数，那么第一个参数是匿名函数，第二个参数是数组，此时 ClickHouse 会按照我们定义的函数来给数组排序；但其实 arraySort 还可以接收三个参数，第一个参数依旧是函数，然后第二个参数和第三个参数都是数组，此时会用数组给数组排序，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 因为有两个数组，所以匿名函数要有两个参数，x 表示第一个数组、y 表示第二个数组</span></span><br><span class="line"><span class="comment">-- 首先不管排序规则是什么，最终输出的都是第一个数组</span></span><br><span class="line"><span class="comment">-- x, y -&gt; y 就表示按照第二个数组来给第一个数组进行排序输出</span></span><br><span class="line"><span class="keyword">SELECT</span> arraySort(x, y <span class="operator">-</span><span class="operator">&gt;</span> y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">22</span>, <span class="number">11</span>, <span class="number">33</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arraySort(lambda(tuple(x, y), y), [1, 2, 3], [22, 11, 33])─┐</span></span><br><span class="line"><span class="comment">│ [2,1,3]                                                    │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 同理 x, y -&gt; x 返回的还是 [1, 2, 3]、 x, y -&gt; -x 返回的是 [3, 2, 1]</span></span><br><span class="line"><span class="comment">-- 只不过此时第二个数组就用不上了</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayReverseSort：对数据进行逆序排序，然后返回</strong></p>
<p><strong>该函数你可以认为它是先按照 arraySort 排序，然后将结果再反过来，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arraySort(x <span class="operator">-</span><span class="operator">&gt;</span> <span class="operator">-</span>x, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) sort, arrayReverseSort(x <span class="operator">-</span><span class="operator">&gt;</span> <span class="operator">-</span>x, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) reverse_sort;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─sort────┬─reverse_sort─┐</span></span><br><span class="line"><span class="comment">│ [3,2,1] │ [1,2,3]      │</span></span><br><span class="line"><span class="comment">└─────────┴──────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>指定了匿名函数，按照相反数进行排序，因为 -3 &lt; -2 &lt; -1，所示 arraySort 排序之后就是 [3, 2, 1]，然后 arrayReverseSort 则是在其基础上直接返回，所以得到的还是 [1, 2, 3]。</strong></p>
<p><strong>至于其它用法和 arraySort 都是一样的，可以看做是在 arraySort 的基础上做了一次反转。不过有一点需要注意，那就是 Null 值和 NaN：</strong></p>
<ul>
<li><code>arraySort：-inf 普通数值 inf NaN Null</code></li>
<li><code>arrayReverseSort：inf 普通数值 -inf NaN Null</code></li>
</ul>
<p><strong>即使是 arrayReverseSort，NaN 和 Null 依然排在最后面。</strong></p>
<p><strong>arrayUniq：返回数组中不同元素的数量</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayUniq([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayUniq([1, 2, 3, 1, 4])─┐</span></span><br><span class="line"><span class="comment">│                          4 │</span></span><br><span class="line"><span class="comment">└────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>也可以传递多个长度相同的数组，会依次取出所有数组中相同位置的元素，然后拼成元组，并计算这些不重复的元组的数量，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 相当于判断 arrayUniq( [(&#x27;a&#x27;, 1, 3), (&#x27;a&#x27;, 1, 3), (&#x27;b&#x27;, 2, 3)] )</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayUniq([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayUniq([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;], [1, 1, 2], [3, 3, 3])─┐</span></span><br><span class="line"><span class="comment">│                                                2 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayJoin：将数组展开成多行</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayJoin(<span class="keyword">range</span>(<span class="number">1</span>, <span class="number">7</span>));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayJoin(range(1, 7))─┐</span></span><br><span class="line"><span class="comment">│                      1 │</span></span><br><span class="line"><span class="comment">│                      2 │</span></span><br><span class="line"><span class="comment">│                      3 │</span></span><br><span class="line"><span class="comment">│                      4 │</span></span><br><span class="line"><span class="comment">│                      5 │</span></span><br><span class="line"><span class="comment">│                      6 │</span></span><br><span class="line"><span class="comment">└────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- || 表示字符串拼接，当 arrayJoin 展开成多行的时候，会自动和其它字段组合</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayJoin(<span class="keyword">range</span>(<span class="number">1</span>, <span class="number">7</span>)) <span class="keyword">AS</span> v, <span class="string">&#x27;A00&#x27;</span> <span class="operator">||</span> <span class="built_in">cast</span>(v <span class="keyword">AS</span> String);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v─┬─concat(&#x27;A00&#x27;, CAST(arrayJoin(range(1, 7)), &#x27;String&#x27;))─┐</span></span><br><span class="line"><span class="comment">│ 1 │ A001                                                  │</span></span><br><span class="line"><span class="comment">│ 2 │ A002                                                  │</span></span><br><span class="line"><span class="comment">│ 3 │ A003                                                  │</span></span><br><span class="line"><span class="comment">│ 4 │ A004                                                  │</span></span><br><span class="line"><span class="comment">│ 5 │ A005                                                  │</span></span><br><span class="line"><span class="comment">│ 6 │ A006                                                  │</span></span><br><span class="line"><span class="comment">└───┴───────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>如果出现了多个 arrayJoin ，那么会做笛卡尔积：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayJoin([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), arrayJoin([<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>])；</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayJoin([1, 2, 3])─┬─arrayJoin([11, 22, 33])─┐</span></span><br><span class="line"><span class="comment">│                    1 │                      11 │</span></span><br><span class="line"><span class="comment">│                    1 │                      22 │</span></span><br><span class="line"><span class="comment">│                    1 │                      33 │</span></span><br><span class="line"><span class="comment">│                    2 │                      11 │</span></span><br><span class="line"><span class="comment">│                    2 │                      22 │</span></span><br><span class="line"><span class="comment">│                    2 │                      33 │</span></span><br><span class="line"><span class="comment">│                    3 │                      11 │</span></span><br><span class="line"><span class="comment">│                    3 │                      22 │</span></span><br><span class="line"><span class="comment">│                    3 │                      33 │</span></span><br><span class="line"><span class="comment">└──────────────────────┴─────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>提到了 arrJoin，那么就必须提一下 groupArray，这算是一个聚合函数，它和 arrayJoin 作用相反，将多行数据合并成数组。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> number <span class="keyword">FROM</span> numbers(<span class="number">5</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─number─┐</span></span><br><span class="line"><span class="comment">│      0 │</span></span><br><span class="line"><span class="comment">│      1 │</span></span><br><span class="line"><span class="comment">│      2 │</span></span><br><span class="line"><span class="comment">│      3 │</span></span><br><span class="line"><span class="comment">│      4 │</span></span><br><span class="line"><span class="comment">└────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> groupArray(number) <span class="keyword">FROM</span> numbers(<span class="number">5</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArray(number)─┐</span></span><br><span class="line"><span class="comment">│ [0,1,2,3,4]        │</span></span><br><span class="line"><span class="comment">└────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>除了 groupArray，还有一个 groupUniqArray，从名字上看显然多了一个去重的功能。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- SELECT arrayJoin([1, 1, 2, 2, 3]) 会自动展开成多行</span></span><br><span class="line"><span class="comment">-- 当然我们也可以将它作为一张表</span></span><br><span class="line"><span class="keyword">SELECT</span> v <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> arrayJoin([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]) v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v─┐</span></span><br><span class="line"><span class="comment">│ 1 │</span></span><br><span class="line"><span class="comment">│ 1 │</span></span><br><span class="line"><span class="comment">│ 2 │</span></span><br><span class="line"><span class="comment">│ 2 │</span></span><br><span class="line"><span class="comment">│ 3 │</span></span><br><span class="line"><span class="comment">└───┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 通过 groupArray 再变成原来的数组</span></span><br><span class="line"><span class="keyword">SELECT</span> groupArray(v) <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> arrayJoin([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]) v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupArray(v)─┐</span></span><br><span class="line"><span class="comment">│ [1,1,2,2,3]   │</span></span><br><span class="line"><span class="comment">└───────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 如果使用 groupUniqArray 的话</span></span><br><span class="line"><span class="keyword">SELECT</span> groupUniqArray(v) <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> arrayJoin([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]) v);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─groupUniqArray(v)─┐</span></span><br><span class="line"><span class="comment">│ [2,1,3]           │</span></span><br><span class="line"><span class="comment">└───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayDifference：计算数组中每相邻的两个元素的差值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 第一个元素固定为 0，第二个元素为 3 - 1，第三个元素为 4 - 3，以此类推</span></span><br><span class="line"><span class="comment">-- 相邻元素相减</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayDifference([<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>])</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayDifference([1, 3, 4, 7, 10])─┐</span></span><br><span class="line"><span class="comment">│ [0,2,1,3,3]                       │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayDistinct：对数组中的元素进行去重</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayDistinct([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayDistinct([1, 1, 1, 2, 2, 3])─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3]                           │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayEnumerateDense：返回一个和原数组大小相等的数组，并指示每个元素在原数组中首次出现的位置（索引都是从 1 开始）</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 22 首次出现在索引为 1 的位置、1 首次出现在索引为 2 的位置</span></span><br><span class="line"><span class="comment">-- 13 首次出现在索引为 4 的位置，因此结果为 [1, 2, 1, 3, 2, 3]</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayEnumerateDense([<span class="number">22</span>, <span class="number">1</span>, <span class="number">22</span>, <span class="number">13</span>, <span class="number">1</span>, <span class="number">13</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayEnumerateDense([22, 1, 22, 13, 1, 13])─┐</span></span><br><span class="line"><span class="comment">│ [1,2,1,3,2,3]                               │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayIntersect：接收多个数组，并取它们的交集</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayIntersect([<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">4</span>]), arrayIntersect([<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">4</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayIntersect([1, 2], [2, 3], [3, 4])─┬─arrayIntersect([1, 2], [2, 3], [2, 4])─┐</span></span><br><span class="line"><span class="comment">│ []                                     │ [2]                                    │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────┴────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayReduce：将一个聚合函数作用在数组上，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayReduce(<span class="string">&#x27;max&#x27;</span>, [<span class="number">1</span>, <span class="number">23</span>, <span class="number">6</span>]), arrayReduce(<span class="string">&#x27;sum&#x27;</span>, [<span class="number">1</span>, <span class="number">23</span>, <span class="number">6</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayReduce(&#x27;max&#x27;, [1, 23, 6])─┬─arrayReduce(&#x27;sum&#x27;, [1, 23, 6])─┐</span></span><br><span class="line"><span class="comment">│                             23 │                             30 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────┴────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>可能有人觉得直接用聚合函数不就好了，答案是不行的，因为这些聚合函数针对的都是多行结果集，而不是数组。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 相当于只有一行数据，所以返回其本身</span></span><br><span class="line"><span class="comment">-- 如果是 sum 就直接报错了， 因为数组之间不能进行加法运算</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">max</span>([<span class="number">11</span>, <span class="number">33</span>, <span class="number">22</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─max([11, 33, 22])─┐</span></span><br><span class="line"><span class="comment">│ [11,33,22]        │</span></span><br><span class="line"><span class="comment">└───────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 如果想返回 33，我们应该将这个数组给展开，变成多行</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">max</span>(arrayJoin([<span class="number">11</span>, <span class="number">33</span>, <span class="number">22</span>]));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─max(arrayJoin([11, 33, 22]))─┐</span></span><br><span class="line"><span class="comment">│                           33 │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>所以聚合函数针对的是多行，而不是数组，如果想用聚合函数，那么应该将数组给展开。或者使用这里的 arrayReduce，相当于将两步合在一起了。当然我们也可以不用 arrayReduce，因为 ClickHouse 为了数组专门提供了相应的操作，比如求数组中最大的元素可以使用更强大的 arrayMax，后面说。</strong></p>
<p><strong>arrayReduceInRanges：对给定范围内的数组元素应用聚合函数，光说不好解释，直接看例子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 会对数组中索引为 1 开始向后的 5 个元素进行 sum，结果为 15</span></span><br><span class="line"><span class="comment">-- 会对数组中索引为 2 开始向后的 4 个元素进行 sum，结果为 14</span></span><br><span class="line"><span class="comment">-- 会对数组中索引为 1 开始向后的 3 个元素进行 sum，结果为 6</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayReduceInRanges(</span><br><span class="line">    <span class="string">&#x27;sum&#x27;</span>,</span><br><span class="line">    [(<span class="number">1</span>, <span class="number">5</span>), (<span class="number">2</span>, <span class="number">4</span>), (<span class="number">1</span>, <span class="number">3</span>)],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayReduceInRanges(&#x27;sum&#x27;, array((1, 5), (2, 4), (1, 3)), [1, 2, 3, 4, 5])─┐</span></span><br><span class="line"><span class="comment">│ [15,14,6]                                                                  │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 以上等价于</span></span><br><span class="line"><span class="keyword">WITH</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>] <span class="keyword">AS</span> arr </span><br><span class="line"><span class="keyword">SELECT</span> [arrayReduce(<span class="string">&#x27;sum&#x27;</span>, arraySlice(arr, <span class="number">1</span>, <span class="number">5</span>)), </span><br><span class="line">        arrayReduce(<span class="string">&#x27;sum&#x27;</span>, arraySlice(arr, <span class="number">2</span>, <span class="number">4</span>)),</span><br><span class="line">        arrayReduce(<span class="string">&#x27;sum&#x27;</span>, arraySlice(arr, <span class="number">1</span>, <span class="number">3</span>))] <span class="keyword">AS</span> v</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v─────────┐</span></span><br><span class="line"><span class="comment">│ [15,14,6] │</span></span><br><span class="line"><span class="comment">└───────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayReverse：对数据进行逆序，然后返回；我们之前还介绍了一个 arrayReverseSort，它在逆序之前会先排序，而这里的 arrayReverse 只是单纯的逆序</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- arrayReverse 和 reverse 作用相同</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayReverse([<span class="number">22</span>, <span class="number">33</span>, <span class="number">11</span>]), reverse([<span class="number">22</span>, <span class="number">33</span>, <span class="number">11</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayReverse([22, 33, 11])─┬─reverse([22, 33, 11])─┐</span></span><br><span class="line"><span class="comment">│ [11,33,22]                 │ [11,33,22]            │</span></span><br><span class="line"><span class="comment">└────────────────────────────┴───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayFlatten：将数组扁平化</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- arrayFlatten 也可以使用 flatten 代替</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayFlatten([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>]]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayFlatten([[1, 2, 3], [11, 22, 33]])─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3,11,22,33]                        │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们之前还介绍了一个 arrayConcat，可以对比一下两者的区别</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayConcat ([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayConcat([1, 2, 3], [11, 22, 33])─┐</span></span><br><span class="line"><span class="comment">│ [1,2,3,11,22,33]                     │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayCompact：从数组中删除连续重复的元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayCompact([<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="keyword">Null</span>, <span class="keyword">Null</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayCompact([2, 2, 1, 1, 1, 3, 3, NULL, NULL])─┐</span></span><br><span class="line"><span class="comment">│ [2,1,3,NULL]                                    │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们看到作用类似于之前介绍的 arrayDistinct，但两者还是有区别的。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayDistinct([<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="keyword">NULL</span>, <span class="keyword">NULL</span>])</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayDistinct([2, 2, 1, 1, 1, 3, 3, NULL, NULL])─┐</span></span><br><span class="line"><span class="comment">│ [2,1,3]                                          │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们发现 arrayDistinct 不包含 Null 值。</strong></p>
<p><strong>arrayZip：类似于 Python 中的 zip，直接看示例：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayZip([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayZip([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], [1, 2, 3], [&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [(&#x27;a&#x27;,1,&#x27;x&#x27;),(&#x27;b&#x27;,2,&#x27;y&#x27;),(&#x27;c&#x27;,3,&#x27;z&#x27;)]                 │</span></span><br><span class="line"><span class="comment">└───────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayMap：对数组中每一个元素都作用相同的函数，根据函数的返回值创建一个新的数组，非常常用的一个功能。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> (x, <span class="number">1</span>), [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayMap(lambda(tuple(x), tuple(x, 1)), [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [(&#x27;a&#x27;,1),(&#x27;b&#x27;,1),(&#x27;c&#x27;,1)]                                │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">*</span> <span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) v1, <span class="built_in">sum</span>(arrayJoin(v1)) v2, arrayReduce(<span class="string">&#x27;sum&#x27;</span>, v1) v3;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v1──────┬─v2─┬─v3─┐</span></span><br><span class="line"><span class="comment">│ [2,4,6] │ 12 │ 12 │</span></span><br><span class="line"><span class="comment">└─────────┴────┴────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>当然也可以作用嵌套数组：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> arrayReduce(<span class="string">&#x27;sum&#x27;</span>, x), [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>], [<span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>]]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayMap(lambda(tuple(x), arrayReduce(&#x27;sum&#x27;, x)), [[1, 2, 3], [11, 22, 33], [33, 44, 55]])─┐</span></span><br><span class="line"><span class="comment">│ [6,66,132]                                                                                 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> arrayReduce(<span class="string">&#x27;max&#x27;</span>, x), [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>], [<span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>]]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayMap(lambda(tuple(x), arrayReduce(&#x27;max&#x27;, x)), [[1, 2, 3], [11, 22, 33], [33, 44, 55]])─┐</span></span><br><span class="line"><span class="comment">│ [3,33,55]                                                                                  │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(x <span class="operator">-</span><span class="operator">&gt;</span> arrayReduce(<span class="string">&#x27;min&#x27;</span>, x), [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>], [<span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>]]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayMap(lambda(tuple(x), arrayReduce(&#x27;max&#x27;, x)), [[1, 2, 3], [11, 22, 33], [33, 44, 55]])─┐</span></span><br><span class="line"><span class="comment">│ [1,11,33]                                                                                  │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>也可以作用多个数组，这些数组的长度必须相等。此外，有多个数组，函数就要有多少个参数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 得到的是 [1 + 11 + 33, 2 + 22 + 44, 3 + 33 + 55]</span></span><br><span class="line"><span class="comment">-- 如果是 arrayMap(x -&gt; arrayReduce(&#x27;sum&#x27;, x), [[1, 2, 3], [11, 22, 33], [33, 44, 55]])</span></span><br><span class="line"><span class="comment">-- 那么得到的是 [1 + 2 + 3, 11 + 22 + 33, 33 + 44 + 55]</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(x, y, z <span class="operator">-</span><span class="operator">&gt;</span> arrayReduce(<span class="string">&#x27;sum&#x27;</span>, [x, y, z]), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>], [<span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>]) <span class="keyword">AS</span> v;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v──────────┐</span></span><br><span class="line"><span class="comment">│ [45,68,91] │</span></span><br><span class="line"><span class="comment">└────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(x, y, z <span class="operator">-</span><span class="operator">&gt;</span> (x <span class="operator">+</span> y, z), [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>], [<span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>]) <span class="keyword">AS</span> v;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v─────────────────────────┐</span></span><br><span class="line"><span class="comment">│ [(12,33),(24,44),(36,55)] │</span></span><br><span class="line"><span class="comment">└───────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayFilter：对数组中每一个元素都作用相同的函数，如果函数返回值为真（非 0），则该元素保留，否则不保留。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayFilter(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">&gt;</span> <span class="number">5</span>, [<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayFilter(lambda(tuple(x), greater(x, 5)), [1, 4, 5, 7, 10])─┐</span></span><br><span class="line"><span class="comment">│ [7,10]                                                         │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> arrayFilter(x <span class="operator">-</span><span class="operator">&gt;</span> length(x) <span class="operator">&gt;</span> <span class="number">1</span>, [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;aa&#x27;</span>, <span class="string">&#x27;aaa&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayFilter(lambda(tuple(x), greater(length(x), 1)), [&#x27;a&#x27;, &#x27;aa&#x27;, &#x27;aaa&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;aa&#x27;,&#x27;aaa&#x27;]                                                             │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> arrayFilter(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="keyword">LIKE</span> <span class="string">&#x27;sa%&#x27;</span>, [<span class="string">&#x27;satori&#x27;</span>, <span class="string">&#x27;koishi&#x27;</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayFilter(lambda(tuple(x), like(x, &#x27;sa%&#x27;)), [&#x27;satori&#x27;, &#x27;koishi&#x27;])─┐</span></span><br><span class="line"><span class="comment">│ [&#x27;satori&#x27;]                                                          │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayFill：对数组中每一个元素都作用相同的函数，如果函数返回值为真，则该元素保留，否则被替换为前一个元素。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 2 会被替换成 4，1 会被替换成 5</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayFill(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">&gt;=</span> <span class="number">3</span>, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">1</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayFill(lambda(tuple(x), greaterOrEquals(x, 3)), [3, 4, 2, 5, 1])─┐</span></span><br><span class="line"><span class="comment">│ [3,4,4,5,5]                                                         │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 第一个元素永远不会被替换，2、3、4、5 都不满足条件，因此都要换成前一个元素</span></span><br><span class="line"><span class="comment">-- 换 2 的时候，2 已经变成了 1，所以 3 的前面是 1，于是 3 也会变成 1</span></span><br><span class="line"><span class="comment">-- 4 和 5 也是同理，因此最终所有值都会变成 1</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayFill(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">&gt;=</span> <span class="number">6</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayFill(lambda(tuple(x), greaterOrEquals(x, 6)), [1, 2, 3, 4, 5])─┐</span></span><br><span class="line"><span class="comment">│ [1,1,1,1,1]                                                         │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayReverseFill：对数组中每一个元素都作用相同的函数，如果函数返回值为真，则该元素保留，否则被替换为后一个元素。注意：此时数组是从后往前扫描的</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 2 会被替换成 5，1 还是 1，最后一个元素不会被替换</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayReverseFill(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">&gt;=</span> <span class="number">3</span>, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">1</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayReverseFill(lambda(tuple(x), greaterOrEquals(x, 3)), [3, 4, 2, 5, 1])─┐</span></span><br><span class="line"><span class="comment">│ [3,4,5,5,1]                                                                │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 因为数组从后往前扫描，所以 4 变成 5、3 也会变成 5，所有值都会变成 5</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayReverseFill(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">&gt;=</span> <span class="number">6</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayReverseFill(lambda(tuple(x), greaterOrEquals(x, 6)), [1, 2, 3, 4, 5])─┐</span></span><br><span class="line"><span class="comment">│ [5,5,5,5,5]                                                                │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayMin：返回数组中最小的元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">11</span>, <span class="number">22</span>, <span class="number">8</span>, <span class="number">33</span>] <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayMin(arr) v1, <span class="built_in">min</span>(arrayJoin(arr)) v2, arrayReduce(<span class="string">&#x27;min&#x27;</span>, arr) v3;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v1─┬─v2─┬─v3─┐</span></span><br><span class="line"><span class="comment">│  8 │  8 │  8 │</span></span><br><span class="line"><span class="comment">└────┴────┴────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayMin 里面还可以传递一个匿名函数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayMin(x <span class="operator">-</span><span class="operator">&gt;</span> <span class="operator">-</span>x, [<span class="number">11</span>, <span class="number">22</span>, <span class="number">8</span>, <span class="number">33</span>])</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayMin(lambda(tuple(x), negate(x)), [11, 22, 8, 33])─┐</span></span><br><span class="line"><span class="comment">│                                                    -33 │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>会按照调用匿名函数的返回值进行判断，选择最小的元素，这里 33 在调用之后返回 -33，显然是最小值。但是这里有一个需要注意的地方，就是它返回的也是匿名函数的返回值。个人觉得应该返回 33 才对，应为我们指定函数只是希望 ClickHouse 能够按照我们指定的规则进行排序，而值还是原来的值，但 ClickHouse 这里设计有点莫测高深了。如果我们以字符串为例，那么会看的更加明显：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayMin(x <span class="operator">-</span><span class="operator">&gt;</span> length(x), [<span class="string">&#x27;ab&#x27;</span>, <span class="string">&#x27;abc&#x27;</span>, <span class="string">&#x27;a&#x27;</span>]) v;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v─┐</span></span><br><span class="line"><span class="comment">│ 1 │</span></span><br><span class="line"><span class="comment">└───┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>我们看到居然返回了一个 1，我们的本意是想选择长度最短的字符串，但是返回的是最短字符串的长度，也就是返回的不是 ‘a’，而是 length(‘a’)。</strong></p>
<p><strong>arrayMax：返回数组中最大的元素</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> [<span class="number">11</span>, <span class="number">22</span>, <span class="number">8</span>, <span class="number">33</span>] <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayMax(arr) v1, <span class="built_in">max</span>(arrayJoin(arr)) v2, arrayReduce(<span class="string">&#x27;max&#x27;</span>, arr) v3;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v1─┬─v2─┬─v3─┐</span></span><br><span class="line"><span class="comment">│ 33 │ 33 │ 33 │</span></span><br><span class="line"><span class="comment">└────┴────┴────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>也可以加上一个匿名函数，作用和 arrayMin 完全一样，并且返回的也是函数调用之后的结果。</strong></p>
<p><strong>arraySum：对数组求总和</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">range</span>(<span class="number">1</span>, <span class="number">101</span>) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arraySum(arr), arrayReduce(<span class="string">&#x27;sum&#x27;</span>, arr), <span class="built_in">sum</span>(arrayJoin(arr));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arraySum(arr)─┬─arrayReduce(&#x27;sum&#x27;, arr)─┬─sum(arrayJoin(arr))─┐</span></span><br><span class="line"><span class="comment">│          5050 │                    5050 │                5050 │</span></span><br><span class="line"><span class="comment">└───────────────┴─────────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>同样可以加一个匿名函数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">range</span>(<span class="number">1</span>, <span class="number">101</span>) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arraySum(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">*</span> <span class="number">2</span>, arr);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arraySum(lambda(tuple(x), multiply(x, 2)), arr)─┐</span></span><br><span class="line"><span class="comment">│                                           10100 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayProduct：对数组求总乘积</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayProduct([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayProduct([1, 2, 3, 4, 5])─┐</span></span><br><span class="line"><span class="comment">│                           120 │</span></span><br><span class="line"><span class="comment">└───────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>同样可以加一个匿名函数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> arrayProduct(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">+</span> <span class="number">1</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayProduct(lambda(tuple(x), plus(x, 1)), [1, 2, 3, 4, 5])─┐</span></span><br><span class="line"><span class="comment">│                                                         720 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayAvg：对数组取平均值</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">range</span>(<span class="number">1</span>, <span class="number">101</span>) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayAvg(arr), arrayReduce(<span class="string">&#x27;avg&#x27;</span>, arr), <span class="built_in">avg</span>(arrayJoin(arr));</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayAvg(arr)─┬─arrayReduce(&#x27;avg&#x27;, arr)─┬─avg(arrayJoin(arr))─┐</span></span><br><span class="line"><span class="comment">│          50.5 │                    50.5 │                50.5 │</span></span><br><span class="line"><span class="comment">└───────────────┴─────────────────────────┴─────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>同样可以加一个匿名函数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> <span class="keyword">range</span>(<span class="number">1</span>, <span class="number">101</span>) <span class="keyword">AS</span> arr <span class="keyword">SELECT</span> arrayAvg(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">*</span> <span class="number">2</span>, arr);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayAvg(lambda(tuple(x), multiply(x, 2)), arr)─┐</span></span><br><span class="line"><span class="comment">│                                             101 │</span></span><br><span class="line"><span class="comment">└─────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>arrayCumSum：对数组进行累和</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 第一个元素不变</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayCumSum([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayCumSum([1, 2, 3, 4, 5])─┐</span></span><br><span class="line"><span class="comment">│ [1,3,6,10,15]                │</span></span><br><span class="line"><span class="comment">└──────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>同样可以加一个匿名函数：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 第一个元素不变</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayCumSum(x <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">*</span> <span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]), arrayCumSum([<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayCumSum(lambda(tuple(x), multiply(x, 2)), [1, 2, 3, 4, 5])─┬─arrayCumSum([2, 4, 6, 8, 10])─┐</span></span><br><span class="line"><span class="comment">│ [2,6,12,20,30]                                                 │ [2,6,12,20,30]                │</span></span><br><span class="line"><span class="comment">└────────────────────────────────────────────────────────────────┴───────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><strong>以上就是关于 ClickHouse 数组的一些函数操作，可以说是非常强大了，不光是功能强大，用起来也很舒服，仿佛有种在写 Python 代码的感觉。当然以上并不是关于数组的全部操作（绝大部分），但说实话已经够用了，即使你当前的需求，某一个函数不能解决，那么也能多个函数组合来解决。比如我们想要计算两个数组中相同位置的元素的差，那么就可以这么做：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 一个函数即可解决</span></span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(x, y <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">-</span> y, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─arrayMap(lambda(tuple(x, y), minus(x, y)), [1, 2, 3], [3, 2, 1])─┐</span></span><br><span class="line"><span class="comment">│ [-2,0,2]                                                         │</span></span><br><span class="line"><span class="comment">└──────────────────────────────────────────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>再比如，计算数组中每个元素减去上一个元素的值，由于第一个元素上面没有值，那么设为空：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 我们只需要选择 arr 的前 N - 1 个元素，然后再在头部插入一个 Null，[Null, 11, 22, 33, 44, 55]</span></span><br><span class="line"><span class="comment">-- 最后让 arr 和它的对应元素依次相减即可</span></span><br><span class="line"><span class="keyword">WITH</span> [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>, <span class="number">66</span>] <span class="keyword">AS</span> arr</span><br><span class="line"><span class="keyword">SELECT</span> arrayMap(</span><br><span class="line">    x, y <span class="operator">-</span><span class="operator">&gt;</span> x <span class="operator">-</span> y, </span><br><span class="line">    arr, </span><br><span class="line">    arrayPushFront(arraySlice(arr, <span class="number">1</span>, length(arr) <span class="operator">-</span> <span class="number">1</span>), <span class="keyword">Null</span>)</span><br><span class="line">) v;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─v─────────────────────┐</span></span><br><span class="line"><span class="comment">│ [NULL,11,11,11,11,11] │</span></span><br><span class="line"><span class="comment">└───────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>显然即使是复杂的需求，也可以通过多个函数组合完成，怎么样，是不是有点酷呢？ClickHouse 内建了很多的函数，这些函数给我们一种仿佛在用编程语言写代码的感觉。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的执行计划以及优化策略(十六)</title>
    <url>/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的执行计划以及优化策略-十六"><a href="#ClickHouse-的执行计划以及优化策略-十六" class="headerlink" title="ClickHouse 的执行计划以及优化策略(十六)"></a>ClickHouse 的执行计划以及优化策略(十六)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h3 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h3><p><strong>如果要在 ClickHouse 20.6 版本之前查看 SQL 语句的执行计划，需要在 config.xml 里面将日志级别设置为 trace。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 新版本默认是 trace --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">level</span>&gt;</span>trace<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>然后还要真正执行相应的 SQL 语句，在执行日志里面查看，很明显这是非常不方便的。于是 ClickHouse 在 20.6 版本里面引入了原生的执行计划的语法（此时处于试用期阶段），并在 20.6.3 版本中正式转正。</strong></p>
<blockquote>
<p><strong>我们当前系列都是基于 ClickHouse 的 21.7.3.14 版本。</strong></p>
</blockquote>
<p><strong>然后我们来介绍如何查看执行计划，不过介绍之前我们先创建一张数据表，这次我们采用真实的数据。首先 ClickHouse 官方提供了两个数据集，其中数据行数和字段数都非常的大，不亚于一些公司生产环境上的数据，我们来下载一下。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载数据集，这里的数据集不是 CSV、JSON，而是 .bin、.mrk 等物理文件</span></span><br><span class="line"><span class="comment"># 也就是说数据集本身就是符合 ClickHouse 物理存储的</span></span><br><span class="line">curl -O https://datasets.clickhouse.tech/hits/partitions/hits_v1.tar</span><br><span class="line"><span class="comment"># 所以我们直接解压到拷贝到 /var/lib/clickhouse 目录下即可</span></span><br><span class="line">tar -xvf hits_v1.tar -C /var/lib/clickhouse</span><br></pre></td></tr></table></figure>

<p><strong>然后我们就可以使用 hits_v1 这张表了，我们之前说过，必须要先创建表然后再导入数据，因为创建表的时候会生成一些元信息，存储在 &#x2F;var&#x2F;lib&#x2F;clickhouse&#x2F;metadata 目录下，而光有数据没有元信息是不行的。但对于当前而言则不用事先创建表，因为 ClickHouse 将元信息也准备好了，所以我们直接拷贝过去即可。压缩包解压之后，会有一个 data 目录和一个 metadata 目录，所以我们解压到 &#x2F;var&#x2F;lib&#x2F;clickhouse 中，会自动将 data 目录里面的内容合并到 &#x2F;var&#x2F;lib&#x2F;clickhouse 的 data 目录中，将 metadata 目录里面的内容合并到 &#x2F;var&#x2F;lib&#x2F;clickhouse 的 metadata 目录中。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori data]<span class="comment"># ls</span></span><br><span class="line">datasets  default  system</span><br><span class="line">[root@satori data]<span class="comment"># ls datasets</span></span><br><span class="line">hits_v1</span><br></pre></td></tr></table></figure>

<p><strong>我们看到里面多了一个 datasets 目录，datasets 目录下才是 hits_v1，显然我们后续需要使用 datasets.hits_v1 进行查询。当然数据集还有一份，我们按照相同的套路即可。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">curl <span class="operator">-</span>O https:<span class="operator">/</span><span class="operator">/</span>datasets.clickhouse.tech<span class="operator">/</span>visits<span class="operator">/</span>partitions<span class="operator">/</span>visits_v1.tar</span><br><span class="line">tar <span class="operator">-</span>xvf visits_v1.tar <span class="operator">-</span>C <span class="operator">/</span>var<span class="operator">/</span>lib<span class="operator">/</span>clickhouse</span><br></pre></td></tr></table></figure>

<p><strong>我们来确认一下：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori datasets]<span class="comment"># ls</span></span><br><span class="line">hits_v1  visits_v1</span><br></pre></td></tr></table></figure>

<p><strong>显然数据集已经准备完毕，不过我们当前使用的是 root 用户，还应该要确保 clickhouse 用户有相应的操作权限。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chown</span> clickhouse:clickhouse /var/lib/clickhouse/data -R</span><br><span class="line"><span class="comment"># 然后重启 ClickHouse，因为我们不是通过 CREATE TABLE 创建的表</span></span><br><span class="line"><span class="comment"># 因此要重启，不然 ClickHouse 是不知道我们通过拷贝文件的方式新增了两张表</span></span><br><span class="line">clickhouse restart</span><br></pre></td></tr></table></figure>

<p><strong>重启之后，执行 SQL 语句进行查看：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913183943809-487548377.png" alt="img"></p>
<p><strong>数据量还是不少的，datasets.hits_v1 有将近 900 万条数据、字段数 130 多个，datasets.visit_v1 有 160 多万条数据、字段数为 180 多个，还是很大的。</strong></p>
<blockquote>
<p><strong>具体都有哪些字段，可以通过 &#x2F;var&#x2F;lib&#x2F;clickhouse&#x2F;metadata&#x2F;datasets 下的 .sql 文件进行查看。</strong></p>
</blockquote>
<p><strong>有了数据集，我们就可以介绍查询计划了。当然使用这种规模的数据集有些小题大做，不过既然 ClickHouse 是为大数据准备的，那么使用大一点的数据集也无妨，而且我们后面也会经常使用这些数据集。</strong></p>
<h4 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h4><p><strong>在 MySQL 中查看执行计划使用的语法是什么呢？没错，EXPLAIN，在 ClickHouse 中也是如此，只不过 ClickHouse 将 EXPLAIN 变得更加丰富。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAN [AST <span class="operator">|</span> SYNTAX <span class="operator">|</span> PLAN <span class="operator">|</span> PIPELINE] [SETTINGS <span class="operator">=</span> <span class="keyword">value</span>, ...]</span><br><span class="line"><span class="keyword">SELECT</span> ... [FORMAT ...]</span><br></pre></td></tr></table></figure>

<p><strong>我们看一下第一个中括号里面的内容，ClickHouse 除了可以让我们查看执行计划之外，还可以查看很多其它内容。</strong></p>
<p><strong>1）AST：查看编译之后的语法树，这个不是很常用</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN AST</span><br><span class="line"><span class="keyword">SELECT</span> UserID, <span class="built_in">count</span>() <span class="keyword">FROM</span> datasets.hits_v1 </span><br><span class="line"><span class="keyword">WHERE</span> EventDate <span class="operator">&lt;</span> toDate(<span class="string">&#x27;2014-03-17&#x27;</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> UserID;</span><br></pre></td></tr></table></figure>

<p><strong>执行一下，查看生成的语法树：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913183954791-1357266678.png" alt="img"></p>
<p><strong>2）SYNTAX：用于优化语法，有时我们指定的查询语句未必是最优的，那么 ClickHouse 在底层会进行优化，EXPLAIN SYNTAX 可以返回对一条 SQL 语句进行优化后的结果。通过对比优化前和优化后的 SQL 语句，可以有助于我们理解 ClickHouse 的优化机制</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN SYNTAX</span><br><span class="line"><span class="keyword">SELECT</span> UserID, <span class="built_in">count</span>() count <span class="keyword">FROM</span> datasets.hits_v1 </span><br><span class="line"><span class="keyword">WHERE</span> EventDate <span class="operator">&lt;</span> toDate(<span class="string">&#x27;2014-03-17&#x27;</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> UserID <span class="keyword">ORDER</span> <span class="keyword">BY</span> count LIMIT <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184005381-91963819.png" alt="img"></p>
<p><strong>我们看到仅仅是做了一些格式上调整，但优化前和优化后的语句本质上没差别，证明对于当前查询而言，我们写的 SQL 语句就是最优的。因为这条语句太简单了，ClickHouse 没有什么可优化的。</strong></p>
<p><strong>然后我们来写几个非常规的语句，比如三元表达式：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 这是嵌套的三元表达式，那么 ClickHouse 会怎么优化呢?</span></span><br><span class="line">EXPLAIN SYNTAX</span><br><span class="line"><span class="keyword">SELECT</span> number <span class="operator">&lt;</span> <span class="number">5</span> ? <span class="string">&#x27;小于 5&#x27;</span> : (number <span class="operator">=</span> <span class="number">5</span> ? <span class="string">&#x27;等于 5&#x27;</span> : <span class="string">&#x27;大于 5&#x27;</span>) <span class="keyword">FROM</span> numbers(<span class="number">10</span>);</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184026557-163630040.png" alt="img"></p>
<p><strong>注意：这里并没有开启优化，只不过是将三元表达式使用 if 语句替换了，因为没有嵌套的三元表达式在底层就是对应 if 函数的一个调用。只不过 ClickHouse 将一些比较特殊的函数调用，抽象成了一些语法糖，但本质上是没有变化的，所以当前的 SQL 语句并没有得到优化。</strong></p>
<p><strong>事实上，ClickHouse 对三元表达式的优化默认是关闭的，我们可以将其打开。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 见名知意，就是当出现 if 的嵌套时，优化成 multiIf</span></span><br><span class="line"><span class="keyword">SET</span> optimize_if_chain_to_multiif <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184036739-210277828.png" alt="img"></p>
<p><strong>SYNTAX 还是很常用的，我们写完一条 SQL 语句之后，可以直接 EXPLAIN SYNTAX 一下，然后将返回的结果替换掉我们原来的 SQL 语句。</strong></p>
<p><strong>PLAN：查看执行计划，默认选项</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN</span><br><span class="line"><span class="keyword">SELECT</span> UserID, <span class="built_in">count</span>() count <span class="keyword">FROM</span> datasets.hits_v1 </span><br><span class="line"><span class="keyword">WHERE</span> EventDate <span class="operator">&lt;</span> toDate(<span class="string">&#x27;2014-03-17&#x27;</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> UserID <span class="keyword">ORDER</span> <span class="keyword">BY</span> count LIMIT <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184015646-1560810255.png" alt="img"></p>
<p><strong>我们看到图中的 EXPLAIN 后面并没有带上 PLAN，说明 PLAN 是默认选项，然后查看执行计划时还可以设置一些额外的参数：</strong></p>
<ul>
<li><code>header：打印计划中各个步骤的 head 说明，默认值为 0 表示关闭，如果开启，设置为 1</code></li>
<li><code>description：打印计划中各个步骤的描述，就是图中括号里面的部分，默认值为 1 表示开启，如果关闭，设置为 0</code></li>
<li><code>actions：打印计划中各个步骤的详细信息，默认值为 0 表示关闭，如果开启，设置为 1</code></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN header <span class="operator">=</span> <span class="number">1</span>, actions <span class="operator">=</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">SELECT</span> UserID, <span class="built_in">count</span>() count <span class="keyword">FROM</span> datasets.hits_v1 </span><br><span class="line"><span class="keyword">WHERE</span> EventDate <span class="operator">&lt;</span> toDate(<span class="string">&#x27;2014-03-17&#x27;</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> UserID <span class="keyword">ORDER</span> <span class="keyword">BY</span> count LIMIT <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<p><strong>输出的内容非常多，可以测试一下。</strong></p>
<p><strong>PIPELINE：查看 PIPELINE 计划，类似于 PLAN</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN PIPELINE <span class="keyword">SELECT</span> <span class="built_in">sum</span>(number) <span class="keyword">FROM</span> numbers(<span class="number">100000</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> number <span class="operator">%</span> <span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184048889-202343307.png" alt="img"></p>
<p><strong>类似于 PLAN，查看 PIPELINE 计划时还可以设置一些额外的参数：</strong></p>
<ul>
<li><code>header：打印计划中各个步骤的 head 说明，默认值为 0 表示关闭，如果开启，设置为 1</code></li>
<li><code>graph：用 DOT 图形语言描述管道图，默认关闭，</code></li>
<li><code>actions：表示当开启 graph 之后是否紧凑打印，默认开启</code></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN PIPELINE header <span class="operator">=</span> <span class="number">1</span>, graph <span class="operator">=</span> <span class="number">1</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">sum</span>(number) <span class="keyword">FROM</span> numbers(<span class="number">100000</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> number <span class="operator">%</span> <span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<p><strong>可以自己查看一下输出。</strong></p>
<h3 id="建表优化"><a href="#建表优化" class="headerlink" title="建表优化"></a>建表优化</h3><p><strong>我们在创建表的时候，需要指定的内容比较多，比如 ORDER BY、表引擎、表参数、分区字段等等，这些对后续数据的查询效率都是有影响的，当然指定合适的数据类型也是非常重要的。下面就来介绍一下常见的优化手段。</strong></p>
<h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p><strong>在建表的时候能用数值类型和日期时间类型表示的字段就不要使用字符串，虽然字符串类型在以 Hive 为中心的数仓建设中非常常见，但 ClickHouse 却并非如此。我们知道在 Hive 中，日期一般都用字符串，不会特意使用 Date 类型。但在 ClickHouse 中，能不要 String 就不要用，因为后期还要转换。</strong></p>
<p><strong>对于 DateTime，ClickHouse 底层会转成时间戳进行存储，但我们不要显式地使用 UInt64 类型来存储。因为 DateTime 不需要经过函数转换处理，执行效率高，可读性好。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_t (</span><br><span class="line">    id UInt32,</span><br><span class="line">    product String,</span><br><span class="line">    amount <span class="type">Decimal</span>(<span class="number">16</span>, <span class="number">2</span>),</span><br><span class="line">    create_time UInt32  <span class="comment">-- 这里使用了整数存储时间</span></span><br><span class="line">) ENGINE <span class="operator">=</span> ReplacingMergeTree(create_time)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMMDD(toDate(create_time))  <span class="comment">-- 需要转换一次，否则报错</span></span><br><span class="line"><span class="keyword">PRIMARY</span> KEY id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p><strong>除了日期类型和数值类型不用字符串表示之外，Null 也是拖累性能的一个罪魁祸首，因为官方已经指出 Null 会影响性能了。因为存储 Nullable 类型的列时，需要创建一个额外的文件来存储 Null 标记，并且 Nullable 类型的列无法被索引。因此除了极特殊的情况，否则不要将列设置为 Nullable，可以用一个不可能出现的默认值、或者在业务中无意义的来代指空，例如将 id 设置为 -1 表示该商品没有 id，而不是使用 Null。</strong></p>
<h4 id="分区和索引"><a href="#分区和索引" class="headerlink" title="分区和索引"></a>分区和索引</h4><p><strong>分区粒度根据业务特点决定，但不宜过粗或者过细，如果数据之间是严格按照时间来划分，比如经常要按天、按月或者按年汇总处理，那么不妨选择按天分区或者按月分区；如果数据按照地区来划分，比如经常针对不同的地区单独汇总，那么不妨按照地区分区。那么分区到底要分多少个区呢？以单表一亿条数据为例，分区大小控制在 10 到 30 个最好。所以如果按照时间分区，那么我们一般都会按天、按月分区，至于按分钟分区则 dark不必，因为这样分区目录就太多了。</strong></p>
<p><strong>还有指定索引列，默认通过 ORDER BY 指定。ORDER BY 在 ClickHouse 中是最重要的，因为分区内的排序通过 ORDER BY 指定，主键（索引）默认也是由 ORDER BY 指定，即使我们显式地使用 PRIMARY KEY 不使用 ORDER BY，那么主键也必须是排序键的前缀。当然这里的 ORDER BY 指的是建表时的 ORDER BY，不是查询语句中的 ORDER BY。</strong></p>
<p><strong>然后我们在通过 ORDER BY 指定索引列的时候，应该指定查询中经常被用来充当筛选条件的列，可以是单一维度，也可以是组合维度，如果是组合维度，那么索引列要满足查询频率大的在前原则。还有基数特别大的不适合做索引列，基数大指的就是那些重复数据非常少的列。</strong></p>
<h4 id="表参数"><a href="#表参数" class="headerlink" title="表参数"></a>表参数</h4><p><strong>index_granularity 是用来控制索引粒度的，默认是 8192，如非必须不建议调整。另外，如果一张表不是必须要保留全量历史数据，则建议指定 TTL，可以免去手动清理过期历史数据的麻烦，TTL 也可以通过 ALTER TABLE 语句随时修改。</strong></p>
<h4 id="写入和删除优化"><a href="#写入和删除优化" class="headerlink" title="写入和删除优化"></a>写入和删除优化</h4><p><strong>尽量不要执行单条或小批量删除、插入操作，这样会产生小分区文件，给后台 Merge 任务带来巨大压力。</strong></p>
<p><strong>不要一次写入太多分区，或者数据写入太快，数据写入太快会导致 Merge 速度跟不上而报错，一般建议每秒钟发起 2 ~ 3 此写入操作，每次操作写入 2w ~ 5 w 条数据（依服务器性能而定）。</strong></p>
<h4 id="常见配置"><a href="#常见配置" class="headerlink" title="常见配置"></a>常见配置</h4><p><strong>我们知道配置文件位于 &#x2F;etc&#x2F;clickhouse-server 目录下，里面有 config.xml 和 users.xml，我们之前一直说 config.xml，但其实 users.xml 也非常重要。它们都表示服务端的配置，而区别主要在于 config.xml 里面的配置是无法覆盖的，我们在命令行经常会使用 set 命令将某个参数进行修改，这些参数则是放在 users.xml 中。当然一个设置即可以在 users.xml 中出现，也可以在 config.xml 中出现，服务端首先会从 config.xml 中找，找不到再去 config.xml 中找。</strong></p>
<p><strong>而我们修改配置主要是为了调整 CPU、内存、IO，瓶颈主要在这里。因为 ClickHouse 会有后台线程 Merge 数据，所以非常的吃 CPU；当然加载数据，对内存也是一个考量；同理还有 IO，因为要从磁盘上读取大量数据。</strong></p>
<p><strong>下面来介绍与这三个配置有关的参数。</strong></p>
<p><strong>1）CPU</strong></p>
<p><strong>background_pool_size：位于 users.xml 中，非常重要的一个参数，表示后台线程池内的线程数量，Merge 线程就是在该线程池中执行，该线程池不仅仅是给 Merge 线程用的。默认值为 16，允许的前提下建议改成 CPU 个数的二倍。所以 ClickHouse 不建议和 HDFS、Yarn 等一起部署，因为 ClickHouse 太吃资源了，不然也达不到如此可观的速度</strong></p>
<p><strong>background_schedule_pool_size：位于 users.xml 中，表示执行后台任务的线程数，默认值为 128，允许的前提下建议改成 CPU 个数的二倍</strong></p>
<p><strong>background_distributed_schedule_pool_size：位于 users.xml 中，表示分布式发送执行后台任务的线程数，默认值为 16，允许的前提下建议改成 CPU 个数的二倍</strong></p>
<p><strong>max_concurrent_queries：位于 config.xml 中，表示最大并发处理的请求数（包含 SELECT、INSERT 等等），默认值为 100，推荐 150 ~ 300，不够再加</strong></p>
<p><strong>max_threads：位于 users.xml 中，表示单个查询所能使用的最大 CPU 个数，默认是 CPU 核数</strong></p>
<p>**以上是关于 CPU 相关的设置，如果发现机器吃不消了，那么不妨减少一下线程数。 **</p>
<p><strong>2）Memory</strong></p>
<p><strong>max_memory_usage：位于 users.xml 中，表示单次 Query 占用内存的最大值，该值可以设置的大一些，这样可以提高集群查询的上限。当然也要保留一些给 OS，比如 128G 的内存，设置为 100G 即可</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184101340-936437929.png" alt="img"></p>
<p><strong>max_bytes_before_external_group_by：表示 GROUP BY 使用的内存的最大值，一旦超过这个最大值，那么会刷新到磁盘进行 GROUP BY，一般按照 max_memory_usage 的一半设置即可。因为 ClickHouse 聚合分两个阶段，查询并建立中间数据、合并中间数据</strong></p>
<p><strong>max_bytes_before_external_sort：表示 ORDER BY 使用的内存的最大值，一旦超过这个最大值，那么会刷新到磁盘进行 ORDER BY。如果不设置该值，那么当内存不够的时候直接报错，设置了该值，ORDER BY 在内存不够的时候可以基于磁盘完成，但是速度相对就慢了（实际测试发现慢得多，甚至无法接受）。该参数和上一个参数都在 users.xml 中设置。</strong></p>
<p><strong>max_table_size_to_drop：位于 config.xml 中，应用于需要删除表或分区的情况，默认是 50 GB，意思是如果删除 50 GB 以上的数据会失败。建议设置为 0，表示无论分区表 多大都可以删除</strong></p>
<p><strong>3）IO</strong></p>
<p><strong>和 HDFS 不同，ClickHouse 不支持设置多数据目录，为了提升 IO 性能，可以挂载虚拟券组（将多块磁盘虚拟成一块磁盘），通过一个券组绑定多块物理磁盘提升读写性能。或者使用 SSD，但是成本就比较高了。</strong></p>
<h3 id="ClickHouse-语法优化规则"><a href="#ClickHouse-语法优化规则" class="headerlink" title="ClickHouse 语法优化规则"></a>ClickHouse 语法优化规则</h3><p><strong>很多数据库底层都内置了优化器，定义好了许多的优化规则，用于给我们的 SQL 语句进行优化，比如大小表 JOIN、谓词下推等等，就是为了避免开发人员执行慢查询。</strong></p>
<p><strong>那么 ClickHouse 会对哪些查询进行优化呢？我们来看一下。</strong></p>
<h4 id="COUNT-优化"><a href="#COUNT-优化" class="headerlink" title="COUNT 优化"></a>COUNT 优化</h4><p><strong>我们说如果统计一张表有多少行，那么使用 count() 或者 count(*) 即可，此时会直接读取 count.txt。还记得这个 count.txt 文件吗？我们在介绍 MergeTree 的时候说过，该文件里面存储了表的行数，当使用 count() 或者 count(*) 的时候，直接读取该文件即可，此时是不需要全表扫描的。类似于关系型数据库也是如此，MySQL 在使用 count() 的时候也是直接计算的 B+ 树的叶子结点个数。</strong></p>
<p><strong>但当我们 count 一个字段的时候，那么就必须要全表扫描了，而且我们说过 count 字段的时候统计的是该字段中非空的值的个数。如果该字段中没有空值，count(字段) 的结果和 count()、count(*) 是相等的。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184112282-99248751.png" alt="img"></p>
<p><strong>对比输出信息的话，我们看到 count(字段) 进行了全表扫描。</strong></p>
<p><strong>再比如 count(1)，我们看看它会不会被优化：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) EXPLAIN SYNTAX <span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">FROM</span> datasets.hits_v1;</span><br><span class="line"></span><br><span class="line">EXPLAIN SYNTAX</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">FROM</span> datasets.hits_v1</span><br><span class="line"></span><br><span class="line">Query id: f59337ec<span class="number">-58e3</span><span class="number">-4</span>a37<span class="operator">-</span>b00d<span class="operator">-</span>eaa796f54f65</span><br><span class="line"></span><br><span class="line">┌─explain───────────────┐</span><br><span class="line">│ <span class="keyword">SELECT</span> <span class="built_in">count</span>()        │</span><br><span class="line">│ <span class="keyword">FROM</span> datasets.hits_v1 │</span><br><span class="line">└───────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.004</span> sec.</span><br></pre></td></tr></table></figure>

<p><strong>因为 1 是一个整型，没有什么实际意义，所以直接变成了 count()。</strong></p>
<h4 id="谓词下推"><a href="#谓词下推" class="headerlink" title="谓词下推"></a>谓词下推</h4><p><strong>在 SQL 中，谓词就是返回 boolean 值的函数，或隐式转换为 bool 的函数，说白了你就简单理解为 WHERE 语句即可。而谓词下推指的是将过滤表达式尽可能移动至靠近数据源的位置，从事后过滤变成事前过滤。</strong></p>
<p><strong>举个最简单的栗子就是 WHERE 和 HAVING，我们知道 WHERE 是发生在 GROUP BY 之前的，HAVAING 发生在 GROUP BY 之后。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> UserID, <span class="built_in">count</span>() <span class="keyword">FROM</span> datasets.hits_v1</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> UserID <span class="keyword">HAVING</span> UserID <span class="operator">=</span> <span class="number">1785640464950496314</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌──────────────UserID─┬─count()─┐</span></span><br><span class="line"><span class="comment">│ 1785640464950496314 │     105 │</span></span><br><span class="line"><span class="comment">└─────────────────────┴─────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p><strong>上面这行 SQL 语句执行的时候虽然没有任何问题，但很明显这是一个糟糕的 SQL 语句，因为要先对将近 900 万的数据进行聚合，然后选择 UserID 为 1785640464950496314 的记录。既然如此，那我们为什么不能先把 UserID 为 1785640464950496314 的记录选出来，然后再单独进行聚合呢？这样的话数据量会少很多。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184209516-1021848259.png" alt="img"></p>
<p><strong>我们看到在优化之后的 SQL 语句将条件从 HAVING 移到了 WHERE，所以将过滤表达式尽可能移动至靠近数据源的位置，在计算之前先将无用数据过滤掉，这个过程就是谓词下推。</strong></p>
<p><strong>当然谓词下推不仅仅是这里的 HAVING，子查询也支持，举个栗子，我们要根据 UserID 从 hits_v1 表中查询几个用户的记录，但是这些值必须存在于 visits_v1 的 UserID 字段中。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> UserID, URL <span class="keyword">FROM</span> datasets.hits_v1</span><br><span class="line"><span class="keyword">WHERE</span> UserID <span class="keyword">IN</span> (<span class="number">329024891984319329</span>, <span class="number">3341630990649416532</span>, <span class="number">3444082748272603552</span>);</span><br></pre></td></tr></table></figure>

<p><strong>显然这是非常简单的，但如果我们规定 UserID 还必须要出现在 visits_v1 表的 UserID 字段中，那么要怎么做呢？最简单的做法就是一个条件即可。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> UserID, URL</span><br><span class="line"><span class="keyword">FROM</span> datasets.hits_v1</span><br><span class="line"><span class="keyword">WHERE</span> UserID <span class="keyword">IN</span> (<span class="number">329024891984319329</span>, <span class="number">3341630990649416532</span>, <span class="number">3444082748272603552</span>)</span><br><span class="line">  <span class="keyword">AND</span> UserID <span class="keyword">IN</span> (<span class="keyword">SELECT</span> UserID <span class="keyword">FROM</span> datasets.visits_v1);</span><br></pre></td></tr></table></figure>

<p><strong>但很明显这条语句就不是最优解，因为子查询会扫描全表，也就是 visits_v1 会全量读取。既然 UserID 要在两个表中都出现，那么就应该优先把过滤条件放在子查询里面。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> UserID, URL</span><br><span class="line"><span class="keyword">FROM</span> datasets.hits_v1</span><br><span class="line"><span class="keyword">WHERE</span> UserID <span class="keyword">IN</span></span><br><span class="line">      (<span class="keyword">SELECT</span> UserID  <span class="comment">-- 数据量大的话，还可以进行去重</span></span><br><span class="line">       <span class="keyword">FROM</span> datasets.visits_v1</span><br><span class="line">       <span class="keyword">WHERE</span> UserID <span class="keyword">IN</span> (<span class="number">329024891984319329</span>, <span class="number">3341630990649416532</span>, <span class="number">3444082748272603552</span>));</span><br></pre></td></tr></table></figure>

<p><strong>这种做法显然更优，因为 visits_v1 不需要全量读取，但 ClickHouse 目前还做不了这种优化，ClickHouse 所能做的子查询谓词下推还是很有限的。当然不光是子查询，相比 Hive，ClickHouse 所做的优化非常有限，不同的 SQL 语句效率相差十倍以上都是很正常的，因为我们写 SQL 就不可以肆无忌惮。</strong></p>
<h4 id="作为表进行-JOIN-的子查询会消除重复字段"><a href="#作为表进行-JOIN-的子查询会消除重复字段" class="headerlink" title="作为表进行 JOIN 的子查询会消除重复字段"></a>作为表进行 JOIN 的子查询会消除重复字段</h4><p><strong>如果子查询中重复选择了某个字段，那么当它作为表进行 JOIN 的时候，会去除重复字段。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN SYNTAX</span><br><span class="line"><span class="keyword">SELECT</span> a.UserID, b.VisitID, a.URL</span><br><span class="line"><span class="keyword">FROM</span> datasets.hits_v1 a <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> UserID, UserID, VisitID</span><br><span class="line">    <span class="keyword">FROM</span> datasets.visits_v1</span><br><span class="line">) b</span><br><span class="line"><span class="keyword">USING</span>(UserID) LIMIT <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p><strong>这里进行 JOIN 的右表是一个子查询，而在这个子查询里面我们选择了两次 UserID，那么 ClickHouse 会进行优化，变成只选择一次。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184200192-1452223116.png" alt="img"></p>
<p><strong>可能有人好奇，如果我给第二个 UserID 起一个别名会怎么样呢？答案是即使起了别名，仍然只会选择一次。</strong></p>
<p><strong>注意：这里的子查询在 JOIN 的时候会删除重复字段，但如果不是在 JOIN 的时候就不一样了。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN SYNTAX</span><br><span class="line"><span class="keyword">SELECT</span> UserID, URL</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> UserID, UserID, URL</span><br><span class="line">    <span class="keyword">FROM</span> datasets.hits_v1</span><br><span class="line">) LIMIT <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p><strong>这里的子查询当中我们选择了两个 UserID，那么 ClickHouse 会不会变成一个呢？</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184254606-1791960429.png" alt="img"></p>
<p><strong>我们看到并没有优化掉，所以 ClickHouse 所做的优化还是比较有限的。</strong></p>
<h4 id="聚合计算外推"><a href="#聚合计算外推" class="headerlink" title="聚合计算外推"></a>聚合计算外推</h4><p><strong>什么是聚合计算外推呢？举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">sum</span>(RequestNum <span class="operator">*</span> <span class="number">2</span>) <span class="keyword">FROM</span> datasets.hits_v1;</span><br></pre></td></tr></table></figure>

<p><strong>你觉得上面的 SQL 有能够优化的地方吗？我们看看 ClickHouse 是如何做的。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184219260-1916876794.png" alt="img"></p>
<p><strong>没优化的时候，相当于是在 sum 之前先给每一条数据做一次乘法运算，然后进行 sum；优化之后则是先进性 sum，最后只对总和进行一次乘法运算，显然后者更优。</strong></p>
<h4 id="聚合函数消除"><a href="#聚合函数消除" class="headerlink" title="聚合函数消除"></a>聚合函数消除</h4><p><strong>我们在使用 GROUP BY 的时候有一个限制，那就是 SELECT 中没有使用聚合函数的字段必须出现在分组字段中。举几个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 字段 b 出现在了 SELECT 中，并且没有使用聚合函数，所以它一定要出现在分组字段（GROUP BY）中</span></span><br><span class="line"><span class="comment">-- 但没有出现，所以报错</span></span><br><span class="line"><span class="keyword">SELECT</span> a, b, <span class="built_in">count</span>(c) <span class="keyword">FROM</span> t <span class="keyword">GROUP</span> <span class="keyword">BY</span> a;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 此时没有问题，a 和 b 都出现在 GROUP BY 中</span></span><br><span class="line"><span class="comment">-- 至于字段 c，它是以 count(c) 的形式出现的，使用了聚合函数，所以没问题</span></span><br><span class="line"><span class="keyword">SELECT</span> a, b, <span class="built_in">count</span>(c) <span class="keyword">FROM</span> t <span class="keyword">GROUP</span> <span class="keyword">BY</span> a, b;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 这条语句也是非法的，因为 b 没有出现在 GROUP BY 中，至于 count(b) 和 b 无关</span></span><br><span class="line"><span class="comment">-- 既然 SELECT 中出现了没有使用聚合函数的字段 b，那么它就必须要出现在 GROUP BY 中</span></span><br><span class="line"><span class="keyword">SELECT</span> a, b, <span class="built_in">count</span>(b), <span class="built_in">count</span>(c) <span class="keyword">FROM</span> t <span class="keyword">GROUP</span> <span class="keyword">BY</span> a;</span><br></pre></td></tr></table></figure>

<p><strong>当然这些属于基础内容了，我主要想表达的是，我们可不可以对分组字段使用聚合函数呢？比如说：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">max</span>(UserID), <span class="built_in">max</span>(Age), <span class="built_in">min</span>(Age), <span class="built_in">sum</span>(Age) <span class="keyword">FROM</span> datasets.hits_v1 <span class="keyword">GROUP</span> <span class="keyword">BY</span> Age</span><br></pre></td></tr></table></figure>

<p><strong>很明显是可以的，但是这么做没有任何意义，因为分组就是把分组字段对应的值相同的归为一组，比如这里的 age，所以每一组的 age 的值都是一样的。既然都一样，那么做聚合就没有太大意义，因此 ClickHouse 会那些对分组字段使用 min、max、any 的聚合函数给删掉。因为每一组的所有值都是一样的，最小值、最大值、第一行的值，三者之间没差别。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184230618-757781969.png" alt="img"></p>
<p><strong>我们看到聚合函数 min、max 被剥掉了，只留下了 Age 字段，因为分组字段的值都是一样的，min、max、any 没有意义。但聚合函数仅限于 max、min、any，如果是 sum 就不会了，虽然从业务的角度上来说也没有太大意义，但毕竟 sum 涉及到加法运算，所以它不会被剥掉。</strong></p>
<h4 id="删除重复的-ORDER-BY-KEY"><a href="#删除重复的-ORDER-BY-KEY" class="headerlink" title="删除重复的 ORDER BY KEY"></a>删除重复的 ORDER BY KEY</h4><p><strong>类似于消除重复字段，如果指定了多个相同的排序字段，那么只会保留一个。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN SYNTAX <span class="keyword">SELECT</span> UserID <span class="keyword">FROM</span> datasets.hits_v1 </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> Age, Age, Age <span class="keyword">DESC</span>, Age <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184305683-1408761507.png" alt="img"></p>
<p><strong>我们看到即使不同的排序，也会只保留相同排序字段的第一个，因为同一个字段即升序又降序本身就很奇怪。</strong></p>
<h4 id="删除重复的-LIMIT-BY-KEY"><a href="#删除重复的-LIMIT-BY-KEY" class="headerlink" title="删除重复的 LIMIT BY KEY"></a>删除重复的 LIMIT BY KEY</h4><p><strong>还记得 LIMIT BY 吗？”LIMIT N BY 字段” 表示按照字段进行分组，然后选出每组的前 N 条数据。如果 BY 后面的字段重复了，那么也会删除掉。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN SYNTAX <span class="keyword">SELECT</span> UserID, URL <span class="keyword">FROM</span> datasets.hits_v1 </span><br><span class="line">LIMIT <span class="number">3</span> <span class="keyword">BY</span> UserID, UserID</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184316965-1106004376.png" alt="img"></p>
<h4 id="删除重复的-USING-KEY"><a href="#删除重复的-USING-KEY" class="headerlink" title="删除重复的 USING KEY"></a>删除重复的 USING KEY</h4><p><strong>USING 也是如此，直接看例子吧。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN SYNTAX</span><br><span class="line"><span class="keyword">SELECT</span> a.UserID, a.UserID, b.VisitID, a.URL, b.UserID</span><br><span class="line"><span class="keyword">FROM</span> datasets.hits_v1 a <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> datasets.visits_v1 b <span class="keyword">USING</span>(UserID, UserID);</span><br></pre></td></tr></table></figure>

<p><strong>USING 里面指定了两个 UserID，那么会变成一个。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184328254-1163018829.png" alt="img"></p>
<p><strong>USING 里面指定了两个 UserID，那么会变成一个，即使我们指定了前缀，比如 USING(a.UserID, b.UserID)，那么依旧会被优化成一个 UserID。</strong></p>
<p><strong>但是说实话，删除重复的 ORDER BY KEY、LIMIT BY KEY、USING KEY，正常情况下很难出现，因为谁会没事故意将一个字段重复写两遍啊。当然字段多了倒是有可能发生，因为字段一多就可能忘记某个字段已经写过一遍了，但是字段少的情况下几乎不可能发生。</strong></p>
<p><strong>所以这个 ClickHouse 的优化机制有点把人当傻子，大概感觉就是当你写了一个 1 + 1 &#x3D; 3，那么它能帮你改成 1 + 1 &#x3D; 2，然而查询一旦复杂，它就无法优化了。所以一切还需要我们来保证，当然后续 ClickHouse 的优化机制会变得越来越完善。</strong></p>
<h4 id="标量替换"><a href="#标量替换" class="headerlink" title="标量替换"></a>标量替换</h4><p><strong>这个主要体现在 WITH 子句上面，我们最开始介绍 WITH 子句的时候说过，WITH 子句可以给一个普通的表达式赋值，也可以给一个查询赋值，但查询只能返回一行数组。最终会将其作为一个标量，后续查询时直接用这个标量进行替换即可。这背后也是 ClickHouse 给我们做的优化，举个例子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> (<span class="keyword">SELECT</span> <span class="built_in">sum</span>(data_uncompressed_bytes) <span class="keyword">FROM</span> system.columns) <span class="keyword">AS</span> total_bytes</span><br><span class="line"><span class="keyword">SELECT</span> database, </span><br><span class="line">       (<span class="built_in">sum</span>(data_uncompressed_bytes) <span class="operator">/</span> total_bytes) <span class="operator">*</span> <span class="number">100</span> <span class="keyword">AS</span> database_disk_usage</span><br><span class="line"><span class="keyword">FROM</span> system.columns</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> database</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> database_disk_usage <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>

<p><strong>注意 WITH 语句中的 total_bytes，它是对 data_uncompressed_bytes 进行 sum 所得到的结果，如果在查询中多次使用 total_bytes，那么难道每次都要计算一遍吗？显然不是的，这个值是提前算好的，是一个标量，因为只有一行数据，如果都多列就是一个元组。后续使用的都是已经算好的值。</strong></p>
<h4 id="三元运算符优化"><a href="#三元运算符优化" class="headerlink" title="三元运算符优化"></a>三元运算符优化</h4><p><strong>如果开启了 optimize_if_chain_to_multiif 参数，那么三元运算符会被替换成 ，multiIf 函数，之前说过，这里就不再赘述了。</strong></p>
<h3 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h3><p><strong>介绍了一些 ClickHouse 的优化规则，我们来看一下在编写 SQL 时如何手动进行优化，或者说有哪些可以优化的点。因为 ClickHouse 的优化规则（或者说内置的优化器）实在太简单了，但凡有点关系型数据库经验的人都不会那么写，因此在编写 SQL 语句的时候只能靠我们保证质量。那么来看看都有哪些注意的点。</strong></p>
<h4 id="PREWHERE-替代-WHERE"><a href="#PREWHERE-替代-WHERE" class="headerlink" title="PREWHERE 替代 WHERE"></a>PREWHERE 替代 WHERE</h4><p><strong>PREWHERE 和 WHERE 语句的作用相同，用来过滤数据，但是 PREWHERE 只支持 MergeTree 系列的引擎。WHERE 语句是读取所有的字段，然后进行数据过滤，而 PREWHERE 则是指定了哪些字段就读取哪些字段。比如 age &gt; 18 and length &gt; 160，WHERE 的话会读取全部字段，然后进行数据过滤，再根据 SELECT 中指定的字段进行丢弃。PREWHERE 则是只读取 age 和 length 两个字段，因为过滤条件只有这两个字段，而将数据过滤之后，再根据 SELECT 中指定的字段进行补全（或丢弃）。</strong></p>
<p><strong>所以两者的区别在于读取的数据量不同，当查询列明显多于筛选列时，使用 PREWHERE 可以十倍提升性能。当然这些我们之前在介绍子句的时候说过了，并且我们说过 ClickHouse 会自动将 WHERE 优化成 PREWHERE，因此我们直接用 WHERE 就好。当然我们还说了有几种情况，ClickHouse 不会自动优化，因为在这几种情况下，优化带来的性能提升不大，具体可以回去看看。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPLAIN <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> datasets.hits_v1 <span class="keyword">WHERE</span> UserID <span class="operator">=</span> <span class="number">610708775678702928</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184338754-748042245.png" alt="img"></p>
<p><strong>在使用 * 的时候，ClickHouse 会自动展开成所有字段，然后重点是我们看到 WHERE 被替换成了 PREWHERE，证明确实会自动优化，当然我们说过可以通过设置 optimize_move_to_prewhere 为 1、0 进行开启、关闭，默认是开启的。另外这个配置可以通过 set 设置，那么它位于哪里呢？没错，显然是 users.xml 中。</strong></p>
<h4 id="数据采样"><a href="#数据采样" class="headerlink" title="数据采样"></a>数据采样</h4><p><strong>当我们要求数据的实时性高于数据的准确性时，数据采样就很有用了。记得在大四实习的时候，当时负责给各大上市公司做审计，由于数据量非常庞大，算一次要花上好几个小时。所以每次都先采样，只算百分之 10 到百分之 20 的数据，如果得出来的结果符合正常预期，那么再跑全量数据，这样会稳妥一些。如果上来就跑全量数据，最后发现结果算的不对就尴尬了。</strong></p>
<p><strong>当然我当时选择采样只是简单的对程序的准确性进行一些检测，但实际生产中的程序基本上都是准确的，这个时候如果用户执行了一个查询，那么为了很快的给出结果，选择随机采样是最合适的方式。以我之前的经验，如果数据倾斜不严重的话，那么采样 10% 的数据和全量数据计算出来的结果差别很小，当然具体怎么做还是要取决于你的业务。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ... <span class="keyword">FROM</span> ... SAMPLE <span class="number">0.1</span></span><br><span class="line"><span class="keyword">WHERE</span> ...</span><br></pre></td></tr></table></figure>

<p><strong>SAMPLE 放在 FROM 之后、WHERE 之前，至于具体用法之前已经说过了，可以回头看一下。</strong></p>
<h4 id="列裁剪与分区裁剪"><a href="#列裁剪与分区裁剪" class="headerlink" title="列裁剪与分区裁剪"></a>列裁剪与分区裁剪</h4><p><strong>ClickHouse 非常适合存储大数据量的宽表，因此我们应该避免使用 SELECT * 操作，这是一个非常影响的操作。应当对列进行裁剪，只选择你需要的列，因为字段越少，消耗的 IO 资源就越少，从而性能就越高。</strong></p>
<p><strong>而分区裁剪就是只读取需要分区，在过滤条件中指定，所以设计一个合适的分区表对后期查询是非常有帮助的。。</strong></p>
<h4 id="ORDER-BY-应当于-WHERE、LIMIT-一起使用"><a href="#ORDER-BY-应当于-WHERE、LIMIT-一起使用" class="headerlink" title="ORDER BY 应当于 WHERE、LIMIT 一起使用"></a>ORDER BY 应当于 WHERE、LIMIT 一起使用</h4><p><strong>对千万级以上的数据集进行排序的时候一定要搭配 WHERE 或 LIMIT 使用，可能有人觉得我只是排个序而已，为啥还要有这么多限制。因为事实上我们很少会对数据进行全局排序，而且数据量一大，全局排序的话内存很容易爆掉；如果设置了 max_bytes_before_external_sort，那么全局排序会在磁盘上进行，此时速度又是一个难以忍受的地方。因此在使用 ORDER BY 的时候，需要搭配 WHERE、LIMIT。</strong></p>
<h4 id="避免构建虚拟列"><a href="#避免构建虚拟列" class="headerlink" title="避免构建虚拟列"></a>避免构建虚拟列</h4><p><strong>虚拟列指的就是我们自己构造出来的字段，而在原表中是没有的，举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A, A <span class="operator">+</span> <span class="number">1</span> <span class="keyword">FROM</span> <span class="keyword">table</span>;</span><br></pre></td></tr></table></figure>

<p><strong>A 是表中的字段，但 A + 1 明显不是，它是我们构造出来的，所以叫虚拟列。但如果非必须的话，最好不要再结果集上构造虚拟机列，因为虚拟列非常消耗资源性能，可以考虑在拿到数据之后由前后端进行处理。</strong></p>
<h4 id="uniqCombined-替代-count-DISTINCT"><a href="#uniqCombined-替代-count-DISTINCT" class="headerlink" title="uniqCombined 替代 count(DISTINCT)"></a>uniqCombined 替代 count(DISTINCT)</h4><p><strong>我们之前说过 ClickHouse 提供了一些语法糖，例如这里的 count(DISTINCT column) 实际上就是 countDistinct(column)，只不过 ClickHouse 提供了类似于关系型数据库中 count(DISTINCT) 语法。并且在具体执行的时候，底层都对应 uniqExact 函数，举个例子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="keyword">DISTINCT</span> UserID), countDistinct(UserID), uniqExact(UserID) </span><br><span class="line"><span class="keyword">FROM</span> datasets.hits_v1;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184348897-1208726092.png" alt="img"></p>
<p><strong>但还是建议使用 count(DISTINCT)，因为这几个都是等价的，那么自然选一个看起来最熟悉的。那么这个我们说的 uniqCombined 有什么关系呢？原因是 uniqExact 是精确去重并统计数量，如果我们在数量上对统计的数据的误差有一定的容忍性，那么可以使用 uniqCombined，该函数使用类似 HyperLogLog 的算法，在速度上可以提升 10 倍以上，但牺牲了一些准确率。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184359366-125449336.png" alt="img"></p>
<h4 id="JOIN-操作"><a href="#JOIN-操作" class="headerlink" title="JOIN 操作"></a>JOIN 操作</h4><p><strong>在介绍 JOIN 之前我先说两句，很多公司在设计关系型数据库的表结构时，都会遵循相应的范式，但对于数据仓库而言是完全不需要的，数仓的重点在于分层。对于 OLAP 型的列式存储数据库而言，尤其是 ClickHouse，能不用 JOIN 就不用 JOIN，最好是单表操作，因此这就需要我们保证数据有冗余度，但这在数仓建设中完全 OK 。并且对于 ClickHouse 而言，它的 JOIN 也是比较奇葩的，那么它是怎么做的呢？</strong></p>
<p><strong>首先不管是 LEFT 还是 RIGHT，当 A 表和 B 表进行 JOIN 的时候，ClickHouse 都会将 B 表加载到内存，然后遍历 A 表数据，查询 B 表中有没有能与之关联上的数据，因此这就引出了第一个优化的原则：当大小表 JOIN 的时候，要保证小表在右侧。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- hits_v1 的数据量要远大于 visits_v1，然后我们来 JOIN 试一下</span></span><br><span class="line"><span class="comment">-- 这里为了避免输出大量信息，我们使用 count(*) 代替</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> datasets.hits_v1 a</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> datasets.visits_v1 b</span><br><span class="line"><span class="keyword">USING</span>(CounterID);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 上面是 hits_v1 作为左表进行左关联，等价于如下：将 hits_v1 作为右表进行右关联</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> datasets.visits_v1 b</span><br><span class="line"><span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> datasets.hits_v1 a</span><br><span class="line"><span class="keyword">USING</span>(CounterID);</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5(%E5%8D%81%E5%85%AD)/1229382-20210913184416415-1275656254.png" alt="img"></p>
<p><strong>我们看到效率确实有差异，而 JOIN 之后的数据量比 hits_v1 表还要多，说明中间产生了笛卡尔积。如果不想产生笛卡尔积，那么只需要在 LEFT JOIN 和 RIGHT JOIN 的前面加上 ANY 即可，默认是 ALL。</strong></p>
<blockquote>
<p><strong>但还是上面那句话，能不用 JOIN 就不要用 JOIN，当涉及到两张表的时候，看看是否可以用子查询来替代。</strong></p>
</blockquote>
<p><strong>然后是谓词下推，我们举个栗子：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.UserID, a.Age, b.CounterID </span><br><span class="line"><span class="keyword">FROM</span> datasets.hits_v1 a</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> datasets.visits_v1 b</span><br><span class="line"><span class="keyword">USING</span>(CounterID) <span class="keyword">WHERE</span> a.EventDate <span class="operator">=</span> <span class="string">&#x27;2020-04-17&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>上面会先对两张表进行 JOIN，完事之后再进行过滤，既然如此的话，那么为什么不能先过滤然后再进行 JOIN 呢？</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.<span class="operator">*</span>, b.CounterID </span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> UserID, Age <span class="keyword">FROM</span> datasets.hits_v1 <span class="keyword">WHERE</span> EventDate <span class="operator">=</span> <span class="string">&#x27;2020-04-17&#x27;</span>) a</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> datasets.visits_v1 b</span><br><span class="line"><span class="keyword">USING</span>(CounterID) </span><br></pre></td></tr></table></figure>

<p><strong>下面的做法会比上面要快，因为在 JOIN 之前就将数据过滤掉了一部分，不要小看这一点，有时对性能的影响很大。并且 ClickHouse 不会主动帮我们发起谓词下推的操作，需要我们自己手动完成。可能有人好奇，如果将过滤条件放在 ON 子句后面会怎么样，答案是会报错，因为 ClickHouse 不允许 ON 子句中出现过滤条件。</strong></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><strong>以上就是 ClickHouse 关于优化方面的内容，说实话都比较简单，总之重点就是我们在写 SQL 的时候一定要注意，不能够随心所欲，因为 ClickHouse 所能做到的优化是非常有限的。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的数据类型(三)</title>
    <url>/2023/02/01/ClickHouse%20%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(%E4%B8%89)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的数据类型-三"><a href="#ClickHouse-的数据类型-三" class="headerlink" title="ClickHouse 的数据类型(三)"></a>ClickHouse 的数据类型(三)</h1><p>​																	本文来源： (<a href="https://www.cnblogs.com/traditional/p/15218628.html">https://www.cnblogs.com/traditional/p/15218628.html</a>) </p>
<hr>
<h3 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h3><p><strong>作为一款分析型数据库，ClickHouse 提供了许多数据类型，它们可以划分为基础类型、复合类型和特殊类型。其中基础类型使 ClickHouse 具备了描述数据的基本能力，而另外两种类型则使 ClickHouse 的数据表达能力更加的丰富立体。</strong></p>
<p><strong>下面就来分门别类的介绍一下。</strong></p>
<h3 id="基础类型"><a href="#基础类型" class="headerlink" title="基础类型"></a>基础类型</h3><p><strong>基础类型只有数值、字符串和时间三种类型，注：准确来说，还有布尔类型（Bool），但由于没有 true、false，所以一般都用整型（UInt8）表示布尔类型，1 为真 0 为假。</strong></p>
<h4 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h4><p><strong>数值类型分为整数、浮点数和 Decimal 三类，接下来分别进行说明。</strong></p>
<p><strong>1）Int</strong></p>
<p><strong>在普遍观念中，常用 Tinyint、Smallint、Int 和 Bigint 指代整数的不同取值范围，而 ClickHouse 则直接使用 Int8、Int16、Int32、Int64 来指代 4 种大小的 Int 类型，其末尾的数字则表示该类型的整数占多少位。可以认为：Int8 等价于 Tinyint、Int16 等价于 Smallint、Int32 等价于 Int、Int64 等价于 Bigint。</strong></p>
<p><strong>ClickHouse 也支持无符号的整数，使用前缀 U 表示，比如：UInt8、UInt16、UInt32、UInt64。</strong></p>
<p><strong>2）Float</strong></p>
<p><strong>与整数类似，ClickHouse 直接使用 Float32 和 Float64 代表单精度浮点数和双精度浮点数，可以看成是 float 和 double。</strong></p>
<p><strong>ClickHouse 的浮点数支持正无穷、负无穷以及非数字的表达方式。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> <span class="number">1</span> <span class="operator">/</span> <span class="number">0</span>, <span class="number">-1</span> <span class="operator">/</span> <span class="number">0</span>, <span class="number">0</span> <span class="operator">/</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="number">1</span> <span class="operator">/</span> <span class="number">0</span>,</span><br><span class="line">    <span class="number">-1</span> <span class="operator">/</span> <span class="number">0</span>,</span><br><span class="line">    <span class="number">0</span> <span class="operator">/</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">Query id: e3b3712c<span class="number">-0506</span><span class="number">-4</span>b3b<span class="operator">-</span>b2d8<span class="number">-7</span>f936c548740</span><br><span class="line"></span><br><span class="line">┌─divide(<span class="number">1</span>, <span class="number">0</span>)─┬─divide(<span class="number">-1</span>, <span class="number">0</span>)─┬─divide(<span class="number">0</span>, <span class="number">0</span>)─┐</span><br><span class="line">│          inf │          <span class="operator">-</span>inf │          nan │</span><br><span class="line">└──────────────┴───────────────┴──────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>3）Decimal</strong></p>
<p><strong>如果要求高精度的数值运算，则需要使用Decimal、即定点数（类似于浮点数），ClickHouse 提供了 Decimal32、Decimal64 和 Decimal128 三种精度的Decimal。在定义表字段的类型时，可以通过两种形式声明：简写方式有 Decimal32(S)、Decimal64(S)、Decimal128(S) 三种，原生方式为 Decimal(P, S)，表示该定点数的整数位加上小数位的总长度最大为 P，其中小数位长度最多为 S。Decimal32 的 P 为 10、Decimal64 的 P 为 19、Decimal128 的 P 为 39。比如某个字段类型是 Decimal32(3)，那么表示该字段存储的定点数，其整数位加上小数位的总长度不超过 10，其中小数部分如果超过 3 位则只保留 3 位。</strong></p>
<p><strong>而在 SQL 中我们可以通过 toDecimal32 或 toDecimal64 将一个整数或浮点数变成定点数，比如：toDecimal32(2, 5) 得到的结果就是 2.00000。另外使用两个不同精度的 Decimal 进行四则远算的时候，它们的小数点位数会 S 发生变化。在进行加法和减法运算时，S 取最大值。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> toDecimal32(<span class="number">22</span>, <span class="number">3</span>) <span class="operator">+</span> toDecimal32(<span class="number">33</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> toDecimal32(<span class="number">22</span>, <span class="number">3</span>) <span class="operator">+</span> toDecimal32(<span class="number">33</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">Query id: a223565d<span class="operator">-</span>e6ba<span class="number">-4</span>db9<span class="operator">-</span>aa7d<span class="number">-1</span>cae37424128</span><br><span class="line"></span><br><span class="line">┌─plus(toDecimal32(<span class="number">22</span>, <span class="number">3</span>), toDecimal32(<span class="number">33</span>, <span class="number">2</span>))─┐</span><br><span class="line">│                                       <span class="number">55.000</span> │</span><br><span class="line">└──────────────────────────────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>在进行乘法运算时，S 取两者之和：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> toDecimal32(<span class="number">22</span>, <span class="number">3</span>) <span class="operator">*</span> toDecimal32(<span class="number">33</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> toDecimal32(<span class="number">22</span>, <span class="number">3</span>) <span class="operator">*</span> toDecimal32(<span class="number">33</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">0</span>f1bd695<span class="number">-9</span>f37<span class="number">-43</span>b4<span class="operator">-</span>a6d1<span class="operator">-</span>b2a62a1dd6c3</span><br><span class="line"></span><br><span class="line">┌─multiply(toDecimal32(<span class="number">22</span>, <span class="number">3</span>), toDecimal32(<span class="number">33</span>, <span class="number">2</span>))─┐</span><br><span class="line">│                                        <span class="number">726.00000</span> │</span><br><span class="line">└──────────────────────────────────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>在进行除法运算时，S 取被除数的值，此时要求被除数的 S 必须大于除数 S，否则报错。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> toDecimal64(<span class="number">6</span>, <span class="number">3</span>) <span class="operator">/</span>  toDecimal64(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> toDecimal64(<span class="number">6</span>, <span class="number">3</span>) <span class="operator">/</span> toDecimal64(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">55</span>b4a58f<span class="operator">-</span>b722<span class="number">-4487</span><span class="number">-8391</span><span class="number">-2</span>c08e6c764ca</span><br><span class="line"></span><br><span class="line">┌─divide(toDecimal64(<span class="number">6</span>, <span class="number">3</span>), toDecimal64(<span class="number">3</span>, <span class="number">2</span>))─┐</span><br><span class="line">│                                        <span class="number">2.000</span> │</span><br><span class="line">└──────────────────────────────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :) <span class="keyword">select</span> toDecimal64(<span class="number">6</span>, <span class="number">3</span>) <span class="operator">/</span>  toDecimal64(<span class="number">3</span>, <span class="number">4</span>)  <span class="comment">-- 这里会报错，因为被除数的 S 小于除数的 S</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> toDecimal64(<span class="number">6</span>, <span class="number">3</span>) <span class="operator">/</span> toDecimal64(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">6</span>f782411<span class="number">-0</span>d15<span class="number">-4</span>ab8<span class="operator">-</span>adab<span class="operator">-</span>be19c9f6b0e2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">0</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.003</span> sec.</span><br><span class="line"></span><br><span class="line">Received exception <span class="keyword">from</span> server (version <span class="number">21.7</span><span class="number">.3</span>):</span><br><span class="line">Code: <span class="number">69.</span> DB::Exception: Received <span class="keyword">from</span> localhost:<span class="number">9000.</span> DB::Exception:</span><br><span class="line"><span class="type">Decimal</span> <span class="keyword">result</span><span class="string">&#x27;s scale is less than argument&#x27;</span>s <span class="keyword">one</span>: While processing toDecimal64(<span class="number">6</span>, <span class="number">3</span>) <span class="operator">/</span> toDecimal64(<span class="number">3</span>, <span class="number">4</span>).</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>另外还有一点需要注意：由于现代计算机系统只支持 32 或者 64 位，所以 Decimal128 是在软件层面模拟出来的，它的速度会比 Decimal32、Decimal64 要慢。</strong></p>
<h4 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h4><p><strong>字符串类型可以细分为 String、FixedString 和 UUID 三类，从命名来看仿佛不像是一款数据库提供的类型，反倒像一门编程语言的设计。</strong></p>
<p><strong>1）String</strong></p>
<p><strong>字符串由 String 定义，长度不限，因为在使用 String 的时候无需声明大小。它完全代替了传统意义上的 Varchar、Text、Clob 和 Blob 等字符类型。String 类型不限定字符集，因为它根本没有这个概念，所以可以将任意编码的字符串存入其中。但是为了程序的规范性和可维护性，在同一套程序中使用统一的编码，比如 utf-8，就是一种很好的约定。</strong></p>
<p><strong>2）FiexedString</strong></p>
<p><strong>FixedString 类型和传统意义上的 Char 类型有些类似，对于一些有着明确长度的场合，可以使用 FixedString(N) 来声明固定长度的字符串。但与 char 不同的是，FixedString 使用 NULL 字节来填充末尾字符，而 char 通常使用空格填充。</strong></p>
<p><strong>可以使用 toFixedString 生成 FixedString。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> toFixedString(<span class="string">&#x27;satori&#x27;</span>, <span class="number">7</span>), length(toFixedString(<span class="string">&#x27;satori&#x27;</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    toFixedString(<span class="string">&#x27;satori&#x27;</span>, <span class="number">7</span>),</span><br><span class="line">    length(toFixedString(<span class="string">&#x27;satori&#x27;</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">45</span>fe6e26<span class="number">-0540</span><span class="number">-40</span>de<span class="number">-9</span>eaf<span class="operator">-</span>aeefd12a3a1b</span><br><span class="line"></span><br><span class="line">┌─toFixedString(<span class="string">&#x27;satori&#x27;</span>, <span class="number">7</span>)─┬─length(toFixedString(<span class="string">&#x27;satori&#x27;</span>, <span class="number">7</span>))─┐</span><br><span class="line">│ satori                     │                                  <span class="number">7</span> │</span><br><span class="line">└────────────────────────────┴────────────────────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>3）UUID</strong></p>
<p><strong>UUID 是一种数据库常见的主键类型，在 ClickHouse 中直接把它作为一种数据类型。UUID 共有 32 位，它的格式为 8-4-4-4-12。如果一个 UUID 类型的字段在写入数据的时候没有被赋值，那么它会按照相应格式用 0 填充。</strong></p>
<h4 id="时间类型"><a href="#时间类型" class="headerlink" title="时间类型"></a>时间类型</h4><p><strong>时间类型分为 DateTime、DateTime64 和 Date三类。</strong></p>
<p><strong>1）DateTime</strong></p>
<p><strong>DateTime 类型包含年、月、日、时、分、秒信息，精确到秒，支持使用字符串的方式写入；</strong></p>
<p><strong>2）DateTime64</strong></p>
<p><strong>DateTime64 可以记录亚秒，它在 DateTime 之上增加了精度的设置。举个栗子：DateTime64 类型的时间可以是 2018-01-01 12:12:32.22；但如果是 DateTime 的话，则是2018-01-01 12:12:32，也就是说最后的 .22 没了。</strong></p>
<p><strong>3）Date</strong></p>
<p><strong>Date 类型不包含具体的时间信息，只精确到天，并且和 DateTime、DateTime64 一样，支持字符串写入。</strong></p>
<h3 id="复合类型"><a href="#复合类型" class="headerlink" title="复合类型"></a>复合类型</h3><p><strong>除了基础数据类型之外，ClickHouse 还提供了数组、元组、枚举和嵌套，总共四种复合类型。这些类型通常都是其他数据库原生不具备的特性，拥有了复合类型之后，ClickHouse 的数据模型表达能力就更强了。</strong></p>
<h4 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h4><p><strong>数据有两种定义形式，常规方式 Array(T)，比如某个字段是包含 UInt8 的数组，那么就可以声明为 Array(UInt8)；需要说明的是，ClickHouse 中的类型是区分大小写的，比如这里的 Array 就不可以写成 array，UInt8 不可以写成 uint8。</strong></p>
<p><strong>当然在查询的时候，我们可以通过 array 函数创建一个数组。注意：ClickHouse 中的绝大部分函数也是区分大小写的，只要是你在其它关系型数据库中没有见过的函数，基本上都区分大小写。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> <span class="keyword">array</span>(<span class="number">1</span>, <span class="number">2</span>) <span class="keyword">as</span> a, toTypeName(a)  <span class="comment">-- toTypeName 表示获取字段的类型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>] <span class="keyword">AS</span> a,</span><br><span class="line">    toTypeName(a)</span><br><span class="line"></span><br><span class="line">Query id: b22e371f<span class="operator">-</span>d5fc<span class="number">-4245</span><span class="operator">-</span>b299<span class="operator">-</span>a79a344fc7ea</span><br><span class="line"></span><br><span class="line">┌─a─────┬─toTypeName(<span class="keyword">array</span>(<span class="number">1</span>, <span class="number">2</span>))─┐</span><br><span class="line">│ [<span class="number">1</span>,<span class="number">2</span>] │ <span class="keyword">Array</span>(UInt8)            │</span><br><span class="line">└───────┴─────────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>这里只是演示，关于具体的语法后面说，</strong></p>
</blockquote>
<p><strong>在查询的时候简写成 [v1, v2, v3, …] 也是可以的；</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> [<span class="number">1</span>, <span class="number">2</span>] <span class="keyword">as</span> a, toTypeName(a)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>] <span class="keyword">AS</span> a,</span><br><span class="line">    toTypeName(a)</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">50</span>d4e367<span class="operator">-</span>cd1b<span class="number">-4826</span><span class="operator">-</span>bca8<span class="operator">-</span>eb913e6fbaeb</span><br><span class="line"></span><br><span class="line">┌─a─────┬─toTypeName([<span class="number">1</span>, <span class="number">2</span>])─┐</span><br><span class="line">│ [<span class="number">1</span>,<span class="number">2</span>] │ <span class="keyword">Array</span>(UInt8)       │</span><br><span class="line">└───────┴────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>从上述的例子中可以发现，在查询时并不需要主动声明数据的元素类型，因为 ClickHouse 的数组拥有类型推断的能力，推断的依据是：以最小存储代价为原则，即使用最小可表达的数据类型。比如：<code>array(1, 2)</code> 会使用 UInt8 作为数组类型。但如果数组中存在 NULL 值，元素类型将变为 Nullable。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">select</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="keyword">NULL</span>] <span class="keyword">as</span> a, toTypeName(a)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="keyword">NULL</span>] <span class="keyword">AS</span> a,</span><br><span class="line">    toTypeName(a)</span><br><span class="line"></span><br><span class="line">Query id: <span class="number">95</span>eb5bfa<span class="number">-5008</span><span class="number">-4</span>bd0<span class="operator">-</span>ac94<span class="operator">-</span>bd2e39de6485</span><br><span class="line"></span><br><span class="line">┌─a──────────┬─toTypeName([<span class="number">1</span>, <span class="number">2</span>, <span class="keyword">NULL</span>])─┐</span><br><span class="line">│ [<span class="number">1</span>,<span class="number">2</span>,<span class="keyword">NULL</span>] │ <span class="keyword">Array</span>(Nullable(UInt8))   │</span><br><span class="line">└────────────┴──────────────────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>数组里面的元素可以有多种，但前提是它们必须能够兼容，比如：<code>[1, 2.13]</code> 可以，但是 <code>[1, &#39;ABC&#39;]</code> 则不行。而在定义表字段的时候，如果使用 Array 类型，则需要指定明确的元素类型，比如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_name (</span><br><span class="line">	arr <span class="keyword">Array</span>(String)  <span class="comment">--指定明确类型</span></span><br><span class="line">) ENGINE <span class="operator">=</span> Memory</span><br></pre></td></tr></table></figure>

<h4 id="Tuple"><a href="#Tuple" class="headerlink" title="Tuple"></a>Tuple</h4><p><strong>元组由 1 ~ n 个元素组成，每个元素之间允许设置不同的数据类型，且彼此之间不要求兼容。元组同样支持类型推断，其推断依据仍然是以最小存储代价为原则。与数组类似，在 SQL 中我们可以通过 Tuple(T) 来定义。</strong></p>
<p><strong>类似数组，我们可以使用 tuple 函数在查询的时候创建元组：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">satori :) <span class="keyword">SELECT</span> tuple(<span class="number">1</span>, <span class="string">&#x27;a&#x27;</span>, now()) <span class="keyword">as</span> a, (<span class="number">1</span>, <span class="number">3</span>, <span class="string">&#x27;666&#x27;</span>) <span class="keyword">as</span> b</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    (<span class="number">1</span>, <span class="string">&#x27;a&#x27;</span>, now()) <span class="keyword">AS</span> a,</span><br><span class="line">    (<span class="number">1</span>, <span class="number">3</span>, <span class="string">&#x27;666&#x27;</span>) <span class="keyword">AS</span> b</span><br><span class="line"></span><br><span class="line">Query id: ab97ea39<span class="operator">-</span>accd<span class="number">-4</span>eaa<span class="number">-85</span>b0<span class="operator">-</span>c1728fde57e4</span><br><span class="line"></span><br><span class="line">┌─a─────────────────────────────┬─b───────────┐</span><br><span class="line">│ (<span class="number">1</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;2021-08-05 01:10:07&#x27;</span>) │ (<span class="number">1</span>,<span class="number">3</span>,<span class="string">&#x27;666&#x27;</span>) │</span><br><span class="line">└───────────────────────────────┴─────────────┘</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">rows</span> <span class="keyword">in</span> set. Elapsed: <span class="number">0.002</span> sec.</span><br><span class="line"></span><br><span class="line">satori :)</span><br></pre></td></tr></table></figure>

<p><strong>关于数组和元组的区别，熟悉 Python 的话应该很清楚，答案是元组不可变。在定义表字段时，元组也需要指定明确的元素类型。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_name (</span><br><span class="line">    <span class="comment">-- 可以指定多个类型</span></span><br><span class="line">    <span class="comment">-- 但是注意：Tuple(String, Int8) 表示 tpl 字段的值只能是含有两个元素的元组</span></span><br><span class="line">    <span class="comment">-- 并且第一个元素为 String，第二个元素为 Int8</span></span><br><span class="line">    tpl Tuple(String, Int8)</span><br><span class="line">) ENGINE <span class="operator">=</span> Memory</span><br></pre></td></tr></table></figure>

<p><strong>而在数据写入的过程中会进行类型检查。例如，写入 <code>(&#39;abc&#39;, 123)</code> 是可行的，但是 <code>(&#39;abc&#39;, &#39;def&#39;)</code> 则报错。</strong></p>
<h4 id="Enum"><a href="#Enum" class="headerlink" title="Enum"></a>Enum</h4><p><strong>ClickHouse 支持枚举类型，这是一种在定义常量时经常会使用的数据类型。ClickHouse 提供了 Enum8 和 Enum16 两种枚举类型，它们之间除了取值范围不同之外，别无二致。枚举固定使用 <code>(String:Int)</code> 键值对的形式定义数据，所以 Enum8 和 Enum16 分别会对应 (String:Int8) 和 (String:Int16)，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_name(</span><br><span class="line">	e Enum(<span class="string">&#x27;ready&#x27;</span><span class="operator">=</span><span class="number">1</span>, <span class="string">&#x27;start&#x27;</span><span class="operator">=</span><span class="number">2</span>, <span class="string">&#x27;success&#x27;</span><span class="operator">=</span><span class="number">3</span>, <span class="string">&#x27;error&#x27;</span><span class="operator">=</span><span class="number">4</span>)</span><br><span class="line">) ENGINE <span class="operator">=</span> Memory</span><br></pre></td></tr></table></figure>

<p><strong>在定义枚举集合的时候，有几点需要注意。首先，Key 和 Value 是不允许重复的，要保证唯一性。其次，Key 和 Value 的值都不能为 Null，但 Key 允许为空字符串。在写入枚举数据的时候，只会用到 Key 字符串部分，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name <span class="keyword">VALUES</span>(<span class="string">&#x27;ready&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>另外在数据写入的时候，会对照枚举集合项的内容进行逐一检查，如果 Key 字符串不存在集合范围内则会抛出异常，比如执行下面的语句就会报错：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name <span class="keyword">VALUES</span>(<span class="string">&#x27;abc&#x27;</span>)  <span class="comment">-- 会报错</span></span><br></pre></td></tr></table></figure>

<p><strong>可能有人觉得，完全可以使用 String 代替枚举，为什么还需要专门实现枚举类型呢？答案是出于对性能的考虑。因为虽然枚举中定义的 Key 是属于 String 类型，但是在后续对枚举的所有操作中（包括排序、分子、去重、过滤等），会使用 Int 类型的 Value 值。</strong></p>
<h4 id="Nested"><a href="#Nested" class="headerlink" title="Nested"></a>Nested</h4><p><strong>嵌套类型，顾名思义是一种嵌套表结构。一张数据表，可以定义任意多个嵌套类型字段，但每个字段的嵌套层级只支持一级，即嵌套表内不能继续使用嵌套类型。对于简单场景的层级关系或关联关系，使用嵌套类型也是一种不错的选择。例如，我们下面创建一张表 nested_test，具体的建表逻辑后面会说，当然本身也不是特别难的东西。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> nested_test (</span><br><span class="line">    name String,</span><br><span class="line">    age UInt8,</span><br><span class="line">    dept Nested(</span><br><span class="line">        id UInt32,</span><br><span class="line">        name String</span><br><span class="line">    )</span><br><span class="line">) ENGINE <span class="operator">=</span> Memory;</span><br></pre></td></tr></table></figure>

<p><strong>ClickHouse 的嵌套类型和传统的嵌套类型不相同，导致在初次接触它的时候会让人十分困惑。以上面这张表为例，如果按照它的字面意思来理解，会很容易理解成 nested_test 与 dept 是一对一的包含关系，其实这是错误的。不信可以执行下面的语句，看看会是什么结果:</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(%E4%B8%89)/1229382-20210816173421844-1247165096.png" alt="img"></p>
<p><strong>我们看到报错了，现在大家应该明白了，嵌套类型本质是一种多维数组的结构。嵌套表中的每个字段都是一个数组，并且行与行之间数组的长度无须对齐。所以需要把刚才的 INSERT 语句调整成下面的形式:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> nested_test <span class="keyword">VALUES</span>(<span class="string">&#x27;nana&#x27;</span>, <span class="number">20</span>, [<span class="number">10000</span>, <span class="number">10001</span>, <span class="number">10002</span>], [<span class="string">&#x27;唐辛子&#x27;</span>, <span class="string">&#x27;ななかぐら&#x27;</span>, <span class="string">&#x27;ゴウマ&#x27;</span>]);</span><br><span class="line"><span class="comment">-- 行与行之间，数组长度无需对齐。</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> nested_test <span class="keyword">VALUES</span>(<span class="string">&#x27;nana&#x27;</span>, <span class="number">20</span>, [<span class="number">10000</span>, <span class="number">10001</span>], [<span class="string">&#x27;唐辛子&#x27;</span>, <span class="string">&#x27;ななかぐら&#x27;</span>]);</span><br></pre></td></tr></table></figure>

<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(%E4%B8%89)/1229382-20210816173429946-443566030.png" alt="img"></p>
<p><strong>需要注意的是，在同一行数据内每个数组字段的长度必须相等。例如，在下面的示例中，由于行内数组字段的长度没有对齐，所以会抛出异常：</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(%E4%B8%89)/1229382-20210816173436084-896104477.png" alt="img"></p>
<p><strong>提示我们长度不一样。</strong></p>
<p><strong>在访问嵌套类型的数据时需要使用点符号，例如:</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(%E4%B8%89)/1229382-20210816173442804-826048657.png" alt="img"></p>
<h3 id="特殊类型"><a href="#特殊类型" class="headerlink" title="特殊类型"></a>特殊类型</h3><p><strong>ClickHouse 还有一类不同寻常的数据类型，将它们定义为特殊类型。</strong></p>
<h4 id="Nullable"><a href="#Nullable" class="headerlink" title="Nullable"></a>Nullable</h4><p><strong>准确来说，Nullable 并不能算是一种独立的数据类型，它更像是一种辅助的修饰符，需要与基础数据类型一起搭配使用。Nullable 类型与 Python 类型注解里面的 Optional 有些相似，它表示某个基础数据类型可以是 NULL 值。其具体用法如下所示:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> null_test (</span><br><span class="line">    col1 String,</span><br><span class="line">    col2 Nullable(UInt8)</span><br><span class="line">) ENGINE <span class="operator">=</span> Memory</span><br></pre></td></tr></table></figure>

<p><strong>通过 Nullable 修饰后 col2 字段可以被写入 NULL 值:</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> null_test <span class="keyword">VALUES</span> (<span class="string">&#x27;nana&#x27;</span>, <span class="keyword">NULL</span>);</span><br></pre></td></tr></table></figure>

<p><strong>在使用 Nullable 类型的时候还有两点值得注意：首先，它只能和基础类型搭配使用，不能用于数组和元组这些复合类型，也不能作为索引字段；其次，应该慎用 Nullable 类型，包括 Nullable 的数据表，不然会使查询和写入性能变慢。因为在正常情况下，每个列字段的数据会被存储在对应的 [Column].bin 文件中。如果一个列字段被 Nullable 类型修饰后，会额外生成一个 [Column].null.bin 文件专门保存它的 NULL 值。这意味着在读取和写入数据时，需要一倍的额外文件操作。</strong></p>
<h4 id="Domain"><a href="#Domain" class="headerlink" title="Domain"></a>Domain</h4><p><strong>域名类型分为 IPv4 和 IPv6 两类，本质上它们是对整型和字符串的进一步封装。IPv4 类型是基于 UInt32 封装的，它的具体用法如下所示：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> ip4_test (</span><br><span class="line">    url String,</span><br><span class="line">    ip IPv4</span><br><span class="line">) ENGINE <span class="operator">=</span> Memory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> ip4_test <span class="keyword">VALUES</span> (<span class="string">&#x27;www.nana.com&#x27;</span>, <span class="string">&#x27;127.0.0.1&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>细心的人可能会问，直接使用字符串不就行了吗？为何多此一举呢？至少有如下两个原因：</strong></p>
<p><strong>1）出于便捷性的考量，例如IPv4类型支持格式检查，格式错误的IP数据是无法被写入的，例如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> ip4_test <span class="keyword">VALUES</span>(<span class="string">&#x27;www,nana.com&#x27;</span>, <span class="string">&#x27;192.0.0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Exception <span class="keyword">on</span> client:</span><br><span class="line">Code: <span class="number">441.</span> DB::Exception: Invalid IPv4 value.: data <span class="keyword">for</span> <span class="keyword">INSERT</span> was parsed <span class="keyword">from</span> query</span><br><span class="line"></span><br><span class="line">Connecting <span class="keyword">to</span> localhost:<span class="number">9000</span> <span class="keyword">as</span> <span class="keyword">user</span> default.</span><br><span class="line">Connected <span class="keyword">to</span> ClickHouse server version <span class="number">21.7</span><span class="number">.3</span> revision <span class="number">54449.</span></span><br></pre></td></tr></table></figure>

<p><strong>2）出于性能的考量，同样以 IPv4 为例，IPv4 使用 UInt32 存储，相比 String 更加紧凑，占用的空间更小，查询性能更快。IPv6 类型是基于 FixedString(16) 封装的，它的使用方法与 IPv4 别无二致，此处不再赘述。</strong></p>
<p><strong>在使用 Domain 类型的时候还有一点需要注意，虽然它从表象上看起来与 String 一样，但 Domain 类型并不是字符串，所以它不支持隐式的自动类型转换。如果需要返回 IP 的字符串形式，则需要显式调用 IPv4NumToString 或 IPv6NumToString 函数进行转换。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的基本介绍(一)</title>
    <url>/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的基本介绍-一"><a href="#ClickHouse-的基本介绍-一" class="headerlink" title="ClickHouse 的基本介绍(一)"></a>ClickHouse 的基本介绍(一)</h1><p>​													</p>
<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><blockquote>
<p><strong>最近公司决定采用 ClickHouse 来做数据的大规模处理，关于 ClickHouse 虽然早有耳闻，但因为时间原因并没有专门去学习。而公司也考虑到目前内部具有 ClickHouse 使用经验的人还不是很多，因此给了相对比较充足的时间去了解。虽然 ClickHouse 诞生于 2016 年，但相对于 Hadoop 生态圈而言，普及度显然还没有那么广，因此除了官网之外还没有看到比较合适的教程。不过幸运的是在京东上面发现了一本关于 ClickHouse 的书，叫《ClickHouse 原理解析与应用实践》，由朱凯老师编写，据悉这是第一本讲解 ClickHouse 的书。看了一下目录，感觉内容还是比较充实的，于是果断买下来，用于学习。</strong></p>
<p><strong>因此本文很多内容均来自于此书，只不过书中的 ClickHouse 版本有些低了（ClickHouse 的发布频率还是挺快的），这里采用了一个比较新的版本，因此安装时的细节会有些不同。那么下面就开始 ClickHouse 的学习之旅吧，看看 ClickHouse 究竟是何方神圣，为何能够异军突起。</strong></p>
</blockquote>
<p><strong>Google 于 2003~2006 年相继发表了三篇论文：”Google File System”、”Google MapReduce”、”Google Bigtable”，将大数据的处理技术带进了大众视野，而 2006 年开源项目 Hadoop 的出现，则标志着大数据处理技术普及的开始，大数据技术真正开始走向大众。Hadoop 最初指的是分布式文件系统 HDFS 和 MapReduce 计算框架，但是它一路高歌猛进，在此基础之上像搭积木一样快速发展成为一个庞大的生态（被称为 Hadoop 生态圈），其中包括 Hive、HBase、Spark 等数十种框架。而在大数据分析场景的解决方案中，传统的关系型数据库很快就被 Hadoop 生态圈所取代，BI 领域就是其中之一。像传统关系型数据库所构建的数据仓库，就被以 Hive 为代表的大数据技术所取代，数据查询分析的手段更是层出不穷，Spark、Impala、Kylin 等框架百花齐放。Hadoop 发展至今，早已上升成为大数据的代名词，仿佛一提到海量数据分析场景下的技术选型，就非 Hadoop 生态莫属。</strong></p>
<p><strong>然而世间并没有银弹（万全之策），Hadoop 也跳不出这个规则。虽然 Hadoop 生态圈已经相当完善了，不同的组件也可以相互对接，例如分布式文件系统 HDFS 可以直接作为其他组件的底层存储（像 HBase、Hive 等），生态内部的组件之间不用重复造轮子，只需相互借力、组合就能形成新的方案。但生态化的另一面则可以看做臃肿和复杂，Hadoop 生态下每种组件都自成一体、相互独立，这种强强组合的技术组件有些时候则显得过于笨重了。与此同时，随着现代化终端系统对实时性的要求越来越高，Hadoop 生态在海量数据和高时效性的双重压力下，也显得有些力不从心了。</strong></p>
<p><strong>而这个时候，ClickHouse出现了，它是俄罗斯的 Yandex 公司于 2016 年开源的列式存储数据库，使用 C++ 语言编写，专门用于 OLAP（联机分析处理），其惊人的性能可以瞬间让你跪倒在它的石榴裙下。</strong></p>
<h2 id="什么是-OLAP？"><a href="#什么是-OLAP？" class="headerlink" title="什么是 OLAP？"></a>什么是 OLAP？</h2><p><strong>这里先回顾一下什么是 OLAP，以及实现 OLAP 的几种常见思路。</strong></p>
<p><strong>前面说了，OLAP 名为联机分析处理，又可以称之为多维分析处理，是由关系型数据之父于 1993 年提出的概念。顾名思义，它指的是通过多种不同的维度审视数据，进行深层次分析。维度可以看成是观察数据的一种视角，例如人类能看到的世界是三维的，它包含长、宽、高三个维度。直接一点理解，维度就好比是一张数据表的字段，而多维分析则是基于这些字段进行聚合查询。那么多维分析通常都包含哪些基本操作呢？为了更好地理解多维分析的概念，可以通过对一个立方体的图像进行具象化来描述。以如下一张销售明细表为例：</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012132202666-1270926469.png" alt="img"></p>
<p><strong>那么数据立方体可以进行如下操作：</strong></p>
<p><strong>下钻：从高层次向低层次明细数据进行穿透。例如从 “省” 下钻到 “市”，从 “湖北省” 穿透到 “武汉” 和 “宜昌” 。</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012132210489-1492902232.png" alt="img"></p>
<p><strong>上卷：和下钻相反，从低层次向高层次汇聚。例如从 “市” 汇聚到 “省”，将 “武汉” 和 “宜昌” 汇聚成 “湖北”。</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012132216589-314917835.png" alt="img"></p>
<p><strong>切片：观察立方体的一层，将一个或多个温度设为单个固定的值，然后观察剩余的维度，例如将商品维度固定为 “足球”。</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012132222084-206492651.png" alt="img"></p>
<p><strong>切块：和切片类似，只是将单个固定值变成多个固定值。例如将商品维度固定为”足球”、”篮球” 和 “乒乓球”。</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012132228079-1585593282.png" alt="img"></p>
<p><strong>旋转：旋转立方体的一面，如果要将数据映射到一张二维表，那么就要进行旋转，等同于行列转换。</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012132234073-1799091680.png" alt="img"></p>
<h3 id="OLAP-架构分类"><a href="#OLAP-架构分类" class="headerlink" title="OLAP 架构分类"></a>OLAP 架构分类</h3><p><strong>为了实现上述操作，将常见的 OLAP 架构大致分为三类。</strong></p>
<p><strong>第一类架构称为 ROLAP（Relational OLAP，关系型 OLAP），顾名思义，它直接使用关系模型构建，数据模型常使用星型模型或者雪花模型，这是最先能够想到、也是最为直接的实现方法。</strong></p>
<blockquote>
<p><strong>星型模型：事实表周围的维度表只能有一层；雪花模型：事实表周围的维度表可以有多层。</strong></p>
</blockquote>
<p><strong>因为 OLAP 概念在最初提出的时候，就是建立在关系型数据库之上的，多维分析的操作可以直接转成 SQL 查询。例如，通过上卷操作查看省份的销售额，就可以转成类似下面的 SQL 语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SUM</span>(价格) <span class="keyword">FROM</span> 销售数据表 <span class="keyword">GROUP</span> <span class="keyword">BY</span> 省;</span><br></pre></td></tr></table></figure>

<p><strong>但是这种架构对数据的实时处理能力要求很高，试想一下，如果对一张存有上亿条记录的表同时执行数十个字段的GROUP BY查询，将会发生什么事情？</strong></p>
<p><strong>第二类架构称为 MOLAP（Multidimensional OLAP，多维型 OLAP），它的出现就是为了缓解 ROLAP 性能问题。</strong></p>
<p><strong>MOLAP 使用多维数组的形式保存数据，其核心思想是借助预先聚合结果（说白了就是提前先算好，然后将结果保存起来），使用空间换取时间的形式从而提升查询性能。也就是说，用更多的存储空间换得查询时间的减少，其具体的实现方式是依托立方体模型的概念。首先，对需要分析的数据进行建模，框定需要分析的维度字段；然后，通过预处理的形式，对各种维度进行组合并事先聚合；最后，将聚合结果以某种索引或者缓存的形式保存起来（通常只保留聚合后的结果，不存储明细数据），这样一来，在随后的查询过程中，可以直接利用结果返回数据。</strong></p>
<p><strong>但是这种架构显然并不完美，原因如下：</strong></p>
<ul>
<li><strong>预聚合只能支持固定的分析场景，所以它无法满足自定义分析的需求。</strong></li>
<li><strong>维度的预处理会导致数据膨胀，这里可以做一次简单的计算，以上面的销售明细表为例，如果数据立方体包含了 5 个维度（字段），那么维度的组合方式就有 2525 种。维度组合爆炸会导致数据膨胀，这样会造成不必要的计算和存储开销。此外，用户并不一定会用到所有维度的组合，那么没有被用到的组合将会浪费。</strong></li>
<li><strong>另外，由于使用了预聚合的方式，数据立方体会有一定的滞后性，不能实时地进行数据分析。所以对于在线实时接收的流量数据，预聚合还需要考虑如何及时更新数据。而且立方体只保留了聚合后的结果数据，因此明细数据是无法查询的。</strong></li>
</ul>
<p><strong>第三类架构称为 HOLAP（Hybrid OLAP，混合架构的OLAP），这种思路可以理解成 ROLAP 和 MOLAP 两者的组合，这里不再展开，我们重点关注 ROLAP 和 MOLAP。</strong></p>
<h3 id="OLAP-实现技术的演进"><a href="#OLAP-实现技术的演进" class="headerlink" title="OLAP 实现技术的演进"></a>OLAP 实现技术的演进</h3><p><strong>在介绍了 OLAP 几种主要的架构之后，再来看看它们背后技术的演进过程，我们把这个演进过程划分为两个阶段。</strong></p>
<p><strong>第一个可以称为传统关系型数据库阶段。在这个阶段中，OLAP 主要基于以 Oracle、MySQL 为代表的一种关系型数据库实现。在 ROLA P架构下，直接使用这些数据作为存储与计算的载体；在 MOLAP 架构下，则借助物化视图的方式实现数据立方体。在这个时期，不论是 ROLAP 还是 MOLAP，在数据体量大、维度数目多的情况下都存在严重的性能问题，甚至存在根本查询不出结果的情况。</strong></p>
<p><strong>第二个阶段可以称为大数据技术阶段。由于大数据技术的普及，人们开始使用大数据技术重构 ROLAP 和 MOLAP。以 ROLAP 架构为例，传统关系型数据库就被 Hive 和 SparkSQL 这类新兴技术所取代。虽然，以 Spark 为代表的分布式计算系统，相比 Oracle 这类传统数据库而言，在面向海量数据的处理性能方面已经优秀很多，但是直接把它们作为面向终端用户的在线查询系统则还是太慢了。我们的用户普遍缺乏耐心，如果一个查询响应需要几十秒甚至数分钟才能返回，那么这套方案就完全行不通。再看 MOLAP 架构，MOLAP 背后也转为依托 MapReduce 或 Spark 这类新兴技术，将其作为立方体的计算引擎，进行立方体的构建，其预聚合结构的存储载体也转向 HBase 这类高性能分布式数据库。大数据技术阶段，主流 MOLAP 架构已经能够在亿万级数据的体量下，实现毫秒级的查询，但我们说 MOLAP 架构会存在维度爆炸、数据同步实时性不高的问题。</strong></p>
<p><strong>不难发现，虽然 OLAP 在经历了大数据技术的洗礼之后，其各方面性能已经有了脱胎换骨式的改观，但不论是 ROLAP 还是 MOLAP，仍然存在各自的痛点。可如果单纯从模型角度考虑，很明显 ROLAP 要更胜一筹，因为关系型数据库的存在，所以关系模型拥有最好的 “群众基础”，也更简单且容易理解。它直接面向明细数据查询，由于不需要预处理，也就自然没有预处理带来的负面影响（维度组合爆炸、数据实时性、更新问题）。那是否存在这样一种技术，它使用 ROLAP 模型，但同时又拥有比肩 MOLAP 的性能呢？</strong></p>
<p><strong>显然是存在的，就是我们今天的主角 ClickHouse，有一篇性能报告，在 10 亿条测试数据的体量下，Spark 被 ClickHouse 打的落花流水。ClickHouse 具有 ROLAP、在线实时查询、完整的 DBMS、列式存储、不需要任何数据预处理、支持批量更新、拥有非常完善的 SQL 支持和函数、支持高可用、不依赖 Hadoop 复杂生态、开箱即用等许多特点。特别是它那夸张的查询性能，我想大多数刚接触 ClickHouse 的人也一定会因为它的性能指标而动容。</strong></p>
<p><strong>在一系列官方公布的基准测试对比中，ClickHouse 都遥遥领先对手，这其中也不乏一些我们耳熟能详的名字。所有用于对比的数据库都使用了相同配置的服务器，在单个节点的情况下，对一张拥有 133 个字段的数据表分别在 1000 万、1 亿和 10 亿三种数据体量下执行基准测试，基准测试的范围涵盖 43 项SQL查询。在 1 亿数据级体量的情况下，ClickHouse 的平均响应速度是 Vertica 的2.63倍、InfiniDB 的 17 倍、MonetDB 的 27 倍、Hive 的 126 倍、MySQL 的 429 倍以及 Greenplum 的 10 倍。</strong></p>
<p><strong>此外 ClickHouse 是一款开源软件，遵循 Apache License 2.0 协议，所以它可以被免费使用。</strong></p>
<blockquote>
<p><strong>ClickHouse 的名字由来：ClickHouse 最初的设计目标是为了服务于自家公司的一款名叫 Metrica 流量分析工具。Metrica 在采集数据的过程中，一次页面点击（Click），就会产生一个事件（Event），就是基于页面的点击事件流（Stream），然后面向数据仓库进行 OLAP 分析。所以 ClickHouse 的全称是 Click Stream、Data WareHouse，简称 ClickHouse。</strong></p>
</blockquote>
<h2 id="初识-ClickHouse"><a href="#初识-ClickHouse" class="headerlink" title="初识 ClickHouse"></a>初识 ClickHouse</h2><p><strong>随着业务的迅猛增长，Yandex 公司的 Metrica 目前已经成为世界第三大 Web 流量分析平台，每天处理超过两百亿个跟踪事件，而之所以能够有如此惊人的体量，在背后为其提供支撑的 ClickHouse 功不可没。ClickHouse 已经为 Metrica 存储了超过 20 万亿行的数据，百分之 90 的查询能够在 1 秒内返回，其集群规模也已经超过了 400 台服务器。虽然 ClickHouse 起初只是为了 Metrica 而研发的，但由于它出众的性能，目前也被广泛应用于 Yandex 公司内部的其它数十个产品中。</strong></p>
<p><strong>除了 Yandex 自己以外，ClickHouse 还被众多商业公司或研究组织应用到了其生产环境。欧洲核子研究中心（CERN，想起了石头门）将它用于保存强对撞机试验后所记录的数十亿事件的测量数据，并成功将先前的数据查询时间从几个小时缩短到几秒；著名的 CDN 服务厂商 CloudFlare 将 ClickHouse 用于 HTTP 的流量分析；国内的头条、阿里巴巴、腾讯和新浪等一众互联网公司都在应用 ClickHouse。</strong></p>
<p><strong>可以说 ClickHouse 具备了人们对一款高性能 OLAP 数据库的美好向往，所以它基本能够胜任各种数据分析类的场景，并且随着数据体量的增大，它的优势也会变得越为明显。ClickHouse 非常适用于商业智能领域，也就是我们所说的 BI 领域。除此之外，它也能够被广泛应用于广告流量、Web、App流量、电信、金融、电子商务、信息安全、网络游戏、物联网等众多其它领域。</strong></p>
<p><strong>想必到了这里，你是不是产生了这样的一种错觉呢？ClickHouse 仿佛违背了物理定律，没有任何缺点，是一个不真实的存在，一款高性能、高可用 OLAP 数据库的一切诉求，ClickHouse 都能满足。但是估计很多人之前都是 Hadoop 生态圈的，那么你在转向 ClickHouse 的时候应该会有一些不适应，因为它和我们平时使用的技术的 “性格” 迥然不同，这是正常现象。如果把数据库比作汽车，那么 ClickHouse 俨然就是一辆手动挡的赛车，它在很多方面不像其它系统那样高度自动化。ClickHouse 的一些概念也和我们平常理解的有所不同，特别是在分片和副本方面，有些时候数据的分片甚至需要手动完成。但在进一步深入使用 ClickHouse 之后，我们就会渐渐理解这些设计的目的，某些看似不自动化的设计，在实际使用中反而带来了极大的灵活性。与 Hadoop 生态的其它数据库相比，ClickHouse 更像是一款传统 MPP 架构的列式存储数据库，它没有采用 Hadoop 生态中常用的主从架构，而是使用了多主对等网络结构，同时它也是基于关系模型的 ROLAP 方案。</strong></p>
<p><strong>那么下面就让我们抽丝剥茧，看看 ClickHouse 都有哪些核心特性。</strong></p>
<h3 id="完备的-DBMS-功能"><a href="#完备的-DBMS-功能" class="headerlink" title="完备的 DBMS 功能"></a>完备的 DBMS 功能</h3><p><strong>ClickHouse 拥有完备的管理功能，所以它称得上是一个 DBMS（DataBase Management System，数据库管理系统），而作为一个 DBMS，它具备如下功能：</strong></p>
<ul>
<li><code>DDL（数据定义语言）：可以动态地创建、修改或者删除数据库、表和视图，而无需重启服务</code></li>
<li><code>DML（数据操作语言）：可以动态地查询、插入、修改或删除数据</code></li>
<li><code>权限控制：可以按照用户粒度设置数据库或者表的操作权限，保障数据的安全性</code></li>
<li><code>数据备份与恢复：提供了数据备份导出与导入恢复机制，满足生产环境的要求</code></li>
<li><code>分布式管理：提供集群模式，能够自动管理多个数据库节点</code></li>
</ul>
<p><strong>上面只列举了一些最具代表性的功能，但这已然足以表明为什么 ClickHouse 称得上是 DBMS 了。</strong></p>
<p><strong>但是注意，ClickHouse 虽然很优秀，但它毕竟是一款面向 OLAP 的数据库，我们不能把它用于任何 OLTP 事务性操作的场景，因为它有以下几点不足：</strong></p>
<ul>
<li><code>不支持事务</code></li>
<li><code>不擅长根据主键按行粒度进行查询（虽然支持），所以不应该把 ClickHouse 当做键值对数据库使用</code></li>
<li><code>不擅长按行删除数据（虽然支持）</code></li>
</ul>
<p><strong>不过这些不足并不能算是 ClickHouse 的缺点，事实上其它的同类高性能面向 OLAP 的数据库一样不擅长上面这些。因为对于 OLAP 数据库而言，上述这些能力不是重点，只能说这是为了极致的查询性能所做的权衡。</strong></p>
<h3 id="列式存储与数据压缩"><a href="#列式存储与数据压缩" class="headerlink" title="列式存储与数据压缩"></a>列式存储与数据压缩</h3><p><strong>列式存储与数据压缩，对于一款高性能数据库来说是必不可少的特性。一个非常流行的观点认为：如果你想让查询变得更快，最简单且有效的方法就是减少数据扫描范围和数据传输时的大小，而列式存储和数据压缩就可以实现上面两点。列式存储和数据压缩通常是伴生的，因为一般来说列式存储是数据压缩的前提。</strong></p>
<p><strong>那什么是列式存储呢？</strong></p>
<p><strong>首先列式存储，或者说按列存储，相比按行存储，前者可以有效减少查询时需要扫描的数据量，我们可以举个栗子说明一下。假设一张数据表 A，里面有 50 个字段 A1 ~ A50，如果我们需要查询前 5 个字段的数据的话，那么可以使用如下 SQL 实现：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A1, A2, A3, A4, A5 <span class="keyword">from</span> A;</span><br></pre></td></tr></table></figure>

<p><strong>但是这样问题来了，数据库每次都会逐行扫描、并获取每行数据的全部字段，这里就是 50 个，然后再从中返回前 5 个字段。因此不难发现，尽管只需要前 5 个字段，但由于数据是按行进行组织的，实际上还是扫描了所有的字段。但如果数据是按列进行存储，则不会出现这样的问题，由于数据按列进行组织，数据库可以直接选择 A1 ~ A5 这 5 列的数据并返回，从而避免多余的数据扫描。为了更好的说明这两者的区别，我们画一张图：</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20210816173126709-1615157780.png" alt="img"></p>
<p><strong>如果是按行存储的话，那么假设我们要计算 age 这一列的平均值，就需要一行一行扫描，所以最终会至少扫描 11 个值（ 3 + 3 + 3 + 2 ）才能找到 age 这一列所存储的 4 个值。这意味着我们要花费更多的时间等待 IO 完成，而且读完之后还要扔掉很多（因为我们只需要部分字段）。但如果是按列存储的话，我们只需要获取 age 这一列的连续快，即可得到我们想要的 4 个值，所以这种操作速度更快、效率更高。</strong></p>
<p><strong>按列存储相比按行存储的另一个优势是对数据压缩的友好性，同样可以举一个栗子简单说明一下压缩的本质是什么。假设有个字符串 abcdefghi_bcdefghi，现在对它进行压缩，如下所示：</strong></p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">压缩前：abcdefghi_bcdefghi</span><br><span class="line">压缩后：<span class="built_in">abcdefghi_</span>(<span class="number">9</span>,<span class="number">8</span>)</span><br></pre></td></tr></table></figure>

<p><strong>可以看到，压缩的本质就是按照一定步长对数据进行匹配扫描，当发现重复部分的时候就会编码转换。例如上面的 <code>(9, 8)</code>，表示从下划线开始向前移动 9 个字节，会匹配到 8 个字节长度的重复项，即 bcdefghi。</strong></p>
<p><strong>尽管真实的压缩算法要比这个复杂许多，但压缩的本质就是如此。数据中的重复项越多，则压缩率越高；压缩率越高，则数据体量越小；而数据体量越小，在网络中传输的速度则越快，并且对网络带宽和磁盘 IO 的压力也就越小。可怎样的数据最可能具备重复的特性呢？答案是属于同一个列字段的数据，因为它们具有相同的数据类型和现实语义，重复项的可能性自然就更高。</strong></p>
<p><strong>ClickHouse 就是一款使用列式存储的数据库，数据按列进行组织，属于同一列的数据会被保存在一起，并进行压缩，而列与列之间的数据也会由不同的文件分别保存（这里主要是指 MergeTree 引擎，后续会详细介绍）。数据默认使用 LZ4 算法压缩，在 Yandex 公司的 Metrica 生产环境中，数据整体的压缩比可以达到 8 比 1（未压缩前 17 PB，压缩后 8 PB）。另外列式存储除了降低 IO 和存储的压力之外，还为向量化执行做好了铺垫。</strong></p>
<h3 id="向量化执行引擎"><a href="#向量化执行引擎" class="headerlink" title="向量化执行引擎"></a>向量化执行引擎</h3><p><strong>坊间有句玩笑：”能用 money 解决的问题，千万别花时间”。而业界也有种调侃与之如出一辙：”能升级硬件解决的问题，千万别优化程序”。有时候，你千辛万苦优化程序逻辑带来的性能提升，还不如直接升级硬件来的简单直接。这虽然是一句玩笑话不能当真，但硬件层面的优化确实是最简单粗暴、并且有效的途径之一。向量化执行就是典型代表，这项寄存器硬件层面的特性，为上层应用的程序在性能上带来了指数级的提升。</strong></p>
<p><strong>向量化执行可以简单地看做成一种消除程序中的循环所做的优化，举个栗子。假设小明在卖果汁，而榨一杯果汁假设需要 2 分钟，有客户抱怨太慢了，那么为了增加速度要怎么办呢？显然多准备几台榨汁机就好了，因此非向量化执行的方式是利用 1 台榨汁机重复 n 次，而向量化执行的方式是利用 n 台榨汁机只执行 1 次。</strong></p>
<p><strong>而为了实现向量化执行，需要利用 CPU 的 SIMD 指令。SIMD 的全称是：Single Instruction Multiple Data，即用单条指令操作多条数据。现代计算机系统概念中，它是通过数据并行以提高性能的一种实现方式（其它的还有指令级并行和线程级并行），它的原理是在 CPU 寄存器层面实现数据的并行计算。</strong></p>
<p><strong>在计算机系统的体系结构中，存储系统是一种层次结构，典型服务器计算机的存储层次结构如下所示：</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012235603619-407134725.png" alt="img"></p>
<p><strong>它们的大小会根据 CPU 的不同而不同，以我之前的个人笔记本电脑为例：</strong></p>
<p><img src="/2022/12/01/ClickHouse%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%20ClickHouse(%E4%B8%80)/1229382-20201012235609340-470453106.png" alt="img"></p>
<p><strong>从左向右距离 CPU 越近，访问速度就越快，显然能够容纳的数据大小也就越小；别忘了，CPU 寄存器也是可以存储数据的，CPU 从寄存器中获取数据的速度是最快的，是内存的 300 倍，磁盘的 3000 万倍。所以利用 CPU 向量化执行的特性，对于程序的性能提升有着非凡的意义。</strong></p>
<blockquote>
<p><strong>ClickHouse 目前使用 SSE 4.2 指令集实现向量化执行。</strong></p>
</blockquote>
<h3 id="关系模型与-SQL-查询"><a href="#关系模型与-SQL-查询" class="headerlink" title="关系模型与 SQL 查询"></a>关系模型与 SQL 查询</h3><p><strong>相比 HBase 和 Redis 这类 NoSQL 数据库，ClickHouse 使用关系模型描述数据并提供了传统数据库的概念（数据库、表、视图和函数等）。与此同时，ClickHouse 完全使用 SQL 作为查询语言（支持 GROUP BY、ORDER BY、JOIN、IN 等大多数标准 SQL），这使得它平易近人，容易理解和学习。因为关系型数据库和 SQL 语言，可以说是软件领域发展至今应用最为广泛的技术之一，也正因为 ClickHouse 提供了标准协议的 SQL 查询接口，使得现有的第三方分析可视化系统可以轻松地与它集成对接。而在 SQL 解析方面，ClickHouse 是大小写敏感的，这意味着 SELECT a 和 SELECT A 所代表的语义是不同的（关键字非大小写敏感）。</strong></p>
<p><strong>关系模型相比文档模型、键值对模型等等，拥有更好的描述能力，也能更加清楚地表示实体之间的关系。更重要的是，在 OLAP 领域，已有的大量数据建模工作都是基于关系模型展开的（星座模型、雪花模型和宽表模型）。ClickHouse 使用了关系模型，所以将构建在传统关系型数据库或者数仓之上的系统迁移到 ClickHouse 的成本会变得更低，可以直接沿用之前的经验成果。</strong></p>
<h3 id="多样化的表引擎"><a href="#多样化的表引擎" class="headerlink" title="多样化的表引擎"></a>多样化的表引擎</h3><p><strong>ClickHouse 并不是直接就一蹴而就的，Metrica 产品的最初架构是基于MySQL实现的，所以在 ClickHouse 的设计中，能够察觉到一些 MySQL 的影子，表引擎的设计就是其中之一。与 MySQL 类似，ClickHouse 也将存储部分进行了抽象，把存储引擎作为一层独立的接口，并且拥有合并树、内存、文件、接口等 20 多种引擎。其中每一种引擎都有着各自的特点，用户可以根据实际业务场景的需求，选择合适的引擎。</strong></p>
<p><strong>通常而言，一个通用系统意味着更广泛的实用性，能够适应更多的场景。但通用的另一种解释是平庸，因为它无法在所有场景中都做到极致。</strong></p>
<p><strong>在软件的世界中，并不会存在一个能够适用任何场景的通用系统，为了突出某项特性势必会在别处有所取舍。所以将表引擎独立设计的好处是显而易见的，通过特定的表引擎支撑特定的场景，十分灵活。对于简单的场景，可直接使用简单的引擎降低成本，而复杂的场景也有合适的选择。</strong></p>
<h3 id="多线程与分布式"><a href="#多线程与分布式" class="headerlink" title="多线程与分布式"></a>多线程与分布式</h3><p><strong>ClickHouse 几乎具备现代化高性能数据库的所有典型特征，对于可以提升性能的手段可谓是全部用尽，对于多线程和分布式这类被广泛应用的技术自然更是不在话下。</strong></p>
<p><strong>如果说向量化执行是通过数据级别的并行方式提升了性能，那么多线程处理就是通过线程级并行的方式实现了性能提升。相比基于底层硬件实现的向量化执行 SIMD，线程级并行通常由更高层次的软件层面控制。现代计算机系统早已普及了多处理器架构，所以现今市面上的服务器都具备良好的多核心多线程处理能力。由于 SIMD 不适合用于带有较多分支判断的场景，ClickHouse 也大量使用了多线程技术以实现提速，以此和向量化执行形成互补。</strong></p>
<p><strong>如果一个篮子装不下所以的鸡蛋，就多用几个篮子来装，这就是分布式设计中分而治之的思想。同理，如果一台服务器性能吃紧，那么就利用多台服务的资源协同处理。为了实现这一目标，首先就要在数据层面实现数据的分布式，因为在分布式领域，存在着一条公认的理论：移动计算优于移动数据。在各服务器之间，通过网络传输数据的成本是很高的，所以相比移动数据，更为聪明的做法是预先将数据分布到各台服务器，将数据的计算查询直接下推到数据所在的服务器。而 ClickHouse 在数据存储方面，既支持分区（纵向扩展，利用多线程资源），也支持分片（横向扩展，利用分布式原理），可以说是将多线程和分布式的技术应用到了极致。</strong></p>
<h3 id="多主架构"><a href="#多主架构" class="headerlink" title="多主架构"></a>多主架构</h3><p><strong>HDFS、Spark、HBase 和 Elasticsearch 这类分布式系统，都采用了 master-slave 主从架构，由一个管控节点作为 Leader 统筹全局，而 ClickHouse 则采用 multi-master 多主架构，集群中的每个节点角色对等，客户端访问任意一个节点都能得到相同的效果。这种多主架构有很多优势，例如对等的角色使系统架构变得更加简单，不用再区分主控节点、数据节点和计算节点，集群中的所有节点功能相同。所以它天然规避了单点故障的问题，非常适合用于多数据中心、异地多活的场景。</strong></p>
<h3 id="在线查询"><a href="#在线查询" class="headerlink" title="在线查询"></a>在线查询</h3><p><strong>ClickHouse 经常会被拿来与其它的分析性数据库做对比，比如 Vertica、SparkSQL、Hive 和 Elasticsearch 等，它与这些数据库确实存在许多相似之处。例如，它们都可以支撑海量数据的查询场景，都拥有分布式架构，都支持列存储、数据分片、计算下推等功能。这其实也说明了 ClickHouse 在设计上吸取了各路奇技淫巧，而与其它数据库相比，ClickHouse 也拥有明显的优势。例如，Vertica 这类商用软件价格高昂；SparkSQL 与 Hive 这类系统无法保障 90% 的查询都能在 1 秒内返回，在大数据量下的复杂查询可能会需要分钟级的响应时间；而 Elasticsearch 这类搜索引擎在处理亿级数据聚合查询时则已经显得捉襟见肘。</strong></p>
<p><strong>正如 ClickHouse 的 “广告词” 所言，其它的开源系统太慢，商用的系统太贵，只有 ClickHouse 在成本与性能之间选择了良好平衡，又快又开源。ClickHouse 当之无愧地阐释了 “在线” 二字的含义，即便是在复杂的查询场景下，它也能够做到极其快速的响应，且无需对数据进行任何预处理加工。</strong></p>
<h3 id="数据分片与分布式查询"><a href="#数据分片与分布式查询" class="headerlink" title="数据分片与分布式查询"></a>数据分片与分布式查询</h3><p><strong>数据分片是将数据进行横向切分，这是一种在面对海量数据的场景下，解决存储和查询瓶颈的有效手段，是一种分之思想的体现。ClickHouse 支持分片，而分片则依赖集群，每个集群可以有一到多个分片，但是注意：一个服务节点只能有一个分片，所以分片的数量取决于节点数量。那么什么是分片呢？往下看。</strong></p>
<p><strong>ClickHouse 并不像其他分布式系统那样，拥有高度自动化的分片功能，ClickHouse 提供了本地表（Local Table）和分布式表（Distributed Table）的概念。一张本地表等同于一份数据的分片，而分布式表本身不存储任何数据，它是本地表的访问代理，其作用类似分库中间件。借助分布式表，能够代理访问多个数据分片，从而实现分布式查询。</strong></p>
<p><strong>这类设计类似于数据库的分库和分表，十分灵活。例如在业务上线的初期，数据体量并不高，此时数据表并不需要多个分片。所以使用单个节点的本地表（单个数据分片）即可满足业务需求，待到业务增长、数据量增大的时候，再通过新增数据分片的方式分流数据，并通过分布式表实现分布式查询。这就好比一辆手动挡赛车，它将所有的选择权都交给了使用者。</strong></p>
<h3 id="ClickHouse-具有无与伦比的查询速度"><a href="#ClickHouse-具有无与伦比的查询速度" class="headerlink" title="ClickHouse 具有无与伦比的查询速度"></a>ClickHouse 具有无与伦比的查询速度</h3><p><strong>ClickHouse 查询速度快我们已经说过了，这里来探讨一下速度快的原因，虽然前面对这个问题已经做出了科学合理的解释，比方说：因为 ClickHouse 是列式存储数据库；ClickHouse 使用了向量化引擎等等。这些解释虽然都站得住脚，但是依然不能消除全部的疑问，因为这些技术不是什么秘密，市面有很多数据库同样使用了这些技术，但是依然没有 ClickHouse 这么快，因此我们需要从另外一个角度来探讨一番 ClickHouse 的秘诀到底是什么？</strong></p>
<p><strong>首先抛出一个疑问：在设计软件架构的时候，做设计的原则应该是自顶向下地去设计，还是自底向上地去设计呢？在传统的观念中，自然是自顶向下的设计，因为在做什么事情的一定先有一个大纲，然后再慢慢实现细节。而 ClickHouse 的设计则采用了自底向上的方式，因为它的原型早在 2008 年就诞生了，在诞生之处它并没有宏伟的规划。相反它的目的很单纯，就是希望能以最快的速度进行 GROUP BY 查询和过滤，那么战斗民族的攻城狮们是如何实现自底向上的设计呢？</strong></p>
<h4 id="着眼硬件，先想后做"><a href="#着眼硬件，先想后做" class="headerlink" title="着眼硬件，先想后做"></a>着眼硬件，先想后做</h4><p><strong>首先从硬件功能层面着手设计，在设计伊始就至少需要想清楚如下几个问题：</strong></p>
<ul>
<li><code>将要使用的硬件水平是怎样的？包括 CPU、内存、硬盘、网络等等</code></li>
<li><code>在这样的硬件上，需要达到怎样的性能？包括延迟、吞吐量等等</code></li>
<li><code>准备使用怎样的数据结构？包括 String、HashTable、Vetcor 等等</code></li>
<li><code>选择这样的数据结构，在硬件上会如何工作？</code></li>
</ul>
<p><strong>如果能想清楚上面这些问题，那么在动手实现功能之前，就已经能够计算出粗略的性能了。所以，基于将硬件功效最大化的目的，ClickHouse 会在内存中进行 GROUP BY，并且使用 HashTable 装载数据。与此同时，攻城狮们非常在意 CPU L3 级别的缓存，因为一次 L3 的缓存失效将会带来 700~100ns 的延迟，这意味着在单核 CPU 上，它会浪费每秒 4000 万次的运算；而在一个 32 线程的 CPU 上，将会浪费每秒 5 亿次的运算。所以别小看这些细节，一点一滴地将它们累加起来，数据是非常可观的。正是因为注意这些细节，ClickHouse 在基准查询中才能做到每秒 1.75 亿次的数据扫描性能。</strong></p>
<h4 id="算法在前，抽象在后"><a href="#算法在前，抽象在后" class="headerlink" title="算法在前，抽象在后"></a>算法在前，抽象在后</h4><p><strong>常有人念叨：”有时候选择比努力更重要”，确实，路线选错了的话再努力也是白搭。在 ClickHouse 的底层实现中，经常会面对一些重复的场景，例如字符串子串查询、数据排序、使用 HashTable 等，如何才能实现性能的最大化呢？算法的选择就变成了重中之重。以字符串为例，有一本专门讲解字符串搜索的书，里面列举了 35 种常见的字符串搜索算法，那么你猜猜 ClickHouse 使用了里面的哪种算法呢？答案是一种都没有，因为性能不够快，在字符串搜索方面，针对不同的场景，ClickHouse 最终选择了这些算法：对于常量，使用 Volnitsky 算法；对于非常量，使用 CPU 的向量化执行 SIMD，暴力优化；正则匹配使用 re2 和 hyperscan 算法。</strong></p>
<blockquote>
<p><strong>性能是算法选择的首要考量指标。</strong></p>
</blockquote>
<h4 id="用于尝鲜，不行就换"><a href="#用于尝鲜，不行就换" class="headerlink" title="用于尝鲜，不行就换"></a>用于尝鲜，不行就换</h4><p><strong>除了字符串之外，其余的场景也与它类似，ClickHouse 会使用最合适、最快的算法。如果市面上出现了号称性能最强大的新算法，那么 ClickHouse 团队就会立即将其纳入并进行验证。如果效果不错就保留使用，不尽人意的话就将其丢弃。</strong></p>
<h4 id="特定场景，特殊优化"><a href="#特定场景，特殊优化" class="headerlink" title="特定场景，特殊优化"></a>特定场景，特殊优化</h4><p><strong>针对同一个场景的不同状况，选择使用不同的实现方式，尽可能将性能最大化。关于这一点，其实在前面介绍字符串查询的时候，针对不同场景选择不同算法的思路就有所体现了。</strong></p>
<p><strong>类似的例子还有很多，例如去重计数 uniqCombined 函数，会根据数据量的不同选择不同的算法；当数据量很小的时候，会选择使用 Array 保存；当数据量中等的时候，会选择 HashSet；而当数据量很大的时候，则使用 HyperLogLog 算法。</strong></p>
<p><strong>对于数据结构化比较清晰的场景，会通过代码生成技术实现循环展开，以减少循环次数。接着就是大家熟知的大杀器 “向量化执行”。SIMD 被广泛地应用于文本转换、数据过滤、数据解压和 JSON 转换等场景。相较于单纯地使用 CPU，利用寄存器暴力优化也算是一种降维打击了。</strong></p>
<h4 id="持续测试，持续改进"><a href="#持续测试，持续改进" class="headerlink" title="持续测试，持续改进"></a>持续测试，持续改进</h4><p><strong>如果只是单纯地在上述细节上下功夫，还不足以构建出如此强大的 ClickHouse，因此还需要一个能够持续验证、持续改进的机制。由于 Yandex 公司的天然优势，ClickHouse 经常使用真实的数据进行测试，这一点很好地保证了测试场景的真实性。与此同时，ClickHouse 算是更新速度最快的开源软件了，差不多每个月都能发布一个版本，没有一个可靠的持续集成环境，这一点是做不到的。正因为拥有这样的频率，ClickHouse 才能快速迭代、快速改进。</strong></p>
<p><strong>所以 ClickHouse 的黑魔法并不是一项单一的技术，而是一种自底向上的、追求极限性能的设计思路，这就是它如此块的秘诀。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的架构设计(二)</title>
    <url>/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的架构设计、安装方式以及连接工具-二"><a href="#ClickHouse-的架构设计、安装方式以及连接工具-二" class="headerlink" title="ClickHouse 的架构设计、安装方式以及连接工具(二)"></a>ClickHouse 的架构设计、安装方式以及连接工具(二)</h1><p>​															</p>
<h3 id="Column-与-Field"><a href="#Column-与-Field" class="headerlink" title="Column 与 Field"></a>Column 与 Field</h3><p><strong>Column 和 Field 是 ClickHouse 中最基础的映射单元，作为一款百分百的列式存储数据库，ClickHouse 按列存储数据，内存中的一个列就用一个 Column 对象表示。Column 对象分为接口和实现两个部分，在 IColumn 接口对象中，定义了对数据进行各种关系运算的方法，例如插入数据的 insertRangeFrom 方法和 insertFrom 方法，用于分页的 cut，以及用于数据过滤的 filter 方法等等。而这些方法的具体实现对象则根据数据类型的不同，由不同的对象实现，例如：ColumnString、ColumnArray 和 ColumnTuple 等等。在大部分场景中，ClickHouse 都会以整列的方式操作数据，但凡事也有例外，如果需要操作单个具体的值（也就是单列中的一行数据），则需要使用 Field 对象。Field 对象代表一个单值，与 Column 对象的泛化设计思路不同，Field 对象使用了聚合的设计模式。在 Field 对象内部聚合 Null、UInt64、String 和 Array 等 13 种数据类型及相应的处理逻辑，说白了就是这些值的类型虽然不同，但它们都是 Field 对象，因为这些类型的数据的处理逻辑都在 Field 对象里面。</strong></p>
<blockquote>
<p><strong>Column 对象是数据表中的一列，Field 对象相当于一个单元格。</strong></p>
</blockquote>
<h3 id="DataType"><a href="#DataType" class="headerlink" title="DataType"></a>DataType</h3><p><strong>数据的序列化和反序列化工作由 DataType 负责，IDataType 接口定义了许多正反序列化的方法，它们成对出现，例如 serializeBinary 和 deserializeBinary、serializeTextJSON 和 deserializeTextJSON 等等，涵盖了常用的二进制、文本、JSON、XML、CSV 和 Protobuf 等多种格式类型。IDataType 也使用了泛化的设计模式，具体方法的实现逻辑由对应数据类型的实例对象来承载，例如 DataTypeString、DataTypeArray 以及 DataTypeTuple 等等。</strong></p>
<blockquote>
<p><strong>接口内部定义相应的方法，具体的数据类负责实现。如果某个类实现了接口内部定义的所有方法，那么这个类就实现了这个接口，其实例对象就可以赋值给接口，通过接口来调用内部的方法。当然调用的方法必须是接口内部已经声明的，如果除了接口内部定义的方法之外，该类还定义了其它的方法，那么这些其它的方法就不能通过接口调用了。</strong></p>
<p><strong>那么接口设计有什么好处呢？首先最直观的一个好处就是实现了多态，因为不管是什么类，只要它实现了接口定义的方法，那么其实例对象就可以赋值给接口，即：一个接口，多种实现。</strong></p>
</blockquote>
<p><strong>另外 DataType 虽然负责序列化相关工作，但它并不直接负责数据的读取，而是从 Column 对象或 Field 对象中读取。在 DataType 的实现类中，聚合了相应数据类型的 Column 对象和 Field 对象。例如 DataTypeString 会引用字符串类型的 ColumnString，而 DataTypeArray 则会引用数组类型的 ColumnArray，以此类推。</strong></p>
<h3 id="Block-和-Block流"><a href="#Block-和-Block流" class="headerlink" title="Block 和 Block流"></a>Block 和 Block流</h3><p><strong>ClickHouse 内部的数据操作是面向 Block 对象进行的，并且采用了流的形式，虽然 Column 对象和 Field 对象组成了数据的基本映射单元，但对应到实际操作，它们还少了一些必要的信息，比如数据的类型和列的名称。于是 ClickHouse 设计了 Block 对象，Block 对象可以看成是数据表的子集，Block 对象的本质是由数据对象、数据类型和列名称组成的三元组，即 Column、DataType、列名称字符串。Column 提供了数据的读取能力，而 DataType 知道如何正反序列化，所以 Block 对象在这些对象的基础上实现了进一步的抽象和封装，从而简化了整个使用的过程，仅通过 Block 对象就能完成一系列的数据操作。只不过在具体的实现过程中，Block 并没有直接聚合 Column 和 DataType 对象，而是通过 ColumnWithAndName 对象进行间接引用。</strong></p>
<p><strong>有了 Block 对象的这一层封装之后，对 Block 流的设计就是水到渠成的事情了，流操作有两组顶层接口：IBlockInputStream 负责数据的读取和关键运算，IBlockOutputStream 负责将数据输出到下一环节。Block 流也是用了泛化的设计模式，对数据的各种操作都会转换成其中一种流的实现。所以 IBlockInputStream 也是一个接口，内部定义了读取数据的若干个 read 虚方法，而具体的实现逻辑则交给它的实现类来填充，IBlockOutputStream 同理。</strong></p>
<p><strong>总共有 60 多个类实现了 IBlockInputStream 接口，它们覆盖了 ClickHouse 数据摄取的方方面面。这些实现类大致可以分为三类：第一类用于处理数据定义的 DDL 操作，例如 DDLQueryStatusInputStream 等；第二类用于处理数据关系运算的相关操作，例如 LimitBlockInputStream、JoinBlockInputStream、AggregatingBlockInputStream等；第三类则是与引擎呼应，每一种引擎都拥有与之对应的 BlockInputStream 实现，例如 MergeTreeBaseSelectBlockInputStream（MergeTree 引擎）、TinyLogBlockInputStream（TinyLog 引擎）以及 KafkaBlockInputStream（Kafka 引擎）等。</strong></p>
<p><strong>IBlockOutputStream 的设计也与 IBlockInputStream 如出一辙，IBlockOutputStream 接口同样定义了若干写入数据的 write 虚方法。但它的实现类比起 IBlockInputStream 要少很多，一共只有 20 多种，这些实现类基本用于引擎的相关处理，负责将数据写入下一环节或者最终目的地，例如：MergeTreeBlockOutputStream、TinyLogBlockOutputStream 以及 StorageFileBlockOutputStream 等。</strong></p>
<h3 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h3><p><strong>在数据表的底层设计中并没有所谓的 Table 对象，它是直接使用 IStroge 接口指代数据表，表的引擎是 ClickHouse 的一个显著特征，不同的表的引擎由不同的子类实现。例如：IStorageSystemOneBlock（系统表）、StorageMergeTree（合并树引擎）和 StorageTinyLog（日志表引擎）等。IStorage 接口定义了 DDL（如 ALTER、RENAME、OPTIMIZE 和 DROP 等）、read 和 write 方法，它们分别负责数据的定义、查询与写入。在数据查询时，IStorage 负责根据 AST 查询语句的指示要求，返回指定列的原始数据。后续对数据的进一步加工、计算和过滤则会统一交由 Interpreter 解释器对象处理。对 Table 发起的一次操作通常都会经历这样的过程，接收 AST 查询语句、根据 AST 返回指定列的数据，之后再将数据交给 Interpreter 做进一步处理。</strong></p>
<h3 id="Parser-和-Interpreter"><a href="#Parser-和-Interpreter" class="headerlink" title="Parser 和 Interpreter"></a>Parser 和 Interpreter</h3><p><strong>Parser 和 Interpreter 是非常重要的两组接口：Parser 分析器负责创建 AST 对象；而 Interpreter 解释器对象则负责解释 AST，并进一步创建查询的执行管道，它们与 IStorage 一起，串联起了整个数据查询的过程。</strong></p>
<p><strong>Parser 分析器可以将一条 SQL 语句以递归下降的方法解析成 AST（抽象语法树），不同的 SQL 语句会交给不同的 Parser 实现类来解析。例如，有负责解析 DDL 查询语句的 ParserRenameQuery、ParserDropQuery 和 ParserAlterQuery 解析器，还有负责解析 INSERT 语句的 ParserInsertQuery 解析器，还有负责 SELECT 语句的 ParserSelectQuery 等等。所以尽管 SQL 语句最终都会被解析成 AST，但不同的 SQL 语句会交给不同的 Parser 实现类进行解析</strong></p>
<p><strong>Interpreter 解释器的作用域就像 Service 服务器一样，起到串联整个查询过程的作用，它会根据解释器的类型，聚合它所需要的资源。首先它会解析 AST 对象，然后执行 “业务逻辑”（例如分支判断、设置参数、调用接口等）；最终返回 IBlock 对象，以线程的形式建立起一个查询执行管道。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20201012235617320-1692152376.png" alt="img"></p>
<h3 id="Functions-与-Aggregate-Functions"><a href="#Functions-与-Aggregate-Functions" class="headerlink" title="Functions 与 Aggregate Functions"></a>Functions 与 Aggregate Functions</h3><p><strong>ClickHouse 主要提供两类函数：普通函数和聚合函数，普通函数由 IFunction 接口定义，拥有数十种函数实现，例如 FunctionFormatDataTime、FunctionSubstring 等。除了一些常见的函数（诸如四则运算、日期转换）之外，也不乏一些非常使用的函数，例如网址提取函数、IP 地址脱敏函数等。普通函数是没有状态的，函数效果作用于每行数据之上。当然，在函数具体执行的过程中，并不会一行一行的运算，而是采用向量化执行的方式直接作用于一整列数据。</strong></p>
<p><strong>聚合函数由 IAggregateFunction 接口定义，相比无状态的普通函数，聚合函数是有状态的。以 COUNT 聚合函数为例，其 AggregateFunctionCount 的状态使用整型UInt64记录。聚合函数的状态支持序列化和反序列化，所以能够在分布式节点直接进行传输，以实现增量计算。</strong></p>
<h3 id="Cluster-与-Replication"><a href="#Cluster-与-Replication" class="headerlink" title="Cluster 与 Replication"></a>Cluster 与 Replication</h3><p><strong>ClickHouse 的集群由分片（Shard）组成，而每个分片又通过副本（Replica）组成，这种分层的概念，在一些流行的分布式系统中非常普遍。例如，在 Elasticsearch 中，一个索引由分片和副本组成，副本可以看做是一种特殊的分片，如果一个索引由 5 个分片组成，副本的基数是 1，那么这个索引一共会拥有 10 个分片（每 1 个分片对应 1 个副本）。</strong></p>
<p><strong>而如果你使用同样的方式来理解 ClickHouse 的分片，那么很可能会栽一个跟头，ClickHouse 的某些设计总是显得独树一帜，而集群与分片便是其中之一。这里有几个与众不同的特性：</strong></p>
<ul>
<li><code>1. ClickHouse 的一个节点只能有 1 个分片，也就是说如果要实现 1 分片、1 副本，则至少需要两个服务节点</code></li>
<li><code>2. 分片只是一个逻辑概念，其物理承载还是要由副本来承担的</code></li>
</ul>
<p><strong>我们来看一下 ClickHouse 的集群配置，这里将会在后面详细说，目前先看看有个印象即可。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ch_cluster</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">host</span>&gt;</span>47.94.174.89<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ch_cluster</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>如果从字面含义上来理解的话，可以认为是自定义集群 ch_cluster 拥有一个 shard（分片）和一个replica（副本），且该副本由 47.94.174.89 服务节点承载。</strong></p>
<p><strong>但是从本质上来理解的话，1 分片、1 副本的配置在 ClickHouse 中只有 1 个物理副本，所以它的正确语义应该是 1 分片、0 副本。分片更像是逻辑层的分组，在物理存储层面则统一使用副本来代表 “分片和副本”。所以如果想真正表示 1 分片、1 副本语义的配置，应该改为 1 个分片和 2 个副本，配置可以改为如下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ch_cluster</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">host</span>&gt;</span>47.94.174.89<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">host</span>&gt;</span>47.93.39.238<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ch_cluster</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>以上就是 ClickHouse 的架构设计，这些内容感觉有点枯燥甚至不好理解，下面就来安装 ClickHouse，进入实际操作环节。</strong></p>
<h2 id="ClickHouse-的安装以及连接工具"><a href="#ClickHouse-的安装以及连接工具" class="headerlink" title="ClickHouse 的安装以及连接工具"></a>ClickHouse 的安装以及连接工具</h2><p><strong>相较于 Hadoop 生态中的一些系统，ClickHouse 的安装显得尤为简单，因为它自成一体，在单节点的情况下不需要额外的依赖，集群的话后面会说。</strong></p>
<p><strong>ClickHouse 支持运行在主流 64 位 CPU 架构的 Linux 操作系统上，可以通过源码编译、预编译压缩包、Docker 镜像和 RPM 等多种方法进行安装。这里我们着重介绍一下离线 RPM 的安装方法，因为它最常用。</strong></p>
<p><strong>先介绍一下环境，我们使用的操作系统为 CentOS 7，是我在阿里云上的服务器，而 ClickHouse 我们选择 21.7.3.14 版本，一个非常新的版本。</strong></p>
<p><strong>1. 下载 RPM 安装包</strong></p>
<p><strong>用于安装的 RPM 包可以从仓库 <a href="https://repo.yandex.ru/clickhouse/rpm/stable/x86_64/">https://repo.yandex.ru/clickhouse/rpm/stable/x86_64/</a> 中进行下载，里面包含了所有版本的 ClickHouse。</strong></p>
<p><strong>我们需要下载以下四个安装包文件：</strong></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">clickho<span class="built_in">use-client</span><span class="literal">-21</span>.<span class="number">7.3</span>.<span class="number">14</span><span class="literal">-2</span>.noarch.rpm</span><br><span class="line">clickho<span class="built_in">use-common</span><span class="literal">-static-21</span>.<span class="number">7.3</span>.<span class="number">14</span><span class="literal">-2</span>.x86_64.rpm</span><br><span class="line">clickho<span class="built_in">use-common</span><span class="literal">-static-dbg-21</span>.<span class="number">7.3</span>.<span class="number">14</span><span class="literal">-2</span>.x86_64.rpm</span><br><span class="line">clickho<span class="built_in">use-server</span><span class="literal">-21</span>.<span class="number">7.3</span>.<span class="number">14</span><span class="literal">-2</span>.noarch.rpm</span><br></pre></td></tr></table></figure>

<p><strong>2. 关闭防火墙并检查环境依赖</strong></p>
<p><strong>首先，考虑到后续的集群部署，通常建议关闭本机的防火墙，在 CentOS 7 中关闭防火墙的方法如下：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 关闭防火墙</span></span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"><span class="comment"># 禁用开机启动项</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service</span><br></pre></td></tr></table></figure>

<p><strong>接着需要验证当前服务器的 CPU 是否支持 SSE 4.2 指令集，因为向量化执行需要用到这项特性：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">grep -q sse4_2 /proc/cpuinfo &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;支持 SSE 4.2 指令集&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;不支持 SSE 4.2 指令集&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173136749-2106854624.png" alt="img"></p>
<p><strong>如果不支持 SSE 指令集，则不能使用上面下载的 RPM 安装包，而是需要使用源码编译的方式安装，当然现在的 CPU 基本上都是支持的。</strong></p>
<p><strong>3. 安装 ClickHouse</strong></p>
<p><strong>我们将上面下载地 RPM 包上传到服务器，然后进行安装。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用通配符，会将当前目录下所有的 rpm 包全部依次安装，非常方便</span></span><br><span class="line"><span class="comment"># 因为我们是安装 ClickHouse，所以该目录除了 ClickHouse 的 rpm 包之外，最好不要有其它的 rpm 包</span></span><br><span class="line">rpm -ivh ./*.rpm</span><br></pre></td></tr></table></figure>

<p><strong>注意，在安装到 clickhouse-server 的时候会提示你设置密码：</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173147043-888452747.png" alt="img"></p>
<p><strong>因为 ClickHouse 在安装的时候会有一个默认的 default 用户，这里会提示你给 default 设置密码，因为 ClickHouse 和 MySQL、PostgreSQL 等数据库一样，也具有用户管理权限。老版本默认没有密码，新版本会让你主动设置，这里我们就不设置了，直接回车就好，这样后续在连接的时候就不需要密码了。</strong></p>
<p><strong>最后，如果想卸载 ClickHouse 也很简单，至于以下几步：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">yum remove clickhouse-client clickhouse-common-static clickhouse-common-static-dbg clickhouse-server -y</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/clickhouse</span><br><span class="line"><span class="built_in">rm</span> -rf /etc/clickhouse-*</span><br><span class="line"><span class="built_in">rm</span> -rf /var/log/clickhouse-server</span><br></pre></td></tr></table></figure>

<h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><p><strong>程序在安装的时候会自动构建整套目录结构，接下来分别说明它们的作用。</strong></p>
<p><strong>1) 首先是核心目录部分</strong></p>
<p><strong>&#x2F;etc&#x2F;clickhouse-server：服务端的配置文件目录, 包括全局配置 config.xml 和用户配置 users.xml 等。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173157010-600531378.png" alt="img"></p>
<p><strong>&#x2F;var&#x2F;lib&#x2F;clickhouse：默认的数据存储目录（通常会修改默认存储路径，将数据保存到大容量磁盘挂载的路径），通过 config.xml 进行修改。</strong></p>
<p><strong>&#x2F;var&#x2F;log&#x2F;clickhouse-server：默认保存日志的目录（通常会修改默认存储路径，将日志保存到大容量磁盘挂载的路径），通过 config.xml 进行修改。</strong></p>
<p><strong>2) 接下来是配置文件部分</strong></p>
<p><strong>&#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;clickhouse.conf：文件句柄数量的配置，默认值如下所示：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># cat /etc/security/limits.d/clickhouse.conf</span></span><br><span class="line">clickhouse	soft	nofile	262144</span><br><span class="line">clickhouse	hard	nofile	262144</span><br><span class="line">[root@satori ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p><strong>该配置也可以通过 config.xml 中的 max_open_files 参数指定。</strong></p>
<p><strong>&#x2F;etc&#x2F;cron.d&#x2F;clickhouse-server：cron 定时任务配置, 用于恢复因异常原因中断的 ClickHouse 服务进程, 其默认的配置如下所示：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># cat /etc/cron.d/clickhouse-server</span></span><br><span class="line"><span class="comment">#*/10 * * * * root ((which service &gt; /dev/null 2&gt;&amp;1 &amp;&amp; (service clickhouse-server condstart ||:)) || /etc/init.d/clickhouse-server condstart) &gt; /dev/null 2&gt;&amp;1</span></span><br><span class="line">[root@satori ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p><strong>可以看到默认情况，每隔 10 秒就会使用 condstart 尝试启动一次 ClickHouse 服务，如果 ClickHouse 服务正在运行，则跳过；如果没有运行，则启动。</strong></p>
<p><strong>3) 最后是在 &#x2F;usr&#x2F;bin 目录下的启动文件</strong></p>
<p><strong>ClickHouse 相关的启动文件都位于 &#x2F;usr&#x2F;bin 目录下。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173206870-757028996.png" alt="img"></p>
<p><strong>可执行文件数量还是蛮多的，其中四个最常用。</strong></p>
<ul>
<li><code>clickhouse: 主程序的可执行文件</code></li>
<li><code>clickhouse-client: 一个指向 ClickHouse 可执行文件的软连接, 供客户端连接使用</code></li>
<li><code>clickhouse-server: 一个指向 ClickHouse 可执行文件的软连接, 供服务端启动使用</code></li>
<li><code>clickhouse-compressor: 内置提供的压缩工具, 可用于数据的正压反解</code></li>
</ul>
<h3 id="启动命令"><a href="#启动命令" class="headerlink" title="启动命令"></a>启动命令</h3><p><strong>ClickHouse 给我们提供了非常优雅的启动方式。</strong></p>
<ul>
<li><strong>启动 ClickHouse：clickhouse start</strong></li>
<li><strong>关闭 ClickHouse：clickhouse stop</strong></li>
<li><strong>重启 ClickHouse：clickhouse restart</strong></li>
</ul>
<p><strong>注意：在安装 ClickHouse 的时候，系统会自动创建一个名为 clickhouse 的用户，启动脚本会基于此用户来启动服务。因此我们需要将 clickhouse 用户具备相关目录的权限，如果不赋权限，ClickHouse 可能会启动失败。</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chown</span> clickhouse.clickhouse /var/log/clickhouse-server/ -R </span><br><span class="line"><span class="built_in">chown</span> clickhouse.clickhouse /var/lib/clickhouse/ -R </span><br><span class="line"><span class="comment"># 如果后续你修改了配置文件，改变了 ClickHouse 的数据存储目录，那么也要记得赋给它相应的权限</span></span><br></pre></td></tr></table></figure>

<p><strong>另外，上面通过 clickhouse start 启动的时候我们没有指定配置文件，没错，通过这种方式启动的话，会自动加载 &#x2F;etc&#x2F;clickhouse-server&#x2F;config.xml。</strong></p>
<p><strong>但如果我们想手动指定配置文件的话，那么需要使用 clickhouse-server。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clickhouse-server --config-file /etc/clickhouse-server/config.xml --daemon</span><br></pre></td></tr></table></figure>

<p><strong>–config-file 负责指定配置文件，这样即使将配置文件放在了别的地方也没有关系，因为我们可以显式地指定它的位置；–daemon 表示后台启动，因为默认是前台启动的。</strong></p>
<p><strong>但是注意：使用 clickhouse-server 启动的话，不能使用 root，需要切换到 clickhouse 用户，所以我们应该这么做。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo -u clickhouse clickhouse-server --config-file /etc/clickhouse-server/config.xml --daemon</span><br></pre></td></tr></table></figure>

<p><strong>注意：sudo -u 后面的 clickhouse 指的是名为 clickhouse 的用户，clickhouse start 里面的 clickhouse 指的是 &#x2F;usr&#x2F;bin 里面的可执行文件。这里由于我们配置文件就在默认路径下，所以也可以直接使用 clickhouse start 启动，默认加载 &#x2F;etc&#x2F;clickhouse-server&#x2F;config.xml、并且后台启动。至于关闭的话，直接 clickhouse stop 即可。</strong></p>
<h3 id="客户端的访问接口"><a href="#客户端的访问接口" class="headerlink" title="客户端的访问接口"></a>客户端的访问接口</h3><p><strong>ClickHouse 服务端的底层访问接口支持 TCP 和 HTTP 两种方式，其中 TCP 拥有更好的性能，其默认监听 9000 端口，主要用于集群间的内部通信及 clickhouse-client 客户端进行连接；而 HTTP 协议则拥有更好的兼容性，可以通过 REST 服务的形式被广泛用于编程语言的客户端，其默认监听 8123 端口。</strong></p>
<p><strong>下面我们来介绍几种连接方式。</strong></p>
<h4 id="使用客户端-clickhouse-client-连接服务端"><a href="#使用客户端-clickhouse-client-连接服务端" class="headerlink" title="使用客户端 clickhouse-client 连接服务端"></a>使用客户端 clickhouse-client 连接服务端</h4><p><strong>通过 clickhouse start 将服务启动之后，我们就可以通过客户端进行连接了，通过 clickhouse-client，默认会连接到本机的 9000 端口，并使用 default 用户，如果想单独指定的话可使用如下方式：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clickhouse-client --host 地址 --port 端口 --user 用户 --password 密码</span><br></pre></td></tr></table></figure>

<p><strong>这里我们的服务端默认也是监听 9000 端口，并且 default 用户还没有密码，所以直接输入 clickhouse-client 即可连接上。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173219404-1535534933.png" alt="img"></p>
<p><strong>我们看到连接成功，并且也查询成功了，我们需要注意一下图中 show databases 前面的提示内容，很明显它就是我们刚才设置的 FQDN。至此，单节点 ClickHouse 的安装就算完毕了，至于集群的搭建我们后面会说。</strong></p>
<p><strong>插句题外话，如果我们想要更新 ClickHouse，那么直接下载新版的 ClickHouse RPM 包即可，然后进行更新：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">rpm -Uvh ./*.rpm</span><br></pre></td></tr></table></figure>

<p><strong>升级的时候，原有的配置均会保留。</strong></p>
<p><strong>然后我们再来聊一下 clickhouse-client，我们上面通过输入 clickhouse-client 进入命令行、然后再执行 SQL 的方式叫做 “交互式执行”，一般用于调试、运维、开发和测试等场景。</strong></p>
<p><strong>通过交互式执行的 SQL 语句，相关查询结果会统一记录到 ~&#x2F;.clickhouse-client-history 文件中，可以作为审计之用。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173228787-1516845254.png" alt="img"></p>
<p><strong>但除了交互式执行之外，还有非交互式执行。非交互式执行主要用于批处理场景，诸如对数据的导入和导出操作，在执行脚本命令时，需要追加 –query 参数指定执行的 SQL 语句。举个栗子：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> xxx.csv | clickhouse-client --query <span class="string">&quot;INSERT INTO some_table FORMAT CSV&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>在导入数据时，它可以接收操作系统的 stdin 标准输入作为写入的数据。所以 cat 命令读取的文件流，将会作为 INSERT 查询的数据输入，而在数据导出时，则可以输出流重定向到文件：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">clickhouse-client --query <span class="string">&quot;SELECT * FROM some_table&quot;</span> &gt;&gt; xxx.csv</span><br></pre></td></tr></table></figure>

<p><strong>默认情况下，clickhouse-client 一次只能运行一条 SQL 语句，如果需要执行多次查询，则需要在循环中重复执行，这显然不是一种高效的方式。此时可以追加 –multiquery 参数，它可以支持一次运行多条SQL查询，多条查询之间使用分号分隔，比如：</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173243014-1287564968.png" alt="img"></p>
<p><strong>多条 SQL 的查询结果集会依次按照顺序返回。</strong></p>
<p><strong>以上就是 clickhouse-client 的两种运行方式，由于提供了非交互式执行的功能，所以 ClickHouse 的客户端比其它数据库的客户端要强大一些。下面整理一下 clickhouse-client 常用的相关参数：</strong></p>
<ul>
<li><code>--host/-h: 指定连接的服务端的地址, 默认是 localhost，如果服务端的地址不是 localhost, 则需要依靠此参数进行指定, 例如 clickhouse-client -h xx.xx.xx.xx</code></li>
<li><code>--port: 服务端的 TCP 端口, 默认是 9000，如果服务端监听的不是 9000, 则需要此参数指定</code></li>
<li><code>--user/-u: 登录的用户名, 默认是 default。如果使用非 default 的用户名登录, 则需要使用此参数指定</code></li>
<li><code>--password: 登录的密码, 默认值为空。如果在用户定义中未设置密码, 则无需填写（比如默认的 default 用户，我们没有设置密码）</code></li>
<li><code>--database/-d: 登录之后所在的数据库, 默认为 default</code></li>
<li><code>--query/-q: 只能在非交互式查询时使用, 用于执行指定的 SQL 语句</code></li>
<li><code>--multiquery/-n: 在非交互式执行时, 允许一次运行多条 SQL 语句, 多条语句之间用分号隔开</code></li>
<li><code>--time/-t: 在非交互式执行时, 会打印每条 SQL 的执行时间</code></li>
</ul>
<p><strong>更多参数可以通过 clickhouse-client –help 查看，数量多到恐怖。</strong></p>
<h4 id="Python-连接-ClickHouse-服务端"><a href="#Python-连接-ClickHouse-服务端" class="headerlink" title="Python 连接 ClickHouse 服务端"></a>Python 连接 ClickHouse 服务端</h4><p><strong>首先 ClickHouse 支持使用 JDBC 连接，但我本身不是 JAVA 方向的，所以这里只介绍使用 Python 连接 ClickHouse 的方式。</strong></p>
<blockquote>
<p><strong>Python 连接 ClickHouse 的话需要安装一个第三方库，直接 pip install clickhouse-driver 即可。</strong></p>
</blockquote>
<p><strong>注意：我们说 HTTP 协议使用的是 8123 端口，但是 Python 这个包比较特殊，它和 clickhouse-client 一样，使用的也是 TCP 协议，也就是说端口需要指定为 9000。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173251635-1249075618.png" alt="img"></p>
<p><strong>使用 Python 是可以连接的，但是注意：我们这里是在服务器上使用 Python 连接的，如果需要在其它机器上连接的话，那么就不能使用 localhost 了。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> clickhouse_driver <span class="keyword">import</span> Client</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要指定具体的 ip</span></span><br><span class="line">client = Client(host=<span class="string">&quot;47.94.174.89&quot;</span>, port=<span class="number">9000</span>)</span><br><span class="line"><span class="built_in">print</span>(client.execute(<span class="string">&quot;show databases&quot;</span>))</span><br></pre></td></tr></table></figure>

<p><strong>不过此时仍无法在其它节点上访问，因为我们还需要修改一下服务端的配置，vim &#x2F;etc&#x2F;clickhouse-server&#x2F;config.xml：</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173300172-176175199.png" alt="img"></p>
<p><strong>listen_host 这个标签默认是被注释掉的，也就是只监听来自本机的请求。这里我们将注释打开，或者不管注释，直接手动增加一条。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 改成 0.0.0.0，这样即可接收来自其它机器上的请求 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">listen_host</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">listen_host</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>此时 Python 即可在其它节点上访问了，注意：服务器的 9000 端口是要对外开放的，这里我阿里云服务器的 9000、8123 端口都已经对外了。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173307872-1755060506.png" alt="img"></p>
<p><strong>此外我们还可以通过 sqlalchemy 去连接，但是默认情况下 sqlalchemy 找不到对应的 dialect，我们需要再安装一个模块：pip install sqlalchemy_clickhouse，安装之后就可以使用了。</strong></p>
<p><strong>但是有一点需要注意：使用 sqlalchemy_clickhouse 的话，那么连接的端口就不能是 9000 了，而是 8123。更准确的说，需要使用 HTTP 端口。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173314413-994480208.png" alt="img"></p>
<p><strong>以上就是 Python 连接 ClickHouse 的两种方式，还是挺容易的。</strong></p>
<h4 id="DataGrip-连接-ClickHouse-服务端"><a href="#DataGrip-连接-ClickHouse-服务端" class="headerlink" title="DataGrip 连接 ClickHouse 服务端"></a>DataGrip 连接 ClickHouse 服务端</h4><p><strong>DataGrip 是 JetBrains 公司开发的一个 IDE，专门负责连接数据库，其中也包含了对 ClickHouse 的支持。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173323068-652157345.png" alt="img"></p>
<p><strong>点击之后下载相应的驱动，然后输入相关信息即可。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173335772-2053147215.png" alt="img"></p>
<p><strong>我们看到连接成功，里面还显示了 ClickHouse 支持的内置函数。然后我们执行 SQL 语句测试一下：</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173345219-323654674.png" alt="img"></p>
<h3 id="内置的实用工具"><a href="#内置的实用工具" class="headerlink" title="内置的实用工具"></a>内置的实用工具</h3><p><strong>我们说 &#x2F;usr&#x2F;bin 下面包含了很多关于 ClickHouse 的启动文件，除了之前介绍的四个，这里再介绍两个，分别是 clickhouse-local 和 clickhouse-benchmark。</strong></p>
<h4 id="clickhouse-local"><a href="#clickhouse-local" class="headerlink" title="clickhouse-local"></a>clickhouse-local</h4><p><strong>clickhouse-local 可以独立运行大部分的 SQL 查询，不需要依赖任何 ClickHouse 服务端程序，它可以理解为 ClickHouse 服务的单机版内核，是一个轻量级的应用程序。clickhouse-local 只能够使用 File 引擎（或者称之为表引擎），关于引擎后面会展开。它的数据与同机运行的 ClickHouse 服务之间也是完全隔离的，互相并不能访问。</strong></p>
<p><strong>clickhouse-local 是非交互式的，每次执行都需要指定数据来源，例如通过 stdin 标准输入，以 echo 打印作为数据来源：</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173352370-520401822.png" alt="img"></p>
<p><strong>也可以借助操作系统的命令，实现对系统用户内存用量的查询。</strong></p>
<p><img src="/2023/02/01/ClickHouse%20%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E3%80%81%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7(%E4%BA%8C)/1229382-20210816173358237-1560136843.png" alt="img"></p>
<p><strong>clickhouse-local 的参数用法可以通过 –help 查看，但是个人觉得不是很常用。</strong></p>
<h4 id="clickhouse-benchmark"><a href="#clickhouse-benchmark" class="headerlink" title="clickhouse-benchmark"></a>clickhouse-benchmark</h4><p><strong>clickhouse-benchmark 是基准测试的小工具，它可以自动运行 SQL 查询，并生成对应的运行指标报告，例如执行下面的语句启动测试：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;SELECT * FROM table&quot;</span> | clickhouse-benchmark -i 5</span><br></pre></td></tr></table></figure>

<p><strong>执行之后，按照指定参数的查询会被执行 5 次。执行完毕之后，会显示包含 QPS、RPS 等指标信息的报告，还会列出各百分位的查询执行时间。</strong></p>
<p><strong>如果想测试多条 SQL，此时就需要将 SQL 写在文件中，然后通过 clickhouse-benchmark -i 5 &lt; 文件路径，将里面的 SQL 按照顺序依次执行。</strong></p>
<blockquote>
<p><strong>这里我就不使用具体的数据测试了，有兴趣可以自己尝试一下。</strong></p>
</blockquote>
<p><strong>clickhouse-benchmark 的一些核心参数可以通过 –help 查看。</strong></p>
<p><strong>以上我们介绍了基于离线 RPM 包安装 ClickHouse 的整个过程，当然也可以使用其它方式安装，比如：在线安装、或者使用 docker 等等。事实上，这种离线安装的方式也不麻烦，相反个人觉得还很简单。然后还介绍了访问 ClickHouse 的两个接口，TCP 接口和 HTTP 接口，以及如何使用 Python 去访问。那么就来学习 ClickHouse 的具体语法了，首先会从数据定义开始。</strong></p>
<p>​																		本文来源： (<a href="https://www.cnblogs.com/traditional/p/15218595.html">https://www.cnblogs.com/traditional/p/15218595.html</a>) </p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的副本与分片(十七)</title>
    <url>/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的副本与分片-十七"><a href="#ClickHouse-的副本与分片-十七" class="headerlink" title="ClickHouse 的副本与分片(十七)"></a>ClickHouse 的副本与分片(十七)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><p><strong>纵使单节点性能再强，也会有遇到瓶颈的那一天，业务量的持续增长、服务器的意外故障，都是 ClickHouse 需要面对的洪水猛兽。但常言道：一个好汉三个帮，一个篱笆三个桩，放在计算机领域就是，一个节点不够，就多来几个节点，下面就来介绍一下 ClickHouse 的集群、副本与分片。</strong></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><strong>集群是副本和分片的基础，它将 ClickHouse 的服务拓扑由单节点延伸到多个节点，但它并不像 Hadoop 生态的某些系统那样，要求所有节点组成一个单一的大集群。ClickHouse 的集群配置非常灵活，用户既可以将所有节点组成一个单一集群，也可以按照业务的诉求把节点划分为多个小的集群。在每个小的集群区域之间，它们的节点、分区和副本数量可以各不相同，如图所示。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202109115-343217210.png" alt="img"></p>
<p><strong>从作用来看，ClickHouse 集群的工作更多是针对逻辑层面的，集群定义了多个节点的拓扑关系，这些节点在后续服务过程中可能会协同工作，而执行层面的具体工作则交给了副本和分片来执行。</strong></p>
<p><strong>集群很好理解，那副本和分片又是什么呢？这对双胞胎兄弟有时看起来泾渭分明，有时又让人分辨不清。这里有两种区分办法，第一种是从数据层面区分，假设 ClickHouse 的 N 个节点组成了一个集群，在集群的各个节点上都有一张结构相同的数据表 Y，如果 Node1 和 Node2 上的 Y 的数据完全不同，则 Node1 和 Node2 互为分片；如果它们的数据完全相同，则它们互为副本。换言之，分片之间的数据是不同的，而副本之间的数据是完全相同的。所以抛开表引擎不同，但从数据层面来看，副本和分片有时候只有一线之隔。</strong></p>
<p><strong>另一种是从功能作用层面区分，使用副本的主要目的是防止数据丢失，增加数据存储的冗余；而使用分片的主要目的是实现数据的水平切分，如图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202116274-494268371.png" alt="img"></p>
<p><strong>下面我们就来逐步介绍副本、分片和集群的使用方法，我们当前是只有一个节点，也就是只有 1 个分片，并且数据只有一份，相当于没有备份，也就是 0 副本。注意：关于副本，不同框架有着不同的定义，比如 HDFS 中的三副本存储，那么数据总共有三份，如果是 1 副本，那么数据就只有 1 份。但是 ClickHouse 中 1 副本表示数据额外有一份备份，那么言下之意就是有两份，但是为了表述方便，后续我们仍采用副本 1、副本 2 来称呼。再比如 ClickHouse 中的 2 副本，那么说明数据有 3 份，但我们会用副本 1、副本 2、副本 3 来称呼。当然这些东西理解就好，只是为了避免出现歧义，需要提前先说清楚。</strong></p>
<p><strong>而我们接下来会从数据表的初始形态 1 分片、0 副本开始介绍；然后再说如何为它添加副本，从而形成 1 分片、1 副本的状态；然后接着再说如何引入分片，将其转化为多分片、1 副本的形态（多副本的形态以此类推）。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202124155-1493622788.png" alt="img"></p>
<p><strong>这种形态的变化过程像极了企业内的业务发展过程，在业务初期我们会从单张数据表开始；在业务上线一段时间之后，可能会为它增加副本，以保证数据的安全，或者希望进行读写分离从而增加并发量；但随着业务的发展，数据量越来越大，因此会进一步为其增加分片，从而实现数据的水平切分。</strong></p>
<h2 id="数据副本"><a href="#数据副本" class="headerlink" title="数据副本"></a>数据副本</h2><p><strong>我们之前介绍 MergeTree 的时候，介绍过它的命名规则，如果在 *MergeTree 的前面加上 Replicated 前缀，则能够组合成一个新的变种引擎，如图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210826121005343-128425369.png" alt="img"></p>
<p><strong>换言之，只有使用了 ReplicatedMergeTree 复制表系列引擎，才能应用副本的能力（后面会说另一种副本的实现方式）；或者用一种更为直接的方式理解，即使用了 ReplicatedMergeTree 的数据表就是副本。</strong></p>
<p><strong>所以 ReplicatedMergeTree 是 MergeTree 的派生引擎，它在 MergeTree 的基础之上加入了分布式协同的能力，如图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202131736-1374698112.png" alt="img"></p>
<p><strong>在 MergeTree 中，一个数据分区又开始创建到全部完成，会经历两个存储区域。</strong></p>
<ul>
<li><code>1. 内存：数据首先会被写入内存缓冲区</code></li>
<li><code>2. 本地磁盘：数据接着会被写入 tmp 临时目录分区，待全部完成之后再将临时目录重命名为正式分区</code></li>
</ul>
<p><strong>而 ReplicatedMergeTree 在上述基础之上增加了 ZooKeeper 的部分，它会进一步在 ZooKeeper 内创建一系列的监听节点，并以此实现多个实例之间的通信。在整个通信过程中，ZooKeeper 并不会涉及表数据的传输。</strong></p>
<h3 id="副本的特点"><a href="#副本的特点" class="headerlink" title="副本的特点"></a>副本的特点</h3><p><strong>作为数据副本的主要实现载体，ReplicatedMergeTree 在设计上有一些显著特点。</strong></p>
<ul>
<li><strong>依赖 ZooKeeper：在执行 INSERT 和 ALTER 查询的时候，ReplicatedMergeTree 需要借助 ZooKeeper 的分布式协同能力，来实现多个副本之间的同步。但是在查询副本的时候，并不需要使用 ZooKeeper，关于这方面的信息，后续会详细介绍。</strong></li>
<li><strong>表级别的副本：副本是在表级别定义的，所以每张表的副本配置都可以按照它的实际需求进行个性化定义，包括副本的数量，以及副本在集群内的分布位置。</strong></li>
<li><strong>多主架构（Multi Master）：可以在任意一个副本上执行 INSERT 和 ALTER 查询，它们的效果是相同的，这些操作会借助 ZooKeeper 的协同能力被分发至每个副本以本地形式执行。</strong></li>
<li><strong>Block 数据块：在执行 INSERT 命令写入数据时，会依据 max_insert_block_size 的大小（默认 1048576 行）将数据切分成若干个 Block 数据块。因此 Block 数据块是数据写入的基本单元，并且具有写入的原子性和唯一性。</strong></li>
<li><strong>原子性：在数据写入时，一个 Block 数据块内的数据要么全部写入成功，要么全部写入失败。</strong></li>
<li><strong>唯一性：在写入一个 Block 数据块的时候，会按照当前 Block 数据块的数据顺序、数据行和数据大小等指标，计算 Hash 信息摘要并记录。在此之后，如果某个待写入的 Block 数据块与先前已被写入的 Block 数据块拥有相同的 Hash 摘要（Block 数据块内数据顺序、数据大小和数据行均相同），则该 Block 数据块会被忽略。这项设置可以预防由异常原因引起的 Block 数据块重复写入的问题。</strong></li>
</ul>
<p><strong>如果光看上面这些文字介绍的话， 可能不够直观，那么下面就用示例逐步展开。</strong></p>
<h3 id="ZooKeeper-的配置方式"><a href="#ZooKeeper-的配置方式" class="headerlink" title="ZooKeeper 的配置方式"></a>ZooKeeper 的配置方式</h3><p><strong>在正式开始之前，还需要做一些准备工作，那就是安装并配置 ZooKeeper，因为 ReplicatedMergeTree 必须对接到它才能工作。关于 zk 的安装，此处不再赘述，使用 3.4.5 以上的版本均可，我这里安装完成，下面重点介绍如何在 ClickHouse 中增加 ZooKeeper 的配置。</strong></p>
<p><strong>ClickHouse 使用一组 zookeeper 标签定义相关配置，默认情况下在 config.xml 中配置即可，将配置写在 config.xml 的 标签里面。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">zookeeper</span>&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;1&quot;</span>&gt;</span>  <span class="comment">&lt;!-- ZooKeeper 所在节点配置，可以配置多个地址 --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 节点 IP，也是当前 ClickHouse Server 所在节点 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span>47.94.174.89<span class="tag">&lt;/<span class="name">host</span>&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- ZooKeeper 监听端口，默认 2181 --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 由于我们后面会搭建副本，并且只用这一个 ZooKeeper，所以要保证 2181 端口对外开放 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">zookeeper</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>当然 config.xml 里面也提供了 zookeeper 这个标签，不过是被注释掉的，这里我们不管它，直接拷贝进去即可。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202140287-1165521929.png" alt="img"></p>
<p><strong>配置完之后，我们使用 clickhouse restart 重启服务。然后 ClickHouse 在它的系统表中贴心地准备了一张名为 zookeeper 的代理表，可以使用 SQL 查询的方式读取远端 ZooKeeper 的数据。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> czxid, mzxid, name, <span class="keyword">value</span> <span class="keyword">FROM</span> system.zookeeper <span class="keyword">WHERE</span> path <span class="operator">=</span> <span class="string">&#x27;/&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><strong>注意：查询的时候必须指定 path 进行条件筛选。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202148316-1323461086.png" alt="img"></p>
<p><strong>这里需要先来简单说一下 ZooKeeper 的数据模型，ZooKeeper 的数据模型和 UNIX 文件系统很类似，整体上可以看做是一棵树。树上的每一个节点都称之为一个 ZNode，可以通过路径进行唯一标识，因为每个节点都有一个名称，我们随便挑两个节点画张图就清晰了。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202154952-1732310430.png" alt="img"></p>
<p><strong>根节点就是 &#x2F;，每一个节点下面可以创建多个子节点，并层层递归下去，所以就像文件系统一样。而我们在查找的时候也是如此，从根节点出发，层层组合，因为每一个节点都有自己的名称，按照顺序组合起来即可得到 path。因此我们指定 path 等于 &#x2F; 即可查到根节点下面的所有节点，而图中的 name 字段显示的就是 ZNode 的名称，注意：只显示一层，不会递归显示。</strong></p>
<p><strong>并且每个 ZNode 默认能够存储 1MB 的数据，而图中 system.zookeeper 的 value 字段显示的就是 ZNode 存储的值，至于 ZNode 的其它属性可以自己查阅一下，这里就不多说了。另外，由于我这 ZooKeeper 很早就存在了，所以里面包含了很多与 ClickHouse 无关的数据，如果你是新安装的，那么信息不会像上面这么多。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 这里我们查询 clickhouse 下面所有的 ZNode，那么将条件改成 path = &#x27;/clickhouse&#x27; 即可</span></span><br><span class="line"><span class="comment">-- 当前只有一个 task_queue，原因是我们还没有建表，而建表之后，这里就会多出一个名为 tables 的 ZNode</span></span><br><span class="line"><span class="comment">-- 然后 /clickhouse/tables 下面又会存在名为 01、02... 的 ZNode，对应副本 1、副本 2....</span></span><br><span class="line"><span class="keyword">SELECT</span> czxid, mzxid, name, <span class="keyword">value</span> <span class="keyword">FROM</span> system.zookeeper</span><br><span class="line"><span class="keyword">WHERE</span> path <span class="operator">=</span> <span class="string">&#x27;/clickhouse&#x27;</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">┌─czxid─┬─mzxid─┬─name───────┬─value─┐</span></span><br><span class="line"><span class="comment">│  1087 │  1087 │ task_queue │       │</span></span><br><span class="line"><span class="comment">└───────┴───────┴────────────┴───────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h3 id="副本的定义形式"><a href="#副本的定义形式" class="headerlink" title="副本的定义形式"></a>副本的定义形式</h3><p><strong>正如前文所言，使用副本的好处甚多。首先，由于增加了数据的存储冗余，所以降低了数据丢失的风险；其次，由于副本采用了多主架构，所以每个副本实例都可以作为数据读、写的入口，这无疑分摊了节点的负载。</strong></p>
<p><strong>在使用副本时，不需要依赖任何集群的配置（关于集群后面说），ReplicatedMergeTree 结合 ZooKeeper 就能完成全部工作。</strong></p>
<p><strong>ReplicatedMergeTree 的定义方式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = ReplicatedMergeTree(&#x27;zk_path&#x27;, &#x27;replica_name&#x27;)</span><br></pre></td></tr></table></figure>

<p><strong>在上述配置项中，有 zk_path 和 replica_name 两项，首先介绍 zk_path 的作用。</strong></p>
<p><strong>zk_path 用于指定在 ZooKeeper 中创建的数据表的路径，路径名称是自定义的，并没有固定规则，用户可以设置成自己希望的任何路径。即便如此，ClickHouse 还是提供了一些约定俗成的配置模板以供参考，例如：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/clickhouse/tables/&#123;shard&#125;/table_name</span><br></pre></td></tr></table></figure>

<p><strong>其中：</strong></p>
<ul>
<li><strong>&#x2F;clickhouse&#x2F;tables 是约定俗成的路径固定前缀，表示存放数据表的根路径。</strong></li>
<li><strong>{shard} 表示分片编号，通常用数值替代，例如 01、02、03，一张数据表可以有多个分片，而每个分片都拥有自己的副本。</strong></li>
<li><strong>table_name 表示数据表的名称，为了方便维护，通常与物理表的名字相同（虽然 ClickHouse 并不要求路径中的表名称和物理表名必须一致）；而 replica_name 的作用是定义在 ZooKeeper 中创建的副本名称，该名称是区分不同副本实例的唯一标识。一种约定俗成的方式是使用所在服务器的域名称。</strong></li>
</ul>
<p><strong>对于 zk_path 而言，同一张数据表的同一个分片的不同副本，应该定义相同的路径；而对于 replica_name 而言，同一张数据表的同一个分片的不同副本，应该定义不同的名称。读起来很拗口，我们举个栗子说明一下。</strong></p>
<p><strong>1 个分片、1 个副本的情形：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- zk_path 相同，replica_name 不同</span></span><br><span class="line">ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/test_1&#x27;</span>, <span class="string">&#x27;192.168.0.1&#x27;</span>)</span><br><span class="line">ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/test_1&#x27;</span>, <span class="string">&#x27;192.168.0.2&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>多个分片、1 个副本的情形：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 分片1（2 分片、1 副本），zk_path 相同，其中 shard = 01，replica_name 不同</span></span><br><span class="line">ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/test_1&#x27;</span>, <span class="string">&#x27;192.168.0.1&#x27;</span>)</span><br><span class="line">ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/test_1&#x27;</span>, <span class="string">&#x27;192.168.0.2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 分片2（2 分片、1 副本），zk_path 相同，其中 shard = 02，replica_name 不同</span></span><br><span class="line">ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/02/test_1&#x27;</span>, <span class="string">&#x27;192.168.0.3&#x27;</span>)</span><br><span class="line">ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/02/test_1&#x27;</span>, <span class="string">&#x27;192.168.0.4&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>首先是 zk_path，无论一张表有多少个分片、多少个副本，它们终归属于同一张表，所以 zk_path 的最后一部分、也就是表名称是不变的，这里始终是 test_1。但问题是多个分片之间要如何区分呢？所以此时就依赖于 {shard}，&#x2F;clickhouse&#x2F;tables&#x2F;01&#x2F;test_1 表示 test_1 的第 1 个分片，&#x2F;clickhouse&#x2F;tables&#x2F;02&#x2F;test_1 表示 test_1 的第 2 个分片，第 3、4、5….. 个分片依次类推，至于其它的表也是同理。</strong></p>
<p><strong>而一个分片不管有多少个副本，这些副本终归都属于同一个分片、同一张表。所以同一张数据表的同一个分片的不同副本，应该定义相同的路径；例如表 test_2 的每个分片都有 3 个副本，那么以第 8 个分片为例，它的所有副本的 zk_path 就都应该配成：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/clickhouse/tables/08/test_2</span><br></pre></td></tr></table></figure>

<p><strong>然后是 replica_name，这个就比较简单了，因为要区分同一个分区内多个副本，显然它们要有不同的名称。所以上面读起来很拗口的第二个句话就解释完了，对于 replica_name 而言，同一张数据表的同一个分片的不同副本，应该定义不同的名称，这里我直接使用 IP 地址替代了。</strong></p>
<h2 id="ReplicatedMergeTree-原理解析"><a href="#ReplicatedMergeTree-原理解析" class="headerlink" title="ReplicatedMergeTree 原理解析"></a>ReplicatedMergeTree 原理解析</h2><p><strong>正如我们之前分析 MergeTree 一样，ReplicatedMergeTree 作为复制表系列的基础表引擎，涵盖了数据副本最为核心的逻辑，我们很明显要拿它入手。只要明白了 ReplicatedMergeTree 的核心原理，就能掌握整个 ReplicatedMergeTree 系列表引擎的使用方法。</strong></p>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p><strong>在 ReplicatedMergeTree 的核心逻辑中，大量运用了 ZooKeeper 的能力，以实现多个 ReplicatedMergeTree 副本实例之间的协同，包括主副本选举、副本状态感知、操作日志分发、任务队列和 BlockID 去重判断等等。在执行 INSERT 数据写入、MERGE 分区和 MUTATION 操作的时候，都会涉及与 ZooKeeper 的通信。但是在通信的过程中，并不会涉及任何表数据的传输，在查询数据的时候也不会访问 ZooKeeper，所以无需担心 ZooKeeper 的承载压力。</strong></p>
<p><strong>因为 ZooKeeper 对 ReplicatedMergeTree 非常重要，所以下面首先从它的数据结构开始介绍。</strong></p>
<h4 id="ZooKeeper-内的节点结构"><a href="#ZooKeeper-内的节点结构" class="headerlink" title="ZooKeeper 内的节点结构"></a>ZooKeeper 内的节点结构</h4><p><strong>ReplicatedMergeTree 需要依靠 ZooKeeper 的时间监听机制以实现各个副本之间的协调，所以在每张 ReplicatedMergeTree 表的创建过程中，它会以 zk_path 为根路径，在 ZooKeeper 中为这张表创建一组监听节点。而按照作用的不同，这些监听节点可以分成如下几类（先有个印象，后面会通过实际案例来体现）：</strong></p>
<p><strong>1）元数据：</strong></p>
<ul>
<li><code>&#123;zk_path&#125;/metadata：保存元数据信息，包括主键、分区键、采样表达式等</code></li>
<li><code>&#123;zk_path&#125;/columns：保存列字段信息，包括列名称和数据类型</code></li>
<li><code>&#123;zk_path&#125;/replicas：保存副本名称，对应设置参数中的 replica_name</code></li>
</ul>
<p><strong>2）判断标识：</strong></p>
<ul>
<li><code>&#123;zk_path&#125;/leader_election：用于主副本的选举工作，主副本会主导 MERGE 和 MUTATION 操作（ALTER DELETE 和 ALTER UPDATE，类似关系型数据库中的 DELETE 和 UPDATE），这些任务在主副本完成之后再借助 ZooKeeper 将消息事件分发至其它副本</code></li>
<li><code>&#123;zk_path&#125;/blocks：记录 Block 数据块的 Hash 信息摘要，以及对应的 partition_id，通过 Hash 信息摘要能够判断 Block 块是否重复；通过 partition_id，则能够找到需要同步的数据分区</code></li>
<li><code>&#123;zk_path&#125;/block_numbers：按照分区的写入顺序，以相同的顺序记录 partition_id，各个副本在本地进行 MERGE 时，都会依照相同的 block_numbers 顺序进行</code></li>
<li><code>&#123;zk_path&#125;/quorum：记录 quorum 的数量，当至少有 quorum 数量的副本写入成功后，整个写入才算成功。quorum 的数量由 insert_quorum 参数控制，默认值为 0</code></li>
</ul>
<p><strong>3）操作日志：</strong></p>
<ul>
<li><p><code>&#123;zk_path&#125;/log：常规操作日志节点（INSERT、MERGE 和 DROP PARTITON），它是整个工作机制中最为重要的一环，保存了副本需要执行的任务指令。log 使用了 ZooKeeper 的持久顺序型节点，每条指令的名称以 log- 为前缀递增，例如 log-0000000000、log-0000000001 等。每一个副本实例都会监听 /log 节点，当有新的指令加入时，它们会把指令加入副本各自的任务队列，并执行任务。关于这方面的逻辑，后续详细介绍</code></p>
</li>
<li><p><code>&#123;zk_path&#125;/mutations：MUTATION 操作日志节点，作用与 log 日志类似，当执行 ALTER DELETE 和 ALTER UPDATE 查询时，操作指令会被添加到这个点。mutations 同样使用了 ZooKeeper 的持久顺序节点，但是它的命名没有前缀，每条指令直接以递增数字的形式保存，例如 0000000000、0000000001 等。关于这方面的逻辑，同样后续展开</code></p>
</li>
<li><pre><code>&#123;zk_path&#125;/replicas/&#123;replica_name&#125;/*：每个副本各自的节点下的一组监听节点，用于指导副本在本地执行具体的任务指令，其中较为重要的节点有如下几个：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  - `&#123;zk_path&#125;/replicas/&#123;replica_name&#125;/queue：任务队列节点，用于执行具体的操作任务。当副本从 /log 或 /mutations 节点监听到操作指令时，会将执行任务添加至该节点下，并基于队列执行`</span><br><span class="line">  - `&#123;zk_path&#125;/replicas/&#123;replica_name&#125;/log_pointer：log 日志指针节点，记录了最后一次执行的 log 日志下标信息，例如 log_poniter:4 对应了 /log/log-0000000003（从 0 开始计数）`</span><br><span class="line">  - `&#123;zk_path&#125;/replicas/&#123;replica_name&#125;/mutation_pointer：mutations 日志指针节点，记录了最后一次执行的 mutations 日志名称，例如 mutation_pointer:0000000000 对应了 &#123;zk_path&#125;/mutations/0000000000`</span><br><span class="line"></span><br><span class="line">#### Entry 日志对象的数据结构</span><br><span class="line"></span><br><span class="line">**从上面的介绍可知，ReplicatedMergeTree 在 ZooKeeper 中有两组非常重要的父节点，那就是 /log 和 /mutations，为了简便，接下来介绍路径时候就不写 &#123;zk_path&#125; 了。它们的作用犹如一座通信塔，是分发操作指令的信息通道，而分发操作之灵的方式，则是为这些父节点添加子节点。所有的副本实例，都会监听父节点的变化，当有子节点被添加时，它们能够实时感知。**</span><br><span class="line"></span><br><span class="line">**当然这些被添加的子节点在 ZooKeeper 中就是相应的 ZNode，而 ZNode 的存储的值在 ClickHouse 中统一被抽象为 Entry 对象，而具体实现则由 LogEntry 和 MutationEntry 对象承载，分别对应 /log 和 /mutations 的子节点的 value。**</span><br><span class="line"></span><br><span class="line">**1）LogEntry：**</span><br><span class="line"></span><br><span class="line">**LogEntry 用于封装 /log 的子节点信息，大白话解释的话，其实 /log 下面的 ZNode 存储的 value 就是 LogEntry，它拥有如下几个核心属性。**</span><br><span class="line"></span><br><span class="line">- `source replica：发送这条 Log 指令的副本来源，对应 replica_name`</span><br><span class="line">- `block_id：当前分区的 BlockID，对应 /blocks 路径下子节点的名称`</span><br><span class="line">- `操作指令类型，主要有 get、merge 和 mutate 三种，分别对应从远程副本下载分区、合并分区以及 MUTATION 操作`</span><br><span class="line">- `当前分区目录的名称`</span><br><span class="line"></span><br><span class="line">**2）MutationEntry：**</span><br><span class="line"></span><br><span class="line">**MutationEntry 用于封装 /mutations 的子节点信息，它同样拥有如下几个核心属性。**</span><br><span class="line"></span><br><span class="line">- `source replica：发送这条 MUTATION 指令的副本来源，对应replica_name`</span><br><span class="line">- `commands：操作指令，主要有 ALTER DELETE 和 ALTER UPDATE`</span><br><span class="line">- `mutation_id：MUTATION 操作的版本号`</span><br><span class="line">- `partition_id：当前分区目录的 ID`</span><br><span class="line"></span><br><span class="line">**以上就是 Entry 日志对象的数据结构信息，在接下来将要介绍的核心流程中，会看到它们的身影。**</span><br><span class="line"></span><br><span class="line">### 分区副本协同的核心流程</span><br><span class="line"></span><br><span class="line">**副本协同的核心流程主要有 INSERT、MERGE、MUTATION 和 ALTER 四种，分别对应了数据写入、分区合并、数据修改和元数据修改。INSERT 和 ALTER 查询是分布式执行的，借助 ZooKeeper 的事件通知机制，多个副本之间会自动进行有效协同，但是它们不会使用 ZooKeeper 存储任何分区数据。至于其他查询并不支持分布式执行，包括 SELECT、CREATE、DROP、RENAME 和 ATTACH。例如，为了创建多个副本，我们需要分别登录每个 ClickHouse 节点，在它们本地执行各自的 CREATE 语句（后面将会介绍如何利用集器配置简化这一操作）。接下来，会依次介绍上述流程的工作机理。为了便于理解，我们先来整体认识一下各个流程的介绍方法。**</span><br><span class="line"></span><br><span class="line">**首先，拟定一个演示场景，即使用 ReplicatedMergeTree 实现一张拥有 1 分片、1 副本的数据表，并以此来贯穿整个讲解过程（对于大于 1 个副本的场景，流程以此类推）。**</span><br><span class="line"></span><br><span class="line">**接着，通过对 ReplicatedMergeTree 分别执行 INSERT、MERGE、MUTATION 和 ALTER 操作，以此来讲解相应的工作原理。与此同时，通过实际案例，论证工作原理。**</span><br><span class="line"></span><br><span class="line">**首先到这里我们只有一个节点就有些捉襟见肘了，因为我们要实现 1 分片、1 副本，那么至少要有两个节点。而在我当前阿里云上有三台服务器，相关信息如下：**</span><br><span class="line"></span><br><span class="line">- `47.94.174.89，主机名为 satori，2 核心 8GB 内存`</span><br><span class="line">- `47.93.39.238，主机名为 matsuri，2 核心 4GB 内存`</span><br><span class="line">- `47.93.235.147，主机名为 aqua，2 核心 4GB 内存`</span><br><span class="line"></span><br><span class="line">**主机 satori 就是我们当前一直使用的节点，然后再加上 matsuri 节点来实现我们的 1 分片、1 副本。**</span><br><span class="line"></span><br><span class="line">#### INSERT 的核心执行流程</span><br><span class="line"></span><br><span class="line">**当需要在 ReplicatedMergeTree 中执行 INSERT 查询以写入数据时，即会进入 INSERT 核心流程。而整个流程按照时间从上往下顺序进行，我们大致将其分了 8 个步骤，那么下面就依次讲解每一个过程。**</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">**1）创建第一个副本实例**</span><br><span class="line"></span><br><span class="line">**使用副本之前，我们需要修改一下配置文件，我们的目的是为了让 satori 节点和 matsuri 节点组合形成 1 分片 1 副本策略，所以需要修改配置文件 config.xml。首先对于 1 分片多副本而言，我们不需要配置集群，只需要配置好 ZooKeeper 即可。当然 1 分片多副本也是可以配置集群的，只不过该集群只有一个分片罢了，但我们说不配置也能实现 1 分片，所以这里我们就采用不配置集群的方式实现；而关于集群的配置，我们在介绍多分片的时候再说，因为如果是多分片，则必须要配置集群，具体内容后面说。下面来看看需要修改哪些配置：**</span><br><span class="line"></span><br><span class="line">```XML</span><br><span class="line">&lt;!-- 配置 ZooKeeper，我们之前就配置过了，可以设置多个 ZooKeeper，这里我们设置单个就行 --&gt;</span><br><span class="line">&lt;zookeeper&gt;   </span><br><span class="line">    &lt;node index=&quot;1&quot;&gt;  </span><br><span class="line">        &lt;host&gt;47.94.174.89&lt;/host&gt;  </span><br><span class="line">        &lt;port&gt;2181&lt;/port&gt;</span><br><span class="line">    &lt;/node&gt;</span><br><span class="line">&lt;/zookeeper&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 开放给外界访问，我们在最开始的时候也改过了 --&gt;</span><br><span class="line">&lt;listen_host&gt;0.0.0.0&lt;/listen_host&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 节点之间进行通信的 IP，需要进行设置，让节点之间可以互相访问，否则副本无法同步 --&gt;</span><br><span class="line">&lt;!-- 注意：我当前用的阿里云服务器不在同一个内网中，所以指定的是公网 IP</span><br><span class="line">     但如果你的多个阿里服务器云在同一个内网，那么建议指定内网 IP，节点之间通信会比使用公网 IP 快很多 --&gt;</span><br><span class="line">&lt;interserver_http_host&gt;47.94.174.89&lt;/interserver_http_host&gt;</span><br><span class="line">&lt;!-- 节点之间进行通信的端口，默认 9009，当然端口无所谓，只要保证彼此之间是开放的就行 --&gt;</span><br><span class="line">&lt;interserver_http_port&gt;9009&lt;/interserver_http_port&gt;</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
<p><strong>修改完配置之后重启 ClickHouse，然后从 satori 节点（47.94.174.89）开始，执行下面的语句，从而创建第一个副本实例：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> replicated_sales_1 (</span><br><span class="line">    id String,</span><br><span class="line">    price Float64,</span><br><span class="line">    create_time DateTime</span><br><span class="line">) </span><br><span class="line"><span class="comment">-- 这里 replica_name 我们就以 &quot;主机名_replica&quot; 的形式命名</span></span><br><span class="line">ENGINE<span class="operator">=</span>ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/replicated_sales_1&#x27;</span>, <span class="string">&#x27;satori_replica&#x27;</span>) </span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br></pre></td></tr></table></figure>

<p><strong>在创建的过程中，ReplicatedMergeTree 会进行一些初始化动作，例如：</strong></p>
<ul>
<li><code>根据 zk_path 初始化所有的 ZooKeeper 节点</code></li>
<li><code>在 /replicas/ 节点下注册自己的副本实例 satori_replica</code></li>
<li><code>启动监听任务，监听 /log 日志节点</code></li>
<li><code>参与副本选举，选举出主副本，选举的方式是向 /leader_election 插入子节点，第一个插入成功的副本就是主副本</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202222625-1610669710.png" alt="img"></p>
<p><strong>此时在 satori 节点上，该表（副本）就创建完毕了。</strong></p>
<p><strong>2）创建第二个副本实例</strong></p>
<p><strong>接着在 matsuri 节点上创建第二个副本，当然要先安装 ClickHouse，这里我已经安装完毕了。然后我们也要修改配置文件。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置 ZooKeeper，ZooKeeper 在 satori 节点上，指定相关 IP 和端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">zookeeper</span>&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;1&quot;</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span>47.94.174.89<span class="tag">&lt;/<span class="name">host</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">zookeeper</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 同理，开放给外界 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">listen_host</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">listen_host</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 节点之间进行通信的 IP，这里改成 matsuri 节点的 IP --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">interserver_http_host</span>&gt;</span>47.93.39.238<span class="tag">&lt;/<span class="name">interserver_http_host</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">interserver_http_port</span>&gt;</span>9009<span class="tag">&lt;/<span class="name">interserver_http_port</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>修改完配置文件之后，启动 ClickHouse，如果已经启动，那么就重启 ClickHouse 。然后创建第二个副本，表结构和 zk_path 和第一个副本相同，而 replica_name 则设置成 matsuri 节点的 IP。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> replicated_sales_1 (</span><br><span class="line">    id String,</span><br><span class="line">    price Float64,</span><br><span class="line">    create_time DateTime</span><br><span class="line">) </span><br><span class="line"><span class="comment">-- 除了 replica_name，其它不变</span></span><br><span class="line">ENGINE<span class="operator">=</span>ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/replicated_sales_1&#x27;</span>, <span class="string">&#x27;matsuri_replica&#x27;</span>) </span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYYYYMM(create_time)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br></pre></td></tr></table></figure>

<p><strong>在创建的过程中，第二个 ReplicatedMergeTree 同样会进行一些初始化动作，例如：</strong></p>
<ul>
<li><code>在 /replicas/ 节点下注册自己的副本实例 matsuri_replica</code></li>
<li><code>启动监听任务，监听 /log 日志节点</code></li>
<li><code>参与副本选举，选举出主副本，显然当前的主副本是 satori_replica 副本</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202232300-293850742.png" alt="img"></p>
<p><strong>两个副本全部创建完了，接下来该干啥了，没错，写入数据。</strong></p>
<p><strong>3）向第一个副本实例写入数据</strong></p>
<p><strong>现在尝试向第一个副本 satori_replica 写入数据，执行如下命令：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> replicated_sales_1</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;A001&#x27;</span>, <span class="number">100</span>, <span class="string">&#x27;2019-05-10 00:00:00&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202240184-445553689.png" alt="img"></p>
<p><strong>在执行上述命令后，首先会在本地完成分区目录的写入：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Renaming temporary part tmp_insert_201905_1_1_0 to 201905_0_0_0</span><br></pre></td></tr></table></figure>

<p><strong>接着向 &#x2F;blocks 节点写入该数据分区的 block_id：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Wrote block with ID &#x27;201905_11789774603085290207_1081647372304402844&#x27;</span><br></pre></td></tr></table></figure>

<p><strong>可能有人觉得这个 ID 是从哪里来的，答案是从 ZooKeeper 上面查的：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202313553-1303882622.png" alt="img"></p>
<p><strong>因为目前只有一个分区，所以 &#x2F;blocks 节点下面只有一个子节点（ZNode），ZNode 的名字就是 block_id，存储的值就是分区目录名。当然这个 block_id 的计算过程我们就不演示了，它不是重点，只要知道它是作为后续去重操作的判断依据即可。比如我们此时再执行一次刚才的 SQL 语句，试图写入重复数据，然后查询时会发现没有任何效果。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202322434-549762506.png" alt="img"></p>
<p><strong>所以副本会自动忽略 block_id 重复的待写入数据。</strong></p>
<p><strong>此外，如果设置了 insert_quorum 参数（默认值为 0）并且值大于等于 2，那么 satori_replica 副本会进一步监控已完成写入操作的副本个数，只有当写入副本个数大于等于 insert_quorum 时，整个写入操作才算成功。</strong></p>
<p><strong>4）由第一个副本实例推送 Log 日志</strong></p>
<p><strong>在第 3 个步骤完成之后，会继续由执行了 INSERT 的副本向 &#x2F;log 节点推送操作日志，在这个栗子中，会由第一个副本 satori_replica 担此重任。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202331023-534547670.png" alt="img"></p>
<p><strong>显然里面只有一个 ZNode，其 name 就是日志的编号：&#x2F;log&#x2F;log-0000000000，而 value 就是对应的 LogEntry。但这里我们没有打印，原因是里面有特殊的换行，导致打印的时候看起来非常的丑，至于内容如下所示：</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">format version:</span> <span class="number">4</span></span><br><span class="line"><span class="attr">create_time:</span> <span class="number">2021-09-17 15:07:47</span></span><br><span class="line"><span class="attr">source replica:</span> <span class="string">satori_replica</span></span><br><span class="line"><span class="attr">block_id:</span> <span class="string">201905_11789774603085290207_1081647372304402844</span></span><br><span class="line"><span class="string">get</span></span><br><span class="line"><span class="string">201905_0_0_0</span></span><br><span class="line"><span class="attr">part_type:</span> <span class="string">Compact</span></span><br></pre></td></tr></table></figure>

<p><strong>信息不难理解，里面的 get 表示操作类型，这里是下载。而需要下载的分区是 201905_0_0_0，其余所有副本都会基于 Log 日志以相同的顺序执行命令。</strong></p>
<p><strong>5）第二个副本实例拉取 Log 日志</strong></p>
<p><strong>matsuri_replica 副本会一直监听 &#x2F;log 节点变化，当 satori_replica 副本推送了 &#x2F;log&#x2F;log-0000000000 之后，matsuri_replica 副本便会触发日志的拉取任务并更新 log_pointer，将其指向最新日志下标：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/replicas/matsuri_replica/log_pointer: 1</span><br><span class="line">-- /replicas/matsuri_replica 下面的 ZNode 有很多，log_pointer 只是其中一个，所以这里再通过 name 过滤一下</span><br><span class="line">-- 注意：我们查看的是 log_pointer，所以不要将 path 指定为 /replicas/matsuri_replica/log_pointer</span><br><span class="line">-- 上面的做法不对的，因为这等于查看 log_pointer 下面所有的 ZNode，而不是 log_pointer 这个 ZNode</span><br><span class="line">SELECT name, value FROM system.zookeeper</span><br><span class="line">WHERE path = &#x27;/clickhouse/tables/01/replicated_sales_1/replicas/matsuri_replica&#x27;</span><br><span class="line">AND name = &#x27;log_pointer&#x27;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202340494-1223174326.png" alt="img"></p>
<p><strong>每拉取一次日志，log_pointer 对应的 value 就会自增 1，初始值是 0。</strong></p>
<p><strong>当 matsuri_replica 副本拉取了 satori_replica 副本推送的日志（这里是 &#x2F;log&#x2F;log-0000000000），便会根据其内容（LogEntry）进行执行。只不过这个动作并不是马上就发生的，而是会将其转成任务对象放在队列中：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/replicas/matsuri_replica/queue</span><br></pre></td></tr></table></figure>

<p><strong>这里放入队列是让其成为 &#x2F;replicas&#x2F;matsuri_replica&#x2F;queue 的子节点（ZNode），这么做的原因是在复杂的情况下，考虑到在同一个时间段内可能会连续收到许多个 LogEntry，所以通过队列的方式消化任务是一种更为合理的设计。注意：拉取的 LogEntry 是一个区间，这同样是因为可能会连续收到多个 LogEntry。不过当前只有一个 LogEntry，所以区间的开头和结尾是同一个 LogEntry。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Pulling 1 entries to queue: log-0000000000 - log-0000000000</span><br></pre></td></tr></table></figure>

<p><strong>但如果我们此时查看 &#x2F;replicas&#x2F;matsuri_replica&#x2F;queue 的话，会发现拿不到任何的信息，这是因为我们往 satori_replica 副本写入数据的之后，很快就同步到 matsuri_replica 副本当中了，所以此时队列中的任务已经被消费掉了，因此就什么也看不到了。我们可以查询 matsuri_replica 副本，看看数据是否真的同步过来了。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202349108-1707497686.png" alt="img"></p>
<p><strong>可以看到数据已经在 matsuri_replica 节点上面了，所以创建数据表需要每个副本都要创建，但是插入数据只需要往一个副本中插入即可，剩余的副本会自动同步。不过数据虽然已经同步过来了，但我们的整个流程还没有说完。当把 LogEntry 转成任务对象放到 queue 之后，该做什么了呢？不用想，肯定是从 queue 取出依次执行。</strong></p>
<p><strong>6）第二个副本实例向其它副本发起下载请求</strong></p>
<p><strong>matsuri_replica 基于 queue 队列发起下载任务，依次取出任务对象（封装 LogEntry）进行执行，当看到类型为 get 的时候，ReplicatedMergeTree 就会明白此时在远端的其它副本中已经成功写入了数据分区，而自己需要同步这些数据。</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">format version:</span> <span class="number">4</span></span><br><span class="line"><span class="attr">create_time:</span> <span class="number">2021-09-17 15:07:47</span></span><br><span class="line"><span class="attr">source replica:</span> <span class="string">satori_replica</span></span><br><span class="line"><span class="attr">block_id:</span> <span class="string">201905_11789774603085290207_1081647372304402844</span></span><br><span class="line"><span class="string">get</span></span><br><span class="line"><span class="string">201905_0_0_0</span></span><br><span class="line"><span class="attr">part_type:</span> <span class="string">Compact</span></span><br></pre></td></tr></table></figure>

<p><strong>因此 matsuri_replica 副本会开始选择远端的某一个副本作为下载来源，那么要选择哪一个呢？算法如下：</strong></p>
<ul>
<li><code>1. 从 /replicas 中拿到所有的副本节点</code></li>
<li><code>2. 遍历这些副本，选取其中一个，选取的副本需要拥有最大的 log_pointer，因为 log_pointer 越大，执行的日志越多，数据也就越完整。以此同时还要 queue 下的 ZNode 少的，因为 ZNode 越少，说明任务执行负担越小</code></li>
</ul>
<p><strong>当前远端只有 satori_replica 一个副本实例，所以会从它这里下载，于是 matsuri_replica 向 satori_replica 发起了 HTTP 请求，希望下载分区 201905_0_0_0。</strong></p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">Fetching part <span class="number">201905</span>_0_0_0 <span class="keyword">from</span> replicas/satori_replica</span><br><span class="line">Sending request to http:<span class="comment">//47.94.174.89:9009/?endpoint=DataPartsExchange</span></span><br></pre></td></tr></table></figure>

<p><strong>如果第一次下载失败，在默认情况下 matsuri_replica 会再尝试 4 次，一共会尝试 5 次。具体尝试次数由 max_fetch_partition_retries_count 参数控制，默认为 5。</strong></p>
<p><strong>7）第一个副本实例向响应数据下载</strong></p>
<p><strong>satori_replica 的 DataPartsExchange 端口服务接收到调用请求，在得知对方来意之后，根据参数做出响应，再基于 DataPartsExchange 将本地分区 201905_0_0_0 响应给 matsuri_replica。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Sending part 201905_0_0_0</span><br></pre></td></tr></table></figure>

<p><strong>8）第二个副本实例下载数据并完成本地写入</strong></p>
<p><strong>matsuri_replica 在接收到 satori_replica 的分区数据后，首先将其写至临时目录：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tmp_fetch_201905_0_0_0</span><br></pre></td></tr></table></figure>

<p><strong>待全部数据接收完成之后，重命名该目录：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Renaming temporary part tmp_fetch_201905_0_0_0 to 201905_0_0_0</span><br></pre></td></tr></table></figure>

<p><strong>至此整个写入流程结束。</strong></p>
<p><strong>可以看到从头到尾，在整个 INSERT 写入的过程中，ZooKeeper 没有进行任何表数据的传输，它只是起着一个分布式协调的作用。客户端往一个副本里面写入分区数据，然后该副本会往 ZooKeeper 里面推送相关日志，其它副本再拉取日志，根据日志内容（LogEntry）从该副本这里下载数据并写入各自的本地文件系统中。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202402797-1086970807.png" alt="img"></p>
<p><strong>另外我们说如果设置了 insert_quorum 并且 insert_quorum &gt;&#x3D; 2，则还会由该副本监控完成写入的副本数量。总之核心就是数据写在哪一个副本，哪一个副本就向 ZooKeeper 里面推日志，然后其它副本拉日志，接着选择一个最合适的远端副本，进行分区数据的点对点下载。</strong></p>
<p><strong>流程图总结：</strong></p>
<p><strong>下面再用一张图总结一下上面的 8 个步骤：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202411365-906877305.png" alt="img"></p>
<h4 id="MERGE-的核心执行流程"><a href="#MERGE-的核心执行流程" class="headerlink" title="MERGE 的核心执行流程"></a>MERGE 的核心执行流程</h4><p><strong>当前我们只写入了一条数据，如果往 201905 这个分区中再写入一条数据呢，显然会创建一个新的分区目录，然后后台线程会在一个合适的时机进行分区目录的合并。这里我们就还往 satori_replica 中写，然后在 matsuri_replica 中读，顺便再次验证副本之间是否会正常同步。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202419691-1875696001.png" alt="img"></p>
<p><strong>之前我们说，每拉取一次日志，log_pointer 就会自增 1，既然这里发生了数据同步，那么肯定涉及日志的拉取。那么按照分析，matsuri_replica 的 log_pointer 应该会变成 2，因为之前是 1，这里又拉取了一次。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202428263-1099973391.png" alt="img"></p>
<p><strong>插入数据我们算是已经明白了，那接下来就是合并数据了，也就是 ReplicatedMergeTree 的分区合并动作：MERGE。</strong></p>
<p><strong>其实无论 MERGE 操作从哪个副本发起，最终合并计划都会由主副本决定。在之前的例子中，satori_replica 已经竞选为主副本，所以为了论证，我们就从 matsuri_replica 开始。整个流程还是按照时间从上往下顺序进行，我们大致将其分了 5 个步骤，那么下面就依次讲解每一个过程。</strong></p>
<p><strong>1）创建远程连接，尝试与主副本通信</strong></p>
<p><strong>首先在 matsuri_replica 副本所在节点执行 OPTIMIZE，强制触发分区合并，这个时候 matsuri_replica 会通过 &#x2F;replicas 找到 satori_replica，并尝试建立和它的远程连接。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">optimize table replicated_sales_1</span><br><span class="line"><span class="title function_">Connection</span> <span class="params">(<span class="number">47.94</span><span class="number">.174</span><span class="number">.89</span>:<span class="number">9000</span>)</span> : Connetion. Database: <span class="keyword">default</span>. User: <span class="keyword">default</span></span><br></pre></td></tr></table></figure>

<p><strong>2）主副本接收通信</strong></p>
<p><strong>主副本接收并建立来自远端副本的连接。</strong></p>
<p><strong>3）由主副本制定 MERGE 计划并推送 Log 日志</strong></p>
<p><strong>由主副本 satori_replica 制定 MERGE 计划，并判断哪些分区需要合并，在选定之后 satori_replica 将合并计划转化为 Log 日志对象并推送，以通知所有副本开始合并。那么信息都有哪些呢，直接通过 ZooKeeper 查看即可。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202436682-1463046358.png" alt="img"></p>
<p><strong>这里我们使用 DataGrip 查询，命令行查询的话，输出的内容不好看。我们注意到 &#x2F;log 下面有三个 ZNode，log-0000000000 是第一次往 satori_replica 写入数据所产生的日志，log-0000000001 是第二次往 satori_replica 写入数据所产生的日志，而 log-0000000002 显然就是 MEREG 操作产生的日志。</strong></p>
<p><strong>根据内容中的 merge 我们可以得知这是一个合并操作，将 201905_0_0_0 和 201905_1_1_1 合并成 201905_0_1_1。并且通过 source replica 我们也能得知，合并操作是从 matsuri_replica 副本发出的。与此同时，主副本还会锁住执行线程，对日志的接收情况进行监听。其监听行为由 replication_alter_partitions_sync 参数控制，默认值为 1。</strong></p>
<ul>
<li><code>如果 replication_alter_partitions_sync 设置为 0，那么不做任何等待</code></li>
<li><code>如果 replication_alter_partitions_sync 设置为 1，只等待主副本自身完成</code></li>
<li><code>如果 replication_alter_partitions_sync 设置为 2，会等待所有副本拉取完成</code></li>
</ul>
<p><strong>4）各个副本分别拉取 Log 日志</strong></p>
<p><strong>主副本将 MERGE 计划制定好之后会推到 ZooKeeper 中，然后所有副本会进行拉取并推送到任务队列 &#x2F;queue 中，也就是成为它的一个 ZNode。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Pulling 1 entries to queue: log-0000000002 - log-0000000002</span><br></pre></td></tr></table></figure>

<p><strong>5）各个副本分别在本地执行 MERGE</strong></p>
<p><strong>satori_replica 和 matsuri_replica 基于各自的 &#x2F;queue 队列执行任务：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Executing log entry to merge parts 201905_0_0_0, 201905_1_1_0 to 201905_0_1_1</span><br></pre></td></tr></table></figure>

<p><strong>各个副本开始在本地执行 MERGE：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Merged 2 parts: from 201905_0_0_0 to 201905_1_1_0</span><br></pre></td></tr></table></figure>

<p><strong>到此，整个合并流程结束。可以看到和插入数据一样，在 MERGE 的过程中，ZooKeeper 也不会涉及任何表数据的传输，所有的合并操作都是由各个副本在本地完成的。并且无论合并动作在哪个副本被触发，首先都会被转交给主副本，再由主副本负责合并计划的制定、消息日志的推送以及日志接收情况的监控。</strong></p>
<p><strong>流程图总结：</strong></p>
<p><strong>同样可以用一张流程图总结一下上面 5 个步骤：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202445490-2126247950.png" alt="img"></p>
<h4 id="MUTATION-的核心流程"><a href="#MUTATION-的核心流程" class="headerlink" title="MUTATION 的核心流程"></a>MUTATION 的核心流程</h4><p><strong>对 ReplicatedMergeTree 数据表执行 ALTER DELETE 或 ALTER UPDATE 操作的时候，会进入 MUTATION 部分的逻辑。和 MERGE 类似，无论 MUTATION 操作从哪个副本发起，都会由主副本进行响应，所以为了方便论证，我们还是从不是主副本的 matsuri_replica 副本开始。整个流程按照时间从上往下顺序进行，大致分为 5 个步骤，下面依次介绍。</strong></p>
<p><strong>1）推送 Mutation 日志</strong></p>
<p><strong>在 matsuri_replica 通过 ALTER DELETE 来删除数据（ALTER UPDATE 与之同理），执行如下命令：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> replicated_sales_1 <span class="keyword">DELETE</span> <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><strong>执行之后，该副本会进行两个重要动作。</strong></p>
<ul>
<li><strong>创建 MUTATION ID</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">created mutation with ID 0000000000</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>将 MUTATION 操作转换为 Mutation 日志，并推送到 &#x2F;mutations&#x2F;0000000000，也就是在 &#x2F;mutations 下面新建一个名为 0000000000 的 ZNode。其中 0000000000 就是 Mutation 日志的 name，而对应的值、也就是 value 被称为 MutationEntry，这里和 Log 日志类似。MutationEntry 内容如下：</strong></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202453652-1012562048.png" alt="img"></p>
<p><strong>由此也能知晓，MUTATION 的操作日志是经由 &#x2F;mutations 节点分发至各个副本中的。</strong></p>
<p><strong>2）所有副本实例各自监听 Mutation 日志</strong></p>
<p><strong>所有副本都会监听 &#x2F;mutations 节点，一旦有新的日志子节点加入，它们都能实时感知。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loading 1 mutation entries: 0000000000 - 0000000000</span><br></pre></td></tr></table></figure>

<p><strong>当监听到有新的 Mutation 日志加入时，并不是所有的副本都会立即响应，它们会先判断自己是不是主副本。</strong></p>
<p><strong>3）由主副本实例响应 Mutation 日志并推送 Log 日志</strong></p>
<p><strong>只有主副本才会响应 Mutation 日志，在这个栗子中 satori_replica 为主副本，所以 satori_replica 将 Mutation 日志转换为 Log 日志并推送至 &#x2F;log 节点，已通知各个副本执行的具体操作。之前 &#x2F;log 下面最后一个 ZNode 是 log-0000000002，所以接下来会写入一个 log-0000000003。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202500455-101160944.png" alt="img"></p>
<p><strong>从日志内容可以看出上述的操作类型为 mutate，而这次需要将 201905_0_1_1 分区修改成 201905_0_1_1_2，修改规则：”201905_0_1_1” + “_” + mutation_id。</strong></p>
<p><strong>4）各个副本实例分别拉取 Log 日志</strong></p>
<p><strong>satori_replica 副本和 matsuri_replica 副本分别监听 &#x2F;log&#x2F;log-0000000003 日志的推送，它们也会分别拉取日志到本地，通推送到各自的 &#x2F;queue 任务队列。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Pulling 1 entries to queue: /log/log-0000000003 - /log/log-0000000003</span><br></pre></td></tr></table></figure>

<p><strong>5）各个副本分别在本地执行 MUTATION</strong></p>
<p><strong>satori_replica 副本和 matsuri_replica 副本基于各自的 &#x2F;queue 队列开始执行任务：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Executing log entry to mutate part 201905_0_1_1 to 201905_0_1_1_2</span><br></pre></td></tr></table></figure>

<p><strong>各个副本开始在本地执行 MUTATION 操作：</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">Cloning part <span class="number">201905</span>_0_1_1 <span class="selector-tag">to</span> tmp_clone_201905_0_1_1_2</span><br><span class="line">Renaming temporary part tmp_clone_201905_0_1_1_2 <span class="selector-tag">to</span> <span class="number">201905</span>_0_1_1_2</span><br></pre></td></tr></table></figure>

<p><strong>至此，整个 MUTATION 流程结束。</strong></p>
<p><strong>可以看到在 MUTATION 的整个过程中，ZooKeeper 同样不会进行任何实质性的数据传输，所有的 MUTATION 操作最终都是由各个副本在本地完成的。而 MUTATION 操作是经过 &#x2F;mutations 节点实现分发的，本着谁执行谁负责的原则，当前是由 matsuri_replica 负责了消息的推送，在 &#x2F;mutations 下面新建了 &#x2F;mutations&#x2F;0000000000。但无论 MUTATION 操作由哪个副本触发，最终都会转交给主副本，再由主副本负责推送到 Log 日志中，以通知各个副本执行最终的 MUTATION 逻辑，同时也由主副本对日志接收的情况进行监控。</strong></p>
<p><strong>流程图总结：</strong></p>
<p><strong>同样可以用一张流程图总结一下上面 5 个步骤：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202509508-862835317.png" alt="img"></p>
<h4 id="ALTER-的核心执行流程"><a href="#ALTER-的核心执行流程" class="headerlink" title="ALTER 的核心执行流程"></a>ALTER 的核心执行流程</h4><p><strong>对 ReplicatedMergeTree 执行 ALTER 操作进行元数据修改的时候，会进入 ALTER 部分的逻辑，例如增加、删除表字段等等。但与之前的几个流程相比，ALTER 的逻辑要显得简单很多，因为整个过程不涉及 &#x2F;log 日志的分发。整个流程按照时间从上往下顺序进行，大致可以分为 3 个步骤，下面依次介绍。</strong></p>
<p><strong>1）修改共享元数据</strong></p>
<p><strong>在 matsuri_replica 副本上修改，增加一个字段。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 增加一个字段 product，表示商品的名字，并且将该字段排在 id 后面</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> replicated_sales_1 <span class="keyword">ADD</span> <span class="keyword">COLUMN</span> product String AFTER id;</span><br></pre></td></tr></table></figure>

<p><strong>执行之后，matsuri_replica 副本会修改 ZooKeeper 内的共享元数据节点 &#x2F;metadata、&#x2F;columns：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Updated shared metadata nodes in ZooKeeper. Waiting for replicas to apply changes.</span><br></pre></td></tr></table></figure>

<p><strong>数据修改后，节点的版本号也会同时提升：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Version of metadata nodes in ZooKeeper changed. Waiting for structure write lock.</span><br></pre></td></tr></table></figure>

<p><strong>与此同时，matsuri_replica 还会负责监听所有副本的修改完成情况：</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">Waiting for satori_replica <span class="selector-tag">to</span> apply changes</span><br><span class="line">Waiting for matsuri_replica <span class="selector-tag">to</span> apply changes</span><br></pre></td></tr></table></figure>

<p><strong>2）监听共享元数据变更并各自执行本地修改</strong></p>
<p><strong>satori_replica 和 matsuri_replica 各自监听共享元数据的变更，之后它们会分别对本地的元数据版本号和共享版本号进行对比。在当前这个案例中，它们会发现本地版本号低于共享版本号，于是开始在各自本地执行更新操作：</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">Metadata changed in ZooKeeper. Applying changes locally.</span><br><span class="line">Applied changes <span class="selector-tag">to</span> the metadata of the <span class="selector-tag">table</span>.</span><br></pre></td></tr></table></figure>

<p><strong>3）确认所有副本完成修改</strong></p>
<p><strong>matsuri_replica 会确认所有副本均已完成修改：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> finished</span><br><span class="line">Done processing query</span><br></pre></td></tr></table></figure>

<p><strong>至此整个 ALTER 流程结束，可以看出该过程 ZooKeeper 同样不会涉及实质性的数据传输，所有的 ALTER 均使用各个副本在本地所完成的。本着谁执行谁负责的原则，在这个案例中由 matsuri_replica 负责对共享元数据进行修改以及对各个副本的修改进度进行监控。</strong></p>
<p><strong>具体执行案例如下，我们在 matsuri_replica 副本上增加一个 product 字段，然后在 satori_replica 副本上查询到了新增加的字段，证明确实进行了同步。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202521412-94419283.png" alt="img"></p>
<p><strong>至于 matsuri_replica 副本我们就不用看了，它里面肯定也是会多出一个 product 字段的。</strong></p>
<p><strong>流程图总结：</strong></p>
<p><strong>同样可以用一张流程图总结一下上面 3 个步骤：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202527956-802735965.png" alt="img"></p>
<h2 id="数据分片"><a href="#数据分片" class="headerlink" title="数据分片"></a>数据分片</h2><p><strong>通过引入数据副本，虽然能够有效降低数据丢失的风险（多份存储），并提升查询的性能（分摊查询、读写分离），但是仍然有一个问题没有解决，那就是数据表的容量问题。因为到目前为止，每个副本自身仍然保存了数据表的全量数据，所以在业务量十分庞大的场景中，依靠副本并不能解决单表的性能瓶颈。想要从根本上解决这类问题，需要借助另外一种手段，即进一步将数据水平切分，也就是我们将要介绍的数据分片。</strong></p>
<p><strong>ClickHouse 中的每个服务节点都可以称为一个 shard（分片），从理论上来讲，假设有 N 张数据表 T，分布在 N 个 ClickHouse 服务节点，而这些数据表之前没有重复数据，那么就可以说数据表 T 有 N 个分片。但是在工程实践中，如果只有这些分片表，那么整个 Sharding 方案基本是不可用的。因为对于一个完整的方案来说，还需要考虑数据在写入时，如何被均匀地写入至各个 shard；以及数据在查询时，如何路由到每个 shard，并组合形成结果集。所以 ClickHouse 的数据分片需要结合 Distributed 表引擎一同使用。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202535125-1777878576.png" alt="img"></p>
<p><strong>我们之前说过 Distributed 表引擎，Distributed 数据表本身不存储任何数据，它只是作为分布式表的一层透明代理，在集群内部自动开展数据的写入、分发、查询、路由等工作。</strong></p>
<h3 id="集群的配置方式"><a href="#集群的配置方式" class="headerlink" title="集群的配置方式"></a>集群的配置方式</h3><p><strong>在 ClickHouse 中，集群配置用 shard 代表分片、replica 代表副本，那么逻辑层面，表示 1 分片 0 副本语义的配置就是：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>而表示 1 分片、1 副本的语义则是：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>而表示 1 分片、2 副本的语义则是：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>而表示 2 分片、0 副本的语义则是：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span><span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span><span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>可以看到这种配置再次体现了，shard 只是逻辑层面的分组，最终的承载都是由副本来实现。</strong></p>
<p><strong>相信分片和副本的概念还是很容易区分的，你就可以理解为分片是把多个副本进行分组，每一组就是一个分片，一个分片下面可以有任意个副本。因此还是那句话，副本才是用来实际承载数据的，而分片只是一个起到一个逻辑组织的作用。同一分片下面的所有副本存放的数据相同，实现高可用，一个副本挂了，其它副本顶上去；不同分片下的副本存放的数据不同，从而实现数据的水平切分。</strong></p>
<p><strong>下面就来搭建分片集群，如果是多分片，那么就需要在 config.xml 中搭建集群配置了。</strong></p>
<p><strong>这里我们搭建 3 分片 0 副本，那么配置如下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 集群的名称，全局唯一，是后续引用集群配置的唯一标识 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 在一个配置文件内可以定义任意组集群，想用哪一个直接通过集群的名称进行引用即可 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ch_cluster_3shard_0replica</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">shard</span>&gt;</span> <span class="comment">&lt;!-- 分片 1 --&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span> <span class="comment">&lt;!-- 该分片只有一个副本，由 satori 节点承载 --&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 注意：这里的 host 需要写主机名，因此我们需要在 /etc/hosts 中配置其它节点的公网 IP 到主机名的映射 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>satori<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span> <span class="comment">&lt;!-- 分片 2 --&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span> <span class="comment">&lt;!-- 该分片只有一个副本，由 matsuri 节点承载 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>matsuri<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span> <span class="comment">&lt;!-- 分片 3 --&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span> <span class="comment">&lt;!-- 该分片只有一个副本，由 aqua 节点承载 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>aqua<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ch_cluster_3shard_0replica</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>如果只是 1 分片，那么只需要配置 ZooKeeper 即可，但如果是多分片，那么除了 ZooKeeper 之外我们还要配置集群。这里首先要为集群起一个名字，然后自定义分片，当然我们说分片只是逻辑层面的分组，副本才是真正存储数据的。所以还需要在 shard 标签中定义 replica 标签，replica 标签中指定相应的 IP 和端口，从配置中我们可以看出一个 shard 可以有多个 replica，具体有多少个则由我们自己决定；此外也可以有多个 shard，每个 shard 内的 replica 也可以不同。我们上面相当于创建了 3 个 shard，每个 shard 都只有 1 个 replica，在 ClickHouse 中也就是 3 分片 0 副本。</strong></p>
<p><strong>那么问题来了，虽然我们这里只是演示多分片，但上面的配置如果真要放在生产上会有什么后果呢？没错，无法达到高可用，因为每个分片只有一个副本，如果一个节点挂了，那么整个服务就不可用了，所以每个 shard 应该配置多个 replica。这里我们不管那么多，先看看如何实现多分片。</strong></p>
<p><strong>我们关闭 satori、matsuri 节点上的 ClickHouse 服务，然后修改其 config.xml 文件，将上面的配置拷贝到 remote_servers 标签下面即可。最后是 aqua 节点，我阿里云上有三个 CentOS，主机名分别是 satori、matsuri、aqua，目前使用了前两个。而 aqua 节点上还没有 ClickHouse，所以我们需要先安装，安装之后将配置拷贝过去。注意：除了上面的关于集群的配置，还有下面这些配置也别忘记，也就是我们在前两个节点中所做的配置，所有节点都应保持一致。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">zookeeper</span>&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;<span class="name">node</span> <span class="attr">index</span>=<span class="string">&quot;1&quot;</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span>47.94.174.89<span class="tag">&lt;/<span class="name">host</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">node</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">zookeeper</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">listen_host</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">listen_host</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 内部通信 IP，改成 aqua 节点 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">interserver_http_host</span>&gt;</span>47.93.235.147<span class="tag">&lt;/<span class="name">interserver_http_host</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">interserver_http_port</span>&gt;</span>9009<span class="tag">&lt;/<span class="name">interserver_http_port</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>所有配置都完成之后，我们启动三台节点上的 ClickHouse，然后验证集群是否搭建成功。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202549652-1741741732.png" alt="img"></p>
<p><strong>我们在 aqua 节点上进行查询，cluster 列表示集群的名字，这里我们选择 cluster 为 ch_cluster_3shard_0replica 的记录；然后 host_name、host_address 表示当前副本所在的节点的主机名、IP；replica_num 表示该副本属于当前所在分片的第几个副本，因为每个分片只有一个副本，所以它们都是 1；shard_num 表示该副本所在的分片是第几个分片，显然 satori 副本处于第一个分片，matsuri 副本处于第二个分片，aqua 处于第三个分片。</strong></p>
<h3 id="基于集群实现分布式-DDL"><a href="#基于集群实现分布式-DDL" class="headerlink" title="基于集群实现分布式 DDL"></a>基于集群实现分布式 DDL</h3><p><strong>我们前面介绍副本的时候为了创建副本表，需要分别登录到每个 ClickHouse 节点，在它们本地执行各自的 CREATE 语句，这是因为在默认情况下，CREATE、DROP、RENAME 等 DDL 语句不支持分布式执行。而在加入集群配置之后，就可以使用新的语法实现分布式 DDL 执行了，语法形式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE/DROP/RENAME TABLE table_name ON CLUSTER cluster_name ...</span><br></pre></td></tr></table></figure>

<p><strong>ON CLUSTER 位于 TABLE table_name 之后，表示集群的每个节点都执行该 DDL 语句，而 cluster_name 就是集群的名称，ClickHouse 会通过 cluster_name 找到该集群的配置信息，然后顺藤摸瓜，分别去各个节点中执行 DDL 语句。下面就用分布式 DLL 的形式建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_1 <span class="keyword">ON</span> CLUSTER ch_cluster_3shard_0replica(</span><br><span class="line">    id UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/&#123;shard&#125;/distributed_test_1&#x27;</span>, <span class="string">&#x27;&#123;replica&#125;&#x27;</span>)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br></pre></td></tr></table></figure>

<p><strong>该语句先不要执行，我们还有一些细节要说，首先就是这里 ENGINE，可以指定其它任意的表引擎。然后是 ON CLUSTER，我们可以在任何一个节点执行这个建表语句，而 ClickHouse 在看到 ON CLUSTER 之后就知道这是一个分布式 DDL，会根据 ch_cluster_3shard_0replica 找到相关的集群配置，然后在其它节点上也执行这个 DDL。</strong></p>
<p><strong>最后是 ReplicatedMergeTree，首先如果在不同的节点上建表，那么 zk_path 和 replica_name 显然是不同的，因此我们不可以写死。否则 ClickHouse 在广播 DDL 给其它节点执行之后，所有分片下的所有副本的 zk_path 和 replica_name 就都是一样的了。因此 ClickHouse 提供了两个动态宏变量 {shard} 和 {replica}，用于替换之前的硬编码方式，而动态宏变量的值可以通过系统表 system.macros 进行查看。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202559072-210194613.png" alt="img"></p>
<p><strong>但问题来了，我们看到查询的结果是空的，原因是我们没有在 config.xml 中没有进行配置。在 config.xml 下面有一个 macros 标签，是被注释掉的，我们配置一下就行了。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202605588-37487189.png" alt="img"></p>
<p><strong>配置如下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- satori 节点 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">macros</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span>01<span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span>satori_name<span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">macros</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- matsuri 节点 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">macros</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span>02<span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span>matsuri_name<span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">macros</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- aqua 节点 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">macros</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span>03<span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replica</span>&gt;</span>aqua_name<span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">macros</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>我们将注释打开，分别进行修改，或者不打开注释，直接在粘贴在 yandex 标签下即可，然后重启三台节点上的 ClickHouse 服务。</strong></p>
<p><strong>然后我们查看宏变量是否生效：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202615424-137419479.png" alt="img"></p>
<p><strong>现在我们就能执行上面那条分布式建表语句了，然后 shard_num 和 replica_name 会用 {shard} 和 {replica} 两个宏变量进行替代。我们下面随便挑一个节点，就在 matsuri 节点上执行上面那条建表语句吧。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202622496-1056051619.png" alt="img"></p>
<p><strong>根据返回的内容，我们看到表在 satori、matsuri、aqua 三个节点上均已成功创建。同理，如果想删除的话，那么也可以执行分布式 DROP。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DROP TABLE distributed_test_1 ON CLUSTER ch_cluster_3shard_0replica</span><br></pre></td></tr></table></figure>

<p><strong>通过搭建集群，我们便可以执行分布式 DDL，记得在上面介绍 1 分片、多副本的时候我们说过，只有 1 个分片的话，不需要搭建集群，只需要借助 ZooKeeper 即可。但很明显，1 分片、多副本这种模式只是不需要搭建，但不是说不能搭建，如果搭建了集群（1 shard、多 replica），一样可以执行分布式 DLL。</strong></p>
<p><strong>然后我们来介绍一下整个流程，当我们在一个节点上执行分布式 DDL，该 DDL 是如何被广播到其它节点上的。</strong></p>
<h4 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h4><p><strong>和 ReplicatedMergeTree 类似，分布式 DDL 语句在执行的过程中也需要借助 ZooKeeper 的协同能力，以实现日志分发。</strong></p>
<p><strong>1）ZooKeeper 内的节点结构</strong></p>
<p><strong>在默认情况下，分布式 DDL 在 ZooKeeper 内使用的根路径为：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/clickhouse/task_queue/ddl</span><br></pre></td></tr></table></figure>

<p><strong>该路径由 config.xml 内的 distributed_ddl 配置指定：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202629918-1346559146.png" alt="img"></p>
<p><strong>在此根路径下，还有一些其它的监听节点，其中包括 DDL 操作日志 &#x2F;query-[seq]，每执行一次分布式 DDL 查询，在该节点下就会新增一条操作日志，以记录相应的操作指令。当各个节点监听到有新日志加入的时候，便会响应执行。DDL 操作日志使用 ZooKeeper 的持久顺序型节点，每条指令的名称以 query- 为前缀，后面的序号递增，例如 query-0000000000、query-0000000001 等等。</strong></p>
<p><strong>另外在每条 query-[seq] 操作日志之下，还有两个状态节点：</strong></p>
<ul>
<li><code>1）/query-[seq]/active：用于状态监控等用途，在任务执行的过程中，该节点下会临时保存当前集群内状态为 active 的节点</code></li>
<li><code>2）/query-[seq]/finished：用于检查任务的完成情况，在任务的执行过程中，每当集群内的某个 host 节点执行完毕之后，便会在该节点下写入记录</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202644867-466036386.png" alt="img"></p>
<p><strong>上述语句表示集群内的 satori、matsuri、aqua 三个节点已经完成任务。</strong></p>
<p><strong>2）DDLLogEntry 日志对象的数据结构</strong></p>
<p><strong>在 &#x2F;query-[seq] 下记录的日志信息由 DDLLogEntry 承载，它拥有如下几个核心属性：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202638591-1102781642.png" alt="img"></p>
<p><strong>query 记录了 DDL 查询的执行语句：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> default.distributed_test_1</span><br><span class="line">UUID \<span class="string">&#x27;d5d4c459-4e89-47b2-95d4-c4594e8957b2\&#x27;</span></span><br><span class="line"><span class="keyword">ON</span> CLUSTER ch_cluster_3shard_0replica</span><br><span class="line">(</span><br><span class="line">    `id` UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> ReplicatedMergeTree(\<span class="string">&#x27;/clickhouse/tables/&#123;shard&#125;/distributed_test_1\&#x27;</span>, \<span class="string">&#x27;&#123;replica&#125;\&#x27;</span>) <span class="keyword">ORDER</span> <span class="keyword">BY</span> id</span><br></pre></td></tr></table></figure>

<p><strong>hosts 记录了指定集群的 hosts 主机列表，集群由分布式 DDL 语句中的 ON CLUSTER 指定。在分布式 DDL 的执行过程中，会根据 hosts 列表逐个判断它们的执行状态。</strong></p>
<p><strong>initiator 记录初始化 host 主机的名称，说白就是分布式 DDL 最开始是在哪个节点执行的</strong></p>
<h4 id="分布式-DDL-的核心执行流程"><a href="#分布式-DDL-的核心执行流程" class="headerlink" title="分布式 DDL 的核心执行流程"></a>分布式 DDL 的核心执行流程</h4><p><strong>与副本协同的核心流程类似，接下来就以上面创建 distributed_test_1 为例，解释分布式 DDL 的核心执行流程。整个流程从上到下按照时间顺序进行，大致可以分为三个步骤：</strong></p>
<p><strong>1）推送 DDL 日志</strong></p>
<p><strong>首先在 matsuri 节点执行 CREATE TABEL ON CLUSTER，本着谁执行谁负责的原则，在这个案例中也会由 matsuri 节点负责创建 DDLLogEntry 日志并将日志推送到 ZooKeeper，同时也会由这个节点负责监控任务的执行进度。</strong></p>
<p><strong>2）拉取日志并执行</strong></p>
<p><strong>matsuri、satori、aqua 三个节点分别监听 &#x2F;ddl&#x2F;query-0000000000 日志的推送，于是它们分别拉取日志到本地。首先它们会判断各自的 host 是否被包含在 DDLLogEntry 的 hosts 列表中，如果包含在内，则进入执行流程，执行完毕后写入 finished 节点；如果不包含，则忽略这次日志的推送。</strong></p>
<p><strong>3）确认执行进度</strong></p>
<p><strong>在步骤 1 执行 DDL 语句之后，客户端会阻塞 180 秒（由参数 distributed_ddl_task_timeout 指定），以期望所有 host 都执行完这个分布式 DDL。如果阻塞时间超过了 180 秒，则会转入后台线程继续等待。</strong></p>
<p><strong>流程图总结：</strong></p>
<p><strong>我们这里有三个副本，但是为了画图方便，图中只画了两个。因为 satori_replica 和 aqua_replica 的表现是一致的，所以 satori_replica 就不画了。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202653371-389429149.png" alt="img"></p>
<h2 id="Distributed-原理解析"><a href="#Distributed-原理解析" class="headerlink" title="Distributed 原理解析"></a>Distributed 原理解析</h2><p><strong>Distributed 表引擎是分布式表的代名词，它自身不存储任何数据，而是作为数据分片的透明代理，能够自动路由数据至集群中的各个节点，所以 Distributed 表引擎需要和其它数据表引擎一起协同工作，如图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202658656-770906243.png" alt="img"></p>
<p><strong>从实体表的层面来看，一张分片表由两部分组成：</strong></p>
<ul>
<li><code>本地表：通常以 _local 为后缀进行命名，本地表是承接数据的载体，可以使用非 Distributed 的任意表引擎，一张本地表对应了一个数据分片</code></li>
<li><code>分布式表：通常以 _all 为后缀进行命名，分布式表只能使用 Distributed 表引擎，它和本地表形成一对多的映射关系，后续将通过分布式表代理操作多张本地表</code></li>
</ul>
<blockquote>
<p><strong>我们刚才在建表的时候，将表起名为 distributed_test_1 实际上是不符合规范的，应该以 _local 为后缀进行命名，不过无所谓，理解就好。</strong></p>
</blockquote>
<p><strong>对于分布式表与本地表之间表结构的一致性检查，Distributed 表引擎采用了读时检查的机制，这意味着如果它们的表结构不兼容，只有在查询时才会抛出错误，而在创建表时并不会进行检查。另外不同 ClickHouse 节点上本地表之间可以使用不同的表引擎，但是通常不建议这么做，保持它们的结构一致，有利于后期的维护、并避免造成不可预计的错误。</strong></p>
<h3 id="定义形式"><a href="#定义形式" class="headerlink" title="定义形式"></a>定义形式</h3><p><strong>Distributed 表引擎的定义形式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENGINE = Distributed(cluster, database, table [, sharding_key])</span><br></pre></td></tr></table></figure>

<p><strong>里面的参数也比较简单，cluster 表示集群的名称，也就是在 config.xml 中配置的集群名称，在分布式表执行写入和查询的过程中，它会使用集群的配置信息来找到相应的 host 节点；database 和 table 则表示数据库和数据表的名称，分布式表使用这组配置映射到本地表；shard_key 表示分片键，在数据写入的过程中，分布式表会依据分片键的规则，将数据分布到各个 host 节点的本地表。</strong></p>
<p><strong>我们之前在三个节点中创建了本地表 distributed_test_1，下面就来创建一张 Distributed 表来作为它们的代理表。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_1_all <span class="keyword">ON</span> CLUSTER ch_cluster_3shard_0replica(</span><br><span class="line">    id UInt64</span><br><span class="line">)ENGINE <span class="operator">=</span> Distributed(ch_cluster_3shard_0replica, <span class="keyword">default</span>, distributed_test_1, rand());</span><br></pre></td></tr></table></figure>

<p><strong>上面的建表语句会创建一张 Distributed 表，名为 distributed_test_1_all，然后通过 ON CLUSTER 会将该建表语句广播到集群的每一个分片节点上，确保它们都会创建一张 Distributed 表，这样就可以在任意一个分片节点发起对所有分片的读、写请求。当然只在一个节点上创建分布式表也是可以的，但是后续的操作只能在该节点上进行。然后是表引擎参数，我们可以看出代理的本地表为 distributed_test_1，其分布在集群 ch_cluster_3shard_0replica 的各个 shard 中，并且在数据写入的时候会根据 rand() 随机函数的取值决定数据写入哪个分片。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202709609-197121402.png" alt="img"></p>
<p><strong>下面在 matsuri 节点执行上述 Distributed 表（分布式表）的建表语句，当然在哪个节点上执行都无所谓的，因为是分布式 DDL，每个分片节点上都会执行：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202715706-329859055.png" alt="img"></p>
<p><strong>至此本地表和分布式表就都创建好了，这里再多提一句，即使没有本地表，也是可以创建分布式表的。因为 Distributed 表运用的是读时检查的机制，所以对于分布式表和本地表的创建顺序没有要求。</strong></p>
<h3 id="查询种类"><a href="#查询种类" class="headerlink" title="查询种类"></a>查询种类</h3><p><strong>Distributed 表的查询操作可以分为如下几类：</strong></p>
<p><strong>1）会作用于本地表的查询：对于 INSERT 和 SELECT 查询，Distributed 表将会以分布式的方式作用于 local 本地表，而对于这些查询的具体规则，一会介绍。</strong></p>
<p><strong>2）只会影响 Distributed 表本身，不会作用于本地表的查询：Distributed 表支持部分元数据的操作，包括 CREATE、DROP、RENAME 和 ALTER，其中 ALTER 并不包括分区的操作（ATTACH PARTITION、REPLACE PARTITION 等）。这些查询只会修改 Distributed 表自身，并不会修改 local 本地表，所以如果想将分布式表和本地表都删掉的话，那么要分别删除。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 删除分布式表</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> distributed_test_1_all <span class="keyword">ON</span> CLUSTER ch_cluster_3shard_0replica;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除本地表</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> distributed_test_1 <span class="keyword">ON</span> CLUSTER ch_cluster_3shard_0replica;</span><br></pre></td></tr></table></figure>

<p><strong>3）不支持的查询：Distributed 表不支持任何 MUTATION 类型的操作，包括 ALTER DELETE 和 ALTER UPDATE。</strong></p>
<h3 id="分片规则"><a href="#分片规则" class="headerlink" title="分片规则"></a>分片规则</h3><p><strong>这里再进一步说明一下分片的规则，我们在创建 Distributed 表的时候，表引擎中指定了 sharding_key，也就是分片键。而分片键是由要求的，它必须返回一个整型类型的取值，比如：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 按照用户 id 的余数划分，userid 是整型</span></span><br><span class="line">ENGINE <span class="operator">=</span> Distributed(cluster, database, <span class="keyword">table</span>, userid)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 也可以是一个返回整数的表达式，比如按照随机数划分</span></span><br><span class="line">ENGINE <span class="operator">=</span> Distributed(cluster, database, <span class="keyword">table</span>, rand())</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 按照用户 id 的散列值划分</span></span><br><span class="line">ENGINE <span class="operator">=</span> Distributed(cluster, database, <span class="keyword">table</span>, intHash64(userid))</span><br></pre></td></tr></table></figure>

<p><strong>如果不声明分片键，那么分布式表只能包含一个分片，这意味着只能映射一张本地表，否则在写入数据的时候会抛出异常。但如果一张分布式表只能包含一个分片，那还不如单机，显然此时就没意义了。因此，虽然 sharding_key 是选填参数，但是通常都会按照业务规则进行设置。</strong></p>
<p><strong>那么设置完分片键之后，数据又是如何被划分的呢？想要搞清楚这一点，需要先明确几个概念。</strong></p>
<h4 id="1-分片权重"><a href="#1-分片权重" class="headerlink" title="1.分片权重"></a>1.分片权重</h4><p><strong>在集群的配置中，有一项 weight（分片权重）的设置：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 集群的名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ch_cluster_3shard_0replica</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">shard</span>&gt;</span> <span class="comment">&lt;!-- 分片 1 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">weight</span>&gt;</span>10<span class="tag">&lt;/<span class="name">weight</span>&gt;</span> <span class="comment">&lt;!-- 分片权重 --&gt;</span></span><br><span class="line">        ......</span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span> <span class="comment">&lt;!-- 分片 2 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">weight</span>&gt;</span>20<span class="tag">&lt;/<span class="name">weight</span>&gt;</span> <span class="comment">&lt;!-- 分片权重 --&gt;</span></span><br><span class="line">        ......</span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p><strong>shard 里面不仅仅可以指定 replica，还可以指定其它属性，比如 weight（权重）。weight 默认为 1，虽然它可以设置成任意整数，但官方建议应该尽可能设置成较小的值，分片权重会影响数据在分片中的倾斜程度，一个分片的权重值越大，那么它被写入的数据就越多。</strong></p>
<h4 id="slot（槽）"><a href="#slot（槽）" class="headerlink" title="slot（槽）"></a>slot（槽）</h4><p><strong>如果把数据比作是水的话，那么 slot 就可以理解为许多的小水槽，数据会顺着这些水槽流进每个数据分片。slot 的数量等于所有分片的权重之和，假设每个集群有两个 shard，第一个 shard 的 weight 为 10，第二个 shard 的 weight 为 20，那么 slot 的数量则等于 30。slot 按照权重元素的取值区间，与对应的分片形成映射关系，如果 slot 值落在 [0, 10) 区间，则对应第一个分片；如果 slot 值落在 [10, 30) 区间，则对应第二个分片。还是比较简单粗暴好理解的，因此 weight 值越大，那么区间范围也就越广，slot 值落在该区间的概率也就越大。</strong></p>
<h4 id="选择函数"><a href="#选择函数" class="headerlink" title="选择函数"></a>选择函数</h4><p><strong>选择函数用于判断一行待写入的数据应该被写入哪个分片，整个判断过程可以分为两步：</strong></p>
<p><strong>1）它会找出 slot 的取值，计算公式如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">slot = shard_value % sum_weight</span><br></pre></td></tr></table></figure>

<p><strong>其中，shard_value 是分片键的取值，sum_weight 是所有分片的权重之和，slot 等于 shard_value 对 sum_weight 取余。假设某一行的数据的 shard_value 是 10，sum_weight 是 30（两分片，第一个分片权重为 10，第二个分片权重为 20），那么 slot 值就等于 10（10 % 30）；再比如 shard_value 如果为 90，那么 slot 值就为 0（90 % 30）。</strong></p>
<p><strong>2）基于 slot 值找到对应的数据分片，当 slot 值等于 10 的时候，它属于 [10, 30) 区间，此时这行数据会对应到第二个 shard；当 slot 值为 0 的时候，它属于 [0, 10) 区间，所以这行数据会对应到第一个分片。</strong></p>
<h3 id="分布式写入的核心流程"><a href="#分布式写入的核心流程" class="headerlink" title="分布式写入的核心流程"></a>分布式写入的核心流程</h3><p><strong>在向集群内的分片写入数据时，通常有两种思路：一种是借助外部计算系统，事先根据分片数量将数据计算均匀，再借由计算系统直接将数据写入 ClickHouse 集群的各个本地表。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202729066-2120076310.png" alt="img"></p>
<p><strong>上述这种方案通常拥有更好的写入性能，因为分片数据是被并行点对点写入的。但这种方案重度依赖于外部系统，而不在 ClickHouse 自身，所以这里主要会介绍第二种思路。</strong></p>
<p><strong>第二种思路是通过 Distributed 表引擎代理写入分片数据，下面就来介绍整个流程。首先关于流程我们大致也能猜到，就是 Distributed 表将数据写入到每个分片的一个副本中，然后获得数据的副本再将数据同步到自己所在分片的其它副本中。因此核心可以分为两个步骤，分别是 “分片写入” 和 “副本复制（同步）”，由于我们目前搭建的是 3 分片 0 副本，所以先介绍 “分片写入”；后续再通过 1 分片 2 副本来介绍 “副本复制”，由于只有三台服务器，所以无法给 3 个分片都配置副本，因为这样至少需要 6 台服务器，于是在介绍副本复制的时候我们会使用 1 分片。当然副本复制和分片数量无关，因为每个分片之间的副本复制所做的事情都是一样的，所在在介绍副本复制的时候，1 分片 和 多分片之间没有什么区别。下面先来看看分片写入的整个过程是怎么样的吧。</strong></p>
<h4 id="将数据写入分片的核心流程"><a href="#将数据写入分片的核心流程" class="headerlink" title="将数据写入分片的核心流程"></a>将数据写入分片的核心流程</h4><p><strong>对 Distributed 表执行 INSERT 查询的时候，会进入数据写入分片的执行逻辑，我们按照时间顺序从上往下，大致可以分为 5 个步骤，下面依次介绍。</strong></p>
<p><strong>1）在第一个分片节点写入本地分片数据</strong></p>
<p><strong>首先在 aqua 节点，对分布式表 distributed_test_1_all 执行 INSERT 查询：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> distributed_test_1_all </span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">10</span>), (<span class="number">30</span>), (<span class="number">50</span>), (<span class="number">200</span>);</span><br></pre></td></tr></table></figure>

<p><strong>执行之后分布式表会做两件事情：第一，根据分片规则划分数据，不过由于分片键是随机函数，所以我们也不知道数据会如何划分；第二，将数据当前分片的数据直接写入本地表 distributed_test_1。</strong></p>
<blockquote>
<p><strong>因为每个节点上都有分布式表，所以我们在任意一个节点执行都是可以的。注意：此时不需要加 ON CLUSTER，我们只在一个节点上执行即可，如果加上 ON CLUSTER，那么每个节点就都会执行一遍，这样可能导致数据的重复写入。</strong></p>
</blockquote>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202737473-492002322.png" alt="img"></p>
<p><strong>对于当前的栗子来说，50 、10 和 100 、30 分别划分到了不同的分片中，注意：图中打印的顺序不代表分片的顺序，所以它们分别划分到了哪一个分片中，我们是不知道的。</strong></p>
<p><strong>2）第一个分片节点建立远端连接，准备发送数据</strong></p>
<p><strong>将发送给远端分片节点的数据以分区为单位（我们创建本地表时没有指定 PARTITION BY，所以当前只有一个分区），分别写入 distributed_test_1_all 存储目录下的临时 bin 文件，该数据文件的命名规则如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;database&#125;@&#123;host_name&#125;:&#123;port&#125;/&#123;increase_num&#125;.bin</span><br></pre></td></tr></table></figure>

<p><strong>我们是在 aqua 节点中写入的数据，所以对于 aqua 节点来说，它有两个远端分片节点：satori、matsuri，因此临时数据文件如下所示：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">distributed_test_1_all/<span class="keyword">default</span><span class="meta">@satori</span>/<span class="number">1.</span>bin</span><br><span class="line">distributed_test_1_all/<span class="keyword">default</span><span class="meta">@matsuri</span>/<span class="number">1.</span>bin</span><br></pre></td></tr></table></figure>

<p><strong>然后和远端的 satori 分片节点、matsuri 分片节点建立连接：</strong></p>
<figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">Connection</span> (<span class="attribute">satori</span>:<span class="number">9000</span>): <span class="selector-tag">Connetced</span> <span class="selector-tag">to</span> <span class="selector-tag">ClickHouse</span> <span class="selector-tag">server</span></span><br><span class="line"><span class="selector-tag">Connection</span> (<span class="attribute">matsuri</span>:<span class="number">9000</span>): <span class="selector-tag">Connetced</span> <span class="selector-tag">to</span> <span class="selector-tag">ClickHouse</span> <span class="selector-tag">server</span></span><br></pre></td></tr></table></figure>

<p><strong>3）第一个分片节点向远端发送数据</strong></p>
<p><strong>此时会有另一种监听任务负责监听 &#x2F;distributed_test_1_all 目录下的文件变化，这些任务负责将目录数据发送至远端分片节点：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">distributed_test_1_all.Distributed.DirectoryMonitor:</span><br><span class="line">Started processing /distributed_test_1_all/default@satori/1.bin</span><br><span class="line">Started processing /distributed_test_1_all/default@matsuri/1.bin</span><br></pre></td></tr></table></figure>

<p><strong>其中每个目录将会由独立的线程负责发送，数据在传输之前会被压缩。</strong></p>
<p><strong>4）其余的分片节点接收数据并写入本地</strong></p>
<p><strong>satori、matsuri 节点会确认建立和 aqua 节点的连接，然后在收到来 aqua 发送的数据之后，将它们写入到本地表。</strong></p>
<p><strong>5）由第一个分片确认完成写入</strong></p>
<p><strong>最后，还是由 aqua 分片节点确认所有的数据发送完毕。至此，整个流程结束，因为过程比较简单，所以流程图就不画了。可以看到，在整个过程中 Distributed 表负责所有分片是我写入工作，本着谁执行谁负责的原则，在当前这个例子中，由 aqua 节点的分布式表负责切分数据，并向所有其它分片节点发送数据。</strong></p>
<p><strong>在由 Distributed 表负责向远端分片节点发送数据时，有异步写和同步写两种模式：如果是异步写，则在 Distributed 表写完本地分片之后，INSERT 查询就会返回成功写入的信息；如果是同步写，则在执行 INSERT 查询之后，会等待所有分片完成写入。至于选择何种模，由 insert_distributed_sync 参数控制，默认为 false，也就是异步写；如果将其设置成 true，那么可以进一步通过 insert_distributed_timeout 参数控制同步等待的超时时间。</strong></p>
<p><strong>我们来测试一下，看看在 aqua 节点上写的数据，有没有被切分、并写入到不同的分片节点中。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202746371-1610187949.png" alt="img"></p>
<p><strong>显然输出一切正常，并且根据输出我们也可以看出：10 和 100 被划分到了 satori 分片节点（shard 1）、30 被划分到了 matsuri 分片节点（shard 2）、50 被划分到了 aqua 分片节点（shard 3）。</strong></p>
<h4 id="副本复制数据的核心流程"><a href="#副本复制数据的核心流程" class="headerlink" title="副本复制数据的核心流程"></a>副本复制数据的核心流程</h4><p><strong>如果在集群的配置中包含了副本，那么除了刚才的分片写入流程之外，还会触发副本数据的复制流程。而数据在多个副本之间，有两种复制方式：第一种是继续借助 Distributed 表引擎，由它将数据写入副本；第二种是借助于 ReplicatedMergeTree 表引擎实现副本数据的分发。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202752365-2031329771.png" alt="img"></p>
<p><strong>1）通过 Distributed 表复制数据</strong></p>
<p><strong>下面我们增加一下配置，实现 1 分片 2 副本。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- </span></span><br><span class="line"><span class="comment">还记得吗，我们之前配置过 1 分片 1 副本，当时我们说，对于单分片而言，可以不配置集群，只配置 ZooKeeper 即可 </span></span><br><span class="line"><span class="comment">但很明显，单分片也是可以配置集群的</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ch_cluster_1shard_2replica</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>satori<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>matsuri<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>aqua<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ch_cluster_1shard_2replica</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>我们将上面的配置增加到 config.xml 的 remote_server 标签中，而我们之间的 ch_cluster_3shard_0replica 不需要动，因为 ClickHouse 支持多个集群，我们想用哪一个，直接通过集群的名称指定即可。</strong></p>
<p><strong>修改完三个节点的配置文件之后，分别重启 ClickHouse。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202801554-1900464415.png" alt="img"></p>
<p><strong>我们查看集群，发现已经生效了，并且 shard_num 都是 1，因为只有 1 个分片。然后 replica_num 分别为 1、2、3，因为该分片下有 3 个副本。</strong></p>
<p><strong>接下来我们在这个集群内创建数据表，首先创建本地表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 我们之前不指定集群的时候，需要在每个副本上分别执行一遍建表语句</span></span><br><span class="line"><span class="comment">-- 当搭建了集群之后，通过 ON CLUSTER 的方式只需要在一个节点上执行即可</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_2 <span class="keyword">ON</span> CLUSTER ch_cluster_1shard_2replica (</span><br><span class="line">    id UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree() </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br></pre></td></tr></table></figure>

<p><strong>这里我们指定的集群是 ch_cluster_1shard_2replica，那么  ClickHouse 会根据集群信息，自动将建表语句分发到集群中的所有节点上执行。并且，由于是通过 Distributed 表复制数据，所以对表引擎没有任何要求。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202810253-39348292.png" alt="img"></p>
<p><strong>显然创建成功，那么接下来创建分布式表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_2_all <span class="keyword">ON</span> CLUSTER ch_cluster_1shard_2replica (</span><br><span class="line">    id UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> Distributed(ch_cluster_1shard_2replica, <span class="keyword">default</span>, distributed_test_2)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202821448-1355354741.png" alt="img"></p>
<p><strong>然后我们向 Distributed 表写入数据，它会负责将数据写入集群内的每个 replica。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202827490-196325264.png" alt="img"></p>
<p><strong>当然，如果查询 satori 节点和 aqua 节点的本地表，肯定也是有数据的。</strong></p>
<p><strong>如果我们配置的是多分片、多副本也是可以的，因为数据会写入到所有分片的所有副本中。不过从这里也能看出，当前方案对 Distributed 表所在节点会造成很大压力，因为它需要同时负责分片以及所有副本的数据写入工作，因此它有可能成为写入的单点瓶颈，所以就有了下面的第二种方案。</strong></p>
<p><strong>2）通过 ReplicatedMergeTree 表复制数据</strong></p>
<p><strong>如果在集群的 shard 配置中增加 internal_replication 参数并将其设置为 true（默认为 false），那么 Distributed 表在该 shard 中只会选择一个合适的 replica 并对其写入数据。此时，如果使用 ReplicatedMergeTree 作为本地表的引擎，该 shard 内的多个 replica 之间的数据则会交给 ReplicatedMergeTree 自己处理，不再由 Distributed 负责，从而为其减负。</strong></p>
<p><strong>在 shard 中选择 replica 的算法大致如下：首先在 ClickHouse 的服务节点中，拥有一个全局技术器 errors_count，当服务出现任何异常时，该计数器都会加 1；然后当一个 shard 拥有多个 replica 时，选择 errors_count 最少的那个。下面我们修改一下配置：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ch_cluster_1shard_2replica</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 增加该配置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">internal_replication</span>&gt;</span>true<span class="tag">&lt;/<span class="name">internal_replication</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">shard</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>satori<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>matsuri<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">    	<span class="tag">&lt;<span class="name">replica</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">host</span>&gt;</span>aqua<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">port</span>&gt;</span>9000<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">replica</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">shard</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ch_cluster_1shard_2replica</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>修改三个节点的配置文件 config.xml，然后重启 ClickHouse。</strong></p>
<p><strong>然后我们创建表，注意：由于指定了 internal_replication 为 true，那么 Distributed 表只会往一个副本中写，这就要求副本之间是可以进行同步的，也就是必须指定 Replicated* 表引擎。我们测试一下，先以 MergeTree 为例，然后再以 ReplicatedMergeTree 为例，看看数据在两者之间的同步情况。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建本地表，表引擎为 MergeTree</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_3 <span class="keyword">ON</span> CLUSTER ch_cluster_1shard_2replica (</span><br><span class="line">    id UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> MergeTree() </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建分布式表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_3_all <span class="keyword">ON</span> CLUSTER ch_cluster_1shard_2replica (</span><br><span class="line">    id UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> Distributed(ch_cluster_1shard_2replica, <span class="keyword">default</span>, distributed_test_3)</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202840577-1265892790.png" alt="img"></p>
<p><strong>指定表引擎为 MergeTree，副本之间无法发生同步。然后我们再创建一张表，将表引擎指定为 ReplicatedMergeTree，看看副本之间是否会发生同步。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建本地表，表引擎为 ReplicatedMergeTree</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_4 <span class="keyword">ON</span> CLUSTER ch_cluster_1shard_2replica (</span><br><span class="line">    id UInt64</span><br><span class="line"><span class="comment">-- 注意这里的 zk_path 和 replica_name，zk_path 显然都是一样的，但是 replica_name 不同</span></span><br><span class="line"><span class="comment">-- 我们可以不使用 ON CLUSTER 和宏变量，而是每个节点手动执行一遍，不同节点指定不同的 replica_name，像最开始介绍副本那样</span></span><br><span class="line"><span class="comment">-- 当然也可以使用 ON CLUSTER，只不过此时不同副本的 replica_name 不同，所以我们需要使用宏变量 &#123;replica&#125;，而在之前我们已经配好了</span></span><br><span class="line"><span class="comment">-- 然后我们知道还有一个宏变量 &#123;shard&#125;，因为是单分片，所以我们不需要使用它，如果是多分片多副本，那么就需要时候用了</span></span><br><span class="line">) ENGINE <span class="operator">=</span> ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/01/distributed_test_4&#x27;</span>, <span class="string">&#x27;&#123;replica&#125;&#x27;</span>) </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建分布式表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> distributed_test_4_all <span class="keyword">ON</span> CLUSTER ch_cluster_1shard_2replica (</span><br><span class="line">    id UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> Distributed(ch_cluster_1shard_2replica, <span class="keyword">default</span>, distributed_test_4)</span><br></pre></td></tr></table></figure>

<p><strong>我们测试一下：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202850487-1826170754.png" alt="img"></p>
<h3 id="分布式查询的核心流程"><a href="#分布式查询的核心流程" class="headerlink" title="分布式查询的核心流程"></a>分布式查询的核心流程</h3><p><strong>当面临数据查询时，毫无疑问要通过分布式表实现，当分布式表接收到 SELECT 查询的时候，会依次查询每个分片的数据，再合并汇总返回。当然我们也可以手动将每个节点都查询一遍，然后手动汇总，但显然不会有人这么做，不然还要分布式表做什么呢。下面就来介绍分布式表的数据查询。</strong></p>
<h4 id="多副本的路由规则"><a href="#多副本的路由规则" class="headerlink" title="多副本的路由规则"></a>多副本的路由规则</h4><p><strong>在查询数据的时候，如果集群中的一个 shard 拥有多个 replica，那么 Distributed 表引擎需要面临副本选择的问题。它会使用负载均衡算法从众多 replica 中选择一个，而具体使用何种算法，则由 load_balancing 参数控制，其取值有如下几种。</strong></p>
<p><strong>1）random</strong></p>
<p><strong>random 是默认的负载均衡算法，正如前文所述，在 ClickHouse 的服务节点中，拥有一个全局计数器 errors_count，当服务发生任何故障时，该计数器都会自增 1。而 randon 算法会选择 errors_count 最小的 replica，如果拥有最小 errors_count 的 replica 有多个，那么就从中随机选择一个。</strong></p>
<p><strong>2）nearest_hostname</strong></p>
<p><strong>nearest_hostname 可以看做是 random 算法的变种，首先它也会选择 errors_count 最小的 replica，但如果拥有最小 errors_count 的 replica 有多个，则比较集群配置中的 host（主机名）和当前 Distributed 表所在节点的主机名的相似度，选择相似度最高的哪一个。</strong></p>
<p><strong>3）in_order</strong></p>
<p><strong>in_order 可以同样可以看做是 random 算法的变种，首先它也会选择 errors_count 最小的 replica，但如果拥有最小 errors_count 的 replica 有多个，则根据集群中 replica 的定义顺序进行选择。</strong></p>
<p><strong>4）first_or_random</strong></p>
<p><strong>first_or_random 可以看做是 in_order 算法的变种，首先它还是会选择 errors_count 最小的 replica，但如果拥有最小 errors_count 的 replica 有多个，则根据集群中 replica 的定义顺序进行选择。但如果选择的 replica 不可用，则进一步随机选择一个其它的 replica。</strong></p>
<p><strong>感觉都没有什么太大区别，直接使用 random 就好。</strong></p>
<h4 id="多分片查询的核心流程"><a href="#多分片查询的核心流程" class="headerlink" title="多分片查询的核心流程"></a>多分片查询的核心流程</h4><p><strong>分布式查询与分布式写入类似，同样本着谁执行谁负责的原则，它会接收 SELECT 查询的 Distributed 表，并负责串联起整个过程。首先它会将针对分布式表的 SQL 语句，按照分片数量拆分成若干个针对本地表的子查询，然后向各个分片发起查询，最后再汇总各个分片的返回结果。以我们之前创建的 distributed_test_1_all 为例，如果对它发起如下查询：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM distributed_test_1_all</span><br></pre></td></tr></table></figure>

<p><strong>那么它会将其转化为如下形式，然后再发送到远端分片节点来执行：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM distributed_test_1</span><br></pre></td></tr></table></figure>

<p><strong>再比如执行如下查询：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT count() FROM distributed_test_1_all</span><br></pre></td></tr></table></figure>

<p><strong>那么 Distributed 表引擎会将查询计划转换为多个分片 UNION 联合查询，如图所示：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202858704-678966492.png" alt="img"></p>
<p><strong>整个执行计划从上大小大致分为两个步骤，下面进行介绍，我们当前是在 aqua 节点查询的分布式表。</strong></p>
<p><strong>1）查询各个分片数据</strong></p>
<p><strong>在上图中，One 和 Remote 步骤是并行执行的，它们分别负责了本地和远端分片的查询动作。其中，在 One 这个步骤会将 SQL 转成对本地表的查询：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT count() FROM default.distributed_test_1</span><br></pre></td></tr></table></figure>

<p><strong>而在 Remote 步骤中，会和其它两个副本节点（satori、matsuri）建立连接，并向其发起远程查询：</strong></p>
<figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">Connection</span> (<span class="attribute">satori</span>:<span class="number">9000</span>): <span class="selector-tag">Connecting</span>. <span class="selector-tag">Database</span>: ...</span><br><span class="line"><span class="selector-tag">Connection</span> (<span class="attribute">matsuri</span>:<span class="number">9000</span>): <span class="selector-tag">Connecting</span>. <span class="selector-tag">Database</span>: ...</span><br></pre></td></tr></table></figure>

<p><strong>satori 节点和 matsuri 节点在收到 aqua 的查询请求后，会分别在本地开始执行，同样，SQL 会转换成对本地表的查询。</strong></p>
<p><strong>2）合并返回结果</strong></p>
<p><strong>多个分片数据均查询返回后，在 aqua 节点将其合并。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202906926-1785526205.png" alt="img"></p>
<p><strong>以上显然是比较简单的，即使执行一些复杂的语句也是没有问题的。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202913185-300366400.png" alt="img"></p>
<p><strong>所以即使 SQL 语句复杂，也是没有问题的，当然我们这个 SQL 语句说复杂就明显太过了。总之你对普通表所做的查询，对分布式表同样可以，像一般的 WHERE 子句、GROUP BY 子句、ORDER BY 子句、LIMIT OFFSET 子句，都没有什么区别。</strong></p>
<p><strong>但我们需要注意的是子查询，不像单表，分布式表的子查询是由很多坑点的。</strong></p>
<h4 id="使用-Global-优化分布式子查询"><a href="#使用-Global-优化分布式子查询" class="headerlink" title="使用 Global 优化分布式子查询"></a>使用 Global 优化分布式子查询</h4><p><strong>如果在分布式查询中使用子查询，可能会面临两难的局面。下面举个栗子，首先使用之前的 3 分片 0 副本集群创建本地表和分布式表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> in_clause_test_1 <span class="keyword">ON</span> CLUSTER ch_cluster_3shard_0replica (</span><br><span class="line">    id UInt64,</span><br><span class="line">    repo UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> ReplicatedMergeTree(<span class="string">&#x27;/clickhouse/tables/&#123;shard&#125;/in_clause_test_1&#x27;</span>, <span class="string">&#x27;&#123;replica&#125;&#x27;</span>)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建分布式表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> in_clause_test_1_all <span class="keyword">ON</span> CLUSTER ch_cluster_3shard_0replica (</span><br><span class="line">    id UInt64,</span><br><span class="line">    repo UInt64</span><br><span class="line">) ENGINE <span class="operator">=</span> Distributed(ch_cluster_3shard_0replica, <span class="keyword">default</span>, in_clause_test_1)</span><br></pre></td></tr></table></figure>

<p><strong>然后写入数据：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202920731-1829720220.png" alt="img"></p>
<p><strong>查询三张本地表的数据如图所示，而将图中的三个结果集合在一块显然就是查询分布式表所得到的结果。其中 id 代表用户的编号，repo 代表仓库的编号。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202928146-1844830346.png" alt="img"></p>
<p><strong>重点来了，如果我想查询至少拥有两个仓库的用户 id 以及对应的仓库编号，这个时候该怎么做呢？如果是关系型数据库、或者说不是分布式表的话，那么显然一个子查询就搞定了，我们上面已经通过 GROUP BY 查询出了相应的 id，然后根据 id 去筛选即可。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    id,</span><br><span class="line">    repo</span><br><span class="line"><span class="keyword">FROM</span> in_clause_test_1_all</span><br><span class="line"><span class="keyword">WHERE</span> id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> id</span><br><span class="line">    <span class="keyword">FROM</span> in_clause_test_1_all</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">count</span>() <span class="operator">&gt;=</span> <span class="number">2</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>首先可以肯定这个语句本身没有任何问题，但执行的时候 ClickHouse 会报出如下错误：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Code: 288. DB::Exception: Received from localhost:9000. DB::Exception: Double-distributed IN/JOIN subqueries is denied (distributed_product_mode = &#x27;deny&#x27;). You may rewrite query to use local tables in subqueries, or use GLOBAL keyword, or set distributed_product_mode to suitable value.: While processing in_clause_test_1_all: While processing id IN (SELECT id FROM in_clause_test_1_all GROUP BY id HAVING count() &gt;= 2).</span><br></pre></td></tr></table></figure>

<p><strong>其原因就在于 ClickHouse 是默认不支持分布式子查询的，而解决办法有两种。</strong></p>
<p><strong>1）通过 distributed_product_mode 参数让其支持分布式子查询</strong></p>
<p><strong>根据报错信息我们知道 distributed_product_mode 默认为 ‘deny’，表示禁止分布式子查询，我们在 users.xml 将其设置成 ‘allow’ 即可，或者直接在命令行中设置也行。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202937479-1952752411.png" alt="img"></p>
<p><strong>将 distributed_product_mode 设置为 ‘allow’ 之后就可以成功执行并获取数据了，虽然结果是符合我们的预期了，但是还有一些需要思考🤔的东西。首先为什么 ClickHouse 会默认将分布式子查询给禁止呢？子查询这么常见，明显不应该禁止啊。所以，我们目前这种使用分布式子查询的方式一定是存在弊端的。</strong></p>
<p><strong>仔细思考一下会很容易发现存在效率上问题，我们知道查询分布式表会依次查询所有的本地表，而子查询里面查询的还是分布式表，这就导致了查询请求会被放大 N 的平方倍，其中 N 是集群内分片节点数量。我们上面只有 3 个分片节点，会进行 9 次查询，这还没有什么；但如果有 100 个分片节点呢，那么最终会导致 10000 次查询请求。而带有一个子查询的 SQL 会导致 10000 次的查询请求，不用想，这绝对是无法接受的。并且这里只有一个子查询，如果有多个子查询呢？如果有的老铁没有对 SQL 进行优化，导致子查询内部又嵌套了子查询，那就不是按平方倍扩大了，而是按立方倍扩大。</strong></p>
<p><strong>而为了解决查询放大的问题，可以使用 GLOBAL IN 进行优化，而从名字上可以看出，它和 IN 相比，在结果上没有什么却别，但是解决了查询放大的问题。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202945368-242588607.png" alt="img"></p>
<p><strong>那么 GLOBAL IN 是如何做的呢？大致可以分为以下几步：</strong></p>
<ul>
<li><code>将 IN 子句单独提出，发起了一次分布式查询</code></li>
<li><code>将分布式表转成本地表后，分别是在本地分片节点和远端分片节点执行查询</code></li>
<li><code>将 IN 子句查询的结果进行汇总，并放入一张临时的内存表进行保存</code></li>
<li><code>将内存表发送到远端分片节点</code></li>
<li><code>将分布式表转为本地表后，开始执行完整的 SQL 语句，IN 子句直接使用临时内存表的数据</code></li>
</ul>
<p><strong>至此，整个核心流程结束。可以看到在使用 GLOBAL 修饰符之后，ClickHouse 使用内存表临时保存饿了 IN 子句查询到的数据，并将其发送到远端分片节点，以此达到了数据共享的目的，从而避免了查询放大的问题。由于数据会在网络间分发，所以需要特别注意临时表的大小，IN 子句返回的数据不宜过大。如果表内存在重复数据，也可以事先在 IN 子句中加入 DISTINCT 进行去重，以减少内存表中的数据量，从而实现更快的传输。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8E%E5%88%86%E7%89%87(%E5%8D%81%E4%B8%83)/1229382-20210927202952793-602254934.png" alt="img"></p>
<p><strong>除了 GLOBAL IN 之外，还有 GLOBAL JOIN 作用是相似的，但我们说能不用 JOIN 就不用 JOIN，将其存成一张宽表是最好的。</strong></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><strong>以上就是副本、分片和集群的使用方法、作用，以及核心流程。</strong></p>
<p><strong>我们首先介绍了数据副本的特点，并详细解释了 ReplicatedMergeTree 表引擎，它是 MergeTree 表引擎的变种，同时也是数据副本的代名词，接着又介绍了数据分片的特点和作用。同时在这个过程中引入了 ClickHouse 集群的概念，并讲解了它的工作原理，最后介绍了 Distributed 表引擎的核心功能与工作流程，借助它的能力，可以实现分布式写入与查询。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的系统表(十八)</title>
    <url>/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的系统表-十八"><a href="#ClickHouse-的系统表-十八" class="headerlink" title="ClickHouse 的系统表(十八)"></a>ClickHouse 的系统表(十八)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h4 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h4><p><strong>我们知道 ClickHouse 自带两个库，分别是 default 和 system，default 是默认的数据库，我们创建表的时候如果不指定库名，那么默认会在 default 下创建。而 system 则是系统库，里面存放了大量与系统相关的表，通过这些系统表我们可以查看服务器的所有状态信息。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">use <span class="keyword">system</span>;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150412313-687075072.png" alt="img"></p>
<p><strong>总共有 69 个系统表，通过这些系统表，我们可以牢牢把控 ClickHouse 服务端的运行状态。下面来看看就来挑几个介绍一下。</strong></p>
<h4 id="system-asynchronous-metrics"><a href="#system-asynchronous-metrics" class="headerlink" title="system.asynchronous_metrics"></a>system.asynchronous_metrics</h4><p><strong>ClickHouse 在后台会定期对一些指标进行计算，得到内存的使用量，该表负责存储相关指标以及对应的值。</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>metric：指标名，String 类型</code></li>
<li><code>value：指标值，Float64 类型</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150422218-1683570183.png" alt="img"></p>
<h4 id="system-asynchronous-metric-log"><a href="#system-asynchronous-metric-log" class="headerlink" title="system.asynchronous_metric_log"></a>system.asynchronous_metric_log</h4><p><strong>和 system.asynchronous_metric 作用相同，但是多了一些时间字段。</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>event_date：日期，Date 类型</code></li>
<li><code>event_time：时间，DateTime 类型</code></li>
<li><code>event_time_microseconds：带毫秒的时间，DateTime64 类型</code></li>
<li><code>name：指标名，String 类型</code></li>
<li><code>value：指标值，Float64 类型</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150430234-577632248.png" alt="img"></p>
<h4 id="system-clusters"><a href="#system-clusters" class="headerlink" title="system.clusters"></a>system.clusters</h4><p><strong>老熟人了这个，负责存储配置文件中的可用集群信息。</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>cluster：集群名称，String 类型</code></li>
<li><code>shard_num：集群中的第几个分片，从 1 开始，UInt32 类型</code></li>
<li><code>shard_weight：分片的权重，UInt32 类型</code></li>
<li><code>replica_num：一个分片中的第几个副本，从 1 开始，UInt32 类型</code></li>
<li><code>host_name：副本所在节点的主机名，String 类型</code></li>
<li><code>host_address：副本所在节点的 IP 地址，String 类型</code></li>
<li><code>port：副本所在节点的端口，UInt16 类型</code></li>
<li><code>is_local：是否为本地节点（和当前执行 SELECT ... FROM syst.clusters 的节点是否是同一个节点），UInt8 类型</code></li>
<li><code>user：连接至服务端的用户，String 类型</code></li>
<li><code>default_database：默认数据库，String 类型</code></li>
<li><code>errors_count：该节点连接副本失败的次数，UInt32 类型</code></li>
<li><code>slowdowns_count：当使用对冲请求建立连接时，导致更改副本变慢的次数，UInt32 类型</code></li>
<li><code>estimated_recovery_time：距离副本错误归零并被认为恢复正常还剩多少秒，UInt32 类型</code></li>
</ul>
<h4 id="system-columns"><a href="#system-columns" class="headerlink" title="system.columns"></a>system.columns</h4><p><strong>非常常用的一张表，负责存储表的字段信息。</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>database：数据库名，String 类型</code></li>
<li><code>table：表名，String 类型</code></li>
<li><code>name：字段名，String 类型</code></li>
<li><code>type：字段的类型，String 类型</code></li>
<li><code>position：字段在表中位于第几列，UInt64 类型</code></li>
<li><code>default_kind：默认值表达式类型，如 DEFAULT、MATERIALIZED、ALIAS，如果没有定义则为空字符串，String 类型</code></li>
<li><code>default_expression：默认值表达式的值，如果没有定义则为空字符串，String 类型</code></li>
<li><code>data_compressed_bytes：该列数据在压缩之后的大小（字节），UInt64 类型</code></li>
<li><code>data_uncompressed_bytes：该列数据未压缩时的大小（字节），UInt64 类型</code></li>
<li><code>marks_bytes：标记的大小（字节），UInt64 类型</code></li>
<li><code>comment：字段的注释，String 类型</code></li>
<li><code>is_in_partition_key：该列是否在分区表达式中，UInt8 类型</code></li>
<li><code>is_in_sorting_key：该列是否在排序键表达式中，UInt8 类型</code></li>
<li><code>is_in_primary_key：该列是否在主键表达式中，UInt8 类型</code></li>
<li><code>is_in_sampling_key：该列是否在 sampling key 表达式中，UInt8 类型</code></li>
<li><code>compression_codec：压缩器的名称，String 类型</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150438818-1598358889.png" alt="img"></p>
<h4 id="system-crash-log"><a href="#system-crash-log" class="headerlink" title="system.crash_log"></a>system.crash_log</h4><p><strong>负责记录发生致命错误时的堆栈跟踪信息，默认情况下 system 库中不存在该表，只有在发生致命错误时该表才会创建。</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>event_date：错误发生日期，Date 类型</code></li>
<li><code>event_time：错误发生时间，DateTime 类型</code></li>
<li><code>timestamp_ns：错误发生时的时间戳，UInt64 类型</code></li>
<li><code>signal：信号值，Int32 类型</code></li>
<li><code>thread_id：错误发生时的线程 ID，UInt64 类型</code></li>
<li><code>query_id：错误发生时的查询 ID，也就是执行哪个查询发生了致命错误，String 类型</code></li>
<li><code>trace：崩溃时的堆栈跟踪，每个元素都是 ClickHouse 服务进程中的虚拟内存地址，Array(UInt64) 类型</code></li>
<li><code>trace_full：崩溃时的堆栈跟踪，每个元素在 ClickHouse 服务进程中都包含一个被调用的方法，Array(String) 类型</code></li>
<li><code>version：ClickHouse 服务器版本，String 类型</code></li>
<li><code>reversion：ClickHouse 服务器版本，UInt32 类型</code></li>
<li><code>build_id：编译器生成的 BuildID，String 类型</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150446364-1806332141.png" alt="img"></p>
<h4 id="system-data-skipping-indices"><a href="#system-data-skipping-indices" class="headerlink" title="system.data_skipping_indices"></a>system.data_skipping_indices</h4><p><strong>负责记录所有表中已存在的跳数索引（二级索引）</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>database：数据库名，String 类型</code></li>
<li><code>table：表名，String 类型</code></li>
<li><code>name：索引名，String 类型</code></li>
<li><code>type：索引类型，String 类型</code></li>
<li><code>expr：索引计算的表达式，String 类型</code></li>
<li><code>granularity：索引粒度，UInt64 类型</code></li>
</ul>
<h4 id="system-databases"><a href="#system-databases" class="headerlink" title="system.databases"></a>system.databases</h4><p><strong>负责记录已存在的数据库的信息（当然用户可以看到的数据库）</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>name：数据库名称，String 类型</code></li>
<li><code>engine：定义数据库时所使用的引擎，String 类型</code></li>
<li><code>data_path：该数据库下数据表的物理存储路径，String 类型</code></li>
<li><code>metadata_path：数据表的元数据的存储路径，String 类型</code></li>
<li><code>uuid：数据库对应的 UUID，每个数据库在创建的时候都会有一个 UUID，UUID 类型</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150455634-1076094929.png" alt="img"></p>
<h4 id="system-disks"><a href="#system-disks" class="headerlink" title="system.disks"></a>system.disks</h4><p><strong>负责记录配置文件中定义的磁盘信息</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>name：磁盘名称，String 类型</code></li>
<li><code>path：在物理文件系统中的挂载点，String 类型</code></li>
<li><code>free_space：磁盘的可用空间，UInt64 类型</code></li>
<li><code>total_space：磁盘的可用空间，UInt64 类型</code></li>
<li><code>keep_free_space：磁盘应保留的空闲可用空间，通过 keep_free_space_bytes 标签定义，UInt64 类型</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150504125-906133554.png" alt="img"></p>
<h4 id="system-distributed-ddl-queue"><a href="#system-distributed-ddl-queue" class="headerlink" title="system.distributed_ddl_queue"></a>system.distributed_ddl_queue</h4><p><strong>负责记录执行过的分布式 DDL 查询</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>entry：query id，String 类型</code></li>
<li><code>host_name：执行分布式 DDL 查询的节点的主机名，String 类型</code></li>
<li><code>host_address：执行分布式 DDL 查询的节点的 IP 地址，String 类型</code></li>
<li><code>port：执行分布式 DDL 查询的节点监听的端口，UInt16 类型</code></li>
<li><code>status：查询的执行状态，Enum8 类型</code></li>
<li><code>cluster：集群名称，String 类型</code></li>
<li><code>query：执行的 query，String 类型</code></li>
<li><code>initiator：执行查询的节点，String 类型</code></li>
<li><code>query_start_time：查询开始时间，DateTime 类型</code></li>
<li><code>query_finish_time：查询结束时间，DateTime 类型</code></li>
<li><code>query_duration_ms：查询执行所花费的时间（毫秒），UInt64 类型</code></li>
<li><code>exception_code：来自 ZooKeeper 的异常码，Enum8 类型</code></li>
</ul>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%A1%A8(%E5%8D%81%E5%85%AB)/1229382-20210928150511320-2137346480.png" alt="img"></p>
<h4 id="system-tables"><a href="#system-tables" class="headerlink" title="system.tables"></a>system.tables</h4><p><strong>负责记录已存在的所有表的元数据信息</strong></p>
<p><strong>字段：</strong></p>
<ul>
<li><code>database：数据库名，String 类型</code></li>
<li><code>name：表名，String 类型</code></li>
<li><code>uuid：创建表时生成的 UUID，UUID 类型</code></li>
<li><code>engine：表使用的引擎，String 类型</code></li>
<li><code>is_temporary：是否是临时表，UInt8 类型</code></li>
<li><code>data_paths：表数据在文件系统中的物理路径，string 类型</code></li>
<li><code>metadata_path：表元数据在文件系统中的物理路径，String 类型</code></li>
<li><code>metadata_modification_time：表元数据最近一次的修改时间，DateTime 类型</code></li>
<li><code>dependencies_database：数据库依赖关系，Array(String) 类型</code></li>
<li><code>dependencies_table：表依赖关系，针对物化视图，Array(String) 类型</code></li>
<li><code>create_table_query：创建该表时的 SQL 语句，String 类型</code></li>
<li><code>engine_full：表引擎的参数，String 类型</code></li>
<li><code>partition_key：分区键表达式，String 类型</code></li>
<li><code>sorting_key：排序键表达式，String 类型</code></li>
<li><code>primary_key：主键表达式，String 类型</code></li>
<li><code>sampling_key：sampling key 表达式，String 类型</code></li>
<li><code>storage_policy：存储策略，String 类型</code></li>
<li><code>total_rows：数据表的总行数，Nullable(UInt64)</code></li>
<li><code>total_bytes：数据表的总大小。如果表存储在磁盘上，返回使用磁盘空间（压缩之后的）；如果表存储在内存中，返回使用的内存大小，单位字节，Nullable(UInt64) 类型</code></li>
<li><code>lifetime_rows：自服务启动以来，插入的数据的总行数，仅适用于 Buffer 表，Nullable(UInt64) 类型</code></li>
<li><code>lifetime_bytes：自服务启动以来，插入的数据所占的总字节数，仅适用于 Buffer 表，Nullable(UInt64) 类型</code></li>
<li><code>comment：表注释</code></li>
</ul>
<p><strong>我们使用 show tables 等价于 SELECT * FROM system.tables WHERE database &#x3D; ‘xxx’。</strong></p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p><strong>以上我们就介绍了一些系统表，当然 ClickHouse 中的系统表远不止我们说的这些，更多内容可以前往<a href="https://clickhouse.com/docs/en/operations/system-tables/">官网</a>查看，写的还是比较详细的。当然我们后面在说 ClickHouse 权限管理的时候，还会再介绍几个系统表。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse 的管理与运维(十九)</title>
    <url>/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/</url>
    <content><![CDATA[<h1 id="ClickHouse-的管理与运维-十九"><a href="#ClickHouse-的管理与运维-十九" class="headerlink" title="ClickHouse 的管理与运维(十九)"></a>ClickHouse 的管理与运维(十九)</h1><p>​																	本文来源： ( <a href="https://www.cnblogs.com/traditional/tag/ClickHouse%EF%BC%9A%E4%B8%80%E6%AC%BE%E9%80%9F%E5%BA%A6%E5%BF%AB%E5%88%B0%E8%AE%A9%E4%BA%BA%E5%8F%91%E6%8C%87%E7%9A%84%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%BA%93/">https://www.cnblogs.com/traditional/tag/ClickHouse：一款速度快到让人发指的列式存储数据库/</a> ) </p>
<hr>
<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><p><strong>下面来说一下 ClickHouse 管理和运维相关的知识，该部分可以让 ClickHouse 变得更加安全与健壮。在前面演示的案例中，为了方便，我们一直使用默认的 default 用户，并且没有配置密码，这显然不符合生产环境的要求。所以接下来，我们就来介绍 ClickHouse 的权限、熔断机制、数据备份和服务监控等知识。</strong></p>
<h2 id="用户配置"><a href="#用户配置" class="headerlink" title="用户配置"></a>用户配置</h2><p><strong>users.xml 配置文件默认位于 &#x2F;etc&#x2F;clickhouse-server 路径下，ClickHouse 用它来定义用户相关的配置项，包括系统参数的设定、用户的定义、权限以及熔断机制等。</strong></p>
<h3 id="用户的角色配置（profile）"><a href="#用户的角色配置（profile）" class="headerlink" title="用户的角色配置（profile）"></a>用户的角色配置（profile）</h3><p><strong>在 users.xml 中有一个 profiles 标签，在该标签中我们可以定义用户角色，先看看默认配置：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182628794-2170109.png" alt="img"></p>
<p><strong>这是 ClickHouse 的默认配置，显然默认有两个角色，分别是 default 和 readonly。需要注意的是，这里的 default 和 readonly 指的是角色，每一个用户都具有一个角色。我们可以在 CLI 中直接切换到想要的角色：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SET profile = &#x27;角色名&#x27;</span><br></pre></td></tr></table></figure>

<p><strong>我们可以测试一下，首先我们默认使用的是 default 用户，该用户对应的角色默认也是 default。然后还有一个 readonly 角色，从名字上也能看出该角色只能读数据，无法写数据，因为内部的 readonly 属性为 1，默认为 0。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182636026-1515976262.png" alt="img"></p>
<p><strong>当 default 用户具有 default 角色时，写数据一切正常，但是将 default 用户的角色切换为 readonly 时则被告知：Cannot execute query in readonly mode。当然，如果我们在 default 角色对应配置中也加上 1，那么具有该角色的用户同样也会无法写数据。</strong></p>
<p><strong>在所有的角色配置（profile）中，名称为 default 的 profile 将作为默认的配置被加载，所以它必须存在。如果缺失名为 default 的 profile，那么 ClickHouse Server 会启动失败：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Application: DB::Exception: Settings profile`default`not found</span><br></pre></td></tr></table></figure>

<p><strong>profile 还支持继承，实现继承的方式是在定义中引用其他的 profile 名称，例如：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">my_role</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">profile</span>&gt;</span>default<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- &lt;profile&gt;default2&lt;/profile&gt; 可以继承多个--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">distributed_product_mode</span>&gt;</span>deny<span class="tag">&lt;/<span class="name">distributed_product_mode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">my_role</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>相当于新建了一个名为 my_role 的角色，然后在对应的 profile 中继承了 default 的所有配置项，并且使用新的参数值覆盖了 default 中原有的 distributed_product_mode 配置项。</strong></p>
<h3 id="配置约束"><a href="#配置约束" class="headerlink" title="配置约束"></a>配置约束</h3><p><strong>constraints 标签可以设置一组约束条件，以保障 profile 内的参数值不会被随意修改，约束条件有如下三种规则：</strong></p>
<ul>
<li><code>min：最小值约束，在设置相应参数的时候，取值不能小于该阈值</code></li>
<li><code>max：最小值约束，在设置相应参数的时候，取值不能大于该阈值</code></li>
<li><code>readonly：只读约束，该参数值不能被修改</code></li>
</ul>
<p><strong>下面举例说明：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182646442-224064581.png" alt="img"></p>
<p><strong>从上面的配置定义中可以看出，在 default 默认的 profile 内，给两组参数设置了约束。首先为 max_memory_usage 设置了 min 和 max 阈值；其次为 distributed_product_mode 设置了只读约束。然后重启 ClickHouse，并尝试修改 max_memory_usage 参数，将它改为 50：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182654179-1342486270.png" alt="img"></p>
<p><strong>可以看到最小值约束阻止了这次修改，接着继续修改 distributed_product_mode 的值：</strong></p>
<p><img src="https://img2020.cnblogs.com/blog/1229382/202110/1229382-20211008182703966-1769998673.png" alt="img"></p>
<p><strong>同样配置约束成功阻止了预期外的修改。还有一点需要明确，在 default 中默认定义的 constraints 约束，将作为默认的全局约束，自动被其它 profile 继承。</strong></p>
<h3 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h3><p><strong>通过 profiles 标签可以为用户定义角色，那么可不可以定义用户呢？显然是可以的，通过 users 标签即可。如果打开配置文件，会发现 users 标签下已经有一个默认的 default 用户，我们之前使用的一直都是这个用户，而我们也可以定义一个新用户，但必须包含如下属性：</strong></p>
<p><strong>password</strong></p>
<p><strong>password 用于设置登录密码，支持明文、SHA256 加密和 double_sha1 加密三种形式，可以任选其中一种进行设置。现在分别介绍它们的使用方法。</strong></p>
<p><strong>1）明文密码：在使用明文密码的时候，直接通过 password 标签定义，例如下面的代码。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">password</span>&gt;</span>123<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>如果 password 为空，则表示免密码登录。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>2）SHA256 加密：在使用 SHA256 加密算法的时候，需要通过 password_sha256_hex 标签定义密码，例如下面的代码。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">password_sha256_hexs</span>&gt;</span>a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3<span class="tag">&lt;/<span class="name">password_sha256_hexs</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>至于计算的方式，可以通过如下命令，比如对 123 进行加密：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># echo -n 123 |openssl dgst -sha256</span></span><br><span class="line">(stdin)= a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3</span><br></pre></td></tr></table></figure>

<p><strong>或者使用 Python：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hashlib.sha256(<span class="string">b&quot;123&quot;</span>).hexdigest()</span><br><span class="line"><span class="string">&#x27;a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3&#x27;</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

<p><strong>3）double_sha1 加密：在使用 double_sha1 加密算法的时候，则需要通过 password_double_sha1_hex 标签定义密码，例如下面的代码。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">password_double_sha1_hex</span>&gt;</span>23ae809ddacaf96af0fd78ed04b6a265e05aa257<span class="tag">&lt;/<span class="name">password_double_sha1_hex</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>至于计算的方式，可以通过如下命令，比如对 123 进行加密：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@satori ~]<span class="comment"># echo -n 123 | openssl dgst -sha1 -binary | openssl dgst -sha1</span></span><br><span class="line">(stdin)= 23ae809ddacaf96af0fd78ed04b6a265e05aa257</span><br></pre></td></tr></table></figure>

<p><strong>或者使用 Python：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_ = hashlib.sha1(<span class="string">b&quot;123&quot;</span>).digest()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hashlib.sha1(_).hexdigest()</span><br><span class="line"><span class="string">&#x27;23ae809ddacaf96af0fd78ed04b6a265e05aa257&#x27;</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

<p><strong>networks</strong></p>
<p><strong>networks 表示被允许登录的网络地址，用于限制用户登录的客户端地址，关于这方面的介绍将会在后续展开。</strong></p>
<p><strong>profile</strong></p>
<p><strong>用户所使用的角色，直接引用相应的名称即可，例如：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">profile</span>&gt;</span>profile_1<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>该配置的语义表示：该用户使用了名为 profile_1 的角色。</strong></p>
<p><strong>quota</strong></p>
<p><strong>quota 用于设置该用户能够使用的资源限额，可以理解成一种熔断机制。关于这方面的介绍同样将会在后续展开。</strong></p>
<p><strong>下面我们就来定义一个完整的实例来定义三个用户，密码分别使用明文密码、sha256 加密、double sha1 加密：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">users</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">default</span>&gt;</span>  <span class="comment">&lt;!-- 默认用户 --&gt;</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="tag">&lt;/<span class="name">default</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 使用明文密码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user_plaintext</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">password</span>&gt;</span>123<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">networks</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">ip</span>&gt;</span>::/0<span class="tag">&lt;/<span class="name">ip</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">networks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">profile</span>&gt;</span>default<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">quota</span>&gt;</span>default<span class="tag">&lt;/<span class="name">quota</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">user_plaintext</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 使用 sha256 加密 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user_sha256</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">password_sha256_hex</span>&gt;</span>a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3<span class="tag">&lt;/<span class="name">password_sha256_hex</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">networks</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">ip</span>&gt;</span>::/0<span class="tag">&lt;/<span class="name">ip</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">networks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">profile</span>&gt;</span>default<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">quota</span>&gt;</span>default<span class="tag">&lt;/<span class="name">quota</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">user_sha256</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 使用 double sha1 加密 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user_double_sha1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">password_double_sha1_hex</span>&gt;</span>23ae809ddacaf96af0fd78ed04b6a265e05aa257<span class="tag">&lt;/<span class="name">password_double_sha1_hex</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">networks</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">ip</span>&gt;</span>::/0<span class="tag">&lt;/<span class="name">ip</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">networks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">profile</span>&gt;</span>default<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">quota</span>&gt;</span>default<span class="tag">&lt;/<span class="name">quota</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">user_double_sha1</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">users</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>由于配置了密码，那么以后使用指定用户登录时，就必须指定密码了，举个栗子：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182722735-2046681283.png" alt="img"></p>
<p><strong>–host 指定 IP，–port 指定端口，–user 指定用户，我们看到指定用户为 user_plaintext 进行登录的时候报错的，原因就是该用户设置了密码，但我们没有指定。而通过 –password 指定密码之后，便可登录成功了。</strong></p>
<p><strong>至于其它用户类似：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置文件中写的是加密后的结果，但是登录时，密码还是使用加密前的结果，这里是 123</span></span><br><span class="line">clickhouse-client --user user_sha256 --password 123</span><br><span class="line">clickhouse-client --user user_double_sha1 --password 123</span><br></pre></td></tr></table></figure>

<h2 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h2><p><strong>权限管理是一个始终都绕不开的话题，ClickHouse 分别从访问、查询和数据等角度出发，层层递进，为我们提供了一个较为立体的权限体系。</strong></p>
<h3 id="访问权限"><a href="#访问权限" class="headerlink" title="访问权限"></a>访问权限</h3><p><strong>访问层控制是整个权限体系的第一层防护，它又可进一步细分成两类权限。</strong></p>
<p><strong>网络访问权限</strong></p>
<p><strong>网络访问权限使用 networks 标签设置，用于限制客户端登录的地址，限制方式可以通过 IP 地址、host 主机名称实现，两者选其一即可。</strong></p>
<p><strong>比如通过 IP 地址设置：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 只能通过 IP 为 127.0.0.1 的主机访问 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ip</span>&gt;</span>127.0.0.1<span class="tag">&lt;/<span class="name">ip</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>通过 host 主机名称设置：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 只能通过主机名为 satori 的主机访问，另外这里配置主机名的时候还可以使用正则 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">host</span>&gt;</span>satori<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>数据库与字典访问权限</strong></p>
<p><strong>在客户端连入服务之后，可以进一步限制某个用户数据库和字典的访问权限，它们分别通过 allow_databases 和 allow_dictionaries 标签进行设置。如果不进行定义，则表示不进行限制。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">user_plaintext</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">password</span>&gt;</span>123<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">allow_databases</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">database</span>&gt;</span>default<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">database</span>&gt;</span>kagura_nana<span class="tag">&lt;/<span class="name">database</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">allow_databases</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">allow_dictionaries</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dictionary</span>&gt;</span>test_dict<span class="tag">&lt;/<span class="name">dictionary</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">allow_dictionaries</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">user_plaintext</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>通过上述操作，该用户在登录之后，将只能看到为其开放了访问权限的数据库和字典。</strong></p>
<h3 id="查询权限"><a href="#查询权限" class="headerlink" title="查询权限"></a>查询权限</h3><p><strong>查询权限是整个权限体系的第二层防护，设置在 profile 中，它决定了拥有此角色的用户能够执行的查询语句，查询权限可以分为以下四类：</strong></p>
<ul>
<li><code>读权限：包括 SELECT、EXISTS、SHOW 和 DESCRIBE 查询</code></li>
<li><code>写权限：包括 INSERT 和 OPTIMIZE 查询</code></li>
<li><code>设置权限：包括 SET 查询</code></li>
<li><code>DDL 权限：包括 CREATE、DROP、ALTER、RENAME、ATTACH、DETACH 和 TRUNCATE 查询</code></li>
<li><code>其它权限：包括 KILL 和 USE 查询，任何用户都可以执行这些查询</code></li>
</ul>
<p><strong>上述权限，可以通过以下两项配置标签控制：</strong></p>
<ul>
<li><strong>1）readonly：读权限、写权限和设置权限均由此标签控制，它有三种取值：</strong><ul>
<li><code>当取值为 0 时，表示不进行任何限制（默认值）</code></li>
<li><code>当取值为 1 时，表示只拥有读权限，即只能执行 SELECT 、EXISTS、SHOW 和 DESCRIBE</code></li>
<li><code>当取值为 2 时，表示拥有读权限和设置权限，相当于在读权限的基础上增加了 SET 查询</code></li>
</ul>
</li>
<li><strong>2）allow_ddl：DDL 权限由此标签控制，它有两种取值：</strong><ul>
<li><code>当取值为 0 时，不允许 DDL 查询</code></li>
<li><code>当取值为 1 时，允许 DDL 查询（默认值）</code></li>
</ul>
</li>
</ul>
<p><strong>举个栗子，我们增加一个角色。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">profiles</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">default</span>&gt;</span>...<span class="tag">&lt;/<span class="name">default</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">readonly</span>&gt;</span>...<span class="tag">&lt;/<span class="name">readonly</span>&gt;</span>  </span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">profile_test</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">readonly</span>&gt;</span>1<span class="tag">&lt;/<span class="name">readonly</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">allow_ddl</span>&gt;</span>0<span class="tag">&lt;/<span class="name">allow_ddl</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">profile_test</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">profiles</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>修改配置文件之后，重启 ClickHouse，然后连接：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182735704-1294115794.png" alt="img"></p>
<p><strong>我们看到切换角色之后，不再具有 DDL 执行权限。当然数据也是只读模式，此时写入数据是失败的。</strong></p>
<p><strong>至此，权限设置已然生效。</strong></p>
<h3 id="数据行级权限"><a href="#数据行级权限" class="headerlink" title="数据行级权限"></a>数据行级权限</h3><p><strong>数据权限是整个权限体系中的第三层防护，它决定了一个用户能够看到什么数据，说人话就是数据粒度更细了，可以只将一张表的部分数据暴露给用户。</strong></p>
<p><strong>而该权限使用 database 标签定义（位于 users 标签内部），database 通过定义用户级别的查询过滤器来实现数据的行级粒度权限，它的定义规则如下所示：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">databases</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">database_name</span>&gt;</span>  <span class="comment">&lt;!-- 数据库名称 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">table_name</span>&gt;</span> <span class="comment">&lt;!-- 表名称 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileter</span>&gt;</span>id &gt; 10<span class="tag">&lt;/<span class="name">fileter</span>&gt;</span>  <span class="comment">&lt;!-- 数据过滤条件，也可以写复杂的条件 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">table_name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">database_name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>我们以之前的 distributed_test_1 为例，测试一下，所以配置文件修改如下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">user_test_2</span>&gt;</span>  <span class="comment">&lt;!-- 新建一个角色 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">password</span>&gt;</span>123<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">networks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ip</span>&gt;</span>::/0<span class="tag">&lt;/<span class="name">ip</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">networks</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">profile</span>&gt;</span>default<span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">quota</span>&gt;</span>default<span class="tag">&lt;/<span class="name">quota</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">databases</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">default</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">distributed_test_1</span>&gt;</span> </span><br><span class="line">                <span class="tag">&lt;<span class="name">filter</span>&gt;</span>id &gt; 10<span class="tag">&lt;/<span class="name">filter</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;/<span class="name">distributed_test_1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">default</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">databases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">user_test_2</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>修改之后重启 ClickHouse：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182745284-100788997.png" alt="img"></p>
<p><strong>整个过程还是很好理解的，那么 ClickHouse 底层是怎么做的呢？答案很简单，从配置文件中 filter 标签的内容也能看出来，就是追加了一个 WHERE 条件。</strong></p>
<p><strong>对于数据权限的使用有一点需要明确，在使用了这项功能之后，PREWHERE 优化将不再生效。所以是直接利用 ClickHouse 的内置过滤器，还是通过拼接 WHERE 查询条件的方式实现行级过滤，需要根据使用场景进行权衡。</strong></p>
<h2 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h2><p><strong>熔断是限制资源被过度使用的一种自我保护机制，当使用的资源数量达到阈值时，那么正在进行的操作会被自动中断。而按照使用资源统计方式的不同，熔断机制可以分为两类。</strong></p>
<h4 id="根据时间周期的累积用量熔断"><a href="#根据时间周期的累积用量熔断" class="headerlink" title="根据时间周期的累积用量熔断"></a>根据时间周期的累积用量熔断</h4><p><strong>在这种方式下，系统资源的用量是按照时间周期累积统计的，当累积量达到阚值，则直到下个计算周期开始之前，该用户将无法继续进行操作。这种方式通过 users.xml 内的 quotas 标签来定义资源配额，以默认的配置为例：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182755378-1601344871.png" alt="img"></p>
<p><strong>看图中最后一行，是 ，显然到此配置文件就结束了，所以 users.xml 中最外层是 yandex 标签，然后 yandex 标签里面有三个子标签，分别是 profiles、users、quotas，分别用于定义角色、定义用户、熔断限流，还是比较简单的，整个结构比较清晰。然后看看 quotas 标签里面的内容都代表什么含义吧。</strong></p>
<ul>
<li><code>default：自定义名称，全局唯一</code></li>
<li><code>duration：累积的时间周期，单位秒</code></li>
<li><code>queries：在周期内允许执行的查询次数，0 表示不限制</code></li>
<li><code>errors：在周期内允许发生异常的次数，0 表示不限制</code></li>
<li><code>result_row：在周期内允许查询返回的结果行数，0 表示不限制</code></li>
<li><code>read_row：在周期内，在分布式查询中，允许远端节点读取的数据行数，0 表示不限制</code></li>
<li><code>execution_time：周期内允许执行的查询时间，单位秒，0 表示不限制</code></li>
</ul>
<p><strong>我们来配置一下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 在 quotas 标签中增加如下配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">limit_1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">interval</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">duration</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">duration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">queries</span>&gt;</span>2<span class="tag">&lt;/<span class="name">queries</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">errors</span>&gt;</span>0<span class="tag">&lt;/<span class="name">errors</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">result_rows</span>&gt;</span>0<span class="tag">&lt;/<span class="name">result_rows</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">read_rows</span>&gt;</span>0<span class="tag">&lt;/<span class="name">read_rows</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution_time</span>&gt;</span>0<span class="tag">&lt;/<span class="name">execution_time</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">interval</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">limit_1</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>在名为 limit_1 的配置中，1 个小时的周期内只允许最多 2 次查询，下面让其作用在 user_test_2 用户上。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">user_test_2</span>&gt;</span> </span><br><span class="line">    ...</span><br><span class="line">    <span class="tag">&lt;<span class="name">quota</span>&gt;</span>limit_1<span class="tag">&lt;/<span class="name">quota</span>&gt;</span> <span class="comment">&lt;!-- 其它部分不变，将 quota 的值从 default 改成 limit_1 --&gt;</span></span><br><span class="line">    ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">user_test_2</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>然后重启 ClickHouse，并以 user_test_2 用户启动。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182808290-1843836494.png" alt="img"></p>
<p><strong>执行两次查询之后，如果再执行的话就会报错，证明熔断机制确实已经生效。</strong></p>
<h4 id="根据单次查询的用量熔断"><a href="#根据单次查询的用量熔断" class="headerlink" title="根据单次查询的用量熔断"></a>根据单次查询的用量熔断</h4><p><strong>在这种方式下，系统资源的用量是按照单次查询统计的，而具体的熔断规则，则是由许多不同配置项组成的，这些配置项需要定义在用户 profile 中。如果某次查询使用的资源用量达到了阈值，则会被中断。以配置项 max memory_usage 为例，它限定了单次查询可以使用的内存用量，在默认的情况下其规定不得超过 10 GB，如果一次查询的内存用量超过 10 GB，则会得到异常。需要注意的是，在单次查询的用量统计中，ClickHouse 是以分区为最小单元进行统计的（不是数据行的粒度），这意味着单次查询的实际内存用量是有可能超过阈值的。</strong></p>
<p><strong>熔断相关的配置比较多，这里介绍几个常用的。</strong></p>
<p><strong>1）max_memory_usage：在单个 ClickHouse 服务进程中，运行一次查询限制使用的最大内存量，默认值为 10GB。</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">max_memory_usage</span>&gt;</span>10000000000<span class="tag">&lt;/<span class="name">max_memory_usage</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>2）max_memory_usage_for_user：在单个 ClickHouse 服务进程中，以用户为单位进行统计，单个用户在运行查询时限制使用的最大内存量，默认值为 0，即不做限制。</strong></p>
<p><strong>3）max_memory_usage_for_all_queries：在单个 ClickHouse 服务进程中，所有运行的查询累加在一起所限制使用的最大内存量，默认值为 0，即不做限制。</strong></p>
<p><strong>4）max_partitions_per_insert_block：在单次 INSERT 写入的时候，限制创建的最大分区个数，默认值为 100 个。如果超过这个阈值，将会出现异常。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Too many partitions for single INSERT block ······</span><br></pre></td></tr></table></figure>

<p><strong>5）max_rows_to_group_by：在执行 GROUP BY 聚合查询的时候，限制去重后的聚合 KEY 的最大个数，默认值为 0，不做限制。当超过阈值时，其处理方式由 group_by_overflow_mode 决定。</strong></p>
<p><strong>6）group_by_overflow_mode：当 max_rows_to_group_by 熔断规则触发时，group_by_overflow_mode 将会提供三种处理方式。</strong></p>
<ul>
<li><code>throw：抛出异常，此乃默认值</code></li>
<li><code>break：立即停止查询，并返回当前数据</code></li>
<li><code>any：仅根据当前已存在的聚合 KEY 继续完成聚合查询</code></li>
</ul>
<p><strong>7）max_bytes_before_external_group_by：在执行 GROUP BY 查询的时候，限制使用的最大内存量，默认值为 0，不做限制。当超过阈值时，聚合查询将会进一步借用本地磁盘。</strong></p>
<h2 id="数据备份"><a href="#数据备份" class="headerlink" title="数据备份"></a>数据备份</h2><p><strong>在之前的系列中，我们已经知道了数据副本的使用方法，那么问题来了：既然已经有了数据副本，那么还需要数据备份吗？显然数据备份是需要的，因为数据副本并不能处理误删数据这类行为。ClickHouse自身提供了多种备份数据的方法，根据数据规模的不同，可以选择不同的形式。</strong></p>
<h4 id="导出文件备份"><a href="#导出文件备份" class="headerlink" title="导出文件备份"></a>导出文件备份</h4><p><strong>如果数据的体量较小，可以通过 dump 形式将数据导出为本地文件，语句如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clickhouse-client --query=&quot;SELECT * FROM table_name&quot; &gt; table_name.tsv</span><br></pre></td></tr></table></figure>

<p><strong>如果想将备份数据导入的话，可以这么做：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat table_name.csv | clickhouse-client --query=&quot;INSERT INTO table_name FORMAT TSV&quot;</span><br></pre></td></tr></table></figure>

<p><strong>上述这种 dump 形式的优势在于，可以利用 SELECT 查询并筛选数据，然后按需备份。如果是备份整个表的数据，也可以直接复制它的整个目录文件。</strong></p>
<h4 id="通过快照表备份"><a href="#通过快照表备份" class="headerlink" title="通过快照表备份"></a>通过快照表备份</h4><p><strong>快照表实质上就是普通的数据表，它通常按照业务规定的备份频率创建，例如按天或者按周创建。所以首先需要建立一张与原表结构相同的数据表，然后再使用 INSERT INTO SELECT句式，点对点地将数据从原表写人备份表。假设数据表 table_name 需要按日进行备份，现在为它创建当天的备份表：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE table_name_bak AS table_name</span><br></pre></td></tr></table></figure>

<p><strong>有了备份表之后就可以点对点地备份数据了。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INSERT INTO table_name_bak SELECT * FROM table_name</span><br></pre></td></tr></table></figure>

<p><strong>如果考虑到容灾问题，也可以将备份表放在不同的 ClickHouse 节点上，此时需要将 SQL 语句改成远程查询的形式：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">INSERT INTO table_name_bak SELECT * FROM remote(&#x27;xx.xx.xx.xx:9000&#x27;, &#x27;default&#x27;, &#x27;table_name&#x27;, &#x27;default&#x27;)</span><br></pre></td></tr></table></figure>

<h4 id="按分区备份"><a href="#按分区备份" class="headerlink" title="按分区备份"></a>按分区备份</h4><p><strong>基于数据分区的备份，ClickHouse 目前提供了 FREEZE 和 FETCH 两种方式，现在分别介绍它们的使用方法。</strong></p>
<p><strong>使用 FREEZE 备份</strong></p>
<p><strong>FREEZE 的完整语法如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TABLE table_name FREEZE PARTITION partition_expr</span><br></pre></td></tr></table></figure>

<p><strong>分区在被备份之后，会被统一保存到 ClickHouse 根路径 &#x2F;shadow&#x2F;N 子目录下。其中 N 是一个自增长的整数，它的含义是备份的次数（FREEZE 执行过多少次），具体次数由 shadow 子目录下的 increment.txt 文件负责记录。而分区备份实质上是对原始目录文件进行硬链接操作，所以并不会导致额外的存储空间。整个备份的目录会一直向上追溯至 data 根路径的整个链路：</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182818378-543092889.png" alt="img"></p>
<p><strong>上面对 partition_test_v1 表的 202008 分区进行了备份，然后我们进入 shadow 子目录，便可看到之前备份的分区目录。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182826343-1704242937.png" alt="img"></p>
<p><strong>如果想还原分区，则需要借助于 ATTACH 装载分区的方式实现，我们需要先将 shadow 子目录下的分区文件复制到相应数据表的 detached 目录下，然后再使用 ATTACH 语句装载。</strong></p>
<p><strong>使用 FETCH 备份</strong></p>
<p><strong>FETCH 只支持 ReplicatedMergeTree 系列的表引擎，其完整语法如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TABLE table_name FETCH PARTITION partition_id FROM zk_path</span><br></pre></td></tr></table></figure>

<p><strong>其工作原理与 ReplicatedMergeTree 同步数据的原理类似，FETCH 通过指定的 zk_path 找到 ReplicatedMergeTree 的所有副本实例，然后从中选择一个最合适的副本，并下载相应的分区数据。例如执行如下语句：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TABLE test_fetch FETCH PARTITION 202009 FROM &#x27;/clickhouse/tables/02/test_fetch&#x27;</span><br></pre></td></tr></table></figure>

<p><strong>表示将 test_fetch 的 201909 分区下载到本地，并保存到对应数据表的 detached 目录下，目录如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data/default/test_fetch/detached/202009_0_0_0</span><br></pre></td></tr></table></figure>

<p><strong>与 FREEZE 一样，对于备份分区的还原操作，也需要借助 ATTACH 装载分区来实现。 另外 FREEZE 和 FETCH 虽然都能实现对分区文件的备份，但是它们并不会备份数据表的元数据。所以说如果想做到万无一失的备份，还需要对数据表的元数据进行备份，它们是 &#x2F;data&#x2F;metadata 目录下的 [table].sql 文件，目前这些元数据需要用户通过复制的形式单独备份。</strong></p>
<h2 id="服务监控"><a href="#服务监控" class="headerlink" title="服务监控"></a>服务监控</h2><p><strong>基于原生功能对 ClickHouse 进行监控，可以从两方面入手：系统表和查询日志，接下来分别介绍它们的使用方法。</strong></p>
<h3 id="系统表"><a href="#系统表" class="headerlink" title="系统表"></a>系统表</h3><p><strong>在众多的 SYSTEM 系统表中，主要由以下三张表支撑了对 ClickHouse 运行指标的查询，它们分别是 metrics、events 和 asynchronous_metrics。</strong></p>
<h4 id="1）metrics"><a href="#1）metrics" class="headerlink" title="1）metrics"></a>1）metrics</h4><p><strong>metrics 表用于统计 ClickHouse 服务在运行时，当前正在执行的高层次的概要信息，包括正在执行的查询总次数、正在发生合并的操作总次数等。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182838146-1057679332.png" alt="img"></p>
<h4 id="events"><a href="#events" class="headerlink" title="events"></a>events</h4><p><strong>events 表用于统计 ClickHouse 服务在运行过程中，已经执行过的高层次的累积概要信息，包括总的查询次数、总的 SELECT 查询次数等。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182846652-1175367593.png" alt="img"></p>
<h4 id="asynchronous-metrics"><a href="#asynchronous-metrics" class="headerlink" title="asynchronous_metrics"></a>asynchronous_metrics</h4><p><strong>asynchronous_metrics 表用于统计 ClickHouse 服务在运行过程中，当前后台正在异步运行的高层次的概要信息，包括当前分配的内存、执行队列中的任务数量等。</strong></p>
<p><img src="/2023/04/11/ClickHouse%20%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4(%E5%8D%81%E4%B9%9D)/1229382-20211008182853513-131246570.png" alt="img"></p>
<h3 id="查询日志"><a href="#查询日志" class="headerlink" title="查询日志"></a>查询日志</h3><p><strong>查询日志目前主要有 6 种类型，它们分别从不同角度记录了 ClickHouse 的操作行为。所有查询日志在默认配置下都是关闭状态，需要在 config.xml 配置中进行更改，接下来分别介绍它们的开启方法。在配置被开启之后，ClickHouse 会为每种类型的查询日志自动生成相应的系统表以供查询。</strong></p>
<h4 id="1-query-log"><a href="#1-query-log" class="headerlink" title="1. query_log"></a>1. query_log</h4><p><strong>query_log 是最常用的查询日志，它记录了 ClickHouse 服务中所有已经执行的查询记录，它的全局定义方式如下所示：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">query_log</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">database</span>&gt;</span>system<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span>&gt;</span>query_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">partition_by</span>&gt;</span>toYYYYMM(event_date)<span class="tag">&lt;/<span class="name">partition_by</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 刷新周期 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">query_log</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>如果只希望具有某些角色用户才能开启 query_log，那么可以在 users.xml 的用户 profile 中增加一个标签：1。</strong></p>
<p><strong>query_log 开启后，即可通过相应的系统表对记录进行查询。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM system.query_log</span><br></pre></td></tr></table></figure>

<p><strong>返回的日志信息十分完善，涵盖了查询语句、执行时间、返回的数据量和执行用户等。</strong></p>
<h4 id="2-query-thread-log"><a href="#2-query-thread-log" class="headerlink" title="2. query_thread_log"></a>2. query_thread_log</h4><p><strong>query_thread_log 记录了所有线程的执行查询的信息，它的全局定义方式如下所示：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">query_thread_log</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">database</span>&gt;</span>system<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span>&gt;</span>query_thread_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">partition_by</span>&gt;</span>toYYYYMM(event_date)<span class="tag">&lt;/<span class="name">partition_by</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 刷新周期 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">query_thread_log</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>如果只希望具有某些角色用户才能开启 query_log，那么可以在 users.xml 的用户 profile 中增加一个标签：1。</strong></p>
<p><strong>log_query_thread 开启后，即可通过相应的系统表对记录进行查询。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM system.log_query_thread</span><br></pre></td></tr></table></figure>

<p><strong>返回的日志信息十分完善，涵盖了线程名称、查询语句、执行时间、和内存使用量等。</strong></p>
<h4 id="3-part-log"><a href="#3-part-log" class="headerlink" title="3. part_log"></a>3. part_log</h4><p><strong>part_log 记录了 MergeTree 系列表引擎的分区操作日志，其全局定义方式如下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">part_log</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">database</span>&gt;</span>system<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span>&gt;</span>part_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">part_log</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>part_log 开启后，即可通过相应的系统表对记录进行查询。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM system.part_log</span><br></pre></td></tr></table></figure>

<p><strong>返回的日志信息十分完善，涵盖了操纵类型、表名称、分区信息和执行时间等。</strong></p>
<h4 id="4-text-log"><a href="#4-text-log" class="headerlink" title="4. text_log"></a>4. text_log</h4><p><strong>text_log 日志记录了 ClickHouse 运行过程中产生的一系列打印日志，包括 INFO、DEBUG 和 TRACE，它的全局定义方式如下：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">text_log</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">database</span>&gt;</span>system<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span>&gt;</span>text_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">text_log</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>text_log 开启后，即可通过相应的系统表对记录进行查询。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM system.text_log</span><br></pre></td></tr></table></figure>

<p><strong>返回的日志信息十分完善，涵盖了线程名称、日志对象、日志信息和执行时间等等。</strong></p>
<h4 id="5-metric-log"><a href="#5-metric-log" class="headerlink" title="5. metric_log"></a>5. metric_log</h4><p><strong>metric_log 日志用于将 system.metrics 和 system.events 中的数据汇聚到一起，它的全局定义方式如下所示：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">metric_log</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">database</span>&gt;</span>system<span class="tag">&lt;/<span class="name">database</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span>&gt;</span>metric_log<span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">flush_interval_milliseconds</span>&gt;</span>7500<span class="tag">&lt;/<span class="name">flush_interval_milliseconds</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 收集 metrics 和 event 的时间 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">collect_interval_milliseconds</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">collect_interval_milliseconds</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">metric_log</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>metric_log 开启后，即可通过相应的系统表对记录进行查询。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM system.metric_log</span><br></pre></td></tr></table></figure>

<p><strong>以上就是几种查询日志，当然，除了这些自身的查询日志之外，ClickHouse 还能够与众多的第三方系统集成，比如 Prometheus。当然监控系统又是一个比较大的话题了，这里就不再展开了，有兴趣可以去调研一下。</strong></p>
]]></content>
      <categories>
        <category>ClickHouse</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>Java8异步利器：CompletableFuture使用教程</title>
    <url>/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>CompletableFuture是jdk8的新特性。CompletableFuture实现了CompletionStage接口和Future接口，前者是对后者的一个扩展，增加了异步会点、流式处理、多个Future组合处理的能力，使Java在处理多任务的协同工作时更加顺畅便利。</p>
<h2 id="一、创建异步任务"><a href="#一、创建异步任务" class="headerlink" title="一、创建异步任务"></a>一、创建异步任务</h2><h3 id="1-supplyAsync"><a href="#1-supplyAsync" class="headerlink" title="1. supplyAsync"></a>1. supplyAsync</h3><p>supplyAsync是创建带有返回值的异步任务。它有如下两个方法，一个是使用默认线程池（ForkJoinPool.commonPool()）的方法，一个是带有自定义线程池的重载方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 带返回值异步请求，默认线程池</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title function_">supplyAsync</span><span class="params">(Supplier&lt;U&gt; supplier)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 带返回值的异步请求，可以自定义线程池</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title function_">supplyAsync</span><span class="params">(Supplier&lt;U&gt; supplier, Executor executor)</span></span><br></pre></td></tr></table></figure>

<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;result&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//等待任务执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;结果-&gt;&quot;</span> + cf.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 自定义线程池</span></span><br><span class="line">        <span class="type">ExecutorService</span> <span class="variable">executorService</span> <span class="operator">=</span> Executors.newSingleThreadExecutor();</span><br><span class="line">        CompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;result&quot;</span>;</span><br><span class="line">        &#125;, executorService);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//等待子任务执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;结果-&gt;&quot;</span> + cf.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680242908549.png" alt="1680242908549"></p>
<h3 id="2-runAsync"><a href="#2-runAsync" class="headerlink" title="2. runAsync"></a>2. runAsync</h3><p>runAsync是创建没有返回值的异步任务。它有如下两个方法，一个是使用默认线程池（ForkJoinPool.commonPool()）的方法，一个是带有自定义线程池的重载方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 不带返回值的异步请求，默认线程池</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> CompletableFuture&lt;Void&gt; <span class="title function_">runAsync</span><span class="params">(Runnable runnable)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 不带返回值的异步请求，可以自定义线程池</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> CompletableFuture&lt;Void&gt; <span class="title function_">runAsync</span><span class="params">(Runnable runnable, Executor executor)</span></span><br></pre></td></tr></table></figure>

<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Void&gt; cf = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;do something....&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//等待任务执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;结果-&gt;&quot;</span> + cf.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 自定义线程池</span></span><br><span class="line">        <span class="type">ExecutorService</span> <span class="variable">executorService</span> <span class="operator">=</span> Executors.newSingleThreadExecutor();</span><br><span class="line">        CompletableFuture&lt;Void&gt; cf = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;do something....&quot;</span>);</span><br><span class="line">        &#125;, executorService);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//等待任务执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;结果-&gt;&quot;</span> + cf.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680242980061.png" alt="1680242980061"><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680250853857.png" alt="1680250853857"></p>
<h3 id="3-获取任务结果的方法"><a href="#3-获取任务结果的方法" class="headerlink" title="3.获取任务结果的方法"></a>3.获取任务结果的方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 如果完成则返回结果，否则就抛出具体的异常</span></span><br><span class="line"><span class="keyword">public</span> T <span class="title function_">get</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, ExecutionException </span><br><span class="line"> </span><br><span class="line"><span class="comment">// 最大时间等待返回结果，否则就抛出具体异常</span></span><br><span class="line"><span class="keyword">public</span> T <span class="title function_">get</span><span class="params">(<span class="type">long</span> timeout, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException, ExecutionException, TimeoutException</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 完成时返回结果值，否则抛出unchecked异常。为了更好地符合通用函数形式的使用，如果完成此 CompletableFuture所涉及的计算引发异常，则此方法将引发unchecked异常并将底层异常作为其原因</span></span><br><span class="line"><span class="keyword">public</span> T <span class="title function_">join</span><span class="params">()</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 如果完成则返回结果值（或抛出任何遇到的异常），否则返回给定的 valueIfAbsent。</span></span><br><span class="line"><span class="keyword">public</span> T <span class="title function_">getNow</span><span class="params">(T valueIfAbsent)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 如果任务没有完成，返回的值设置为给定值</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">complete</span><span class="params">(T value)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 如果任务没有完成，就抛出给定异常</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">completeExceptionally</span><span class="params">(Throwable ex)</span> </span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<h2 id="二、异步回调处理"><a href="#二、异步回调处理" class="headerlink" title="二、异步回调处理"></a>二、异步回调处理</h2><h3 id="1-thenApply和thenApplyAsync"><a href="#1-thenApply和thenApplyAsync" class="headerlink" title="1. thenApply和thenApplyAsync"></a>1. thenApply和thenApplyAsync</h3><p>thenApply 表示某个任务执行完成后执行的动作，即回调方法，会将该任务的执行结果即方法返回值作为入参传递到回调方法中，带有返回值。</p>
<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = cf1.thenApplyAsync((result) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            result += <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//等待任务1执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf1结果-&gt;&quot;</span> + cf1.get());</span><br><span class="line">        <span class="comment">//等待任务2执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf2结果-&gt;&quot;</span> + cf2.get());</span><br><span class="line">&#125;</span><br><span class="line"> <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = cf1.thenApply((result) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            result += <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//等待任务1执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf1结果-&gt;&quot;</span> + cf1.get());</span><br><span class="line">        <span class="comment">//等待任务2执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf2结果-&gt;&quot;</span> + cf2.get());</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680243133808.png" alt="图片"><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680250915645.png" alt="1680250915645"></p>
<p>从上面代码和测试结果我们发现thenApply和thenApplyAsync区别在于，使用thenApply方法时子任务与父任务使用的是同一个线程，而thenApplyAsync在子任务中是另起一个线程执行任务，并且thenApplyAsync可以自定义线程池，默认的使用ForkJoinPool.commonPool()线程池。</p>
<h3 id="2-thenAccept和thenAcceptAsync"><a href="#2-thenAccept和thenAcceptAsync" class="headerlink" title="2. thenAccept和thenAcceptAsync"></a>2. thenAccept和thenAcceptAsync</h3><p>thenAccep表示某个任务执行完成后执行的动作，即回调方法，会将该任务的执行结果即方法返回值作为入参传递到回调方法中，无返回值。</p>
<p>测试代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf2 = cf1.thenAccept((result) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//等待任务1执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf1结果-&gt;&quot;</span> + cf1.get());</span><br><span class="line">        <span class="comment">//等待任务2执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf2结果-&gt;&quot;</span> + cf2.get());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf2 = cf1.thenAcceptAsync((result) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//等待任务1执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf1结果-&gt;&quot;</span> + cf1.get());</span><br><span class="line">        <span class="comment">//等待任务2执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf2结果-&gt;&quot;</span> + cf2.get());</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680250407628.png" alt="1680250407628"></p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252474421.png" alt="1680252474421"></p>
<p>从上面代码和测试结果我们发现thenAccep和thenAccepAsync区别在于，使用thenAccep方法时子任务与父任务使用的是同一个线程，而thenAccepAsync在子任务中可能是另起一个线程执行任务，并且thenAccepAsync可以自定义线程池，默认的使用ForkJoinPool.commonPool()线程池。</p>
<h3 id="3-thenRun和thenRunAsync"><a href="#3-thenRun和thenRunAsync" class="headerlink" title="3.thenRun和thenRunAsync"></a>3.thenRun和thenRunAsync</h3><p>thenRun表示某个任务执行完成后执行的动作，即回调方法，无入参，无返回值。</p>
<p>测试代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + &quot; cf1 do something....&quot;);</span><br><span class="line">            return 1;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf2 = cf1.thenRun(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + &quot; cf2 do something....&quot;);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        //等待任务1执行完成</span><br><span class="line">        System.out.println(&quot;cf1结果-&gt;&quot; + cf1.get());</span><br><span class="line">        //等待任务2执行完成</span><br><span class="line">        System.out.println(&quot;cf2结果-&gt;&quot; + cf2.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + &quot; cf1 do something....&quot;);</span><br><span class="line">            return 1;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf2 = cf1.thenRunAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + &quot; cf2 do something....&quot;);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        //等待任务1执行完成</span><br><span class="line">        System.out.println(&quot;cf1结果-&gt;&quot; + cf1.get());</span><br><span class="line">        //等待任务2执行完成</span><br><span class="line">        System.out.println(&quot;cf2结果-&gt;&quot; + cf2.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252558062.png" alt="1680252558062"></p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252599639.png" alt="1680252599639"></p>
<p>从上面代码和测试结果我们发现thenRun和thenRunAsync区别在于，使用thenRun方法时子任务与父任务使用的是同一个线程，而thenRunAsync在子任务中可能是另起一个线程执行任务，并且thenRunAsync可以自定义线程池，默认的使用ForkJoinPool.commonPool()线程池。</p>
<h3 id="4-whenComplete和whenCompleteAsync"><a href="#4-whenComplete和whenCompleteAsync" class="headerlink" title="4.whenComplete和whenCompleteAsync"></a>4.whenComplete和whenCompleteAsync</h3><p>whenComplete是当某个任务执行完成后执行的回调方法，会将执行结果或者执行期间抛出的异常传递给回调方法，如果是正常执行则异常为null，回调方法对应的CompletableFuture的result和该任务一致，如果该任务正常执行，则get方法返回执行结果，如果是执行异常，则get方法抛出异常。</p>
<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="type">int</span> <span class="variable">a</span> <span class="operator">=</span> <span class="number">1</span>/<span class="number">0</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = cf1.whenComplete((result, e) -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;上个任务结果：&quot;</span> + result);</span><br><span class="line">            System.out.println(<span class="string">&quot;上个任务抛出异常：&quot;</span> + e);</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line"><span class="comment">//        //等待任务1执行完成</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;cf1结果-&gt;&quot; + cf1.get());</span></span><br><span class="line"><span class="comment">//        //等待任务2执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf2结果-&gt;&quot;</span> + cf2.get());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252678256.png" alt="1680252678256"></p>
<p>whenCompleteAsync和whenComplete区别也是whenCompleteAsync可能会另起一个线程执行任务，并且thenRunAsync可以自定义线程池，默认的使用ForkJoinPool.commonPool()线程池。</p>
<h3 id="5-handle和handleAsync"><a href="#5-handle和handleAsync" class="headerlink" title="5.handle和handleAsync"></a>5.handle和handleAsync</h3><p>跟whenComplete基本一致，区别在于handle的回调方法有返回值。</p>
<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="comment">// int a = 1/0;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = cf1.handle((result, e) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;上个任务结果：&quot;</span> + result);</span><br><span class="line">            System.out.println(<span class="string">&quot;上个任务抛出异常：&quot;</span> + e);</span><br><span class="line">            <span class="keyword">return</span> result+<span class="number">2</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//等待任务2执行完成</span></span><br><span class="line">        System.out.println(<span class="string">&quot;cf2结果-&gt;&quot;</span> + cf2.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果 ：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252727458.png" alt="1680252727458"></p>
<h2 id="三、多任务组合处理"><a href="#三、多任务组合处理" class="headerlink" title="三、多任务组合处理"></a>三、多任务组合处理</h2><h3 id="1-thenCombine、thenAcceptBoth-和runAfterBoth"><a href="#1-thenCombine、thenAcceptBoth-和runAfterBoth" class="headerlink" title="1. thenCombine、thenAcceptBoth 和runAfterBoth"></a>1. thenCombine、thenAcceptBoth 和runAfterBoth</h3><p>这三个方法都是将两个CompletableFuture组合起来处理，只有两个任务都正常完成时，才进行下阶段任务。</p>
<p>区别：thenCombine会将两个任务的执行结果作为所提供函数的参数，且该方法有返回值；thenAcceptBoth同样将两个任务的执行结果作为方法入参，但是无返回值；runAfterBoth没有入参，也没有返回值。注意两个任务中只要有一个执行异常，则将该异常信息作为指定任务的执行结果。</p>
<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf3 = cf1.thenCombine(cf2, (a, b) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> a + b;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf3 = cf1.thenAcceptBoth(cf2, (a, b) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">            System.out.println(a + b);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf3 = cf1.runAfterBoth(cf2, () -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252820126.png" alt="1680252820126"></p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252857615.png" alt="1680252857615"></p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680252909115.png" alt="1680252909115"></p>
<h3 id="2-applyToEither、acceptEither和runAfterEither"><a href="#2-applyToEither、acceptEither和runAfterEither" class="headerlink" title="2.applyToEither、acceptEither和runAfterEither"></a>2.applyToEither、acceptEither和runAfterEither</h3><p>这三个方法和上面一样也是将两个CompletableFuture组合起来处理，当有一个任务正常完成时，就会进行下阶段任务。</p>
<p>区别：applyToEither会将已经完成任务的执行结果作为所提供函数的参数，且该方法有返回值；acceptEither同样将已经完成任务的执行结果作为方法入参，但是无返回值；runAfterEither没有入参，也没有返回值。</p>
<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;String&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf1 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf2 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf3 = cf1.applyToEither(cf2, (result) -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;接收到&quot;</span> + result);</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf3 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;String&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf1 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf2 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf3 = cf1.acceptEither(cf2, (result) -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;接收到&quot;</span> + result);</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;String&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf1 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf1 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf2 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf2 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf3 = cf1.runAfterEither(cf2, () -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;cf3 任务完成&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680253073210.png" alt="1680253073210"></p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680253114302.png" alt="1680253114302"></p>
<p>从上面可以看出cf1任务完成需要2秒，cf2任务完成需要5秒，使用applyToEither组合两个任务时，只要有其中一个任务完成时，就会执行cf3任务，显然cf1任务先完成了并且将自己任务的结果传值给了cf3任务，cf3任务中打印了接收到cf1任务完成，接着完成自己的任务，并返回cf3任务完成；acceptEither和runAfterEither类似，acceptEither会将cf1任务的结果作为cf3任务的入参，但cf3任务完成时并无返回值；runAfterEither不会将cf1任务的结果作为cf3任务的入参，它是没有任务入参，执行完自己的任务后也并无返回值。</p>
<h3 id="3-allOf-x2F-anyOf"><a href="#3-allOf-x2F-anyOf" class="headerlink" title="3. allOf &#x2F; anyOf"></a>3. allOf &#x2F; anyOf</h3><p>allOf：CompletableFuture是多个任务都执行完成后才会执行，只有有一个任务执行异常，则返回的CompletableFuture执行get方法时会抛出异常，如果都是正常执行，则get返回null。</p>
<p>anyOf ：CompletableFuture是多个任务只要有一个任务执行完成，则返回的CompletableFuture执行get方法时会抛出异常，如果都是正常执行，则get返回执行完成任务的结果。</p>
<p>测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;String&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf1 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf1 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">                <span class="type">int</span> <span class="variable">a</span> <span class="operator">=</span> <span class="number">1</span>/<span class="number">0</span>;</span><br><span class="line">                Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf2 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf2 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf3 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf3 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf3 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cfAll = CompletableFuture.allOf(cf1, cf2, cf3);</span><br><span class="line">        System.out.println(<span class="string">&quot;cfAll结果-&gt;&quot;</span> + cfAll.get());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        CompletableFuture&lt;String&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf1 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf1 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf2 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf2 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;String&gt; cf3 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;cf3 任务完成&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;cf3 任务完成&quot;</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Object&gt; cfAll = CompletableFuture.anyOf(cf1, cf2, cf3);</span><br><span class="line">        System.out.println(<span class="string">&quot;cfAll结果-&gt;&quot;</span> + cfAll.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680253292909.png" alt="1680253292909"></p>
<p><img src="/2023/03/31/Java8%E5%BC%82%E6%AD%A5%E5%88%A9%E5%99%A8%EF%BC%9ACompletableFuture%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/1680253328002.png" alt="1680253328002"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
      <tags>
        <tag>base</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL优化万能公式：5 大步骤 + 10 个案例</title>
    <url>/2022/08/16/SQL%E4%BC%98%E5%8C%96%E4%B8%87%E8%83%BD%E5%85%AC%E5%BC%8F%EF%BC%9A5%20%E5%A4%A7%E6%AD%A5%E9%AA%A4%20+%2010%20%E4%B8%AA%E6%A1%88%E4%BE%8B-sql-you-hua-wan-neng-gong-shi-5da-bu-zhou-10ge-an-li/</url>
    <content><![CDATA[<h2 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h2><p>在应用开发的早期，数据量少，开发人员开发功能时更重视功能上的实现，随着生产数据的增长，很多SQL语句开始暴露出性能问题，对生产的影响也越来越大，有时可能这些有问题的SQL就是整个系统性能的瓶颈。</p>
<h2 id="2、SQL优化一般步骤"><a href="#2、SQL优化一般步骤" class="headerlink" title="2、SQL优化一般步骤"></a>2、SQL优化一般步骤</h2><p><strong>1、通过慢查日志等定位那些执行效率较低的SQL语句</strong></p>
<p><strong>2、explain 分析SQL的执行计划</strong></p>
<p>需要重点关注type、rows、filtered、extra。</p>
<p>type由上至下，效率越来越高</p>
<ul>
<li>ALL 全表扫描</li>
<li>index 索引全扫描</li>
<li>range 索引范围扫描，常用语&lt;,&lt;&#x3D;,&gt;&#x3D;,between,in等操作</li>
<li>ref 使用非唯一索引扫描或唯一索引前缀扫描，返回单条记录，常出现在关联查询中</li>
<li>eq_ref 类似ref，区别在于使用的是唯一索引，使用主键的关联查询</li>
<li>const&#x2F;system 单条记录，系统会把匹配行中的其他列作为常数处理，如主键或唯一索引查询</li>
<li>null MySQL不访问任何表或索引，直接返回结果</li>
<li>虽然上至下，效率越来越高，但是根据cost模型，假设有两个索引idx1(a, b, c),idx2(a, c)，SQL为”select * from t where a &#x3D; 1 and b in (1, 2) order by c”;如果走idx1，那么是type为range，如果走idx2，那么type是ref；当需要扫描的行数，使用idx2大约是idx1的5倍以上时，会用idx1，否则会用idx2</li>
</ul>
<p>Extra</p>
<ul>
<li>Using filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。</li>
<li>Using temporary：使用了临时表保存中间结果，性能特别差，需要重点优化</li>
<li>Using index：表示相应的 select 操作中使用了覆盖索引（Coveing Index）,避免访问了表的数据行，效率不错！如果同时出现 using where，意味着无法直接通过索引查找来查询到符合条件的数据。</li>
<li>Using index condition：MySQL5.6之后新增的ICP，using index condtion就是使用了ICP（索引下推），在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据。</li>
</ul>
<p><strong>3、show profile 分析</strong></p>
<p>了解SQL执行的线程的状态及消耗的时间。</p>
<p>默认是关闭的，开启语句“set profiling &#x3D; 1;”</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> PROFILES ;<span class="keyword">SHOW</span> PROFILE <span class="keyword">FOR</span> QUERY  #&#123;id&#125;;</span><br></pre></td></tr></table></figure>



<p><strong>4、trace</strong></p>
<p>trace分析优化器如何选择执行计划，通过trace文件能够进一步了解为什么优惠券选择A执行计划而不选择B执行计划。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> optimizer_trace<span class="operator">=</span>&quot;enabled=on&quot;;<span class="keyword">set</span> optimizer_trace_max_mem_size<span class="operator">=</span><span class="number">1000000</span>;<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> information_schema.optimizer_trace;</span><br></pre></td></tr></table></figure>



<p><strong>5、确定问题并采用相应的措施</strong></p>
<ul>
<li>优化索引</li>
<li>优化SQL语句：修改SQL、IN 查询分段、时间查询分段、基于上一次数据过滤</li>
<li>改用其他实现方式：ES、数仓等</li>
<li>数据碎片处理</li>
</ul>
<h2 id="3、场景分析"><a href="#3、场景分析" class="headerlink" title="3、场景分析"></a>3、场景分析</h2><p><strong>案例1、最左匹配</strong></p>
<p>索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">KEY `idx_shopid_orderno` (`shop_id`,`order_no`)</span><br></pre></td></tr></table></figure>



<p>SQL语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _t <span class="keyword">where</span> orderno<span class="operator">=</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<p>查询匹配从左往右匹配，要使用order_no走索引，必须查询条件携带shop_id或者索引(shop_id,order_no)调换前后顺序</p>
<p><strong>案例2、隐式转换</strong></p>
<p>索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">KEY `idx_mobile` (`mobile`)</span><br></pre></td></tr></table></figure>



<p>SQL语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _user <span class="keyword">where</span> mobile<span class="operator">=</span><span class="number">12345678901</span></span><br></pre></td></tr></table></figure>



<p>隐式转换相当于在索引上做运算，会让索引失效。mobile是字符类型，使用了数字，应该使用字符串匹配，否则MySQL会用到隐式替换，导致索引失效。</p>
<p><strong>案例3、大分页</strong></p>
<p>索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">KEY `idx_a_b_c` (`a`, `b`, `c`)</span><br></pre></td></tr></table></figure>



<p>SQL语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _t <span class="keyword">where</span> a <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> b <span class="operator">=</span> <span class="number">2</span> <span class="keyword">order</span> <span class="keyword">by</span> c <span class="keyword">desc</span> limit <span class="number">10000</span>, <span class="number">10</span>;</span><br></pre></td></tr></table></figure>



<p>对于大分页的场景，可以优先让产品优化需求，如果没有优化的，有如下两种优化方式，</p>
<p>一种是把上一次的最后一条数据，也即上面的c传过来，然后做“c &lt; xxx”处理，但是这种一般需要改接口协议，并不一定可行。</p>
<p>另一种是采用延迟关联的方式进行处理，减少SQL回表，但是要记得索引需要完全覆盖才有效果，SQL改动如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select t1.* from _t t1, (select id from _t where a = 1 and b = 2 order by c desc limit 10000, 10) t2 where t1.id = t2.id;</span><br></pre></td></tr></table></figure>



<p><strong>案例4、in + order by</strong></p>
<p>索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">KEY `idx_shopid_status_created` (`shop_id`, `order_status`, `created_at`)</span><br></pre></td></tr></table></figure>



<p>SQL语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _order <span class="keyword">where</span> shop_id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> order_status <span class="keyword">in</span> (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>) <span class="keyword">order</span> <span class="keyword">by</span> created_at <span class="keyword">desc</span> limit <span class="number">10</span></span><br></pre></td></tr></table></figure>



<p>in查询在MySQL底层是通过n*m的方式去搜索，类似union，但是效率比union高。</p>
<p>in查询在进行cost代价计算时（代价 &#x3D; 元组数 * IO平均值），是通过将in包含的数值，一条条去查询获取元组数的，因此这个计算过程会比较的慢，所以MySQL设置了个临界值(eq_range_index_dive_limit)，5.6之后超过这个临界值后该列的cost就不参与计算了。因此会导致执行计划选择不准确。默认是200，即in条件超过了200个数据，会导致in的代价计算存在问题，可能会导致Mysql选择的索引不准确。</p>
<p>处理方式，可以(order_status, created_at)互换前后顺序，并且调整SQL为延迟关联。</p>
<p><strong>案例5、范围查询阻断，后续字段不能走索引</strong></p>
<p>索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">KEY `idx_shopid_created_status` (`shop_id`, `created_at`, `order_status`)</span><br></pre></td></tr></table></figure>



<p>SQL语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _order <span class="keyword">where</span> shop_id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> created_at <span class="operator">&gt;</span> <span class="string">&#x27;2021-01-01 00:00:00&#x27;</span> <span class="keyword">and</span> order_status <span class="operator">=</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>



<p>范围查询还有“IN、between”</p>
<p><strong>案例6、不等于、不包含不能用到索引的快速搜索。（可以用到ICP）</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _order <span class="keyword">where</span> shop_id<span class="operator">=</span><span class="number">1</span> <span class="keyword">and</span> order_status <span class="keyword">not</span> <span class="keyword">in</span> (<span class="number">1</span>,<span class="number">2</span>)<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _order <span class="keyword">where</span> shop_id<span class="operator">=</span><span class="number">1</span> <span class="keyword">and</span> order_status <span class="operator">!=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>



<p>在索引上，避免使用NOT、!&#x3D;、&lt;&gt;、!&lt;、!&gt;、NOT EXISTS、NOT IN、NOT LIKE等</p>
<p><strong>案例7、优化器选择不使用索引的情况</strong></p>
<p>如果要求访问的数据量很小，则优化器还是会选择辅助索引，但是当访问的数据占整个表中数据的蛮大一部分时（一般是20%左右），优化器会选择通过聚集索引来查找数据。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _order <span class="keyword">where</span>  order_status <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>



<p>查询出所有未支付的订单，一般这种订单是很少的，即使建了索引，也没法使用索引。</p>
<p><strong>案例8、复杂查询</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">sum</span>(amt) <span class="keyword">from</span> _t <span class="keyword">where</span> a <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> b <span class="keyword">in</span> (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>) <span class="keyword">and</span> c <span class="operator">&gt;</span> <span class="string">&#x27;2020-01-01&#x27;</span>;<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _t <span class="keyword">where</span> a <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> b <span class="keyword">in</span> (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>) <span class="keyword">and</span> c <span class="operator">&gt;</span> <span class="string">&#x27;2020-01-01&#x27;</span> limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure>



<p>如果是统计某些数据，可能改用数仓进行解决；</p>
<p>如果是业务上就有那么复杂的查询，可能就不建议继续走SQL了，而是采用其他的方式进行解决，比如使用ES等进行解决。</p>
<p><strong>案例9、asc和desc混用</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> _t <span class="keyword">where</span> a<span class="operator">=</span><span class="number">1</span> <span class="keyword">order</span> <span class="keyword">by</span> b <span class="keyword">desc</span>, c <span class="keyword">asc</span></span><br></pre></td></tr></table></figure>



<p>desc 和asc混用时会导致索引失效</p>
<p><strong>案例10、大数据</strong></p>
<p>对于推送业务的数据存储，可能数据量会很大，如果在方案的选择上，最终选择存储在MySQL上，并且做7天等有效期的保存。</p>
<p>那么需要注意，频繁的清理数据，会照成数据碎片，需要联系DBA进行数据碎片处理</p>
<p>来源：cnblogs.com&#x2F;powercto&#x2F;p&#x2F;14410128.html</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title>hashmap底层数据结构</title>
    <url>/2021/08/18/hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h2 id="一、HashMap简介"><a href="#一、HashMap简介" class="headerlink" title="一、HashMap简介"></a>一、HashMap简介</h2><p>1、它是一个通过Map接口实现的一个双列集合，主要是以键值对的方式进行存储，每一个键值对都有一个键和一个值。</p>
<p>2、每一个键都是唯一的，值可以重复，后面添加的键会覆盖前面相同的键。</p>
<p>3、HashMap存储结构采用的是哈希表的结构，元素的存储顺序不能保存一致，如果键是自定义的对象的话，需要重写hashcode方法与equals方法，才能保证键的唯一。</p>
<h2 id="二、HashMap存储的原理"><a href="#二、HashMap存储的原理" class="headerlink" title="二、HashMap存储的原理"></a>二、HashMap存储的原理</h2><h3 id="1、版本区别"><a href="#1、版本区别" class="headerlink" title="1、版本区别"></a>1、版本区别</h3><p><strong>jdk8以前：</strong></p>
<p>在jdk1.7中，首先是把元素放在一个个数组里面，后来存放的数据元素越来越多，于是就出现了链表，对于数组中的每一个元素，都可以有一条链表来存储元素。这就是有名的“拉链式”存储方法。<br><img src="/2021/08/18/hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-840e869c0ea34c8cad5655d3d316d8e4.png" alt="image.png"></p>
<p><strong>jdk8以后：</strong></p>
<p>由于存储的元素越来越多，链表也越来越长，在查找一个元素时候效率不仅没有提高（链表不适合查找，适合增删），反倒是下降了不少，于是就对这条链表进行了一个改进。如何改进呢？就是把这条链表变成一个适合查找的树形结构，没错就是红黑树。值得注意的是，因为需要为了退化成链表和遍历做准备，这个红黑树并不是纯红黑树，而是红黑树和双向链表的叠加结构。</p>
<p><img src="/2021/08/18/hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-ab9163a96dc44373910d0ef343bc8db6.png" alt="image.png"></p>
<h3 id="2、存储的流程"><a href="#2、存储的流程" class="headerlink" title="2、存储的流程"></a>2、存储的流程</h3><p><img src="/2021/08/18/hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-e3c1b70070d14acf9a3d26733f1a2de3.png" alt="image.png"></p>
<h3 id><a href="#" class="headerlink" title></a></h3><h2 id="三、HashMap数据结构"><a href="#三、HashMap数据结构" class="headerlink" title="三、HashMap数据结构"></a>三、HashMap数据结构</h2><h3 id="1、hash表数据结构"><a href="#1、hash表数据结构" class="headerlink" title="1、hash表数据结构"></a>1、hash表数据结构</h3><h4 id="1）简介"><a href="#1）简介" class="headerlink" title="1）简介"></a>1）简介</h4><p>哈希表是一个通过数组和链表相结合而成的数据结构，既避免了数组的增删慢，也避免了链表查询查询慢的的缺陷。</p>
<p><strong>数组</strong> ：</p>
<p>数组的存储区是连续的，占用内存严重，故空间复杂度很大。但数组的二分查找时间度小；数组的特点：寻址容易，插入和删除困难。</p>
<p><strong>链表</strong> ：</p>
<p>链表的储存区离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度大；</p>
<p>链表的特点：寻址困难，插入和删除容易。</p>
<h4 id="2）保证数据唯一的原理"><a href="#2）保证数据唯一的原理" class="headerlink" title="2）保证数据唯一的原理"></a>2）保证数据唯一的原理</h4><ol>
<li><p>当HashMap集合存储元素的时候,就会调用该元素的hashCode0方法计算哈希值</p>
</li>
<li><p>判断该哈希值对应的位置上是否有相同哈希值的元素</p>
</li>
<li><p>如果该位置上没有相同哈希值的元素,就直接存储</p>
</li>
<li><p>如果该位置上有相同哈希值的元素,就说明产生了哈希冲突</p>
</li>
<li><p>产生了哈希冲实,就得调用该元素的equals方法,与该哈希值位置上的所有元素进行-比较</p>
</li>
<li><p>如果比较完后,没有一个元素与该元素相同,就直接存储</p>
</li>
<li><p>如果比较完后,只要有任意一个元素与该元素相同,就不存储</p>
</li>
</ol>
<p><img src="/2021/08/18/hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-5e50cc4ebbdf4cd59e62ef6f41491a37.png" alt="image.png"></p>
<h3 id="3、红黑树的数据结构"><a href="#3、红黑树的数据结构" class="headerlink" title="3、红黑树的数据结构"></a>3、红黑树的数据结构</h3><h4 id="1）简介-1"><a href="#1）简介-1" class="headerlink" title="1）简介"></a>1）简介</h4><p>红黑树是一种自平衡的二叉查找树，是计算机科学中用到的一种数据结构，它是在1972年由Rudolf Bayer发明的，当时被称之为平衡二叉B树，后来，在1978年被Leoj.Guibas和Robert Sedgewick修改为如今的”红黑树”。它是一种特殊的二叉查找树，红黑树的每一个节点上都有存储位表示节点的颜色，可以是红或者黑；</p>
<p>红黑树不是高度平衡的，它的平衡是通过”红黑树的特性”进行实现的；</p>
<h4 id="2）红黑树特性"><a href="#2）红黑树特性" class="headerlink" title="2）红黑树特性"></a>2）红黑树特性</h4><ol>
<li><p>每一个节点或是红色的，或者是黑色的。</p>
</li>
<li><p>根节点必须是黑色</p>
</li>
<li><p>每个叶节点(Nil)是黑色的；（如果一个节点没有子节点或者父节点，则该节点相应的指针属性值为Nil，这些Nil视为叶节点）</p>
</li>
<li><p>如果某一个节点是红色，那么它的子节点必须是黑色(不能出现两个红色节点相连的情况)</p>
</li>
<li><p>对每一个节点，从该节点到其所有后代叶节点的简单路径上，均包含相同数目的黑色节点；</p>
</li>
<li><p>在进行元素插入的时候，和之前一样； 每一次插入完毕以后，使用黑色规则进行校验，如果不满足红黑规则，就需要通过变色，左旋和右旋来调整树，使其满足红黑规则；</p>
</li>
</ol>
<p><img src="/2021/08/18/hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-4bf5d88b307548c7bb2a52a715858cad.png" alt="image.png"></p>
<h4 id="3）与AVL树的区别"><a href="#3）与AVL树的区别" class="headerlink" title="3）与AVL树的区别"></a>3）与AVL树的区别</h4><p> 1、红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。</p>
<p> 2、平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新节点之后需要旋转的次数不能预知。</p>
<h2 id="四、算法"><a href="#四、算法" class="headerlink" title="四、算法"></a>四、算法</h2><h4 id="1、负载因子（load-factor）"><a href="#1、负载因子（load-factor）" class="headerlink" title="1、负载因子（load factor）"></a>1、负载因子（load factor）</h4><p>   如果一个hash表中桶的个数为 size , 存储的元素个数为used .则我们称 used &#x2F; size 为负载因子loadFactor . 一般的情况下，当loadFactor&lt;&#x3D;1时，hash表查找的期望复杂度为O(1). 因此。每次往hash表中加入元素时。我们必须保证是在loadFactor &lt;1的情况下，才可以加入。</p>
<h4 id="2、初始容量与扩容"><a href="#2、初始容量与扩容" class="headerlink" title="2、初始容量与扩容"></a>2、初始容量与扩容</h4><p>HashMap的初始容量为16，Hashtable初始容量为11，两者的负载填充因子默认都是0.75。</p>
<p>如果size大小到达阈值，则扩容一倍，依旧为2的整次幂</p>
<p>最大容量：因为计算采用int值，int值最大为2的31次-1，达不到2的31次，所以为2的30次。</p>
<h4 id="3、扩容的实现"><a href="#3、扩容的实现" class="headerlink" title="3、扩容的实现"></a>3、扩容的实现</h4><p>当我们加入一个新元素时。一旦loadFactor大于等于1了，我们不能单纯的往hash表里边加入元素。</p>
<p>由于加入完之后，loadFactor将大于1，这样也就不能保证查找的期望时间复杂度为常数级了。这时。我们应该对桶数组进行一次容量扩张，让size增大 。</p>
<p>这样就能保证加入元素后 used &#x2F; size 仍然小于等于1 ， 从而保证查找的期望时间复杂度为O(1).可是。怎样进行容量扩张呢？ C++中的vector的容量扩张是一种好方法。</p>
<p>于是有了例如以下思路 ：　Hash表中每次发现loadFactor&#x3D;&#x3D;1时，就开辟一个原来桶数组的两倍空间（称为新桶数组），然后把原来的桶数组中元素所有转移过来到新的桶数组中。注意这里转移是须要元素一个个又一次哈希到新桶中的。原因后面会讲到。</p>
<p>   这样的方法的缺点是，容量扩张是一次完毕的，期间要花非常长时间一次转移hash表中的全部元素。这样在hash表中loadFactor&#x3D;&#x3D;1时。往里边插入一个元素将会等候非常长的时间。</p>
<h4 id="4、Redis中的实现"><a href="#4、Redis中的实现" class="headerlink" title="4、Redis中的实现"></a>4、Redis中的实现</h4><ol>
<li><p>Redis 是一个高效的 key-value 缓存系统，也可以理解为基于键值对的数据库。</p>
</li>
<li><p>Redis也是采取<strong>链地址法</strong>解决哈希冲突。</p>
</li>
<li><p>我们知道，Java发生扩容的瞬间，是需要先将原哈希表中所有键值对都转移到新的哈希表中，这个过程是比较慢的，此时插入该元素的性能相当低。</p>
</li>
<li><p>而Redis对于这一部分，采取的是<strong>分摊转移</strong>的方式。即当插入一个新元素x触发了扩容时，先转移第一个不为空的桶到新的哈希表，然后将该元素插入。而下一次再次插入时，继续转移旧哈希表中第一个不为空的桶，再插入元素。直至旧哈希表为空为止。这样一来，理想情况下，插入的时间复杂度是O(1)。</p>
</li>
<li><p>在Redis的实现中，新插入的键值对会放在箱子中链表的头部，而不是在尾部继续插入。</p>
</li>
<li><p>这种方案是基于两点考虑：</p>
</li>
<li><p>一是由于找到链表尾部的时间复杂度为O(n)，且需要额外的内存地址来保存链表的尾部位置，而头插法的时间复杂度为O(1)。</p>
</li>
<li><p>二是处于Redis的实际应用场景来考虑。对于一个数据库系统来说，最新插入的数据往往更可能频繁地被获取，所以这样也能节省查找的耗时</p>
</li>
</ol>
<h2 id="五、ConcurrentHashMap、HashTable、HashMap区别"><a href="#五、ConcurrentHashMap、HashTable、HashMap区别" class="headerlink" title="五、ConcurrentHashMap、HashTable、HashMap区别"></a>五、ConcurrentHashMap、HashTable、HashMap区别</h2><h3 id="1、HashMap"><a href="#1、HashMap" class="headerlink" title="1、HashMap"></a>1、HashMap</h3><p>因为多线程环境下，使用Hashmap进行put操作可能会引起死锁，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。【PS：HashMap 是允许key值为空的】</p>
<h3 id="2、HashTable"><a href="#2、HashTable" class="headerlink" title="2、HashTable"></a>2、HashTable</h3><p>Hashtable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下Hashtable的效率非常低下。因为当一个线程访问Hashtable的同步方法时，其他线程访问Hashtable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p>
<p><img src="/2021/08/18/hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hashmap%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-ba4fef5ef17740c79a373e929b5db03f.png" alt="image.png"></p>
<h3 id="3、ConcurrentHashMap"><a href="#3、ConcurrentHashMap" class="headerlink" title="3、ConcurrentHashMap"></a>3、ConcurrentHashMap</h3><p><strong>1）jdk7版本</strong></p>
<p>ConcurrentHashMap和HashMap设计思路差不多，但是为支持并发操作，做了一定的改进，ConcurrentHashMap引入Segment 的概念，目的是将map拆分成多个Segment(默认16个)。操作ConcurrentHashMap细化到操作某一个Segment。在多线程环境下，不同线程操作不同的Segment，他们互不影响，这便可实现并发操作。</p>
<p><strong>2）jdk8版本</strong></p>
<p>jdk8版本的ConcurrentHashMap相对于jdk7版本，发送了很大改动，jdk8直接抛弃了Segment的设计，采用了  较为轻捷的Node + CAS + Synchronized设计，保证线程安全。</p>
<p><strong>3）总结</strong></p>
<p>1、get方法不加锁；</p>
<p>2、put、remove方法要使用锁</p>
<p>jdk7使用锁分离机制(Segment分段加锁)</p>
<p>jdk8使用cas + synchronized 实现锁操作</p>
<p>3、Iterator对象的使用，运行一边更新，一遍遍历(可以根据原理自己拓展)</p>
<p>4、复合操作，无法保证线程安全，需要额外加锁保证</p>
<p>5、并发环境下，ConcurrentHashMap 效率较Collections.synchronizedMap()更高</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>fastdfs应用</title>
    <url>/2021/07/22/fastdfs%E5%BA%94%E7%94%A8-fastdfs%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<ul>
<li><h3 id="从应用层面详解fastdfs各组件"><a href="#从应用层面详解fastdfs各组件" class="headerlink" title="从应用层面详解fastdfs各组件"></a>从应用层面详解fastdfs各组件</h3></li>
<li><h3 id="fastdfs的多服务器场景使用及部署配置说明"><a href="#fastdfs的多服务器场景使用及部署配置说明" class="headerlink" title="fastdfs的多服务器场景使用及部署配置说明"></a>fastdfs的多服务器场景使用及部署配置说明</h3></li>
</ul>
<h2 id><a href="#" class="headerlink" title></a></h2><h2 id="相关的文章"><a href="#相关的文章" class="headerlink" title="相关的文章"></a>相关的文章</h2><p>1、单体安装教程 <a href="https://blog.csdn.net/suoyanming/article/details/88797360">https://blog.csdn.net/suoyanming/article/details/88797360</a></p>
<p>2、开源中国fastdfs主页 <a href="https://www.oschina.net/p/fastdfs">p&#x2F;fastdfs</a></p>
<p>3、github主页（不确定是否是原作者维护） <a href="https://github.com/happyfish100/fastdfs">happyfish100&#x2F;fastdfs</a></p>
<p>4、对fastdfs-nginx-module 实现原理讲的非常清楚 <strong><a href="https://www.cnblogs.com/littleatp/p/4361318.html">https://www.cnblogs.com/littleatp/p/4361318.html</a></strong>   </p>
<h1 id="一、FastDFS"><a href="#一、FastDFS" class="headerlink" title="一、FastDFS"></a><strong>一、FastDFS</strong></h1><p>1、FastDFS是一个开源的轻量级<a href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/1250388">分布式文件系统</a>，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。</p>
<p>2、FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。</p>
<h1 id="二、深入认识FastDFS"><a href="#二、深入认识FastDFS" class="headerlink" title="二、深入认识FastDFS"></a><strong>二、深入认识FastDFS</strong></h1><ul>
<li>任何一个中间件的应用，都必须深入了解该中间件内部各组件的承担的功能角色、运行机制，能深入了解各组件的实现原理更好。这样才能灵活应对实际应用场景、多变的业务需求、生产环境应急等问题，快速实施架构调整。</li>
<li>我们一直在使用FastDFS作为图片文件数据库，部署架构为单体（即：一个tracker、一个storage、一个group）,由于本次用于部署fastdfs的服务器硬盘空间报警，当务之急必须更改fastdfs部署架构，扩展存储。</li>
<li>下面从项目总体情况、tracker 、storage、fastdfs-nginx-module 、group 组件详细说明其功能角色及运行机制</li>
</ul>
<h2 id="1、项目总体情况"><a href="#1、项目总体情况" class="headerlink" title="1、项目总体情况"></a><strong>1、项目总体情况</strong></h2><ul>
<li>​    fastdfs是开源的项目</li>
<li>​    通过github源码可看出，该项目是基于C语言开发的</li>
<li>​    fastdfs是基于操作系统OS的文件管理系统功能之上进行分布式文件管理（Linux、FreeBSD等），通过看文件在硬盘的保存方式也可以得出</li>
<li>​    提供C、Java和PHP API接口</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20190325165732189.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20190325165748158.png" alt="img"></p>
<h2 id="2、tracker跟踪器"><a href="#2、tracker跟踪器" class="headerlink" title="2、tracker跟踪器"></a><strong>2、tracker跟踪器</strong></h2><ul>
<li><p><strong>主要做调度工作， 起负载均衡的作用</strong></p>
</li>
<li><p><strong>在内存中记录集群中所有存储组group和存储服务器storage 的状态信息, 是客户端和数据服务器交互的枢纽</strong></p>
</li>
<li><p><strong>tracker的核心工作内容</strong>：</p>
</li>
</ul>
<p>（1） 记录集群中有多少个group（group1\group2….）</p>
<p>(2) 每个group 分布在那个几个storage上，以及storage所在机器的ip，端口等信息，group之间的同步由tracker 和storage一起完成（后面细讲）</p>
<p>（3）如果同一个group 存在多个storage, 而这些storage又被分布在一台或多台机器上，那么对该group上传或读取文件具体落到那个机器上（即那个storage）？（有点绕）</p>
<p>tracker完美的解决了这个问题，即对分布式部署架构下：多group、多storage的上传和下载做负载均衡策略，通过配置tracker.conf可实现具体负载均衡策略</p>
<p>(4) tracker 可部署多台，多个tracker在服务器内存中记录的信息是一样的，通过nginx对tracker做负载均衡，以提高并发性能及容灾能力</p>
<p>（5）tracker 不去主动读取storage的相关信息，而是由storage主动推送给tracker （<strong>这也是为什么必须先启动tracker的原因</strong>） </p>
<p>（6）以下图片摘自网上 ： 上传文件过程 、下载文件过程，通过图片可以看到，tracker的核心工作是为客户端找到一个storage, client客户端和storage进行上传下载通信。</p>
<p><img src="https://img-blog.csdnimg.cn/201903251658268.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<ul>
<li><h6 id="tracker-conf-在分布式部署架构下，通过tracker负载均衡给client端返回特定storage信息，而负载均衡的策略配置主要在tracker-conf中"><a href="#tracker-conf-在分布式部署架构下，通过tracker负载均衡给client端返回特定storage信息，而负载均衡的策略配置主要在tracker-conf中" class="headerlink" title="tracker.conf (在分布式部署架构下，通过tracker负载均衡给client端返回特定storage信息，而负载均衡的策略配置主要在tracker.conf中)"></a><strong>tracker.conf (在分布式部署架构下，通过tracker负载均衡给client端返回特定storage信息，而负载均衡的策略配置主要在tracker.conf中)</strong></h6><h2 id="核心参数配置说明"><a href="#核心参数配置说明" class="headerlink" title="核心参数配置说明"></a>核心参数配置说明</h2></li>
</ul>
<h3 id="（1）disabled-x3D-false"><a href="#（1）disabled-x3D-false" class="headerlink" title="（1）disabled&#x3D;false"></a>（1）disabled&#x3D;false</h3><p>​     <strong>#配置文件是否失效</strong></p>
<p>​     # is this config file disabled</p>
<p>​    # false for enabled</p>
<p>​    # true for disabled disabled&#x3D;false</p>
<p>​    # is this config file disabled # false for enabled # true for disabled</p>
<h3 id="（2）port-x3D-22122"><a href="#（2）port-x3D-22122" class="headerlink" title="（2）port&#x3D;22122"></a>（2）port&#x3D;22122</h3><p>​      #服务端口</p>
<p>​      # the tracker server port</p>
<h3 id="（3）-base-path-x3D-x2F-data-x2F-fastdfs-x2F-tracker"><a href="#（3）-base-path-x3D-x2F-data-x2F-fastdfs-x2F-tracker" class="headerlink" title="（3） base_path&#x3D;&#x2F;data&#x2F;fastdfs&#x2F;tracker"></a><strong>（3） base_path&#x3D;&#x2F;data&#x2F;fastdfs&#x2F;tracker</strong></h3><p>​       # 存放track 数据及日志文件目录 </p>
<p>​       # the base path to store data and log files</p>
<p>​		work_threads&#x3D;4</p>
<p>​     #时线程数：一般和cpu的个数设为同一个值     </p>
<p>​     # work thread count, should &lt;&#x3D; max_connections</p>
<p>​     # default value is 4</p>
<p>​      # since V2.00</p>
<h3 id="（4）（重要）-store-lookup-x3D-1"><a href="#（4）（重要）-store-lookup-x3D-1" class="headerlink" title="（4）（重要） store_lookup&#x3D;1"></a><strong>（4）（重要） store_lookup&#x3D;1</strong></h3><p><strong>上传文件选择哪个一个group 的 策略：0：轮询；1:指定组 ； 2： 负载均衡，选择剩余存储空间最大的组group 上传文件</strong></p>
<p>​       # the method of selecting group to upload files</p>
<p>​       # 0: round robin</p>
<p>​       # 1: specify group</p>
<p>​      # 2: load balance, select the max free space group to <strong>upload file</strong></p>
<h3 id="（5）（重要）-store-group-x3D-group2"><a href="#（5）（重要）-store-group-x3D-group2" class="headerlink" title="（5）（重要） store_group&#x3D;group2"></a><strong>（5）（重要） store_group&#x3D;group2</strong></h3><p>​    # 当 store_lookup&#x3D;1 时，该配置有效，指定存储的组名</p>
<p>​     # which group to upload file</p>
<p>​     # when store_lookup set to 1, must set store_group to the group name</p>
<h3 id="（6）（重要）-store-server-x3D-0"><a href="#（6）（重要）-store-server-x3D-0" class="headerlink" title="（6）（重要） store_server&#x3D;0"></a><strong>（6）（重要） store_server&#x3D;0</strong></h3><p>​    # 应用场景： 存在多个相同的组，例如group1 ， 在多个storage 服务器上 例如：192.168.0.171 、，</p>
<p>​              当上传文件时优先选择那个storage的策略配置<strong>：~ 0：轮询 ；1：按ip升序排序后选择第一个ip，即最小的那个ip (192.168.0.164)；2：按优先级排列的第一个服务器顺序，数字越小优先级越 高，storage服务器的优先在storage.conf中配置 upload_priority 参数</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20190325165901337.png" alt="img"></p>
<p>  # <strong>which storage server to upload file</strong></p>
<p>​    # 0: round robin (default)</p>
<p>​    # 1: the first server order by ip address</p>
<p>​    # 2: the first server order by priority (the minimal)</p>
<h3 id="（7）（重要）-store-path-x3D-0"><a href="#（7）（重要）-store-path-x3D-0" class="headerlink" title="（7）（重要） store_path&#x3D;0"></a><strong>（7）（重要） store_path&#x3D;0</strong></h3><p>​    # 应用场景：选择具体一个组的那一条存储路径（<strong>一个group有多条存储路径，一般一个服务器有两块大硬盘挂载到了两个路径下，专门用来存放文件</strong>），~0：轮询，2：负载均衡，选择剩余空间最大的路径 </p>
<p>​     （<strong>逻辑~重要</strong>） 通过上面的配置参数确定了3件事的基础上，该配置才会起作用：</p>
<p>​    （1）确定了要存储在那个group上，例如group1；（2）确定上传文件要保存在那一台storage 中的group1，假如是192.168.0.171；（3） 此时如果 192.168.0.171 上的storage server中group1 有两个存储路径，即store_path0,store_path1**,(对应的文件路径即M00,M01)**</p>
<p><img src="https://img-blog.csdnimg.cn/20190325165922761.png" alt="img"></p>
<p> # which path(means disk or mount point) of the storage server to upload file</p>
<p>​    # 0: round robin</p>
<p>   # 2: load balance, select the max free space path to upload file</p>
<h3 id="（8）download-server-x3D-0"><a href="#（8）download-server-x3D-0" class="headerlink" title="（8）download_server&#x3D;0"></a><strong>（8）download_server&#x3D;0</strong></h3><p>​    # 下载文件时存储服务器的选择策略； 应用场景：要下载的文件所在group 存在多个storage 服务器上， ~0：轮询 ；1：当前文件上载到的源存储服务器</p>
<p>​    # which storage server to download file</p>
<p>​    # 0: round robin (default)</p>
<p>​    # 1: the source storage server which the current file uploaded to</p>
<h3 id="（9）reserved-storage-space-x3D-10"><a href="#（9）reserved-storage-space-x3D-10" class="headerlink" title="（9）reserved_storage_space &#x3D; 10%"></a><strong>（9）reserved_storage_space &#x3D; 10%</strong></h3><p>  # 给系统或其他应用程序预留存储空间设置 </p>
<p>  #（<strong>重要</strong>）场景：某一个group所在某一个storage服务器（可能存在多个服务器上）剩余的存储空间小于等于这个阀值时，则文件不能被保存，即使该group的其他storage服务器还有很大的存储空间</p>
<p>  # reserved storage space for system or other applications.</p>
<p>  # if the free(available) space of any stoarge server in</p>
<p>  # a group &lt;&#x3D; reserved_storage_space,</p>
<p>  # no file can be uploaded to this group.</p>
<p>  # bytes unit can be one of follows:</p>
<p>  ### G or g for gigabyte(GB)</p>
<p>  ### M or m for megabyte(MB)</p>
<p>  ### K or k for kilobyte(KB)</p>
<p>  ### no unit for byte(B)</p>
<p>  ### XX.XX% as ratio such as reserved_storage_space &#x3D; 10%</p>
<p><img src="https://img-blog.csdnimg.cn/20190325165954851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/2019032517001063.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20190325170031269.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<h2 id="3、storage-存储服务器"><a href="#3、storage-存储服务器" class="headerlink" title="3、storage 存储服务器"></a><strong>3、storage 存储服务器</strong></h2><ul>
<li><p>storage 定期向tracker发送心跳，报告自己的状态，tracker会将同组的 storage server信息返回给storage （该部分逻辑后面再细讲） </p>
</li>
<li><p>tracker不负责具体的文件上传、下载实现，这些都是有storage完成的</p>
</li>
<li><p>storage保存文件和文件的属性</p>
</li>
<li><p>storage server是基于操作系统的文件管理系统进行文件管理的（上面有提到）</p>
</li>
<li><p>group之间文件同步由storage server 和tacker server一起完成的（该部分逻辑后面再细讲） </p>
</li>
<li><p>storage server的状态（7个）</p>
</li>
<li><p>FDFS_STORAGE_STATUS_INIT :初始化，尚未得到同步已有数据的源服务器</p>
</li>
<li><p>FDFS_STORAGE_STATUS_WAIT_SYNC :等待同步，已得到同步已有数据的源服务器</p>
</li>
<li><p>FDFS_STORAGE_STATUS_SYNCING :同步中</p>
</li>
<li><p>FDFS_STORAGE_STATUS_DELETED :已删除，该服务器从本组中摘除（注：本状态的功能尚未实现）</p>
</li>
<li><p>FDFS_STORAGE_STATUS_OFFLINE :离线</p>
</li>
<li><p>FDFS_STORAGE_STATUS_ONLINE :在线，尚不能提供服务</p>
</li>
<li><p>FDFS_STORAGE_STATUS_ACTIVE :在线，可以提供服务</p>
</li>
</ul>
<h3 id="storage-conf-核心参数配置"><a href="#storage-conf-核心参数配置" class="headerlink" title="storage.conf 核心参数配置"></a>storage.conf 核心参数配置</h3><h3 id="（1）port-x3D-23000"><a href="#（1）port-x3D-23000" class="headerlink" title="（1）port&#x3D;23000"></a>（1）port&#x3D;23000</h3><p>   # storage 服务端口</p>
<p>   # the storage server port</p>
<h3 id="（2）base-path-x3D-x2F-usr-x2F-local-x2F-fastdfs-x2F-fdfs-storage"><a href="#（2）base-path-x3D-x2F-usr-x2F-local-x2F-fastdfs-x2F-fdfs-storage" class="headerlink" title="（2）base_path&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;fdfs_storage"></a>（2）base_path&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;fdfs_storage</h3><p>   #存放storage 服务的数据和日志</p>
<p>   # the base path to store data and log files</p>
<h3 id="（3）store-path0-x3D-x2F-usr-x2F-local-x2F-fastdfs-x2F-fdfs-storage"><a href="#（3）store-path0-x3D-x2F-usr-x2F-local-x2F-fastdfs-x2F-fdfs-storage" class="headerlink" title="（3）store_path0&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;fdfs_storage"></a><strong>（3）store_path0&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;fdfs_storage</strong></h3><p>   # 存储路径配置，可以配置多个，对应的 store_path_count&#x3D;1 参数需要累加</p>
<p>   # store_path#, based 0, if store_path0 not exists, it’s value is base_path</p>
<p>   # the paths must be exist</p>
<p>   #store_path1&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs2</p>
<h3 id="（4）tracker-server-x3D-192-168-0-171-22122"><a href="#（4）tracker-server-x3D-192-168-0-171-22122" class="headerlink" title="（4）tracker_server&#x3D;192.168.0.171:22122"></a><strong>（4）tracker_server&#x3D;192.168.0.171:22122</strong></h3><p>   #tracker 服务的 ip和端口， ip替换为域名也可以，可以配置多个 </p>
<p>   # tracker_server can ocur more than once, and tracker_server format is</p>
<p>   # “host:port”, host can be hostname or ip address</p>
<h3 id="（5）file-distribute-path-mode-x3D-0"><a href="#（5）file-distribute-path-mode-x3D-0" class="headerlink" title="（5）file_distribute_path_mode&#x3D;0"></a><strong>（5）file_distribute_path_mode&#x3D;0</strong></h3><p>  # 分布式存储文件策略： 当storage下有多个存储路径时，该配置起作用 ~ # 0: 轮询   # 1: 根据文件名hash结果随机存储</p>
<p>  # the mode of the files distributed to the data path</p>
<p>  # 0: round robin(default)</p>
<p>  # 1: random, distributted by hash code </p>
<h3 id="（6）upload-priority-x3D-10-（在tracker-conf-中有提到）"><a href="#（6）upload-priority-x3D-10-（在tracker-conf-中有提到）" class="headerlink" title="（6）upload_priority&#x3D;10 （在tracker.conf 中有提到）"></a>（6）upload_priority&#x3D;10 （在tracker.conf 中有提到）</h3><p># 上传文件事，同组内的storage 服务器优先级设置，且当 tracker.conf 中store_server&#x3D; 2时 起作用，值越小，优先级越高。</p>
<p># the priority as a source server for uploading file.</p>
<p># the lower this value, the higher its uploading priority.</p>
<p># default value is 10</p>
<h2 id="4、group"><a href="#4、group" class="headerlink" title="4、group"></a><strong>4、group</strong></h2><ul>
<li>group 分组是fastdfs应对大流量应用系统中处理高并发、高容灾的经典设计，并且group还起到了应用隔离的功能</li>
<li>一个group可以存在多个storage中（在storage中也可以提到）</li>
<li>根据client端的请求分配到不同的group，文件系统具备直接的负载均衡；</li>
<li>group内有storage服务节点坏掉时，需从其他group内恢复数据</li>
</ul>
<h2 id="5、-fastdfs-nginx-module"><a href="#5、-fastdfs-nginx-module" class="headerlink" title="5、 fastdfs-nginx-module"></a><strong>5、 fastdfs-nginx-module</strong></h2><ul>
<li><p>fastdfs 中storage、tracker 均提供的http服务，可以直接下载文件，但考虑到性能及负载实现难易度的问题，一般都用web服务器来下载文件，例如nginx、apache</p>
</li>
<li><p>fastdfs-nginx-module 就是fastdfs基于ngnix实现文件http传输的组件，以nginx module的方式添加到nginx 程序中</p>
</li>
<li><p>每个storage 均需安装 fastdfs-nginx-module 、Nginx ，当前storage找不到文件时，向<strong>源storage</strong>主机发起redirect重定向或proxy转发代理动作</p>
</li>
<li><p>fastdfs-nginx-module 安装后目录结构如下图</p>
<p>说明及图片 摘自：<a href="https://www.cnblogs.com/littleatp/p/4361318.html">https://www.cnblogs.com/littleatp/p/4361318.html</a></p>
</li>
</ul>
<p>​     (1)ngx_http_fastdfs_module.c  ~ nginx 模块接口实现文件，用于向nginx 接入fastdfs-module核心模块逻辑</p>
<p>​    （2）common.c  ~ fastdfs-module核心模块，实现了初始化、文件下载的主要逻辑</p>
<p>​    （3）config   ~ 编译模块所用的配置，里面定义了一些重要的常量，调用fastdfs基础组件功能，以及扩展配置文件路径、文件下载chunk大小</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">（4）mod_fastdfs.conf  ~扩展配置文件的demo，一般会将该文件拷贝到config指定的目录下 例如：/etc/fdfs</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20190325170102450.png" alt="img"></p>
<ul>
<li>初始化： nginx启动时，  fastdfs-nginx-module 要完成初始化如下图 ，我们一般在mod_fastdfs.conf配置参数，如下图</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20190325170132699.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/2019032517015280.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20190325170205559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><strong>（重要）： fastdfs-nginx-module 初始化的过程要加载mod_fastdfs.conf参数，如果本机器下存在多个storage,且有多个group（group1、group2）,则 mod_fastdfs.conf 配置需做如下变动</strong></p>
<h3 id="-1"><a href="#-1" class="headerlink" title></a></h3><p><strong>（1）组名：group_name&#x3D;group1&#x2F;group2   多个用&#x2F;区分开</strong></p>
<p><strong>（2）设置组个数：group_count &#x3D; 4</strong></p>
<p><strong>（4）设置各group信息：</strong></p>
<p><strong>[group1]</strong></p>
<p><strong>group_name&#x3D;group1</strong></p>
<p><strong>storage_server_port&#x3D;23000</strong></p>
<p><strong>store_path_count&#x3D;1</strong></p>
<p><strong>store_path0&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;storage</strong></p>
<p><strong>[group2]</strong></p>
<p><strong>group_name&#x3D;group2</strong></p>
<p><em><strong>*storage_server_port&#x3D;23010*</strong></em></p>
<p><strong>store_path_count&#x3D;1</strong></p>
<p><strong>store_path0&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs&#x2F;storage</strong></p>
<h3 id="（重要）通过nginx-从fastdfs下载文件，详细说明可参考https-www-cnblogs-com-littleatp-p-4361318-html"><a href="#（重要）通过nginx-从fastdfs下载文件，详细说明可参考https-www-cnblogs-com-littleatp-p-4361318-html" class="headerlink" title="（重要）通过nginx 从fastdfs下载文件，详细说明可参考https://www.cnblogs.com/littleatp/p/4361318.html"></a><strong>（重要）通过nginx 从fastdfs下载文件，详细说明可参考<a href="https://www.cnblogs.com/littleatp/p/4361318.html">https://www.cnblogs.com/littleatp/p/4361318.html</a></strong></h3><p><img src="https://img-blog.csdnimg.cn/20190325170230230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<h3 id="6、各组件运行机制总结-重要"><a href="#6、各组件运行机制总结-重要" class="headerlink" title="6、各组件运行机制总结**(重要)**"></a>6、各组件运行机制总结**(重要)**</h3><ul>
<li>​    一个group 对应多个 storage (1:N)</li>
<li>​    一个storage对应一个group  (1:1)</li>
<li>​    一个tracker对应多个storage(1:N)</li>
<li>​    一个storage对应多个tracker(1:N) , tracker 和storage的关系是多对多（N:M）</li>
<li>​    一个storage下有多个存储路径 store_path(1:N)</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20190325170336507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<h3 id="7、部署架构汇总"><a href="#7、部署架构汇总" class="headerlink" title="7、部署架构汇总"></a><strong>7、部署架构汇总</strong></h3><h3 id="1）单体部署-单group-单storage-单tracker"><a href="#1）单体部署-单group-单storage-单tracker" class="headerlink" title="1）单体部署: 单group\单storage\单tracker"></a>1）单体部署: 单group\单storage\单tracker</h3><p><img src="https://img-blog.csdnimg.cn/20190325170402345.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<h3 id="2）单服务器多storage部署-（在实际生产环境中没有意义）"><a href="#2）单服务器多storage部署-（在实际生产环境中没有意义）" class="headerlink" title="2）单服务器多storage部署*（在实际生产环境中没有意义）*"></a><strong>2）单服务器多storage部署*<em>（在实际生产环境中没有意义）*</em></strong></h3><h3 id="多group-多storage-单tracker"><a href="#多group-多storage-单tracker" class="headerlink" title="多group\多storage\单tracker"></a><strong>多group\多storage\单tracker</strong></h3><p><img src="https://img-blog.csdnimg.cn/20190325170430665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<h3 id="3）多服务器多group且group不互备，单tracker（我们项目本次硬盘扩展部署架构）"><a href="#3）多服务器多group且group不互备，单tracker（我们项目本次硬盘扩展部署架构）" class="headerlink" title="3）多服务器多group且group不互备，单tracker（我们项目本次硬盘扩展部署架构）"></a>3）多服务器多group且group不互备，单tracker<strong>（我们项目本次硬盘扩展部署架构）</strong></h3><p>   由于目前服务器资源紧缺暂不做group互备，后面需要做group互备</p>
<p><img src="https://img-blog.csdnimg.cn/20190325170500305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
<ul>
<li><h3 id="部署步骤及参数配置"><a href="#部署步骤及参数配置" class="headerlink" title="部署步骤及参数配置"></a><strong>部署步骤及参数配置</strong></h3><p>（1）两台服务器分别为192.168.0.171、192.168.0.164， 171服务器担任的功能角色更多一些: 文件下载请求 nginx同一入口（分发到storage1、stroage2）、tracker server  、storage1 - group0（fastdfs-nginx-module）。</p>
<p>164服务器主要负责storage1 -group2 的存储、下载功能，没有tacker server，直接连接171服务器的tracker,需要安装nginx 、 fastdfs-nginx-module</p>
</li>
</ul>
<p>（2) 171、 164 都需要安装 fastdfs 、fastdfs-nginx-module、 nginx 安装步骤 与 知识库文档  <a href="http://192.168.0.109:8090/pages/viewpage.action?pageId=1606067">Centos7 上安装 FastDFS</a> 一致 ，但注意一点164服务器不用启动及配置tracker</p>
<p>（ 3） 171 tracker.conf 配置</p>
<p>   <strong>171 tracker.conf 核心参数配置说明，其他参数见附件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># is this config file disabled</span><br><span class="line"></span><br><span class="line"># false for enabled</span><br><span class="line"></span><br><span class="line"># true for disabled</span><br><span class="line"></span><br><span class="line">disabled=false</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the tracker server port</span><br><span class="line"></span><br><span class="line">port=22122</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the base path to store data and log files</span><br><span class="line"></span><br><span class="line">base_path=/data/fastdfs/tracker</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the method of selecting group to upload files</span><br><span class="line"></span><br><span class="line"># 0: round robin</span><br><span class="line"></span><br><span class="line"># 1: specify group</span><br><span class="line"></span><br><span class="line"># 2: load balance, select the max free space group to upload file</span><br><span class="line"></span><br><span class="line">store_lookup=1</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># which group to upload file</span><br><span class="line"></span><br><span class="line"># when store_lookup set to 1, must set store_group to the group name</span><br><span class="line"></span><br><span class="line">store_group=group2</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># which storage server to upload file</span><br><span class="line"></span><br><span class="line"># 0: round robin (default)</span><br><span class="line"></span><br><span class="line"># 1: the first server order by ip address</span><br><span class="line"></span><br><span class="line"># 2: the first server order by priority (the minimal)</span><br><span class="line"></span><br><span class="line">store_server=0</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># which path(means disk or mount point) of the storage server to upload file</span><br><span class="line"></span><br><span class="line"># 0: round robin</span><br><span class="line"></span><br><span class="line"># 2: load balance, select the max free space path to upload file</span><br><span class="line"></span><br><span class="line">store_path=0</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># which storage server to download file</span><br><span class="line"></span><br><span class="line"># 0: round robin (default)</span><br><span class="line"></span><br><span class="line"># 1: the source storage server which the current file uploaded to</span><br><span class="line"></span><br><span class="line">download_server=0</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># reserved storage space for system or other applications.</span><br><span class="line"></span><br><span class="line"># if the free(available) space of any stoarge server in</span><br><span class="line"></span><br><span class="line"># a group &lt;= reserved_storage_space,</span><br><span class="line"></span><br><span class="line"># no file can be uploaded to this group.</span><br><span class="line"></span><br><span class="line"># bytes unit can be one of follows:</span><br><span class="line"></span><br><span class="line">### G or g for gigabyte(GB)</span><br><span class="line"></span><br><span class="line">### M or m for megabyte(MB)</span><br><span class="line"></span><br><span class="line">### K or k for kilobyte(KB)</span><br><span class="line"></span><br><span class="line">### no unit for byte(B)</span><br><span class="line"></span><br><span class="line">### XX.XX% as ratio such as reserved_storage_space = 10%</span><br><span class="line"></span><br><span class="line">reserved_storage_space = 10%</span><br></pre></td></tr></table></figure>



<h3 id="（4）171-storage-conf-配置"><a href="#（4）171-storage-conf-配置" class="headerlink" title="（4）171 storage.conf 配置"></a>（4）171 storage.conf 配置</h3><p><strong>171 storage 核心参数配置，其他参数见附件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># the name of the group this storage server belongs to</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># comment or remove this item for fetching from tracker server,</span><br><span class="line"></span><br><span class="line"># in this case, use_storage_id must set to true in tracker.conf,</span><br><span class="line"></span><br><span class="line"># and storage_ids.conf must be configed correctly.</span><br><span class="line"></span><br><span class="line">group_name=group0</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the storage server port</span><br><span class="line"></span><br><span class="line">port=23000</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the base path to store data and log files</span><br><span class="line"></span><br><span class="line">base_path=/data/fastdfs/storage</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># path(disk or mount point) count, default value is 1</span><br><span class="line"></span><br><span class="line">store_path_count=1</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># store_path#, based 0, if store_path0 not exists, it&#x27;s value is base_path</span><br><span class="line"></span><br><span class="line"># the paths must be exist</span><br><span class="line"></span><br><span class="line">store_path0=/data/fastdfs/storage</span><br><span class="line"></span><br><span class="line">#store_path1=/home/yuqing/fastdfs2</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># tracker_server can ocur more than once, and tracker_server format is</span><br><span class="line"></span><br><span class="line">#  &quot;host:port&quot;, host can be hostname or ip address</span><br><span class="line"></span><br><span class="line">tracker_server=192.168.0.171:22122</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the priority as a source server for uploading file.</span><br><span class="line"></span><br><span class="line"># the lower this value, the higher its uploading priority.</span><br><span class="line"></span><br><span class="line"># default value is 10</span><br><span class="line"></span><br><span class="line">upload_priority=10</span><br></pre></td></tr></table></figure>

<h3 id="（5）171-fastdfs-nginx-module-配置参数-（mod-fastdfs-conf）"><a href="#（5）171-fastdfs-nginx-module-配置参数-（mod-fastdfs-conf）" class="headerlink" title="（5）171 fastdfs_nginx_module 配置参数 （mod_fastdfs.conf）"></a>（5）171 fastdfs_nginx_module 配置参数 （mod_fastdfs.conf）</h3><p><strong>171 mod_fastdfs.conf 核心参数配置，其他参数见附件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># the base path to store log files</span><br><span class="line"></span><br><span class="line">base_path=/data/fastdfs/storage</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># if load FastDFS parameters from tracker server # since V1.12 # default value is false</span><br><span class="line"></span><br><span class="line">load_fdfs_parameters_from_tracker=true</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># FastDFS tracker_server can ocur more than once, and tracker_server format is</span><br><span class="line"></span><br><span class="line">#  &quot;host:port&quot;, host can be hostname or ip address</span><br><span class="line"></span><br><span class="line"># valid only when load_fdfs_parameters_from_tracker is true</span><br><span class="line"></span><br><span class="line">tracker_server=192.168.0.171:22122</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the port of the local storage server # the default value is 23000</span><br><span class="line"></span><br><span class="line">storage_server_port=23000</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the group name of the local storage server group_name=group0</span><br><span class="line"></span><br><span class="line"># if the url / uri including the group name # set to false when uri like /M00/00/00/xxx # set to true when uri like $&#123;group_name&#125;/M00/00/00/xxx, such as group1/M00/xxx # default value is false</span><br><span class="line"></span><br><span class="line">url_have_group_name = true</span><br><span class="line"></span><br><span class="line"># path(disk or mount point) count, default value is 1 # must same as storage.conf store_path_count=1</span><br><span class="line"></span><br><span class="line"># store_path#, based 0, if store_path0 not exists, it&#x27;s value is base_path # the paths must be exist # must same as storage.conf</span><br><span class="line"></span><br><span class="line">store_path0=/data/fastdfs/storage</span><br><span class="line"></span><br><span class="line">#store_path1=/home/yuqing/fastdfs1</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># set the group count # set to none zero to support multi-group</span><br><span class="line"></span><br><span class="line"># set to 0  for single group only</span><br><span class="line"></span><br><span class="line"># groups settings section as [group1], [group2], ..., [groupN]</span><br><span class="line"></span><br><span class="line"># default value is 0 # since v1.14</span><br><span class="line"></span><br><span class="line">group_count = 0</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># group settings for group #1 # since v1.14</span><br><span class="line"></span><br><span class="line"># when support multi-group, uncomment following section</span><br><span class="line"></span><br><span class="line">#[group1] #group_name=group1 #storage_server_port=23000</span><br><span class="line"></span><br><span class="line">#store_path_count=2</span><br><span class="line"></span><br><span class="line">#store_path0=/home/yuqing/fastdfs</span><br><span class="line"></span><br><span class="line">#store_path1=/home/yuqing/fastdfs1</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># group settings for group #2</span><br><span class="line"></span><br><span class="line"># since v1.14</span><br><span class="line"></span><br><span class="line"># when support multi-group, uncomment following section as neccessary</span><br><span class="line"></span><br><span class="line">#[group2] #group_name=group2</span><br><span class="line"></span><br><span class="line">#storage_server_port=23000</span><br><span class="line"></span><br><span class="line">#store_path_count=1</span><br><span class="line"></span><br><span class="line">#store_path0=/home/yuqing/fastdfs</span><br></pre></td></tr></table></figure>

<h3 id="（6）171-nginx-参数配置-nginx-conf"><a href="#（6）171-nginx-参数配置-nginx-conf" class="headerlink" title="（6）171 nginx 参数配置 nginx.conf"></a>（6）171 nginx 参数配置 nginx.conf</h3><p><strong>171 nginx.conf 核心参数配置，详见附件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">events &#123;</span><br><span class="line"></span><br><span class="line">    worker_connections  1024;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;    </span><br><span class="line"></span><br><span class="line">    include       mime.types;    </span><br><span class="line"></span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    sendfile        on;    </span><br><span class="line"></span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">        #keepalive_timeout  0;    </span><br><span class="line"></span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">        #gzip  on;</span><br><span class="line"></span><br><span class="line">    # 192.168.0.164 storage group2 </span><br><span class="line"></span><br><span class="line">    upstream fdfs_group2_164 &#123; </span><br><span class="line"></span><br><span class="line">        server 192.168.0.164:8288 weight=1 max_fails=2 fail_timeout=30s; </span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    server &#123;        </span><br><span class="line"></span><br><span class="line">        listen       8070;        </span><br><span class="line"></span><br><span class="line">        server_name  localhost,192.168.0.171;</span><br><span class="line"></span><br><span class="line">            #charset koi8-r;</span><br><span class="line"></span><br><span class="line">            #access_log  logs/host.access.log  main;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">            location / &#123;            </span><br><span class="line"></span><br><span class="line">            root   html;            </span><br><span class="line"></span><br><span class="line">            max_ranges 1;            </span><br><span class="line"></span><br><span class="line">            index  index.html index.htm;        </span><br><span class="line"></span><br><span class="line">        &#125; </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        location /group0/M00&#123;            </span><br><span class="line"></span><br><span class="line">            root /data/fastdfs/storage/data;            </span><br><span class="line"></span><br><span class="line">            ngx_fastdfs_module;            </span><br><span class="line"></span><br><span class="line">            if ($request_method = &#x27;OPTIONS&#x27;) &#123;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;Range&#x27;;               </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Content-Type&#x27; &#x27;text/plain charset=UTF-8&#x27;;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Content-Length&#x27; 0;                </span><br><span class="line"></span><br><span class="line">                return 204;              &#125;            </span><br><span class="line"></span><br><span class="line">            if ($request_method = &#x27;POST&#x27;) &#123;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;Range&#x27;;              &#125;            </span><br><span class="line"></span><br><span class="line">            if ($request_method = &#x27;GET&#x27;) &#123;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;Range&#x27;;                </span><br><span class="line"></span><br><span class="line">                add_header &#x27;Access-Control-Expose-Headers&#x27; &#x27;Accept-Ranges, Content-Encoding, Content-Length, Content-Range&#x27;;              &#125;      </span><br><span class="line"></span><br><span class="line">            if ($arg_attname ~* \.(doc|docx|txt|pdf|zip|rar|txt|jpg|png|gif|bmp)$) &#123;</span><br><span class="line"></span><br><span class="line">                add_header &quot;Content-Disposition&quot; &quot;attachment;filename=$arg_attname&quot;;</span><br><span class="line"></span><br><span class="line">                    &#125;        </span><br><span class="line"></span><br><span class="line">            &#125; </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        location ~* /group2/(M00|M01) &#123;  </span><br><span class="line"></span><br><span class="line">                proxy_next_upstream http_502 http_504 error timeout invalid_header; </span><br><span class="line"></span><br><span class="line">                proxy_pass http://fdfs_group2_164;</span><br><span class="line"></span><br><span class="line">                expires 30d; </span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">         error_page   500 502 503 504  /50x.html;        </span><br><span class="line"></span><br><span class="line">        location = /50x.html &#123;             root   html;         &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="（7）164-storage参数配置"><a href="#（7）164-storage参数配置" class="headerlink" title="（7）164 storage参数配置"></a>（7）164 storage参数配置</h3><p><strong>164 storage.con 核心参数配置，其他参数见附件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># the name of the group this storage server belongs to # # comment or remove this item for fetching from tracker server, # in this case, use_storage_id must set to true in tracker.conf,</span><br><span class="line"></span><br><span class="line"># and storage_ids.conf must be configed correctly.</span><br><span class="line"></span><br><span class="line">group_name=group2</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the storage server</span><br><span class="line"></span><br><span class="line"> port port=23000</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the base path to store data and log files</span><br><span class="line"></span><br><span class="line">base_path=/usr/local/fastdfs/fdfs_storage</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># path(disk or mount point) count, default value is 1 store_path_count=1</span><br><span class="line"></span><br><span class="line"># store_path#, based 0, if store_path0 not exists, it&#x27;s value is base_path # the paths must be exist</span><br><span class="line"></span><br><span class="line">store_path0=/usr/local/fastdfs/fdfs_storage</span><br><span class="line"></span><br><span class="line">#store_path1=/home/yuqing/fastdfs2</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># tracker_server can ocur more than once, and tracker_server format is #  &quot;host:port&quot;, host can be hostname or ip address</span><br><span class="line"></span><br><span class="line">tracker_server=192.168.0.171:22122</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the priority as a source server for uploading file. # the lower this value, the higher its uploading priority. # default value is 10</span><br><span class="line"></span><br><span class="line">upload_priority=10</span><br></pre></td></tr></table></figure>

<h3 id="（8）-164-fastdfs-nginx-module-参数配置-（mod-fastdfs-conf）"><a href="#（8）-164-fastdfs-nginx-module-参数配置-（mod-fastdfs-conf）" class="headerlink" title="（8） 164 fastdfs_nginx_module 参数配置 （mod_fastdfs.conf）"></a>（8） 164 fastdfs_nginx_module 参数配置 （mod_fastdfs.conf）</h3><p><strong>164 mod_fastdfs.conf 核心参数配置，其他参数见附件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># the base path to store log files</span><br><span class="line"></span><br><span class="line">base_path=/usr/local/fastdfs/</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># if load FastDFS parameters from tracker server # since V1.12 # default value is false</span><br><span class="line"></span><br><span class="line">load_fdfs_parameters_from_tracker=true</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># FastDFS tracker_server can ocur more than once, and tracker_server format is #  &quot;host:port&quot;, host can be hostname or ip address # valid only when load_fdfs_parameters_from_tracker is true tracker_server=192.168.0.171:22122</span><br><span class="line"></span><br><span class="line"># the port of the local storage server # the default value is 23000</span><br><span class="line"></span><br><span class="line">storage_server_port=23000</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># the group name of the local storage server</span><br><span class="line"></span><br><span class="line">group_name=group2</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># if the url / uri including the group name</span><br><span class="line"></span><br><span class="line"># set to false when uri like /M00/00/00/xxx</span><br><span class="line"></span><br><span class="line"># set to true when uri like $&#123;group_name&#125;/M00/00/00/xxx, such as group1/M00/xxx</span><br><span class="line"></span><br><span class="line"># default value is false</span><br><span class="line"></span><br><span class="line">url_have_group_name = true</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># path(disk or mount point) count, default value is 1 # must same as storage.conf</span><br><span class="line"></span><br><span class="line">store_path_count=1</span><br><span class="line"></span><br><span class="line"># store_path#, based 0, if store_path0 not exists, it&#x27;s value is base_path</span><br><span class="line"></span><br><span class="line"># the paths must be exist # must same as storage.conf</span><br><span class="line"></span><br><span class="line">store_path0=/usr/local/fastdfs/fdfs_storage</span><br><span class="line"></span><br><span class="line">#store_path1=/home/yuqing/fastdfs1</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># set the group count # set to none zero to support multi-group</span><br><span class="line"></span><br><span class="line"># set to 0  for single group only</span><br><span class="line"></span><br><span class="line"># groups settings section as [group1], [group2], ..., [groupN]</span><br><span class="line"></span><br><span class="line"># default value is 0 # since v1.14</span><br><span class="line"></span><br><span class="line">group_count = 0</span><br></pre></td></tr></table></figure>

<h3 id="（9）164-nginx参数配置，nginx-conf"><a href="#（9）164-nginx参数配置，nginx-conf" class="headerlink" title="（9）164 nginx参数配置，nginx.conf"></a>（9）164 nginx参数配置，nginx.conf</h3><p><strong>164 nginx.conf 参数配置，详见附件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user  www  www;</span><br><span class="line"></span><br><span class="line">worker_processes  12;</span><br><span class="line"></span><br><span class="line">error_log  /var/log/nginx/error.log;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line"></span><br><span class="line">    worker_connections  1024;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line"></span><br><span class="line">    include       mime.types;</span><br><span class="line"></span><br><span class="line">     default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">       client_max_body_size 10m;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line"></span><br><span class="line">        listen       8288;</span><br><span class="line"></span><br><span class="line">        server_name  192.168.0.164,localhost;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">        location /group2/M00/&#123;</span><br><span class="line"></span><br><span class="line">            root /usr/local/fastdfs/fdfs_storage/data;</span><br><span class="line"></span><br><span class="line">             ngx_fastdfs_module;</span><br><span class="line"></span><br><span class="line">        if ($request_method = &#x27;OPTIONS&#x27;) &#123;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;Range&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Content-Type&#x27; &#x27;text/plain charset=UTF-8&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Content-Length&#x27; 0;</span><br><span class="line"></span><br><span class="line">                 return 204;</span><br><span class="line"></span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line">             if ($request_method = &#x27;POST&#x27;) &#123;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;Range&#x27;;</span><br><span class="line"></span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line">             if ($request_method = &#x27;GET&#x27;) &#123;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Methods&#x27; &#x27;GET, POST, OPTIONS&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Allow-Headers&#x27; &#x27;Range&#x27;;</span><br><span class="line"></span><br><span class="line">                 add_header &#x27;Access-Control-Expose-Headers&#x27; &#x27;Accept-Ranges, Content-Encoding, Content-Length, Content-Range&#x27;;</span><br><span class="line"></span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                if ($arg_attname ~* \.(doc|docx|txt|pdf|zip|rar|txt|jpg|png|gif|bmp)$) &#123;</span><br><span class="line"></span><br><span class="line">                 add_header &quot;Content-Disposition&quot; &quot;attachment;filename=$arg_attname&quot;;</span><br><span class="line"></span><br><span class="line">                 &#125;</span><br><span class="line"></span><br><span class="line">         &#125;  </span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4）真正分布式集群部署：多服务器多group且group间互备，多tracker"><a href="#4）真正分布式集群部署：多服务器多group且group间互备，多tracker" class="headerlink" title="4）真正分布式集群部署：多服务器多group且group间互备，多tracker"></a><strong>4）真正分布式集群部署：多服务器多group且group间互备，多tracker</strong></h3><p><img src="https://img-blog.csdnimg.cn/20190325170807597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1b3lhbm1pbmc=,size_16,color_FFFFFF,t_70" alt="img"></p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
      <tags>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>shiro使用</title>
    <url>/2021/07/12/shiro%E4%BD%BF%E7%94%A8-shiro%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="shiro"><a href="#shiro" class="headerlink" title="shiro"></a>shiro</h1><h2 id="一、shiro是什么"><a href="#一、shiro是什么" class="headerlink" title="一、shiro是什么?"></a>一、shiro是什么?</h2><p>​	 Shiro是Apache下的一个开源项目。shiro属于轻量级框架，相对于SpringSecurity简单的多，也没有SpringSecurity那么复杂 。</p>
<h2 id="二、主要功能"><a href="#二、主要功能" class="headerlink" title="二、主要功能"></a>二、主要功能</h2><h3 id="shiro主要有三大功能模块："><a href="#shiro主要有三大功能模块：" class="headerlink" title="shiro主要有三大功能模块："></a>shiro主要有三大功能模块：</h3><h6 id="1-Subject：主体，一般指用户。"><a href="#1-Subject：主体，一般指用户。" class="headerlink" title="1. Subject：主体，一般指用户。"></a>1. Subject：主体，一般指用户。</h6><h6 id="2-SecurityManager：安全管理器，管理所有Subject，可以配合内部安全组件。-类似于SpringMVC中的DispatcherServlet"><a href="#2-SecurityManager：安全管理器，管理所有Subject，可以配合内部安全组件。-类似于SpringMVC中的DispatcherServlet" class="headerlink" title="2. SecurityManager：安全管理器，管理所有Subject，可以配合内部安全组件。(类似于SpringMVC中的DispatcherServlet)"></a>2. SecurityManager：安全管理器，管理所有Subject，可以配合内部安全组件。(类似于SpringMVC中的DispatcherServlet)</h6><h6 id="3-Realms：用于进行权限信息的验证，一般需要自己实现。"><a href="#3-Realms：用于进行权限信息的验证，一般需要自己实现。" class="headerlink" title="3. Realms：用于进行权限信息的验证，一般需要自己实现。"></a>3. Realms：用于进行权限信息的验证，一般需要自己实现。</h6><h3 id="细分功能"><a href="#细分功能" class="headerlink" title="细分功能"></a>细分功能</h3><h6 id="1-Authentication：身份认证-x2F-登录-账号密码验证-。"><a href="#1-Authentication：身份认证-x2F-登录-账号密码验证-。" class="headerlink" title="1. Authentication：身份认证&#x2F;登录(账号密码验证)。"></a>1. Authentication：身份认证&#x2F;登录(账号密码验证)。</h6><h6 id="2-Authorization：授权，即角色或者权限验证。"><a href="#2-Authorization：授权，即角色或者权限验证。" class="headerlink" title="2. Authorization：授权，即角色或者权限验证。"></a>2. Authorization：授权，即角色或者权限验证。</h6><h6 id="3-Session-Manager：会话管理，用户登录后的session相关管理。"><a href="#3-Session-Manager：会话管理，用户登录后的session相关管理。" class="headerlink" title="3. Session Manager：会话管理，用户登录后的session相关管理。"></a>3. Session Manager：会话管理，用户登录后的session相关管理。</h6><h6 id="4-Cryptography：加密，密码加密等。"><a href="#4-Cryptography：加密，密码加密等。" class="headerlink" title="4. Cryptography：加密，密码加密等。"></a>4. Cryptography：加密，密码加密等。</h6><h6 id="5-Web-Support：Web支持，集成Web环境。"><a href="#5-Web-Support：Web支持，集成Web环境。" class="headerlink" title="5. Web Support：Web支持，集成Web环境。"></a>5. Web Support：Web支持，集成Web环境。</h6><h6 id="6-Caching：缓存，用户信息、角色、权限等缓存到如redis等缓存中。"><a href="#6-Caching：缓存，用户信息、角色、权限等缓存到如redis等缓存中。" class="headerlink" title="6. Caching：缓存，用户信息、角色、权限等缓存到如redis等缓存中。"></a>6. Caching：缓存，用户信息、角色、权限等缓存到如redis等缓存中。</h6><h6 id="7-Concurrency：多线程并发验证，在一个线程中开启另一个线程，可以把权限自动传播过去。"><a href="#7-Concurrency：多线程并发验证，在一个线程中开启另一个线程，可以把权限自动传播过去。" class="headerlink" title="7. Concurrency：多线程并发验证，在一个线程中开启另一个线程，可以把权限自动传播过去。"></a>7. Concurrency：多线程并发验证，在一个线程中开启另一个线程，可以把权限自动传播过去。</h6><h6 id="8-Testing：测试支持；"><a href="#8-Testing：测试支持；" class="headerlink" title="8. Testing：测试支持；"></a>8. Testing：测试支持；</h6><h6 id="9-Run-As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问。"><a href="#9-Run-As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问。" class="headerlink" title="9. Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问。"></a>9. Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问。</h6><h6 id="10-Remember-Me：记住我，登录后，下次再来的话不用登录了"><a href="#10-Remember-Me：记住我，登录后，下次再来的话不用登录了" class="headerlink" title="10. Remember Me：记住我，登录后，下次再来的话不用登录了"></a>10. Remember Me：记住我，登录后，下次再来的话不用登录了</h6><h3 id="三、具体实现"><a href="#三、具体实现" class="headerlink" title="三、具体实现"></a>三、具体实现</h3><h3 id="1、项目目录"><a href="#1、项目目录" class="headerlink" title="1、项目目录"></a>1、项目目录</h3><p><img src="/2021/07/12/shiro%E4%BD%BF%E7%94%A8-shiro%E4%BD%BF%E7%94%A8/1604471130107-03fd3901e8644ec985962a56e1d4f28d.png" alt="1604471130107.png"></p>
<h3 id="pom-xml依赖文件"><a href="#pom-xml依赖文件" class="headerlink" title="pom.xml依赖文件"></a>pom.xml依赖文件</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shiro_demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.2.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spring.shiro.version</span>&gt;</span>1.6.0<span class="tag">&lt;/<span class="name">spring.shiro.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- shiro --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shiro<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shiro-spring<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spring.shiro.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--页面模板依赖--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-thymeleaf<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--热部署依赖--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-devtools<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="Permissions权限实体类"><a href="#Permissions权限实体类" class="headerlink" title="Permissions权限实体类"></a>Permissions权限实体类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bean;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Permissions</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">    <span class="keyword">private</span> String permissionsName;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="Role角色实体"><a href="#Role角色实体" class="headerlink" title="Role角色实体"></a>Role角色实体</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bean;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Role</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">    <span class="keyword">private</span> String roleName;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 角色对应权限集合</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Set&lt;Permissions&gt; permissions;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="User实体"><a href="#User实体" class="headerlink" title="User实体"></a>User实体</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bean;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">    <span class="keyword">private</span> String userName;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Set&lt;Role&gt; roles;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="业务层，模拟数据库"><a href="#业务层，模拟数据库" class="headerlink" title="业务层，模拟数据库"></a>业务层，模拟数据库</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.example.bean.Permissions;</span><br><span class="line"><span class="keyword">import</span> org.example.bean.Role;</span><br><span class="line"><span class="keyword">import</span> org.example.bean.User;</span><br><span class="line"><span class="keyword">import</span> org.example.service.LoginService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LoginServiceImpl</span> <span class="keyword">implements</span> <span class="title class_">LoginService</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> User <span class="title function_">getUserByName</span><span class="params">(String getMapByName)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> getMapByName(getMapByName);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模拟数据库查询</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> userName 用户名</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> User</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> User <span class="title function_">getMapByName</span><span class="params">(String userName)</span> &#123;</span><br><span class="line">        <span class="type">Permissions</span> <span class="variable">permissions1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Permissions</span>(<span class="string">&quot;1&quot;</span>, <span class="string">&quot;query&quot;</span>);</span><br><span class="line">        <span class="type">Permissions</span> <span class="variable">permissions2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Permissions</span>(<span class="string">&quot;2&quot;</span>, <span class="string">&quot;add&quot;</span>);</span><br><span class="line">        Set&lt;Permissions&gt; permissionsSet = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(<span class="number">2</span>);</span><br><span class="line">        permissionsSet.add(permissions1);</span><br><span class="line">        permissionsSet.add(permissions2);</span><br><span class="line">        <span class="type">Role</span> <span class="variable">role</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Role</span>(<span class="string">&quot;1&quot;</span>, <span class="string">&quot;admin&quot;</span>, permissionsSet);</span><br><span class="line">        Set&lt;Role&gt; roleSet = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        roleSet.add(role);</span><br><span class="line">        <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>(<span class="string">&quot;1&quot;</span>, <span class="string">&quot;wsl&quot;</span>, <span class="string">&quot;123456&quot;</span>, roleSet);</span><br><span class="line">        Map&lt;String, User&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(<span class="number">1</span>);</span><br><span class="line">        map.put(user.getUserName(), user);</span><br><span class="line"></span><br><span class="line">        Set&lt;Permissions&gt; permissionsSet1 = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(<span class="number">2</span>);</span><br><span class="line">        permissionsSet1.add(permissions1);</span><br><span class="line">        <span class="type">Role</span> <span class="variable">role1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Role</span>(<span class="string">&quot;2&quot;</span>, <span class="string">&quot;user&quot;</span>, permissionsSet1);</span><br><span class="line">        Set&lt;Role&gt; roleSet1 = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        roleSet1.add(role1);</span><br><span class="line">        <span class="type">User</span> <span class="variable">user1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>(<span class="string">&quot;2&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;123456&quot;</span>, roleSet1);</span><br><span class="line">        map.put(user1.getUserName(), user1);</span><br><span class="line">        <span class="keyword">return</span> map.get(userName);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="CustomRealm用户权限配置类"><a href="#CustomRealm用户权限配置类" class="headerlink" title="CustomRealm用户权限配置类"></a>CustomRealm用户权限配置类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.shiro;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authc.AuthenticationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authc.AuthenticationInfo;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authc.AuthenticationToken;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authc.SimpleAuthenticationInfo;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authz.AuthorizationInfo;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authz.SimpleAuthorizationInfo;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.realm.AuthorizingRealm;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.subject.PrincipalCollection;</span><br><span class="line"><span class="keyword">import</span> org.example.bean.User;</span><br><span class="line"><span class="keyword">import</span> org.example.service.LoginService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 权限控制以及权限认证</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomRealm</span> <span class="keyword">extends</span> <span class="title class_">AuthorizingRealm</span> &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> LoginService loginService;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 权限配置类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> principalCollection</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> AuthorizationInfo <span class="title function_">doGetAuthorizationInfo</span><span class="params">(PrincipalCollection principalCollection)</span> &#123;</span><br><span class="line">        <span class="comment">//获取当前登录用户名</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">userName</span> <span class="operator">=</span> principalCollection.getPrimaryPrincipal().toString();</span><br><span class="line">        <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> loginService.getUserByName(userName);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//添加角色和权限</span></span><br><span class="line">        <span class="type">SimpleAuthorizationInfo</span> <span class="variable">simpleAuthorizationInfo</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleAuthorizationInfo</span>();</span><br><span class="line">        user.getRoles().forEach(role -&gt; &#123;</span><br><span class="line">            simpleAuthorizationInfo.addRole(role.getRoleName());</span><br><span class="line">            role.getPermissions().forEach(permission -&gt; simpleAuthorizationInfo.addStringPermission(permission.getPermissionsName()));</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> simpleAuthorizationInfo;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 权限认证类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> authenticationToken</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> AuthenticationException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> AuthenticationInfo <span class="title function_">doGetAuthenticationInfo</span><span class="params">(AuthenticationToken authenticationToken)</span> <span class="keyword">throws</span> AuthenticationException &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">username</span> <span class="operator">=</span> authenticationToken.getPrincipal();</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(username)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//获取用户信息</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> username.toString();</span><br><span class="line">        <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> loginService.getUserByName(name);</span><br><span class="line">        <span class="keyword">if</span> (user == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">//这里返回后会报出对应异常</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//这里验证authenticationToken和simpleAuthenticationInfo的信息</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SimpleAuthenticationInfo</span>(name, user.getPassword(), getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="shiro配置类"><a href="#shiro配置类" class="headerlink" title="shiro配置类"></a>shiro配置类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.mgt.SecurityManager;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.spring.web.ShiroFilterFactoryBean;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.web.mgt.DefaultWebSecurityManager;</span><br><span class="line"><span class="keyword">import</span> org.example.shiro.CustomRealm;</span><br><span class="line"><span class="keyword">import</span> org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * shiro具体配置类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ShiroConfig</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@ConditionalOnMissingBean</span></span><br><span class="line">    <span class="keyword">public</span> DefaultAdvisorAutoProxyCreator <span class="title function_">defaultAdvisorAutoProxyCreator</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">DefaultAdvisorAutoProxyCreator</span> <span class="variable">defaultAAP</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultAdvisorAutoProxyCreator</span>();</span><br><span class="line">        defaultAAP.setProxyTargetClass(<span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">return</span> defaultAAP;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将自己的验证方式加入容器</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> CustomRealm <span class="title function_">myShiroRealm</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">CustomRealm</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 权限管理，配置主要是Realm的管理认证</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> SecurityManager <span class="title function_">securityManager</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">DefaultWebSecurityManager</span> <span class="variable">securityManager</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultWebSecurityManager</span>();</span><br><span class="line">        securityManager.setRealm(myShiroRealm());</span><br><span class="line">        <span class="keyword">return</span> securityManager;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Filter工厂，设置对应的过滤条件和跳转条件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ShiroFilterFactoryBean <span class="title function_">shiroFilterFactoryBean</span><span class="params">(SecurityManager securityManager)</span> &#123;</span><br><span class="line">        <span class="type">ShiroFilterFactoryBean</span> <span class="variable">shiroFilterFactoryBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ShiroFilterFactoryBean</span>();</span><br><span class="line">        shiroFilterFactoryBean.setSecurityManager(securityManager);</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">//登出</span></span><br><span class="line">        map.put(<span class="string">&quot;/logout&quot;</span>, <span class="string">&quot;logout&quot;</span>);</span><br><span class="line">        <span class="comment">//对所有用户认证</span></span><br><span class="line">        map.put(<span class="string">&quot;/**&quot;</span>, <span class="string">&quot;authc&quot;</span>);</span><br><span class="line">        <span class="comment">//登录</span></span><br><span class="line">        shiroFilterFactoryBean.setLoginUrl(<span class="string">&quot;/login&quot;</span>);</span><br><span class="line">        <span class="comment">//首页</span></span><br><span class="line">        shiroFilterFactoryBean.setSuccessUrl(<span class="string">&quot;/index&quot;</span>);</span><br><span class="line">        <span class="comment">//错误页面，认证不通过跳转</span></span><br><span class="line">        shiroFilterFactoryBean.setUnauthorizedUrl(<span class="string">&quot;/error&quot;</span>);</span><br><span class="line">        shiroFilterFactoryBean.setFilterChainDefinitionMap(map);</span><br><span class="line">        <span class="keyword">return</span> shiroFilterFactoryBean;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> AuthorizationAttributeSourceAdvisor <span class="title function_">authorizationAttributeSourceAdvisor</span><span class="params">(SecurityManager securityManager)</span> &#123;</span><br><span class="line">        <span class="type">AuthorizationAttributeSourceAdvisor</span> <span class="variable">authorizationAttributeSourceAdvisor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AuthorizationAttributeSourceAdvisor</span>();</span><br><span class="line">        authorizationAttributeSourceAdvisor.setSecurityManager(securityManager);</span><br><span class="line">        <span class="keyword">return</span> authorizationAttributeSourceAdvisor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="ExceptionHandler统一异常处理类"><a href="#ExceptionHandler统一异常处理类" class="headerlink" title="ExceptionHandler统一异常处理类"></a>ExceptionHandler统一异常处理类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.handler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authz.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ControllerAdvice;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ExceptionHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ResponseBody;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ControllerAdvice</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyExceptionHandler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ExceptionHandler</span></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">ErrorHandler</span><span class="params">(AuthorizationException e)</span> &#123;</span><br><span class="line">        log.error(<span class="string">&quot;没有通过权限验证！&quot;</span>, e);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;没有通过权限验证！&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="controller"><a href="#controller" class="headerlink" title="controller"></a>controller</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.SecurityUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authc.AuthenticationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authc.UnknownAccountException;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authc.UsernamePasswordToken;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authz.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authz.annotation.RequiresPermissions;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.authz.annotation.RequiresRoles;</span><br><span class="line"><span class="keyword">import</span> org.apache.shiro.subject.Subject;</span><br><span class="line"><span class="keyword">import</span> org.example.bean.User;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/login&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">login</span><span class="params">(User user)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(user.getUserName()) || StringUtils.isEmpty(user.getPassword())) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;请输入用户名和密码！&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//用户认证信息</span></span><br><span class="line">        <span class="type">Subject</span> <span class="variable">subject</span> <span class="operator">=</span> SecurityUtils.getSubject();</span><br><span class="line">        <span class="type">UsernamePasswordToken</span> <span class="variable">usernamePasswordToken</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">UsernamePasswordToken</span>(</span><br><span class="line">                user.getUserName(),</span><br><span class="line">                user.getPassword()</span><br><span class="line">        );</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//进行验证，这里可以捕获异常，然后返回对应信息</span></span><br><span class="line">            subject.login(usernamePasswordToken);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnknownAccountException e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;用户名不存在！&quot;</span>, e);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;用户名不存在！&quot;</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AuthenticationException e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;账号或密码错误！&quot;</span>, e);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;账号或密码错误！&quot;</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AuthorizationException e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;没有权限！&quot;</span>, e);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;没有权限&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;login success&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequiresRoles(&quot;admin&quot;)</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/admin&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">admin</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;admin success!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequiresPermissions(&quot;query&quot;)</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/index&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">index</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;index success!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequiresPermissions(&quot;add&quot;)</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/add&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">add</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;add success!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>权限</category>
      </categories>
      <tags>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot 优雅的实现统一返回处理</title>
    <url>/2021/08/17/springboot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%9F%E4%B8%80%E8%BF%94%E5%9B%9E%E5%A4%84%E7%90%86-springbootyou-ya-de-shi-xian-tong-yi-fan-hui-chu-li/</url>
    <content><![CDATA[<h1 id="springboot-优雅的实现统一返回处理"><a href="#springboot-优雅的实现统一返回处理" class="headerlink" title="springboot 优雅的实现统一返回处理"></a>springboot 优雅的实现统一返回处理</h1><p>前言：随着前后端分离这种模式的趋势下，后端开发人员更注重后端方面的代码，但是对后端人员在代码编写的过程当中需要越来越规范，这样不仅可以提高开发效率，更可以让代码后期维护起来更加的方便。</p>
<p>这篇文章主要是当接口返回的统一处理，能够让前端人员有个统一的接收后台的接口返回。</p>
<h2 id="1、自定义常用的状态码"><a href="#1、自定义常用的状态码" class="headerlink" title="1、自定义常用的状态码"></a>1、自定义常用的状态码</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义状态码枚举</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">ResultCode</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作成功</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    RC200(<span class="number">200</span>, <span class="string">&quot;操作成功&quot;</span>),</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作失败</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    RC900(<span class="number">900</span>, <span class="string">&quot;操作失败&quot;</span>),</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 服务异常</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    RC500(<span class="number">500</span>, <span class="string">&quot;系统异常，请稍后重试&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义状态码</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> code;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义描述</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String message;</span><br><span class="line"></span><br><span class="line">    ResultCode(<span class="type">int</span> code, String message) &#123;</span><br><span class="line">        <span class="built_in">this</span>.code = code;</span><br><span class="line">        <span class="built_in">this</span>.message = message;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getCode</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> code;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getMessage</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> message;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>当然可以定义定义一些其他状态码，可以让前端根据不同的状态码进行不同的处理，这里只定义部分常用状态码。</p>
<h2 id="2、统一结果返回包装类"><a href="#2、统一结果返回包装类" class="headerlink" title="2、统一结果返回包装类"></a>2、统一结果返回包装类</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.spring.response.constant;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义结果包装类</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ResultData</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 状态码</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> status;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回消息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String message;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回的结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> T data;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 有结果返回值操作成功</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data 数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt;  泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 包装结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; ResultData&lt;T&gt; <span class="title function_">success</span><span class="params">(T data)</span> &#123;</span><br><span class="line">        ResultData&lt;T&gt; resultData = <span class="keyword">new</span> <span class="title class_">ResultData</span>&lt;&gt;();</span><br><span class="line">        resultData.setStatus(ResultCode.RC200.getCode());</span><br><span class="line">        resultData.setMessage(ResultCode.RC200.getMessage());</span><br><span class="line">        resultData.setData(data);</span><br><span class="line">        <span class="keyword">return</span> resultData;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 无结果返回值操作成功</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt;  泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 包装结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; ResultData&lt;T&gt; <span class="title function_">success</span><span class="params">()</span> &#123;</span><br><span class="line">        ResultData&lt;T&gt; resultData = <span class="keyword">new</span> <span class="title class_">ResultData</span>&lt;&gt;();</span><br><span class="line">        resultData.setStatus(ResultCode.RC200.getCode());</span><br><span class="line">        resultData.setMessage(ResultCode.RC200.getMessage());</span><br><span class="line">        <span class="keyword">return</span> resultData;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 有状态码的失败</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> code    状态码</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message 失败消息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt;     泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 包装失败</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; ResultData&lt;T&gt; <span class="title function_">fail</span><span class="params">(<span class="type">int</span> code, String message)</span> &#123;</span><br><span class="line">        ResultData&lt;T&gt; resultData = <span class="keyword">new</span> <span class="title class_">ResultData</span>&lt;&gt;();</span><br><span class="line">        resultData.setStatus(code);</span><br><span class="line">        resultData.setMessage(message);</span><br><span class="line">        <span class="keyword">return</span> resultData;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 无状态码的失败</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message 失败消息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt;     泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 包装失败</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; ResultData&lt;T&gt; <span class="title function_">fail</span><span class="params">( String message)</span> &#123;</span><br><span class="line">        ResultData&lt;T&gt; resultData = <span class="keyword">new</span> <span class="title class_">ResultData</span>&lt;&gt;();</span><br><span class="line">        resultData.setStatus(ResultCode.RC999.getCode());</span><br><span class="line">        resultData.setMessage(message);</span><br><span class="line">        <span class="keyword">return</span> resultData;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里只封装的部分方法，可以根据自己的实际需求封装不同方法。</p>
<p><strong>写一个简单的请求demo</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/getHi&quot;)</span></span><br><span class="line">   <span class="keyword">public</span> ResultData&lt;String&gt; <span class="title function_">getHi</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="keyword">return</span> ResultData.success(<span class="string">&quot;hi&quot;</span>);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p><strong>返回结果</strong></p>
<p><img src="/2021/08/17/springboot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%9F%E4%B8%80%E8%BF%94%E5%9B%9E%E5%A4%84%E7%90%86-springbootyou-ya-de-shi-xian-tong-yi-fan-hui-chu-li/1.png"></p>
<p><strong>模拟一个服务器的异常</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/getHi&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> ResultData&lt;String&gt; <span class="title function_">getHi</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">a</span> <span class="operator">=</span> <span class="number">1</span>/<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> ResultData.success(<span class="string">&quot;hi&quot;</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p><strong>结果</strong></p>
<p><img src="/2021/08/17/springboot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%9F%E4%B8%80%E8%BF%94%E5%9B%9E%E5%A4%84%E7%90%86-springbootyou-ya-de-shi-xian-tong-yi-fan-hui-chu-li/2.png" alt="2"></p>
<p>这种返回结果肯定不是前端开发人员想处理的，所以我们还要对服务端如果出现一个异常，也需要处理统一的返回格式。</p>
<h2 id="3、自定义异常类，以及全局异常处理"><a href="#3、自定义异常类，以及全局异常处理" class="headerlink" title="3、自定义异常类，以及全局异常处理"></a>3、自定义异常类，以及全局异常处理</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.spring.response.exception;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.example.spring.response.constant.ResultCode;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义义务异常</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BizException</span> <span class="keyword">extends</span> <span class="title class_">RuntimeException</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> ResultCode resultCode;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BizException</span><span class="params">(String message)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(message);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BizException</span><span class="params">(ResultCode resultCode)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(resultCode.getMessage());</span><br><span class="line">        <span class="built_in">this</span>.resultCode = resultCode;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getMessage</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>.getMessage();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.spring.response.handler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.example.spring.response.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.example.spring.response.constant.ResultData;</span><br><span class="line"><span class="keyword">import</span> com.example.spring.response.exception.BizException;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.HttpStatus;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ExceptionHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ResponseStatus;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestControllerAdvice;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 全局统一异常处理</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestControllerAdvice</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RestExceptionHandler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义异常处理。</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> e the e</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> ResultData</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@ExceptionHandler(BizException.class)</span></span><br><span class="line">    <span class="meta">@ResponseStatus(HttpStatus.EXPECTATION_FAILED)</span></span><br><span class="line">    <span class="keyword">public</span> ResultData&lt;String&gt; <span class="title function_">exception</span><span class="params">(BizException e)</span> &#123;</span><br><span class="line">        log.error(<span class="string">&quot;全局异常信息 e=&#123;&#125;&quot;</span>, e.getMessage(), e);</span><br><span class="line">        <span class="keyword">return</span> ResultData.fail(e.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 默认全局异常处理。</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> e the e</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> ResultData</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@ExceptionHandler(Exception.class)</span></span><br><span class="line">    <span class="meta">@ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)</span></span><br><span class="line">    <span class="keyword">public</span> ResultData&lt;String&gt; <span class="title function_">exception</span><span class="params">(Exception e)</span> &#123;</span><br><span class="line">        log.error(<span class="string">&quot;全局异常信息 e=&#123;&#125;&quot;</span>, e.getMessage(), e);</span><br><span class="line">        <span class="keyword">return</span> ResultData.fail(ResultCode.RC500.getCode(),e.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>运行结果</strong></p>
<p><img src="/2021/08/17/springboot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%9F%E4%B8%80%E8%BF%94%E5%9B%9E%E5%A4%84%E7%90%86-springbootyou-ya-de-shi-xian-tong-yi-fan-hui-chu-li/3.png" alt="3"></p>
<p>能够正确的返回。</p>
<p>当时回头一想，统一处理但是每次返回结果的时候自己都得重复手动包装一下自定义的类，这样可以用代码来处理，所以下面实现自动包装返回的结果。</p>
<h2 id="4、自定义自动包装统一返回类"><a href="#4、自定义自动包装统一返回类" class="headerlink" title="4、自定义自动包装统一返回类"></a>4、自定义自动包装统一返回类</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.spring.response.handler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.example.spring.response.constant.ResultData;</span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.databind.ObjectMapper;</span><br><span class="line"><span class="keyword">import</span> lombok.SneakyThrows;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.core.MethodParameter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.core.io.Resource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.MediaType;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.converter.HttpMessageConverter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.server.ServerHttpRequest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.server.ServerHttpResponse;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestControllerAdvice;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.mvc.method.annotation.ResponseBodyAdvice;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 统一包装返回结果</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RestControllerAdvice</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ResponseAdvice</span> <span class="keyword">implements</span> <span class="title class_">ResponseBodyAdvice</span>&lt;Object&gt; &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ObjectMapper objectMapper;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">supports</span><span class="params">(MethodParameter methodParameter, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; aClass)</span> &#123;</span><br><span class="line">        <span class="comment">//返回true则对返回值需要处理</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 接口返回前包装结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@SneakyThrows</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">beforeBodyWrite</span><span class="params">(Object o, MethodParameter methodParameter, MediaType mediaType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; aClass, ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse)</span> &#123;</span><br><span class="line">        <span class="comment">//如果是String类型，转为json</span></span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> String) &#123;</span><br><span class="line">            <span class="keyword">return</span> objectMapper.writeValueAsString(ResultData.success(o));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果异常、文件形式，直接返回</span></span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> ResultData || o <span class="keyword">instanceof</span> Resource ) &#123;</span><br><span class="line">            <span class="keyword">return</span> o;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ResultData.success(o);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>写个demo测试一下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;getWorld&quot;)</span></span><br><span class="line">   <span class="keyword">public</span> Order <span class="title function_">getWorld</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Order</span>(<span class="number">1L</span>,<span class="string">&quot;购物车&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@GetMapping(&quot;/getError&quot;)</span></span><br><span class="line">   <span class="keyword">public</span> Order <span class="title function_">getError</span><span class="params">()</span>&#123;</span><br><span class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">BizException</span>(<span class="string">&quot;失败了&quot;</span>);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>返回结果：</p>
<p><img src="/2021/08/17/springboot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%9F%E4%B8%80%E8%BF%94%E5%9B%9E%E5%A4%84%E7%90%86-springbootyou-ya-de-shi-xian-tong-yi-fan-hui-chu-li/5.png" alt="5"><img src="/2021/08/17/springboot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%9F%E4%B8%80%E8%BF%94%E5%9B%9E%E5%A4%84%E7%90%86-springbootyou-ya-de-shi-xian-tong-yi-fan-hui-chu-li/6.png" alt="6"></p>
<p>这样就可以优雅的实现统一返回值的处理。</p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意:"></a>注意:</h3><p>特别注意这个类的判断！！！</p>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot+redisson实现分布式锁</title>
    <url>/2021/05/12/springboot+redisson%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-springbootredisson-shi-xian-fen-bu-shi-suo/</url>
    <content><![CDATA[<h2 id="redisson-springboot-实现分布式锁"><a href="#redisson-springboot-实现分布式锁" class="headerlink" title="redisson+springboot 实现分布式锁"></a>redisson+springboot 实现分布式锁</h2><p>在一些场景时，需要保证数据的不重复，以及数据的准确性，特别是特定下，某些数据的准确性显得尤为重要，所以这个时候要保证某个方法同一时刻只能有一个线程执行。在单机情况下可以用jdk的乐观锁进行保证数据的准确性。而在分布式系统中，这种jdk的锁就无法满足这种场景。</p>
<p>所以需要使用redssion实现分布式锁，它不仅可以实现分布式锁，也可以在某些情况下保证不重复提交，保证接口的幂等性。</p>
<p>redisson是基于redis实现的分布式锁，因为redis执行命令操作时是单线程，所以可以保证线程安全。当然还有其他实现分布式锁的方案，例如zk，MongoDB等。</p>
<h4 id="简单来聊一下各自优缺点"><a href="#简单来聊一下各自优缺点" class="headerlink" title="简单来聊一下各自优缺点"></a>简单来聊一下各自优缺点</h4><table>
<thead>
<tr>
<th>方案</th>
<th>实现原理</th>
<th>优点</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>MongoDB</td>
<td>1.加锁：执行findAndModify原子命令查找document，若不存在则新增<br>2.解锁：删除document</td>
<td>实现较为简单</td>
<td>1.大部分公司数据库用MySQL，可能缺乏相应的MongoDB运维、开发人员<br>2.锁无超时自动失效机制</td>
</tr>
<tr>
<td>ZooKeepe</td>
<td>1.加锁：在&#x2F;lock目录下创建临时有序节点，判断创建的节点序号是否最小。若是，则表示获取到锁；否，则则watch &#x2F;lock目录下序号比自身小的前一个节点<br>2.解锁：删除节点</td>
<td>1.由zk保障系统高可用<br>2.Curator框架已原生支持系列分布式锁命令，使用简单</td>
<td>需单独维护一套zk集群，维保成本高</td>
</tr>
<tr>
<td>redis</td>
<td>1. 加锁：执行setnx，若成功再执行expire添加过期时间<br>2. 解锁：执行delete命令</td>
<td>实现简单，相比数据库和分布式系统的实现，该方案最轻，性能最好</td>
<td>1.setnx和expire分2步执行，非原子操作；若setnx执行成功，但expire执行失败，就可能出现死锁<br>2.delete命令存在误删除非当前线程持有的锁的可能<br>3.不支持阻塞等待、不可重入</td>
</tr>
<tr>
<td>redis Lua脚本能力</td>
<td>1. 加锁：执行SET lock_name random_value EX seconds NX 命令 <br>2. 解锁：执行Lua脚本，释放锁时验证random_value – ARGV[1]为random_value, KEYS[1]为lock_name</td>
<td>同上；实现逻辑上也更严谨，除了单点问题，生产环境采用用这种方案，问题也不大。</td>
<td>不支持锁重入，不支持阻塞等待</td>
</tr>
<tr>
<td>redisson</td>
<td>redisson这个框架重度依赖了Lua脚本和Netty，加锁、解锁Lua脚本是redisson分布式锁</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="分布式锁需满足四个条件"><a href="#分布式锁需满足四个条件" class="headerlink" title="分布式锁需满足四个条件"></a>分布式锁需满足四个条件</h4><p>首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件：</p>
<ol>
<li>互斥性。在任意时刻，只有一个客户端能持有锁。</li>
<li>不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。</li>
<li>解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了，即不能误解锁。</li>
<li>具有容错性。只要大多数Redis节点正常运行，客户端就能够获取和释放锁</li>
</ol>
<h4 id="redisson实现分布式锁案例"><a href="#redisson实现分布式锁案例" class="headerlink" title="redisson实现分布式锁案例"></a>redisson实现分布式锁案例</h4><h5 id="1、导入依赖"><a href="#1、导入依赖" class="headerlink" title="1、导入依赖"></a>1、导入依赖</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-aop<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--&lt;dependency&gt;</span></span><br><span class="line"><span class="comment">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span></span><br><span class="line"><span class="comment">            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;</span></span><br><span class="line"><span class="comment">        &lt;/dependency&gt;--&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;</span></span><br><span class="line">       <span class="comment">&lt;!-- &lt;dependency&gt;</span></span><br><span class="line"><span class="comment">            &lt;groupId&gt;org.redisson&lt;/groupId&gt;</span></span><br><span class="line"><span class="comment">            &lt;artifactId&gt;redisson&lt;/artifactId&gt;</span></span><br><span class="line"><span class="comment">            &lt;version&gt;3.12.0&lt;/version&gt;</span></span><br><span class="line"><span class="comment">        &lt;/dependency&gt;--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.18.16<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>8.0.22<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h5 id="2、配置redisson-single-单机"><a href="#2、配置redisson-single-单机" class="headerlink" title="2、配置redisson-single(单机)"></a>2、配置redisson-single(单机)</h5><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#单机</span></span><br><span class="line"><span class="attr">singleServerConfig:</span></span><br><span class="line">  <span class="attr">idleConnectionTimeout:</span> <span class="number">10000</span></span><br><span class="line">  <span class="attr">pingTimeout:</span> <span class="number">1000</span></span><br><span class="line">  <span class="attr">connectTimeout:</span> <span class="number">10000</span></span><br><span class="line">  <span class="attr">timeout:</span> <span class="number">3000</span></span><br><span class="line">  <span class="attr">retryAttempts:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">retryInterval:</span> <span class="number">1500</span></span><br><span class="line">  <span class="attr">reconnectionTimeout:</span> <span class="number">3000</span></span><br><span class="line">  <span class="attr">failedAttempts:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">subscriptionsPerConnection:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">clientName:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">&quot;redis://localhost:6379&quot;</span></span><br><span class="line">  <span class="attr">subscriptionConnectionMinimumIdleSize:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">subscriptionConnectionPoolSize:</span> <span class="number">50</span></span><br><span class="line">  <span class="attr">connectionMinimumIdleSize:</span> <span class="number">32</span></span><br><span class="line">  <span class="attr">connectionPoolSize:</span> <span class="number">64</span></span><br><span class="line">  <span class="attr">database:</span> <span class="number">0</span></span><br><span class="line">  <span class="comment">#在最新版本中dns的检查操作会直接报错 所以我直接注释掉了</span></span><br><span class="line">  <span class="comment">#dnsMonitoring: false</span></span><br><span class="line">  <span class="attr">dnsMonitoringInterval:</span> <span class="number">5000</span></span><br><span class="line"><span class="attr">threads:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">nettyThreads:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">codec:</span> <span class="type">!&lt;org.redisson.codec.JsonJacksonCodec&gt;</span> &#123;&#125;</span><br><span class="line"><span class="attr">transportMode :</span> <span class="string">&quot;NIO&quot;</span></span><br></pre></td></tr></table></figure>

<h5 id="3、配置application"><a href="#3、配置application" class="headerlink" title="3、配置application"></a>3、配置application</h5><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">spring:</span> </span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">host:</span> <span class="string">localhost</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">    <span class="attr">database:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="number">2000</span></span><br></pre></td></tr></table></figure>

<h5 id="4、编写redisson配置类"><a href="#4、编写redisson配置类" class="headerlink" title="4、编写redisson配置类"></a>4、编写redisson配置类</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedissonConfig</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean(destroyMethod=&quot;shutdown&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> RedissonClient <span class="title function_">redisson</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">return</span> Redisson.create(</span><br><span class="line">                Config.fromYAML(<span class="keyword">new</span> <span class="title class_">ClassPathResource</span>(<span class="string">&quot;redisson-single.yml&quot;</span>).getInputStream()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="5、具体业务实现"><a href="#5、具体业务实现" class="headerlink" title="5、具体业务实现"></a>5、具体业务实现</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GoodsServiceImpl</span> <span class="keyword">extends</span> <span class="title class_">ServiceImpl</span>&lt;GoodsMapper, Goods&gt; <span class="keyword">implements</span> <span class="title class_">GoodsService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RedissonClient redissonClient;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">LOCK_KEY</span> <span class="operator">=</span> <span class="string">&quot;lock&quot;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 库存递减</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id  id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> num 数量</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">killGoods</span><span class="params">(Long id, Integer num)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> LOCK_KEY + id;</span><br><span class="line">        <span class="type">RLock</span> <span class="variable">lock</span> <span class="operator">=</span> redissonClient.getLock(key);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//上锁</span></span><br><span class="line">            lock.lock();</span><br><span class="line">            <span class="type">Goods</span> <span class="variable">goods</span> <span class="operator">=</span> <span class="built_in">this</span>.getById(id);</span><br><span class="line">            <span class="keyword">if</span> (goods.getQuantity()&lt;=<span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            log.info(<span class="string">&quot;库存数量======&quot;</span>+goods.getQuantity());</span><br><span class="line">            <span class="comment">//将库存减操作</span></span><br><span class="line">            goods.setQuantity(goods.getQuantity()-<span class="number">1</span>);</span><br><span class="line">            <span class="built_in">this</span>.updateById(goods);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//解锁</span></span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h5 id="6、接口实现"><a href="#6、接口实现" class="headerlink" title="6、接口实现"></a>6、接口实现</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GoodsController</span> &#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> GoodsService goodsService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;test&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">createOrderTest</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!goodsService.killGoods(<span class="number">1405065181720055809L</span>, <span class="number">1</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;库存不足&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;创建订单成功&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="7、测试，用ab测试工具"><a href="#7、测试，用ab测试工具" class="headerlink" title="7、测试，用ab测试工具"></a>7、测试，用ab测试工具</h5><p>模拟200个并发测试</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">D:\develop\Apache24\bin&gt;ab  -n 200 -c 200 &quot;http://localhost:8080/test&quot;</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="/2021/05/12/springboot+redisson%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-springbootredisson-shi-xian-fen-bu-shi-suo/1623922545310-b997fe37fc3c4af18ecef38b4e142ff8.png" alt="1623922545310.png"></p>
<p><img src="/2021/05/12/springboot+redisson%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-springbootredisson-shi-xian-fen-bu-shi-suo/1623922677743-deda4b67d30e452696770467e442c5f9.png" alt="1623922677743.png"></p>
<p>没有库存变成负数的情况，说明分布式锁已生效</p>
]]></content>
      <categories>
        <category>分布式锁</category>
      </categories>
      <tags>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot+mybatis_plus实现读写分离</title>
    <url>/2021/10/10/springboot+mybatis_plus%E5%AE%9E%E7%8E%B0%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB-springbootmybatisplus%E5%AE%9E%E7%8E%B0%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/</url>
    <content><![CDATA[<h3 id="1、引言"><a href="#1、引言" class="headerlink" title="1、引言"></a>1、引言</h3><p>读写分离要做的事情就是对于一条SQL该选择哪个数据库去执行，至于谁来做选择数据库这件事儿，无非两个，要么中间件帮我们做，要么程序自己做。</p>
<p>因此，一般来讲，读写分离有两种实现方式。第一种是依靠中间件（比如：MyCat），也就是说应用程序连接到中间件，中间件帮我们做SQL分离；第二种是应用程序自己去做分离。这里我们选择程序自己来做，主要是利用Spring提供的路由数据源，以及AOP</p>
<p>然而，应用程序层面去做读写分离最大的弱点（不足之处）在于无法动态增加数据库节点，因为数据源配置都是写在配置中的，新增数据库意味着新加一个数据源，必然改配置，并重启应用。当然，好处就是相对简单。</p>
<h4 id="1-1项目地址"><a href="#1-1项目地址" class="headerlink" title="1.1项目地址"></a>1.1项目地址</h4><p><strong>git-hub</strong>:<a href="https://github.com/wenlinshan/wenlinshan/tree/main/master-slave-demo">https://github.com/wenlinshan/wenlinshan/tree/main/master-slave-demo</a></p>
<h3 id="2、AbstractRoutingDataSource"><a href="#2、AbstractRoutingDataSource" class="headerlink" title="2、AbstractRoutingDataSource"></a>2、AbstractRoutingDataSource</h3><p>基于特定的查找key路由到特定的数据源。它内部维护了一组目标数据源，并且做了路由key与目标数据源之间的映射，提供基于key查找数据源的方法。</p>
<h3 id="3、实践"><a href="#3、实践" class="headerlink" title="3、实践"></a>3、实践</h3><h4 id="3-1-maven依赖"><a href="#3-1-maven依赖" class="headerlink" title="3.1. maven依赖"></a>3.1. maven依赖</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.0.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.wenlinshan<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>master-slave-demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>master-slave-demo<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>master-slave-demo<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.reporting.outputEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.reporting.outputEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-aop<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--mybatis--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.3.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-autoconfigure<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-lang3<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--驱动--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- druid --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3-2-数据源配置"><a href="#3-2-数据源配置" class="headerlink" title="3.2. 数据源配置"></a>3.2. 数据源配置</h4><p><strong>application.yml</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#配置数据源，根据不同库模拟主从库</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8000</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">druid:</span></span><br><span class="line">      <span class="attr">master:</span></span><br><span class="line">        <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">        <span class="attr">password:</span> <span class="string">root</span></span><br><span class="line">        <span class="attr">driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">        <span class="attr">url:</span> <span class="string">jdbc:mysql://localhost:3306/m1?characterEncoding=utf8&amp;verifyServerCertificate=false&amp;useSSL=true&amp;serverTimezone=Asia/Shanghai</span></span><br><span class="line">        <span class="attr">initialSize:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">minIdle:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">maxActive:</span> <span class="number">20</span></span><br><span class="line">      <span class="attr">slave1:</span></span><br><span class="line">        <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">        <span class="attr">password:</span> <span class="number">123456</span></span><br><span class="line">        <span class="attr">driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">        <span class="attr">url:</span> <span class="string">jdbc:mysql://localhost:3306/s1?characterEncoding=utf8&amp;verifyServerCertificate=false&amp;useSSL=true&amp;serverTimezone=Asia/Shanghai</span></span><br><span class="line">        <span class="attr">initialSize:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">minIdle:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">maxActive:</span> <span class="number">20</span></span><br><span class="line">      <span class="attr">slave2:</span></span><br><span class="line">        <span class="attr">username:</span> <span class="string">wen</span></span><br><span class="line">        <span class="attr">password:</span> <span class="number">123456</span></span><br><span class="line">        <span class="attr">driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">        <span class="attr">url:</span> <span class="string">jdbc:mysql://localhost:3306/s2?characterEncoding=utf8&amp;verifyServerCertificate=false&amp;useSSL=true&amp;serverTimezone=Asia/Shanghai</span></span><br><span class="line">        <span class="attr">initialSize:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">minIdle:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">maxActive:</span> <span class="number">20</span></span><br><span class="line"><span class="attr">mybatis-plus:</span></span><br><span class="line">  <span class="comment"># 如果是放在src/main/java目录下 classpath:/com/yourpackage/*/mapper/*Mapper.xml</span></span><br><span class="line">  <span class="comment"># 如果是放在resource目录 classpath:/mapper/*Mapper.xml</span></span><br><span class="line">  <span class="attr">mapper-locations:</span> <span class="string">classpath:/mapper/*Mapper.xml</span></span><br><span class="line">  <span class="comment">#实体扫描，多个package用逗号或者分号分隔</span></span><br><span class="line">  <span class="attr">typeAliasesPackage:</span> <span class="string">com.seawatebt.ssm.entity</span></span><br><span class="line">  <span class="attr">configuration:</span></span><br><span class="line">    <span class="comment">#配置返回数据库(column下划线命名&amp;&amp;返回java实体是驼峰命名)，自动匹配无需as（没开启这个，SQL需要写as： select user_id as userId）</span></span><br><span class="line">    <span class="attr">map-underscore-to-camel-case:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">cache-enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment">#配置JdbcTypeForNull, oracle数据库必须配置</span></span><br><span class="line">    <span class="attr">jdbc-type-for-null:</span> <span class="string">&#x27;null&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="3-3-设置路由key-x2F-查找数据源"><a href="#3-3-设置路由key-x2F-查找数据源" class="headerlink" title="3.3. 设置路由key &#x2F; 查找数据源"></a>3.3. 设置路由key &#x2F; 查找数据源</h4><p>目标数据源就是那前3个这个我们是知道的，但是使用的时候是如果查找数据源的呢？</p>
<p>首先，我们定义一个枚举来代表这三个数据源</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@desc</span> 数据库类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">DBTypeEnum</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主节点</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    MASTER,</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从1</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    SLAVE1,</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从2</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    SLAVE2;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>新建DataSourceContextHolder</strong></p>
<p>接下来，通过ThreadLocal将数据源设置到每个线程上下文中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.constant.DBTypeEnum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过ThreadLocal将数据源设置到每个线程上下文</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataSourceContextHolder</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;DBTypeEnum&gt; CONTEXT_HOLDER = <span class="keyword">new</span> <span class="title class_">ThreadLocal</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">AtomicInteger</span> <span class="variable">COUNTER</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(-<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(DBTypeEnum dbType)</span> &#123;</span><br><span class="line">        CONTEXT_HOLDER.set(dbType);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> DBTypeEnum <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> CONTEXT_HOLDER.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span>&#123;</span><br><span class="line">        CONTEXT_HOLDER.remove();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">master</span><span class="params">()</span> &#123;</span><br><span class="line">        set(DBTypeEnum.MASTER);</span><br><span class="line">        System.out.println(<span class="string">&quot;切换到master&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">slave</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//  轮询</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> COUNTER.getAndIncrement() % <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (COUNTER.get() &gt; <span class="number">9999</span>) &#123;</span><br><span class="line">            COUNTER.set(-<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (index == <span class="number">0</span>) &#123;</span><br><span class="line">            set(DBTypeEnum.SLAVE1);</span><br><span class="line">            System.out.println(<span class="string">&quot;切换到slave1&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            set(DBTypeEnum.SLAVE2);</span><br><span class="line">            System.out.println(<span class="string">&quot;切换到slave2&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>设置路由key</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.lang.Nullable;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 声明路由数据源key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyRoutingDataSource</span> <span class="keyword">extends</span> <span class="title class_">AbstractRoutingDataSource</span> &#123;</span><br><span class="line">    <span class="meta">@Nullable</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> Object <span class="title function_">determineCurrentLookupKey</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> DataSourceContextHolder.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>多数据源配置</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder;</span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.constant.DBTypeEnum;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Qualifier;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.context.properties.ConfigurationProperties;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.sql.DataSource;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 关于数据源配置，参考SpringBoot官方文档第79章《Data Access》</span></span><br><span class="line"><span class="comment"> * 79. Data Access</span></span><br><span class="line"><span class="comment"> * 79.1 Configure a Custom DataSource</span></span><br><span class="line"><span class="comment"> * 79.2 Configure Two DataSources</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataSourceConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 配置主数据源</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 数据源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean(name = &quot;master&quot;)</span></span><br><span class="line">    <span class="meta">@ConfigurationProperties(prefix = &quot;spring.datasource.druid.master&quot; )</span></span><br><span class="line">    <span class="keyword">public</span> DataSource <span class="title function_">masterDataSource</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> DruidDataSourceBuilder.create().build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 配置从数据源</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 数据源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean(name = &quot;slave1&quot;)</span></span><br><span class="line">    <span class="meta">@ConfigurationProperties(prefix = &quot;spring.datasource.druid.slave1&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> DataSource <span class="title function_">slave1DataSource</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> DruidDataSourceBuilder.create().build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 配置从数据源</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 数据源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean(name = &quot;slave2&quot;)</span></span><br><span class="line">    <span class="meta">@ConfigurationProperties(prefix = &quot;spring.datasource.druid.slave2&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> DataSource <span class="title function_">slave2DataSource</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> DruidDataSourceBuilder.create().build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 配置路由数据源</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> masterDataSource 主节点</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> slave1DataSource 从节点</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> slave2DataSource 从节点</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 数据源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> DataSource <span class="title function_">myRoutingDataSource</span><span class="params">(<span class="meta">@Qualifier(&quot;master&quot;)</span> DataSource masterDataSource,</span></span><br><span class="line"><span class="params">                                          <span class="meta">@Qualifier(&quot;slave1&quot;)</span> DataSource slave1DataSource,</span></span><br><span class="line"><span class="params">                                          <span class="meta">@Qualifier(&quot;slave2&quot;)</span> DataSource slave2DataSource)</span> &#123;</span><br><span class="line">        Map&lt;Object, Object&gt; targetDataSources = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(<span class="number">3</span>);</span><br><span class="line">        targetDataSources.put(DBTypeEnum.MASTER, masterDataSource);</span><br><span class="line">        targetDataSources.put(DBTypeEnum.SLAVE1, slave1DataSource);</span><br><span class="line">        targetDataSources.put(DBTypeEnum.SLAVE2, slave2DataSource);</span><br><span class="line">        <span class="type">MyRoutingDataSource</span> <span class="variable">myRoutingDataSource</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyRoutingDataSource</span>();</span><br><span class="line">        <span class="comment">//设置默认数据源</span></span><br><span class="line">        myRoutingDataSource.setDefaultTargetDataSource(masterDataSource);</span><br><span class="line">        myRoutingDataSource.setTargetDataSources(targetDataSources);</span><br><span class="line">        <span class="keyword">return</span> myRoutingDataSource;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里，我们配置了4个数据源，1个master，2两个slave，1个路由数据源。前3个数据源都是为了生成第4个数据源，而且后续我们只用这最后一个路由数据源。</p>
<p><strong>MyBatis配置</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.core.MybatisConfiguration;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.type.JdbcType;</span><br><span class="line"><span class="keyword">import</span> org.mybatis.spring.SqlSessionFactoryBean;</span><br><span class="line"><span class="keyword">import</span> org.omg.PortableInterceptor.Interceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.core.io.support.PathMatchingResourcePatternResolver;</span><br><span class="line"><span class="keyword">import</span> org.springframework.jdbc.datasource.DataSourceTransactionManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.PlatformTransactionManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.annotation.EnableTransactionManagement;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Resource;</span><br><span class="line"><span class="keyword">import</span> javax.sql.DataSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * mybatis 配置</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@EnableTransactionManagement</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyBatisConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource(name = &quot;myRoutingDataSource&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> DataSource myRoutingDataSource;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean(name = &quot;sqlSessionFactory&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> SqlSessionFactory <span class="title function_">sqlSessionFactory</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">MybatisSqlSessionFactoryBean</span> <span class="variable">sqlSessionFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MybatisSqlSessionFactoryBean</span>();</span><br><span class="line">        sqlSessionFactory.setDataSource(myRoutingDataSource);</span><br><span class="line">        <span class="type">MybatisConfiguration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MybatisConfiguration</span>();</span><br><span class="line">        configuration.setJdbcTypeForNull(JdbcType.NULL);</span><br><span class="line">        configuration.setMapUnderscoreToCamelCase(<span class="literal">true</span>);</span><br><span class="line">        configuration.setCacheEnabled(<span class="literal">false</span>);</span><br><span class="line">        sqlSessionFactory.setConfiguration(configuration);</span><br><span class="line">        <span class="keyword">return</span> sqlSessionFactory.getObject();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> PlatformTransactionManager <span class="title function_">platformTransactionManager</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DataSourceTransactionManager</span>(myRoutingDataSource);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于Spring容器中现在有4个数据源，所以我们需要为事务管理器和MyBatis手动指定一个明确的数据源。</p>
<h4 id="3-4-使用aop实现数据源切换"><a href="#3-4-使用aop实现数据源切换" class="headerlink" title="3.4 使用aop实现数据源切换"></a>3.4 使用aop实现数据源切换</h4><p>默认情况下，所有的查询都走从库，插入&#x2F;修改&#x2F;删除走主库。我们通过方法名来区分操作类型（CRUD）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.aop;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.config.DataSourceContextHolder;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.After;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Aspect;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Before;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Pointcut;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 设置切面 执行具体方法选择的数据源</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataSourceAop</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 需要读的方法,切面</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Pointcut(&quot;!@annotation(com.wenlinshan.masterslavedemo.annotation.Master)&quot; +</span></span><br><span class="line"><span class="meta">            &quot;&amp;&amp; (execution(* com.wenlinshan.masterslavedemo.service..*.select*(..)) &quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.get*(..)))&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readPointcut</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 写切面</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Pointcut(&quot;@annotation(com.wenlinshan.masterslavedemo.annotation.Master) &quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.insert*(..))&quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.save*(..))&quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.add*(..))&quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.update*(..))&quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.edit*(..))&quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.delete*(..))&quot; +</span></span><br><span class="line"><span class="meta">            &quot;|| execution(* com.wenlinshan.masterslavedemo.service..*.remove*(..))&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writePointcut</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before(&quot;readPointcut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">read</span><span class="params">()</span> &#123;</span><br><span class="line">        DataSourceContextHolder.slave();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before(&quot;writePointcut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">()</span> &#123;</span><br><span class="line">        DataSourceContextHolder.master();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After(&quot;readPointcut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readAfter</span><span class="params">()</span> &#123;</span><br><span class="line">        DataSourceContextHolder.clear();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After(&quot;writePointcut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeAfter</span><span class="params">()</span> &#123;</span><br><span class="line">        DataSourceContextHolder.clear();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>有一般情况就有特殊情况，特殊情况是某些情况下我们需要强制读主库，针对这种情况，我们定义一个主键，用该注解标注的就读主库</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.annotation;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Master &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Goods表</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.domain;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.IdType;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.TableField;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.TableId;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.TableName;</span><br><span class="line"><span class="keyword">import</span> java.math.BigDecimal;</span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Builder;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@TableName(value = &quot;goods&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Goods</span> &#123;</span><br><span class="line">    <span class="meta">@TableId(value = &quot;id&quot;, type = IdType.ASSIGN_ID)</span></span><br><span class="line">    <span class="keyword">private</span> Long id;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@TableField(value = &quot;`name`&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@TableField(value = &quot;quantity&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> Integer quantity;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@TableField(value = &quot;price&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> BigDecimal price;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">COL_ID</span> <span class="operator">=</span> <span class="string">&quot;id&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">COL_NAME</span> <span class="operator">=</span> <span class="string">&quot;name&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">COL_QUANTITY</span> <span class="operator">=</span> <span class="string">&quot;quantity&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">COL_PRICE</span> <span class="operator">=</span> <span class="string">&quot;price&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4、测试"><a href="#4、测试" class="headerlink" title="4、测试"></a>4、测试</h3><p><strong>service</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.annotation.Master;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"><span class="keyword">import</span> javax.annotation.Resource;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;</span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.domain.Goods;</span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.mapper.GoodsMapper;</span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.service.GoodsService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.annotation.Transactional;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GoodsServiceImpl</span> <span class="keyword">extends</span> <span class="title class_">ServiceImpl</span>&lt;GoodsMapper, Goods&gt; <span class="keyword">implements</span> <span class="title class_">GoodsService</span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> goods 商品</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span>  是否成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="meta">@Transactional(rollbackFor = Exception.class)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">saveGoods</span><span class="params">(Goods goods)</span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="built_in">this</span>.save(goods);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 是否成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Transactional(rollbackFor = Exception.class)</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">deleteGoods</span><span class="params">(Long id)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.removeById(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询全部</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 全部</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;Goods&gt; <span class="title function_">getGoodsAll</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.list();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询单个</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 商品</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Master</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Goods <span class="title function_">getGoodsById</span><span class="params">(Long id)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.getById(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>controller</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wenlinshan.masterslavedemo.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.annotation.Master;</span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.domain.Goods;</span><br><span class="line"><span class="keyword">import</span> com.wenlinshan.masterslavedemo.service.GoodsService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.annotation.Transactional;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.DeleteMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.PostMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Resource;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GoodsController</span> &#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> GoodsService goodsService;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> goods 商品</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span>  是否成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/saveGoods&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">saveGoods</span><span class="params">(Goods goods)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> goodsService.saveGoods(goods);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 是否成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@DeleteMapping(&quot;/deleteGoods&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">deleteGoods</span><span class="params">(Long id)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> goodsService.deleteGoods(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询全部</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 全部</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/getGoodsAll&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;Goods&gt; <span class="title function_">getGoodsAll</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> goodsService.getGoodsAll();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询单个</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 商品</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;getGoodsById&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Goods <span class="title function_">getGoodsById</span><span class="params">(Long id)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> goodsService.getGoodsById(id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>spring中多线程情况下如何保证事务</title>
    <url>/2023/07/25/spring%E4%B8%AD%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%83%85%E5%86%B5%E4%B8%8B%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Springboot项目，有个需求，需要提供接口，接口调用方每一次调用时，会保存或者更新大量数据，接口需要满足以下要求：</p>
<ul>
<li>数据保存要保证数据原子性：要么全部保存成功，要么全部不保存。</li>
<li>保证接口性能。</li>
</ul>
<p>实践发现，即使使用批量保存，接口耗时也久，所以需要开启多线程来保存。现在的问题是，在开启多线程保存的情况下，如何保证数据的原子性。</p>
<h2 id="使用声明式事务出现的问题"><a href="#使用声明式事务出现的问题" class="headerlink" title="使用声明式事务出现的问题"></a>使用声明式事务出现的问题</h2><p>具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Transactional(rollbackFor = Exception.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">saveUser</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Long</span> <span class="variable">userId</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line">        CompletableFuture&lt;Void&gt; f1 = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">                <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">                user.setId(userId);</span><br><span class="line">                user.setName(<span class="string">&quot;wls&quot;</span>);</span><br><span class="line">                user.setEmail(<span class="string">&quot;1396523950@qq.com&quot;</span>);</span><br><span class="line">                save(user);</span><br><span class="line">        &#125;, threadPoolExecutor);</span><br><span class="line">        CompletableFuture&lt;Void&gt; f2 = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">           </span><br><span class="line">                <span class="type">UserLog</span> <span class="variable">userLog</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">UserLog</span>();</span><br><span class="line">                userLog.setUserId(userId);</span><br><span class="line">                userLogService.save(userLog);</span><br><span class="line">                <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span> / <span class="number">0</span>;</span><br><span class="line">        &#125;, threadPoolExecutor);</span><br><span class="line">    	<span class="comment">//等待所有执行完</span></span><br><span class="line">        CompletableFuture.allOf(f1, f2).join();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>此时可以发现 user保存成功，userLog未保存成功，说明整个方法的事务并未保证原子性。</p>
<h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><ul>
<li>开启多线程，每个线程都是使用独立的DB连接。否则由于数据库是串行阻塞操作，最终还是会变成排队操作数据库。</li>
<li>依赖spring事务异常回滚机制。</li>
<li>有个统一的标识来标识“是否有线程操作失败”。</li>
<li>线程如果出现异常：先捕获异常，将标识设置为失败，然后继续抛出异常。</li>
<li>线程如果没有异常，在执行的最后，判断标识是失败，也就是“有其他线程有执行失败”，就自定义抛出异常来回滚。</li>
<li>通过锁来保证：所有的线程都操作完之后，一起判断标识是否成功；确保不会出现“还有线程的业务未执行完成，其他线程就已经结束工作”。</li>
</ul>
<h2 id="最终代码"><a href="#最终代码" class="headerlink" title="最终代码"></a>最终代码</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserService</span> <span class="keyword">extends</span> <span class="title class_">ServiceImpl</span>&lt;UserMapper, User&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> ThreadPoolExecutor threadPoolExecutor;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> DataSourceTransactionManager dataSourceTransactionManager;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> UserLogService userLogService;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">saveUser</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">CyclicBarrier</span> <span class="variable">cb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CyclicBarrier</span>(<span class="number">2</span>);</span><br><span class="line">        <span class="type">AtomicBoolean</span> <span class="variable">flag</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicBoolean</span>(<span class="literal">false</span>);</span><br><span class="line">        <span class="type">Long</span> <span class="variable">userId</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line">        CompletableFuture&lt;Void&gt; f1 = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">            <span class="type">DefaultTransactionDefinition</span> <span class="variable">defaultTransactionDefinition</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultTransactionDefinition</span>();</span><br><span class="line">            <span class="type">TransactionStatus</span> <span class="variable">transaction</span> <span class="operator">=</span> dataSourceTransactionManager.getTransaction(defaultTransactionDefinition);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">                user.setId(userId);</span><br><span class="line">                user.setName(<span class="string">&quot;wls&quot;</span>);</span><br><span class="line">                user.setEmail(<span class="string">&quot;1396523950@qq.com&quot;</span>);</span><br><span class="line">                save(user);</span><br><span class="line">                <span class="comment">// 等待所有线程的事务结果</span></span><br><span class="line">                cb.await();</span><br><span class="line">                log.info(<span class="string">&quot;f1： &quot;</span>+flag.get());</span><br><span class="line">                <span class="comment">// 如果标志需要回滚，则回滚</span></span><br><span class="line">                <span class="keyword">if</span> (flag.get()) &#123;</span><br><span class="line">                    dataSourceTransactionManager.rollback(transaction);</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                dataSourceTransactionManager.commit(transaction);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                flag.set(<span class="literal">true</span>);</span><br><span class="line">                dataSourceTransactionManager.rollback(transaction);</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    cb.await();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException | BrokenBarrierException ex) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(ex);</span><br><span class="line">                &#125;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;, threadPoolExecutor);</span><br><span class="line">        CompletableFuture&lt;Void&gt; f2 = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">            <span class="type">DefaultTransactionDefinition</span> <span class="variable">defaultTransactionDefinition</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultTransactionDefinition</span>();</span><br><span class="line">            <span class="type">TransactionStatus</span> <span class="variable">transaction</span> <span class="operator">=</span> dataSourceTransactionManager.getTransaction(defaultTransactionDefinition);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="type">UserLog</span> <span class="variable">userLog</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">UserLog</span>();</span><br><span class="line">                userLog.setUserId(userId);</span><br><span class="line">                userLogService.save(userLog);</span><br><span class="line">                <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span> / <span class="number">0</span>;</span><br><span class="line">                <span class="comment">// 等待所有线程的事务结果</span></span><br><span class="line">                cb.await();</span><br><span class="line">                log.info(<span class="string">&quot;f2： &quot;</span>+flag.get());</span><br><span class="line">                <span class="comment">// 如果标志需要回滚，则回滚</span></span><br><span class="line">                <span class="keyword">if</span> (flag.get()) &#123;</span><br><span class="line">                    dataSourceTransactionManager.rollback(transaction);</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                dataSourceTransactionManager.commit(transaction);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                flag.set(<span class="literal">true</span>);</span><br><span class="line">                dataSourceTransactionManager.rollback(transaction);</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    cb.await();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException | BrokenBarrierException ex) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(ex);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">throw</span>  <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, threadPoolExecutor);</span><br><span class="line">        CompletableFuture.allOf(f1, f2).join();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong></p>
<p>使用<code>CyclicBarrier</code> 和手动事务时需要控制任务的超时时间。</p>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>spring事务的传播行为</title>
    <url>/2022/10/25/spring%E4%BA%8B%E5%8A%A1%E7%9A%84%E4%BC%A0%E6%92%AD%E8%A1%8C%E4%B8%BA-spring-shi-wu-de-chuan-bo-xing-wei/</url>
    <content><![CDATA[<h2 id="一、多个事务方法相互调用时，事务如何在这些方法间传播"><a href="#一、多个事务方法相互调用时，事务如何在这些方法间传播" class="headerlink" title="一、多个事务方法相互调用时，事务如何在这些方法间传播"></a>一、多个事务方法相互调用时，事务如何在这些方法间传播</h2><p>方法A是一个事务的方法，方法A执行过程中调用了方法B，那么方法B有无事务以及方法B对事务的要求不同都会对方法A的事务具体执行造成影响，同时方法A的事务对方法B的事务执行也有影响，这种影响具体是什么就由两个方法所定义的事务传播类型所决定。</p>
<p><strong>REQUIRED</strong>（Spring默认的事务传播类型）：如果当前没有事务，则自己新建一个事务，如果当前存在事务，则加入这个事务。举例说明:如果方法A所在的方法里面的sql没有事务，那么就会与方法B里面的sql事务放在一起，要么同时成功，要么同时失败。如果方法A所在的方法里面的sql有事务，那么方法B所在的方法里面的sql就会加入方法A的sql的事务，要么同时成功，要么同时失败。</p>
<p><strong>SUPPORTS</strong>:当前存在事务，则加入当前事务，如果当前没有事务，就以非事务方法执行。举例说明:如果方法A所在的方法里面的sql有事务，那么方法B里面的sql则会加入方法A的事务，要么同时成功，要么同时失败。如果方法A所在的方法里面的sql没有事务，那么方法B所在的方法里面的sql就会以非事务运行。</p>
<p><strong>MANDATORY</strong>:当前存在事务，则加入当前事务，如果当前事务不存在，则抛出异常。举例说明:如果方法A所在的方法里面的sql有事务，那么方法B里面的sql则会加入方法A的事务，要么同时成功，要么同时失败。如果方法A所在的方法里面的sql没有事务，那么方法B所在的方法就会抛出异常。</p>
<p><strong>REQUIRES_NEW</strong>:创建一个新事物，如果存在当前事务，则挂起该事务。举例说明:如果方法A所在的方法里面的sql有事务，同时方法B所在的方法里面的sql也有事务，那么先执行方法A里面的事务，再去执行方法B里面的事务。这种情况下，A事务回滚就只是回滚A自己的事务，B亦是如此。</p>
<p><strong>NOT_SUPPORTED</strong>:以非事务方式执行，如果当前存在事务，则挂起当前事务。举例说明:如果方法A所在的方法里面的sql有事务，那么方法A里面的sql单独在事务里执行，方法B里面的sql一定是以非事务运行。如果方法A里面的sql没有事务，那么方法A与方法B里面的sql都是以非事务方式执行。</p>
<p><strong>NEVER</strong>:不使用事务，如果当前事务存在，则抛出异常。</p>
<p><strong>NESTED</strong>:如果当前事务存在，则在嵌套事务中执行，否则REQUIRED的操作一样（开启一个事务）。举例说明:如果方法A所在的sql有事务，那么方法B所在的sql则会嵌套在方法A的事务中执行。</p>
<p><strong>NESTED</strong>和<strong>REQUIRES_NEW</strong>的区别:<strong>REQUIRES_NEW</strong>是新建一个事务并且新开启的这个事务与原事务无关，而<strong>NESTED</strong>则是当前存在事务时（我们把当前事务称之为父事务）会开启一个嵌套事务（称之为一个子事务）。在<strong>NESTED</strong>情况下父事务回滚时，子事务也会回滚，而在<strong>REQUIRES_NEW</strong>的情况下，原有事务回滚，不会影响新开启的事务。</p>
<h2 id="二、关于spring的事务传播特性"><a href="#二、关于spring的事务传播特性" class="headerlink" title="二、关于spring的事务传播特性"></a>二、关于spring的事务传播特性</h2><p>1、why<br>为什么会有事务传播机制？</p>
<p>场景一： serviceA 方法调用了 serviceB 方法，但两个方法都有事务，这个时候如果 serviceB 方法异常，是让 serviceB 方法提交，还是两个一起回滚。场景二：serviceA 方法调用了 serviceB 方法，但是只有 serviceA 方法加了事务，是否把 serviceB 也加入 serviceA 的事务，如果 serviceB 异常，是否回滚 serviceA 。场景三：serviceA 方法调用了 serviceB 方法，两者都有事务，serviceB 已经正常执行完，但 serviceA 异常，是否需要回滚 serviceB 的数据。<br>所以，我们需要有对应的事务传播机制来控制事务。</p>
<p>2、传播机制生效的条件<br>有了spring事务传播机制，那这种机制存在的条件呢？我们知道，spring的事务是基于aop的，确切来说，是基于JDK动态代理的AOP，这种AOP有什么特点呢？ 它是基于类或者接口的，也就是说，当 @Transactional写在一个方法上时，这个方法将会被spring动态代理， 生成一个动态代理类， 对原方法进行修饰增强，但是要注意！！ 原先的方法的类并没有什么不同，并没有事务，spring动态代理这个类生成的代理类才有事务，才有增强，也就是说，在同一个类里面通过this.xx()调用本类的事务方法时，事务是不会生效的，因为你调用的不是代理类。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Transactional</span> </span><br><span class="line"><span class="meta">@Override</span> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span> &#123; <span class="built_in">this</span>.method2(); &#125;</span><br><span class="line"></span><br><span class="line"> <span class="meta">@Transactional(propagation = Propagation.REQUIRES_NEW)</span> </span><br><span class="line"><span class="meta">@Override</span> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span> &#123; </span><br><span class="line">xx </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>解决方案：</p>
<p>关键在于获取类的代理对象，而不是通过this去调用，所以以下方法都是基于这个关键点去解决的。</p>
<p>1、最简单的，两个事务方法放在不同的service里面，这个比较简单，就不给例子了。（推荐）</p>
<p>2、AOP上下文。spring提供了AOP上下文AopContext，因此通过AopContext，可以很方便的获取到代理对象。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Myservice</span>&#123; </span><br><span class="line"></span><br><span class="line">	<span class="meta">@Transactional</span> </span><br><span class="line">	<span class="meta">@Override</span> </span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span> &#123; </span><br><span class="line">		((Myservice)AopContext.currentProxy()).method2(); </span><br><span class="line">	&#125; </span><br><span class="line"></span><br><span class="line">	<span class="meta">@Transactional(propagation = Propagation.REQUIRES_NEW)</span> </span><br><span class="line">	<span class="meta">@Override</span> </span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span> &#123; </span><br><span class="line">		xx </span><br><span class="line">	&#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>一运行，报错了，因为exposeProxy默认为false，我们要暴露代理类，就要设置为true，可以在springboot启动类上加一个注解</p>
<p>@EnableAspectJAutoProxy(exposeProxy &#x3D; true)<br>3、ApplicationContext。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Myservice</span>&#123; </span><br><span class="line">	<span class="meta">@Autowired</span> </span><br><span class="line">	ApplicationContext context; </span><br><span class="line"></span><br><span class="line">	Myservice service; </span><br><span class="line"></span><br><span class="line">	<span class="meta">@PostConstruct</span> <span class="comment">//初始化时调用，不加也行 </span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">void</span> 	<span class="title function_">getMyservice</span><span class="params">()</span> &#123; </span><br><span class="line">		service = context.getBean(Myservice.class); </span><br><span class="line">	&#125; </span><br><span class="line"></span><br><span class="line">	<span class="meta">@Transactional</span> </span><br><span class="line">	<span class="meta">@Override</span> </span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span> &#123; </span><br><span class="line">		service.method2(); </span><br><span class="line">	&#125; </span><br><span class="line"></span><br><span class="line">	<span class="meta">@Transactional(propagation = Propagation.REQUIRES_NEW)</span> </span><br><span class="line">	<span class="meta">@Override</span> </span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span> &#123; </span><br><span class="line">		xx </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第二和第三种的区别就在于，2是直接获取代理类，3是通过调用getBean间接获取代理类，总的来说，第一种是最方便的，也是最推荐的做法。</p>
<p>3、传播机制类型<br>下面的类型都是针对于被调用方法来说的，理解起来要想象成两个 service 方法的调用才可以。</p>
<p><strong>PROPAGATION_REQUIRED:</strong> (默认) 支持当前事务，如果当前没有事务，则新建事务如果当前存在事务，则加入当前事务，合并成一个事务<br><strong>REQUIRES_NEW:</strong> （一般用在子方法需要单独事务） 新建事务，如果当前存在事务，则把当前事务挂起这个方法会独立提交事务，不受调用者的事务影响，父级异常，它也是正常提交<br>（上面两个类型是常用的，下面的比较少用）</p>
<p><strong>NESTED:</strong>  如果当前存在事务，它将会成为父级事务的一个子事务，方法结束后并没有提交，只有等父事务结束才提交,如果当前没有事务，则新建事务如果它异常，父级可以捕获它的异常而不进行回滚，正常提交,但如果父级异常，它必然回滚，这就是和  <strong>REQUIRES_NEW</strong>  的区别<br><strong>SUPPORTS:</strong>  如果当前存在事务，则加入事务如果当前不存在事务，则以非事务方式运行，这个和不写没区别<br><strong>NOT_SUPPORTED:</strong> 以非事务方式运行如果当前存在事务，则把当前事务挂起<br><strong>MANDATORY:</strong> 如果当前存在事务，则运行在当前事务中如果当前无事务，则抛出异常，也即父级方法必须有事务<br><strong>NEVER:</strong> 以非事务方式运行，如果当前存在事务，则抛出异常，即父级方法必须无事务</p>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper自己实现分布式锁</title>
    <url>/2022/08/22/zookeeper%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-zookeeper-zi-ji-shi-xian-fen-bu-shi-suo/</url>
    <content><![CDATA[<pre><code>在一些并发请求的时候，需要保证数据的准确性，在同一时刻只能允许一个请求对同一条数据进行修改操作。在之前的单机应用当中，很容易想到利用jdk的锁来实现，例如 synchronized或者lock 。但是在如今业务复杂的分布式系统中jdk的锁并不适用，所以必须要要用分布式锁。
</code></pre>
<p>常见的几种分布式锁的实现方案，Redis、Mysql 、zookeeper；</p>
<p>本文主要讲的是如何使用zk实现分布式锁：</p>
<pre><code>     ZooKeeper是一个开源的分布式协调服务，他为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名空间服务，配置服务和分布式锁等分布式基础服务。 

    ZooKeeper的数据模型是内存中的一个ZNode数，由斜杠(/)进行分割的路径，就是一个ZNode，每个ZNode上除了保存自己的数据内容，还保存一系列属性信息。

    ZooKeeper中的数据节点分为两种：持久节点和临时节点。所谓的持久节点是指一旦这个ZNode创建成功，除非主动进行ZNode的移除操作，节点会一直保存在ZooKeeper上；而临时节点的生命周期是跟客户端的（Session）会话相关联的，一旦客户端会话失效，这个会话上的所有临时节点都会被自动移除。
</code></pre>
<p><strong>具体思路：</strong></p>
<p>1、首先zookeeper中我们可以创建一个&#x2F;distributed_lock持久化节点<br>2、然后再在&#x2F;distributed_lock节点下创建自己的临时顺序节点，比如：&#x2F;distributed_lock&#x2F;task_00000000008<br>3、获取所有的&#x2F;distributed_lock下的所有子节点，并排序<br>4、判读自己创建的节点是否最小值（第一位）<br>5、如果是，则获取得到锁，执行自己的业务逻辑，最后删除这个临时节点。<br>6、如果不是最小值，则需要监听自己创建节点前一位节点的数据变化，并阻塞。<br>7、当前一位节点被删除时，我们需要通过递归来判断自己创建的节点是否在是最小的，如果是则执行5）；如果不是则执行6）（就是递归循环的判断）</p>
<h3 id="一、导入依赖"><a href="#一、导入依赖" class="headerlink" title="一、导入依赖"></a>一、导入依赖</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.0.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zk_lock<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>zk_lock<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>zk_lock<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cn.hutool<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hutool-all<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.7.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>8.0.22<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-validation<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.101tec<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zkclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>主要包括了zk客户端的依赖，mybatis-plus的依赖。</p>
<h3 id="二、数据的配置"><a href="#二、数据的配置" class="headerlink" title="二、数据的配置"></a>二、数据的配置</h3><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#数据库</span></span><br><span class="line"><span class="attr">spring.datasource.driver-class-name</span>=<span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="attr">spring.datasource.url</span>=<span class="string">jdbc:mysql://localhost:3306/db3?characterEncoding=utf8&amp;verifyServerCertificate=false&amp;useSSL=true&amp;serverTimezone=Asia/Shanghai</span></span><br><span class="line"><span class="attr">spring.datasource.username</span>=<span class="string">root</span></span><br><span class="line"><span class="attr">spring.datasource.password</span>=<span class="string">root</span></span><br></pre></td></tr></table></figure>

<h3 id="三、具体代码实现"><a href="#三、具体代码实现" class="headerlink" title="三、具体代码实现"></a>三、具体代码实现</h3><p>分布式锁工具类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.zk_lock.util;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.I0Itec.zkclient.IZkDataListener;</span><br><span class="line"><span class="keyword">import</span> org.I0Itec.zkclient.ZkClient;</span><br><span class="line"><span class="keyword">import</span> org.I0Itec.zkclient.ZkConnection;</span><br><span class="line"><span class="keyword">import</span> org.I0Itec.zkclient.exception.ZkNodeExistsException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Comparator;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wls</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributedLockUtil</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 常量</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">CONNECTION_STRING</span> <span class="operator">=</span> <span class="string">&quot;localhost:2181&quot;</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 父节点</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">LOCK_NODE</span> <span class="operator">=</span> <span class="string">&quot;/distributed_lock&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">CHILDREN_NODE</span> <span class="operator">=</span> <span class="string">&quot;/lock_&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> DistributedLockUtil distributedLockUtil;</span><br><span class="line">    <span class="keyword">public</span>  <span class="keyword">static</span> ZkClient zkClient;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建zkClient</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">DistributedLockUtil</span><span class="params">()</span> &#123;</span><br><span class="line">        distributedLockUtil = <span class="built_in">this</span>;</span><br><span class="line">        <span class="comment">// 连接到Zookeeper</span></span><br><span class="line">        zkClient = <span class="keyword">new</span> <span class="title class_">ZkClient</span>(<span class="keyword">new</span> <span class="title class_">ZkConnection</span>(CONNECTION_STRING));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建节点</span></span><br><span class="line">        <span class="keyword">if</span> (!zkClient.exists(LOCK_NODE)) &#123;</span><br><span class="line">            zkClient.create(LOCK_NODE, <span class="string">&quot;分布式锁节点&quot;</span>, CreateMode.PERSISTENT);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取锁</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 锁名字</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">getLock</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 1.在Zookeeper指定节点下创建临时顺序节点</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">lockName</span> <span class="operator">=</span> zkClient.createEphemeralSequential(LOCK_NODE + CHILDREN_NODE, <span class="string">&quot;&quot;</span>);</span><br><span class="line">            <span class="comment">// 尝试获取锁</span></span><br><span class="line">            acquireLock(lockName);</span><br><span class="line">            <span class="keyword">return</span> lockName;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 尝试获取锁</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException 异常</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">acquireLock</span><span class="params">(String lockName)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 2.获取lock节点下的所有子节点</span></span><br><span class="line">        List&lt;String&gt; childrenList = zkClient.getChildren(LOCK_NODE);</span><br><span class="line">        <span class="comment">// 3.对子节点进行排序,获取最小值</span></span><br><span class="line">        childrenList.sort(<span class="keyword">new</span> <span class="title class_">Comparator</span>&lt;String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(String o1, String o2)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> Integer.parseInt(o1.split(<span class="string">&quot;_&quot;</span>)[<span class="number">1</span>]) - Integer.parseInt(o2.split(<span class="string">&quot;_&quot;</span>)[<span class="number">1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 4.判断当前创建的节点是否在第一位</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">lockPosition</span> <span class="operator">=</span> childrenList.indexOf(lockName.split(<span class="string">&quot;/&quot;</span>)[lockName.split(<span class="string">&quot;/&quot;</span>).length - <span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">if</span> (lockPosition &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 不存在该节点</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ZkNodeExistsException</span>(<span class="string">&quot;不存在的节点：&quot;</span> + lockName);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (lockPosition == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 获取到锁</span></span><br><span class="line">            log.info(<span class="string">&quot;获取到锁：&quot;</span> + lockName);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 未获取到锁，阻塞</span></span><br><span class="line">        log.info(<span class="string">&quot;...... 未获取到锁，阻塞等待 。。。。。。&quot;</span>);</span><br><span class="line">        <span class="comment">// 5.如果未获取得到锁,监听当前创建的节点前一位的节点</span></span><br><span class="line">        <span class="keyword">final</span> <span class="type">CountDownLatch</span> <span class="variable">latch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="type">IZkDataListener</span> <span class="variable">listener</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IZkDataListener</span>() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * 当被删除时的监听事件</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> dataPath 节点</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@throws</span> Exception 异常</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleDataDeleted</span><span class="params">(String dataPath)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="comment">// 6.前一个节点被删除,当不保证轮到自己</span></span><br><span class="line">                log.info(<span class="string">&quot;。。。。。。前一个节点被删除  。。。。。。&quot;</span>);</span><br><span class="line">                acquireLock(lockName);</span><br><span class="line">                latch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleDataChange</span><span class="params">(String dataPath, Object data)</span> &#123;</span><br><span class="line">                <span class="comment">//节点被改变</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//监听前一个节点</span></span><br><span class="line">            zkClient.subscribeDataChanges(LOCK_NODE + <span class="string">&quot;/&quot;</span> + childrenList.get(lockPosition - <span class="number">1</span>), listener);</span><br><span class="line">            <span class="comment">//阻塞</span></span><br><span class="line">            latch.await();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            log.info(<span class="string">&quot;。。。。。取消订阅。。。。。。&quot;</span>);</span><br><span class="line">            <span class="comment">//取消监听</span></span><br><span class="line">            zkClient.unsubscribeDataChanges(LOCK_NODE + <span class="string">&quot;/&quot;</span> + childrenList.get(lockPosition - <span class="number">1</span>), listener);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 释放锁（删除节点）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> lockName 锁名字</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">releaseLock</span><span class="params">(String lockName)</span> &#123;</span><br><span class="line">        zkClient.delete(lockName);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">closeZkClient</span><span class="params">()</span> &#123;</span><br><span class="line">        zkClient.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>具体业务实现</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 库存递减</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id  id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> num 数量</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">killGoods</span><span class="params">(Long id, Integer num)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">lock</span> <span class="operator">=</span> DistributedLockUtil.getLock();</span><br><span class="line">        <span class="keyword">if</span> (Objects.nonNull(lock)) &#123;</span><br><span class="line">            <span class="type">Goods</span> <span class="variable">goods</span> <span class="operator">=</span> <span class="built_in">this</span>.getById(id);</span><br><span class="line">            <span class="keyword">if</span> (goods.getQuantity() &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">//库存数量不足,释放锁</span></span><br><span class="line">                DistributedLockUtil.releaseLock(lock);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            log.info(<span class="string">&quot;库存数量======&quot;</span> + goods.getQuantity());</span><br><span class="line">            <span class="comment">//将库存减操作</span></span><br><span class="line">            goods.setQuantity(goods.getQuantity() - <span class="number">1</span>);</span><br><span class="line">            <span class="built_in">this</span>.updateById(goods);</span><br><span class="line">            DistributedLockUtil.releaseLock(lock);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">**</span><br><span class="line"> * <span class="meta">@author</span> wenlinshan</span><br><span class="line"> * <span class="meta">@version</span> <span class="number">1.0</span></span><br><span class="line"> * <span class="meta">@date</span> <span class="number">2021</span>/<span class="number">6</span>/<span class="number">16</span> <span class="number">11</span>:<span class="number">06</span></span><br><span class="line"> * <span class="meta">@desc</span></span><br><span class="line"> */</span><br><span class="line"><span class="meta">@RequestMapping</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GoodsController</span> &#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> GoodsService goodsService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;test&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">createOrderTest</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!goodsService.killGoods(<span class="number">1405065181720055809L</span>, <span class="number">1</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;库存不足&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;创建订单成功&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;close&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">closeZk</span><span class="params">()</span>&#123;</span><br><span class="line">        DistributedLockUtil.closeZkClient();</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;关闭成功&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>至此一个简单的分布式锁的demo已经实现。<br>除此之外可以使用现成的框架curator来使用分布式锁。</p>
]]></content>
      <categories>
        <category>分布式锁</category>
      </categories>
  </entry>
  <entry>
    <title>分享一篇文章-神奇的 SQL 之别样的写法</title>
    <url>/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/</url>
    <content><![CDATA[<h1 id="神奇的-SQL-之别样的写法-→-行行比较"><a href="#神奇的-SQL-之别样的写法-→-行行比较" class="headerlink" title="神奇的 SQL 之别样的写法 → 行行比较"></a>神奇的 SQL 之别样的写法 → 行行比较</h1><p>​																							本文链接：cnblogs.com&#x2F;youzhibing&#x2F;p&#x2F;15101096.html</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>　　数据库版本： MySQL 5.7.20-log </p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/747662-20210812093924974-1727100840-5f29462b905c4e689c2edaa5e5fd8656.png" alt="747662202108120939249741727100840.png"><br>　　建表 SQL</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/747662-20210812101129712-1532849175-bbdd23d16de14dbcad4767d644ec77dd.png"><img src="https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DROP TABLE IF EXISTS `t_ware_sale_statistics`;</span><br><span class="line">CREATE TABLE `t_ware_sale_statistics` (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;,</span><br><span class="line">  `business_id` bigint(20) NOT NULL COMMENT &#x27;业务机构编码&#x27;,</span><br><span class="line">  `ware_inside_code` bigint(20) NOT NULL COMMENT &#x27;商品自编码&#x27;,</span><br><span class="line">  `weight_sale_cnt_day` double(16,4) DEFAULT NULL COMMENT &#x27;平均日销量&#x27;,</span><br><span class="line">  `last_thirty_days_sales` double(16,4) DEFAULT NULL COMMENT &#x27;最近30天销量&#x27;,</span><br><span class="line">  `last_sixty_days_sales` double(16,4) DEFAULT NULL COMMENT &#x27;最近60天销量&#x27;,</span><br><span class="line">  `last_ninety_days_sales` double(16,4) DEFAULT NULL COMMENT &#x27;最近90天销量&#x27;,</span><br><span class="line">  `same_period_sale_qty_thirty` double(16,4) DEFAULT NULL COMMENT &#x27;去年同期30天销量&#x27;,</span><br><span class="line">  `same_period_sale_qty_sixty` double(16,4) DEFAULT NULL COMMENT &#x27;去年同期60天销量&#x27;,</span><br><span class="line">  `same_period_sale_qty_ninety` double(16,4) DEFAULT NULL COMMENT &#x27;去年同期90天销量&#x27;,</span><br><span class="line">  `create_user` bigint(20) DEFAULT NULL COMMENT &#x27;创建人&#x27;,</span><br><span class="line">  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;,</span><br><span class="line">  `modify_user` bigint(20) DEFAULT NULL COMMENT &#x27;最终修改人&#x27;,</span><br><span class="line">  `modify_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;最终修改时间&#x27;,</span><br><span class="line">  `is_delete` tinyint(2) DEFAULT &#x27;2&#x27; COMMENT &#x27;是否删除，1：是，2：否&#x27;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  KEY `idx_business_ware` (`business_id`,`ware_inside_code`) USING BTREE</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC COMMENT=&#x27;商品销售统计&#x27;;</span><br></pre></td></tr></table></figure>

<p>　　初始化数据</p>
<p>　　　　准备了 769063 条数据</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/747662-20210812101326865-671080270-b45b9d3614094235ac973bbccbb533ff.png" alt="74766220210812101326865671080270.png"></p>
<h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><p>　　业务机构下销售商品，同个业务机构可以销售不同的商品，同个商品可以在不同的业务机构销售，也就说：业务机构与商品是多对多的关系</p>
<p>　　假设现在有 n 个机构，每个机构下有几个商品，如何查询出这几个门店下各自商品的销售情况？</p>
<p>　　具体点，类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-54d46ffcf96a41b1b031a9bbb6cb048f.png" alt="image.png"></p>
<p>　　如何查出 100001 下商品 1000、1001、1003 、 100002 下商品 1003、1004 、 100003 下商品 1006、1008、1009 的销售情况</p>
<p>　　相当于是双层列表（业务机构列表中套商品列表）的查询；业务机构列表和商品列表都不是固定的，而是动态的</p>
<p>　　那么问题就是：如何查询多个业务机构下，某些商品的销售情况</p>
<p>　　（问题经我一描述，可能更模糊了，大家明白意思了就好！）</p>
<h2 id="循环查询"><a href="#循环查询" class="headerlink" title="循环查询"></a>循环查询</h2><p>　　这个很容易想到，在代码层面循环业务机构列表，每个业务机构查一次数据库，伪代码如下：</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-a3ac667739d5455c919bcecd75f15bff.png" alt="image.png"></p>
<p>　　具体的 SQL 类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-074d4491afe3486dac874d8d490430b2.png" alt="image.png"></p>
<p>　　SQL 能走索引</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-e5cf8ad05afa4ed5acd18d6e02350666.png" alt="image.png"></p>
<p>　　实现简单，也好理解，SQL 也能走索引，一切看起来似乎很完美</p>
<p>　　然而现实是：部门开发规范约束，不能循环查数据库</p>
<p>　　哦豁，这种方式只能放弃，另寻其他方式了</p>
<h2 id="OR-拼接"><a href="#OR-拼接" class="headerlink" title="OR 拼接"></a>OR 拼接</h2><p>　　通过 MyBatis 的 动态 SQL 功能，进行 SQL 拼接，类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-d29c4ea236a44e6090958ca5b928b5fe.png" alt="image.png"></p>
<p>　　具体的 SQL 类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-0e12a2c6179a4d86b207cae587539247.png" alt="image.png"></p>
<p>　　SQL 也能走索引</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-8d7ba0be6aba4adaa40b03c8d0c9de94.png" alt="image.png"></p>
<p>　　实现简单，也好理解，SQL 也能走索引，而且只查询一次数据库，貌似可行</p>
<p>　　唯一可惜的是：有点费 OR，如果业务机构比较多，那 SQL 会比较长</p>
<p>　　作为候选人之一吧，我们接着往下看</p>
<h2 id="混查过滤"><a href="#混查过滤" class="headerlink" title="混查过滤"></a>混查过滤</h2><p>　　同样是利用 Mybatis 的 动态 SQL ，将 business_id 列表拼在一起、 ware_inside_code 拼在一起，类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-bf46b637269849438a7714ea7b551442.png" alt="image.png"></p>
<p>　　具体的 SQL 类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-328446ff1a134354ae9468bfe122402a.png" alt="image.png"></p>
<p>　　SQL 也能走索引<br><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-bee2180d1e54452a9f83faa314693d72.png" alt="image.png"></p>
<p>　　实现简单，也好理解，SQL 也能走索引，而且只查询一次数据库，似乎可行</p>
<p>　　但是：查出来的结果集大于等于我们想要的结果集，你品，你细品！</p>
<p>　　所以还需要对查出来的结果集进行一次过滤，过滤出我们想要的结果集</p>
<p>　　姑且也作为候选人之一吧，我们继续往下看</p>
<h2 id="行行比较"><a href="#行行比较" class="headerlink" title="行行比较"></a>行行比较</h2><p>　　SQL-92 中加入了行与行比较的功能，这样一来，比较谓词 &#x3D; 、&lt; 、&gt; 和 IN 谓词的参数就不再只是标量值了，还可以是值列表了</p>
<p>　　当然，还是得用到 Mybatis 的 动态 SQL ，类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-3ed941854ff448a2afca75acfb7201cf.png" alt="image.png"></p>
<p>　　具体的 SQL 类似如下</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-e9794c1ebbf44fb3a3034de018e80e98.png" alt="image.png"></p>
<p>　　SQL 同样能走索引</p>
<p><img src="/2021/08/31/%E5%88%86%E4%BA%AB%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0-%E7%A5%9E%E5%A5%87%E7%9A%84%20SQL%20%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95-%E7%A5%9E%E5%A5%87%E7%9A%84sql%E4%B9%8B%E5%88%AB%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95md/image-793ecb0c293c4bfabef1401a36589a15.png" alt="image.png"></p>
<p>　　实现简单，SQL 也能走索引，而且只查询一次数据库，感觉可行</p>
<p>　　只是：有点不好理解，因为我们平时这么用的少，所以这种写法看起来很陌生</p>
<p>　　另外，行行比较是 SQL 规范，不是某个关系型数据库的规范，也就说关系型数据库都应该支持这种写法</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>　　1、最后选择了 行行比较 这种方式来实现了需求</p>
<p>　　　　别问我为什么，问就是逼格高！</p>
<p>　　2、某一个需求的实现往往有很多种方式，我们需要结合业务以及各种约束综合考虑，选择最合适的那个</p>
<p>　　3、行行比较是 SQL-92 中引入的，SQL-92 是 1992 年制定的规范</p>
<p>　　　　行行比较不是新特性，而是很早就存在的基础功能</p>
]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
  </entry>
  <entry>
    <title>设计模式——状态模式</title>
    <url>/2021/06/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<p>在一些复杂的业务当中，涉及到某个业务有多个状态，按照传统写法无非就是<code>if else </code>，其实还是有一种比较优雅的实现方式，就是设计模式中的状态机模式。没有spring之前虽然也能实现状态机模式，但是并不优雅。下面来说一个用springboot来实现状态机模式的案例。</p>
<pre><code>  举一个例子，比如订单：订单当中涉及到多个状态的跳转，有的时候还需要对修改状态前的逻辑进行判断，这个时候用状态机模式就是很好的实现。
</code></pre>
<h5 id="1、引入部分依赖"><a href="#1、引入部分依赖" class="headerlink" title="1、引入部分依赖"></a>1、引入部分依赖</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>order_demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.0.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.18.20<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="主要的包结构"><a href="#主要的包结构" class="headerlink" title="主要的包结构:"></a>主要的包结构:</h5><p><img src="/2021/06/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/Snipaste_2021-06-09_22-35-07-d55e4019a7c149b39de4eaa9e76a5e05.png" alt="Snipaste_20210609_223507.png"></p>
<h5 id="2、订单类："><a href="#2、订单类：" class="headerlink" title="2、订单类："></a>2、订单类：</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:33</span></span><br><span class="line"><span class="comment"> * 订单类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Order</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * id</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Long id;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 金额</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> BigDecimal price;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 状态</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Integer status;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建时间</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Date createTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="3、创建订单状态处理超类"><a href="#3、创建订单状态处理超类" class="headerlink" title="3、创建订单状态处理超类"></a>3、创建订单状态处理超类</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bll;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.example.pojo.Order;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:43</span></span><br><span class="line"><span class="comment"> * 订单状态处理超类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">OrderState</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 原来状态</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> newOrder 新订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> oldOrder 老订单</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">handle</span><span class="params">(Order newOrder,Order oldOrder)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4、各个状态处理类"><a href="#4、各个状态处理类" class="headerlink" title="4、各个状态处理类"></a>4、各个状态处理类</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bll;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.example.pojo.Order;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:46</span></span><br><span class="line"><span class="comment"> * 订单各状态处理</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderStateCommon</span> <span class="keyword">implements</span> <span class="title class_">OrderState</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handle</span><span class="params">(Order newOrder, Order oldOrder)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 生成日志</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> order 订单</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">buildOrderLog</span><span class="params">(Order order)</span> &#123;</span><br><span class="line">        <span class="comment">//保存日志</span></span><br><span class="line">        System.out.println(<span class="string">&quot;保存日志订单状态: &quot;</span> + order.getStatus());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.example.pojo.Order;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Objects;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:52</span></span><br><span class="line"><span class="comment"> * 订单状态: 1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component(OrderStateFactory.ORDER_STATUS + 1)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderStateFor1</span> <span class="keyword">extends</span> <span class="title class_">OrderStateCommon</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handle</span><span class="params">(Order newOrder, Order oldOrder)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (Objects.isNull(oldOrder))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;不做操作&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;订单状态:1 处理逻辑==&gt;&quot;</span>);</span><br><span class="line">        <span class="comment">//保存日志</span></span><br><span class="line">        <span class="built_in">super</span>.buildOrderLog(newOrder);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bll;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.example.pojo.Order;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:52</span></span><br><span class="line"><span class="comment"> * 订单状态: 2</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component(OrderStateFactory.ORDER_STATUS + 2)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderStateFor2</span> <span class="keyword">extends</span> <span class="title class_">OrderStateCommon</span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handle</span><span class="params">(Order newOrder, Order oldOrder)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;订单状态:2 处理逻辑==&gt;&quot;</span>);</span><br><span class="line">        <span class="comment">//保存日志</span></span><br><span class="line">        <span class="built_in">super</span>.buildOrderLog(newOrder);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bll;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.example.pojo.Order;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:52</span></span><br><span class="line"><span class="comment"> * 订单状态: 3</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component(OrderStateFactory.ORDER_STATUS + 3)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderStateFor3</span> <span class="keyword">extends</span> <span class="title class_">OrderStateCommon</span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handle</span><span class="params">(Order newOrder, Order oldOrder)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;订单状态:3 处理逻辑==&gt;&quot;</span>);</span><br><span class="line">        <span class="comment">//保存日志</span></span><br><span class="line">        <span class="built_in">super</span>.buildOrderLog(newOrder);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="5、工厂类"><a href="#5、工厂类" class="headerlink" title="5、工厂类"></a>5、工厂类</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.bll;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wenlinshan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:56</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderStateFactory</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义bean名字前缀</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">ORDER_STATUS</span> <span class="operator">=</span> <span class="string">&quot;orderStatus&quot;</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注入到容器里面</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    Map&lt;String, OrderState&gt; states = <span class="keyword">new</span> <span class="title class_">ConcurrentHashMap</span>&lt;&gt;(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取对应状态的执行类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> status 状态</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 具体状态的执行类</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> OrderState <span class="title function_">getState</span><span class="params">(Integer status)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (states.containsKey(ORDER_STATUS + status)) &#123;</span><br><span class="line">            <span class="keyword">return</span> states.get(ORDER_STATUS + status);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;未找到执行状态的类&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="6、主要的入口类代码"><a href="#6、主要的入口类代码" class="headerlink" title="6、主要的入口类代码"></a>6、主要的入口类代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.example.bll.OrderState;</span><br><span class="line"><span class="keyword">import</span> org.example.bll.OrderStateFactory;</span><br><span class="line"><span class="keyword">import</span> org.example.pojo.Order;</span><br><span class="line"><span class="keyword">import</span> org.example.service.IOrderService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Objects;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 21:37</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderServiceImpl</span> <span class="keyword">implements</span> <span class="title class_">IOrderService</span> &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> OrderStateFactory factory;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">saveOrUpdateOrder</span><span class="params">(Order order)</span> &#123;</span><br><span class="line">        <span class="comment">//查找出原来的订单</span></span><br><span class="line">        <span class="type">Order</span> <span class="variable">oldOrder</span> <span class="operator">=</span> <span class="built_in">this</span>.getById(order.getId());</span><br><span class="line">        <span class="keyword">if</span> (Objects.isNull(oldOrder)) &#123;</span><br><span class="line">            <span class="comment">//新增</span></span><br><span class="line">            <span class="built_in">this</span>.save(order);</span><br><span class="line">            <span class="keyword">if</span> (Objects.nonNull(order.getStatus())) &#123;</span><br><span class="line">                <span class="comment">//调用状态机</span></span><br><span class="line">                factory.getState(order.getStatus()).handle(order,<span class="literal">null</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//修改</span></span><br><span class="line">        <span class="type">OrderState</span> <span class="variable">orderState</span> <span class="operator">=</span> Objects.isNull(order.getStatus()) ? factory.getState(oldOrder.getStatus()) : factory.getState(order.getStatus());</span><br><span class="line">        orderState.handle(order,oldOrder);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>至此，所有的代码都已实现，下面开始演示‘</p>
<h5 id="7、测试类："><a href="#7、测试类：" class="headerlink" title="7、测试类："></a>7、测试类：</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.example.pojo.Order;</span><br><span class="line"><span class="keyword">import</span> org.example.service.IOrderService;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.math.BigDecimal;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021/6/9 22:03</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RunWith(SpringRunner.class)</span></span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderTest</span> &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IOrderService orderService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testOrder1</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Order</span> <span class="variable">order</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Order</span>(<span class="number">1L</span>, BigDecimal.ONE, <span class="number">2</span>, <span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">        orderService.saveOrUpdateOrder(order);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<p><img src="/2021/06/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/Snipaste_2021-06-09_22-44-33-75bd239201e04e57ae2fd7865222739e.png" alt="Snipaste_20210609_224433.png"></p>
]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解Redis</title>
    <url>/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/</url>
    <content><![CDATA[<h2 id="一、redis的基本概念"><a href="#一、redis的基本概念" class="headerlink" title="一、redis的基本概念"></a>一、redis的基本概念</h2><p>redis是一个内存数据库</p>
<h3 id="1、NOSQL"><a href="#1、NOSQL" class="headerlink" title="1、NOSQL"></a>1、NOSQL</h3><p>即 Not-Only SQL（ 泛指非关系型的数据库），作为关系型数据库的补充。</p>
<h3 id="2、主要作用"><a href="#2、主要作用" class="headerlink" title="2、主要作用"></a>2、主要作用</h3><p>（1）为热点数据加速查询（主要场景）。如热点商品、热点新闻、热点资讯、推广类等高访问量信息等。</p>
<p>（2）即时信息查询。如各位排行榜、各类网站访问统计、公交到站信息、在线人数信息（聊天室、网站）、设备信号等。</p>
<p>（3）时效性信息控制。如验证码控制、投票控制等。</p>
<p>（4）分布式数据共享。如分布式集群架构中的 session 分离消息队列。</p>
<h2 id="二、redis基本数据类型（value的数据类型）"><a href="#二、redis基本数据类型（value的数据类型）" class="headerlink" title="二、redis基本数据类型（value的数据类型）"></a>二、redis基本数据类型（value的数据类型）</h2><h3 id="1、String"><a href="#1、String" class="headerlink" title="1、String"></a>1、String</h3><p>以key-value的方式进行存储</p>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-5efbb45995f141b9a9c3762d8e0f9b2a.png" alt="image.png"></p>
<h3 id="2、hash"><a href="#2、hash" class="headerlink" title="2、hash"></a>2、hash</h3><p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-4c9f503efbe2476b9e2d56d7b7c105bc.png" alt="image.png"></p>
<h3 id="3、list"><a href="#3、list" class="headerlink" title="3、list"></a>3、list</h3><p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-f7bd516f28f540158964f23626beef7e.png" alt="image.png"></p>
<h3 id="4、set"><a href="#4、set" class="headerlink" title="4、set"></a>4、set</h3><p>set类型：与hash存储结构完全相同，仅存储键，不存储值（nil），并且值是不允许重复的</p>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-026d5d4a5ea64ee7bdc5ef3d3fdaed9b.png" alt="image.png"><br><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-122cdbd1b2304d2792c20b26d418f633.png" alt="image.png"></p>
<h3 id="5、zset"><a href="#5、zset" class="headerlink" title="5、zset"></a>5、zset</h3><h2 id="三、Jedis"><a href="#三、Jedis" class="headerlink" title="三、Jedis"></a>三、Jedis</h2><p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-ed7ac2231b2a4fad9073ee67a62d09fe.png" alt="image.png"></p>
<h3 id="1、基于连接池的连接"><a href="#1、基于连接池的连接" class="headerlink" title="1、基于连接池的连接"></a>1、基于连接池的连接</h3><p>JedisPool：Jedis提供的连接池技术 </p>
<p>poolConfig:连接池配置对象 </p>
<p>host:redis服务地址</p>
<p>port:redis服务端口号</p>
<p>创建jedis的配置文件：jedis.properties</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jedis.host=192.168.40.130  </span><br><span class="line">jedis.port=6379  </span><br><span class="line">jedis.maxTotal=50  </span><br><span class="line">jedis.maxIdle=10</span><br></pre></td></tr></table></figure>

<p> 创建JedisUtils，使用静态代码块初始化资源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class JedisUtils &#123;</span><br><span class="line">    private static int maxTotal;</span><br><span class="line">    private static int maxIdel;</span><br><span class="line">    private static String host;</span><br><span class="line">    private static int port;</span><br><span class="line">    private static JedisPoolConfig jpc;</span><br><span class="line">    private static JedisPool jp;</span><br><span class="line"></span><br><span class="line">    static &#123;</span><br><span class="line">        ResourceBundle bundle = ResourceBundle.getBundle(&quot;redis&quot;);</span><br><span class="line">        maxTotal = Integer.parseInt(bundle.getString(&quot;redis.maxTotal&quot;));</span><br><span class="line">        maxIdel = Integer.parseInt(bundle.getString(&quot;redis.maxIdel&quot;));</span><br><span class="line">        host = bundle.getString(&quot;redis.host&quot;);</span><br><span class="line">        port = Integer.parseInt(bundle.getString(&quot;redis.port&quot;));</span><br><span class="line">        //Jedis连接池配置</span><br><span class="line">        jpc = new JedisPoolConfig();</span><br><span class="line">        jpc.setMaxTotal(maxTotal);</span><br><span class="line">        jpc.setMaxIdle(maxIdel);</span><br><span class="line">        jp = new JedisPool(jpc,host,port);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 对外访问接口，提供jedis连接对象，连接从连接池获取，在JedisUtils中添加一个获取jedis的方法：getJedis</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static Jedis getJedis()&#123;</span><br><span class="line">	Jedis jedis = jedisPool.getResource();</span><br><span class="line">	return jedis;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="四、数据删除淘汰策略"><a href="#四、数据删除淘汰策略" class="headerlink" title="四、数据删除淘汰策略"></a>四、数据删除淘汰策略</h2><h3 id="1、定时删除"><a href="#1、定时删除" class="headerlink" title="1、定时删除"></a>1、定时删除</h3><p>创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作</p>
<ul>
<li><p><strong>优点</strong>：节约内存，到时就删除，快速释放掉不必要的内存占用</p>
</li>
<li><p><strong>缺点</strong>：CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量</p>
</li>
<li><p><strong>总结</strong>：用处理器性能换取存储空间（拿时间换空间）</p>
</li>
</ul>
<h3 id="2、惰性删除"><a href="#2、惰性删除" class="headerlink" title="2、惰性删除"></a>2、惰性删除</h3><p>数据到达过期时间，不做处理。等下次访问该数据时，我们需要判断</p>
<ol>
<li>如果未过期，返回数据</li>
<li>发现已过期，删除，返回不存在</li>
</ol>
<ul>
<li><p><strong>优点</strong>：节约CPU性能，发现必须删除的时候才删除</p>
</li>
<li><p><strong>缺点</strong>：内存压力很大，出现长期占用内存的数据</p>
</li>
<li><p><strong>总结</strong>：用存储空间换取处理器性能（拿空间换时间）</p>
</li>
</ul>
<h3 id="3、定期删除"><a href="#3、定期删除" class="headerlink" title="3、定期删除"></a>3、定期删除</h3><ul>
<li><p>Redis启动服务器初始化时，读取配置server.hz的值，默认为10</p>
</li>
<li><p>每秒钟执行server.hz次<strong>serverCron()</strong>——–&gt;<strong>databasesCron()</strong>———&gt;<strong>activeExpireCycle()</strong></p>
</li>
<li><p>**activeExpireCycle()*<em>对每个expires[</em>]逐一进行检测，每次执行耗时：250ms&#x2F;server.hz</p>
</li>
<li><p>对某个expires[*]检测时，随机挑选W个key检测</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">如果key超时，删除key</span><br><span class="line"></span><br><span class="line">如果一轮中删除的key的数量&gt;W*25%，循环该过程</span><br><span class="line"></span><br><span class="line">如果一轮中删除的key的数量≤W*25%，检查下一个expires[*]，0-15循环</span><br><span class="line"></span><br><span class="line">W取值=ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP属性值</span><br></pre></td></tr></table></figure>

<ul>
<li>参数current_db用于记录<strong>activeExpireCycle()</strong> 进入哪个expires[*] 执行</li>
<li>如果activeExpireCycle()执行时间到期，下次从current_db继续向下执行</li>
</ul>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-eaaeab2df1fa4b34a80b616ccf0e1250.png" alt="image.png"></p>
<p>总的来说：定期删除就是周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度</p>
<ul>
<li><p><strong>特点1</strong>：CPU性能占用设置有峰值，检测频度可自定义设置</p>
</li>
<li><p><strong>特点2</strong>：内存压力不是很大，长期占用内存的冷数据会被持续清理</p>
</li>
<li><p><strong>总结</strong>：周期性抽查存储空间（随机抽查，重点抽查）</p>
</li>
</ul>
<h3 id="4、数据淘汰策略（逐出算法）"><a href="#4、数据淘汰策略（逐出算法）" class="headerlink" title="4、数据淘汰策略（逐出算法）"></a>4、数据淘汰策略（逐出算法）</h3><p>当新数据进入redis时，如果内存不足怎么办？在执行每一个命令前，会调用<strong>freeMemoryIfNeeded()<strong>检测内存是否充足。如果内存不满足新 加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法。</strong>（3类8种）</strong></p>
<p><strong>第一类</strong>：检测易失数据（可能会过期的数据集server.db[i].expires ）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">volatile-lru：挑选最近最少使用的数据淘汰</span><br><span class="line">volatile-lfu：挑选最近使用次数最少的数据淘汰</span><br><span class="line">volatile-ttl：挑选将要过期的数据淘汰</span><br><span class="line">volatile-random：任意选择数据淘汰</span><br></pre></td></tr></table></figure>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-9d92b3d0047f4e65b66bdfce123d13bd.png" alt="image.png"></p>
<p><strong>第二类</strong>：检测全库数据（所有数据集server.db[i].dict ）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">allkeys-lru：挑选最近最少使用的数据淘汰</span><br><span class="line">allkeLyRs-lfu：：挑选最近使用次数最少的数据淘汰</span><br><span class="line">allkeys-random：任意选择数据淘汰，相当于随机</span><br></pre></td></tr></table></figure>

<p><strong>第三类</strong>：放弃数据驱逐</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">no-enviction（驱逐）：禁止驱逐数据(redis4.0中默认策略)，会引发OOM(Out Of Memory)</span><br></pre></td></tr></table></figure>

<h2 id="五、redis集群"><a href="#五、redis集群" class="headerlink" title="五、redis集群"></a>五、redis集群</h2><h3 id="1、主从复制"><a href="#1、主从复制" class="headerlink" title="1、主从复制"></a>1、主从复制</h3><p>单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑<strong>读高并发</strong>的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的<strong>读请求全部走从节点</strong>。这样也可以很轻松实现水平扩容，<strong>支撑读高并发</strong>。</p>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-d313f43c4d2f431196ddec6f20e08972.png" alt="image.png"></p>
<h4 id="1）主从复制的作用"><a href="#1）主从复制的作用" class="headerlink" title="1）主从复制的作用"></a>1）主从复制的作用</h4><ul>
<li><p>读写分离：master写、slave读，提高服务器的读写负载能力</p>
</li>
<li><p>负载均衡：基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数 量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量</p>
</li>
<li><p>故障恢复：当master出现问题时，由slave提供服务，实现快速的故障恢复</p>
</li>
<li><p>数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式</p>
</li>
<li><p>高可用基石：基于主从复制，构建哨兵模式与集群，实现Redis的高可用方案</p>
</li>
</ul>
<h4 id="2）主从复制工作流程"><a href="#2）主从复制工作流程" class="headerlink" title="2）主从复制工作流程"></a>2）主从复制工作流程</h4><p>主从复制过程大体可以分为3个阶段</p>
<ul>
<li><p>建立连接阶段（即准备阶段）</p>
</li>
<li><p>数据同步阶段</p>
</li>
<li><p>命令传播阶段（反复同步）<br><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-0b915a6d7314481b9e5f03c7eb6cf48d.png" alt="image.png"></p>
</li>
</ul>
<h5 id="阶段一：建立连接"><a href="#阶段一：建立连接" class="headerlink" title="阶段一：建立连接"></a>阶段一：建立连接</h5><p>建立slave到master的连接，使master能够识别slave，并保存slave端口号</p>
<p>流程如下：</p>
<ol>
<li><p>步骤1：设置master的地址和端口，保存master信息</p>
</li>
<li><p>步骤2：建立socket连接</p>
</li>
<li><p>步骤3：发送ping命令（定时器任务）</p>
</li>
<li><p>步骤4：身份验证</p>
</li>
<li><p>步骤5：发送slave端口信息</p>
</li>
</ol>
<p>至此，主从连接成功！</p>
<p>当前状态：</p>
<p>slave：保存master的地址与端口</p>
<p>master：保存slave的端口</p>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-5218299629984afeb49550cb754c4dcc.png" alt="image.png"></p>
<h5 id="阶段二：数据同步"><a href="#阶段二：数据同步" class="headerlink" title="阶段二：数据同步"></a>阶段二：数据同步</h5><ul>
<li>在slave初次连接master后，复制master中的所有数据到slave</li>
<li>将slave的数据库状态更新成master当前的数据库状态</li>
</ul>
<p>同步过程如下：</p>
<ol>
<li><p>步骤1：请求同步数据</p>
</li>
<li><p>步骤2：创建RDB同步数据</p>
</li>
<li><p>步骤3：恢复RDB同步数据</p>
</li>
<li><p>步骤4：请求部分同步数据</p>
</li>
<li><p>步骤5：恢复部分同步数据</p>
</li>
</ol>
<p>至此，数据同步工作完成！</p>
<p>当前状态：</p>
<p>slave：具有master端全部数据，包含RDB过程接收的数据</p>
<p>master：保存slave当前数据同步的位置</p>
<p>总体：之间完成了数据克隆</p>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-bcd8b524679c43d2b683535ef58192f4.png" alt="image.png"></p>
<p><strong>数据同步阶段master说明</strong></p>
<p>1：如果master数据量巨大，数据同步阶段应避开流量高峰期，避免造成master阻塞，影响业务正常执行</p>
<p>2：复制缓冲区大小设定不合理，会导致数据溢出。如进行全量复制周期太长，进行部分复制时发现数据已经存在丢失的情况，必须进行第二次全量复制，致使slave陷入死循环状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">repl-backlog-size ?mb</span><br></pre></td></tr></table></figure>

<ol>
<li>master单机内存占用主机内存的比例不应过大，建议使用50%-70%的内存，留下30%-50%的内存用于执 行bgsave命令和创建复制缓冲区</li>
</ol>
<p><img src="/2021/08/18/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-shen-ru-li-jie-redis/image-f80b80cac8d84ea5a6f1f9c7b5faf1a0.png" alt="image.png"><img src="https://cdn.nlark.com/yuque/0/2020/png/2396018/1599985757856-9f821705-f68d-4bf4-a7bb-b4db0ce971ab.png" alt="img"></p>
<p><strong>数据同步阶段slave说明</strong></p>
<ol>
<li>为避免slave进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务</li>
</ol>
<p>  slave-serve-stale-data yes|no</p>
<ol>
<li><p>数据同步阶段，master发送给slave信息可以理解master是slave的一个客户端，主动向slave发送命令</p>
</li>
<li><p>多个slave同时对master请求数据同步，master发送的RDB文件增多，会对带宽造成巨大冲击，如果master带宽不足，因此数据同步需要根据业务需求，适量错峰</p>
</li>
<li><p>slave过多时，建议调整拓扑结构，由一主多从结构变为树状结构，中间的节点既是master，也是 slave。注意使用树状结构时，由于层级深度，导致深度越高的slave与最顶层master间数据同步延迟 较大，数据一致性变差，应谨慎选择</p>
</li>
</ol>
<h5 id="2-2-1-3-阶段三：命令传播"><a href="#2-2-1-3-阶段三：命令传播" class="headerlink" title="2.2.1.3 阶段三：命令传播"></a>2.2.1.3 阶段三：命令传播</h5><ul>
<li>当master数据库状态被修改后，导致主从服务器数据库状态不一致，此时需要让主从数据同步到一致的状态，同步的动作称为命令传播</li>
<li>master将接收到的数据变更命令发送给slave，slave接收命令后执行命令</li>
</ul>
<p><strong>命令传播阶段的部分复制</strong></p>
<p>命令传播阶段出现了断网现象：</p>
<p>网络闪断闪连：忽略</p>
<p>短时间网络中断：部分复制</p>
<p>长时间网络中断：全量复制</p>
<p>这里我们主要来看部分复制，部分复制的三个核心要素</p>
<ol>
<li><p>服务器的运行 id（run id）</p>
</li>
<li><p>主服务器的复制积压缓冲区</p>
</li>
<li><p>主从服务器的复制偏移量</p>
</li>
</ol>
<p><strong>服务器运行ID（runid）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">概念：服务器运行ID是每一台服务器每次运行的身份识别码，一台服务器多次运行可以生成多个运行id组成：运行id由40位字符组成，是一个随机的十六进制字符例如：fdc9ff13b9bbaab28db42b3d50f852bb5e3fcdce作用：运行id被用于在服务器间进行传输，识别身份如果想两次操作均对同一台服务器进行，必须每次操作携带对应的运行id，用于对方识别实现方式：运行id在每台服务器启动时自动生成的，master在首次连接slave时，会将自己的运行ID发送给slave，slave保存此ID，通过info Server命令，可以查看节点的runid</span><br></pre></td></tr></table></figure>

<p><strong>复制缓冲区</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">概念：复制缓冲区，又名复制积压缓冲区，是一个先进先出（FIFO）的队列，用于存储服务器执行过的命令，每次传播命令，master都会将传播的命令记录下来，并存储在复制缓冲区	复制缓冲区默认数据存储空间大小是1M	当入队元素的数量大于队列长度时，最先入队的元素会被弹出，而新元素会被放入队列作用：用于保存master收到的所有指令（仅影响数据变更的指令，例如set，select）数据来源：当master接收到主客户端的指令时，除了将指令执行，会将该指令存储到缓冲区中</span><br><span class="line">​```![]()![]()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>默认分类</category>
      </categories>
      <tags>
        <tag>cloud</tag>
      </tags>
  </entry>
</search>
